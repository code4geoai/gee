{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd4d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import geoai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f1f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_imagery = './pabbi_satellite_image_COG.tif'\n",
    "vector_file = './pabb_crop_V3.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3744485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parcels 7012\n",
      "Number of Parcels with values (other than null): 6515\n",
      "Details of Crop are : Landuse_Ma\n",
      "Agriculture     5759\n",
      "Stream           302\n",
      "Other            229\n",
      "Road/Streets     172\n",
      "Graveyard         29\n",
      "Built up          24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gdf = gpd.read_file(vector_file)\n",
    "\n",
    "print(f\"Total Number of Parcels {len(gdf)}\")\n",
    "\n",
    "print(f\"Number of Parcels with values (other than null): {gdf['Landuse_Ma'].notna().sum()}\")\n",
    "\n",
    "print(f\"Details of Crop are : {gdf['Landuse_Ma'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c6c46",
   "metadata": {},
   "source": [
    "# Setting Class Ids for Land use Before generating Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d007496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    'Agriculture': 1,\n",
    "    'Stream': 2,\n",
    "    'Other': 3,\n",
    "    'Road/Streets': 4,\n",
    "    'Graveyard': 5,\n",
    "    'Built up': 6\n",
    "}\n",
    "\n",
    "gdf['class_id'] = gdf['Landuse_Ma'].map(label_map)\n",
    "\n",
    "gdf = gdf[gdf['class_id'].notna()]\n",
    "gdf['class_id'] = gdf['class_id'].astype('uint8')\n",
    "gdf=gdf.to_crs('EPSG:4326')\n",
    "print(gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c5a4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 2 4 5 3]\n",
      "0\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(gdf['class_id'].unique())\n",
    "print(gdf['class_id'].isnull().sum())\n",
    "print(gdf['class_id'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c3d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to temporary file\n",
    "gdf.to_file('temp_cleaned_vector.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e0a59",
   "metadata": {},
   "source": [
    "This code didnot work so i have to use the above code for manual vector to raster conversion.\n",
    "geoai.vector_to_raster(\n",
    "    vector_path=vector_file,\n",
    "    reference_raster=satellite_imagery,\n",
    "    attribute_field='class_id',\n",
    "    output_path='Labelraster_For_Unet_v4.tif',\n",
    "    dtype='uint8',\n",
    "    plot_result=True,\n",
    "    nodata=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b0114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_8e1e077fd6844b9740816a019aa03785 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;html, body {\n",
       "                width: 100%;\n",
       "                height: 100%;\n",
       "                margin: 0;\n",
       "                padding: 0;\n",
       "            }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;#map {\n",
       "                position:absolute;\n",
       "                top:0;\n",
       "                bottom:0;\n",
       "                right:0;\n",
       "                left:0;\n",
       "                }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;script&gt;\n",
       "                L_NO_TOUCH = false;\n",
       "                L_DISABLE_3D = false;\n",
       "            &lt;/script&gt;\n",
       "\n",
       "        \n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet.fullscreen@3.0.0/Control.FullScreen.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet.fullscreen@3.0.0/Control.FullScreen.css&quot;/&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.draw/1.0.2/leaflet.draw.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.draw/1.0.2/leaflet.draw.css&quot;/&gt;\n",
       "    &lt;script src=&quot;https://unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_8e1e077fd6844b9740816a019aa03785&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "    \n",
       "            \n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_8e1e077fd6844b9740816a019aa03785 = L.map(\n",
       "                &quot;map_8e1e077fd6844b9740816a019aa03785&quot;,\n",
       "                {\n",
       "                    center: [20.0, 0.0],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 2,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "  &quot;drawExport&quot;: false,\n",
       "  &quot;layersControl&quot;: true,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "            L.control.scale().addTo(map_8e1e077fd6844b9740816a019aa03785);\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_5f3ec94110bee92ea211ec01c679003e = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 24,\n",
       "  &quot;maxNativeZoom&quot;: 24,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_5f3ec94110bee92ea211ec01c679003e.addTo(map_8e1e077fd6844b9740816a019aa03785);\n",
       "        \n",
       "    \n",
       "            L.control.fullscreen(\n",
       "                {\n",
       "  &quot;position&quot;: &quot;topleft&quot;,\n",
       "  &quot;title&quot;: &quot;Full Screen&quot;,\n",
       "  &quot;titleCancel&quot;: &quot;Exit Full Screen&quot;,\n",
       "  &quot;forceSeparateButton&quot;: false,\n",
       "}\n",
       "            ).addTo(map_8e1e077fd6844b9740816a019aa03785);\n",
       "        \n",
       "    \n",
       "            var options = {\n",
       "              position: &quot;topleft&quot;,\n",
       "              draw: {},\n",
       "              edit: {},\n",
       "            }\n",
       "                // FeatureGroup is to store editable layers.\n",
       "                var drawnItems_draw_control_fab9f88f64b288f947a0d8f9f982c315 =\n",
       "                    new L.featureGroup().addTo(\n",
       "                        map_8e1e077fd6844b9740816a019aa03785\n",
       "                    );\n",
       "\n",
       "            options.edit.featureGroup = drawnItems_draw_control_fab9f88f64b288f947a0d8f9f982c315;\n",
       "            var draw_control_fab9f88f64b288f947a0d8f9f982c315 = new L.Control.Draw(\n",
       "                options\n",
       "            ).addTo( map_8e1e077fd6844b9740816a019aa03785 );\n",
       "            map_8e1e077fd6844b9740816a019aa03785.on(L.Draw.Event.CREATED, function(e) {\n",
       "                var layer = e.layer,\n",
       "                    type = e.layerType;\n",
       "                var coords = JSON.stringify(layer.toGeoJSON());\n",
       "                layer.on(&#x27;click&#x27;, function() {\n",
       "                    alert(coords);\n",
       "                    console.log(coords);\n",
       "                });\n",
       "                drawnItems_draw_control_fab9f88f64b288f947a0d8f9f982c315.addLayer(layer);\n",
       "            });\n",
       "            map_8e1e077fd6844b9740816a019aa03785.on(&#x27;draw:created&#x27;, function(e) {\n",
       "                drawnItems_draw_control_fab9f88f64b288f947a0d8f9f982c315.addLayer(e.layer);\n",
       "            });\n",
       "\n",
       "            \n",
       "        \n",
       "    \n",
       "\n",
       "            var geocoderOpts_geocoder_dafbd2433e4aec510f61b1619a406a23 = {\n",
       "  &quot;collapsed&quot;: true,\n",
       "  &quot;position&quot;: &quot;topleft&quot;,\n",
       "  &quot;defaultMarkGeocode&quot;: true,\n",
       "  &quot;zoom&quot;: 11,\n",
       "  &quot;provider&quot;: &quot;nominatim&quot;,\n",
       "  &quot;providerOptions&quot;: {\n",
       "},\n",
       "};\n",
       "\n",
       "            // note: geocoder name should start with lowercase\n",
       "            var geocoderName_geocoder_dafbd2433e4aec510f61b1619a406a23 = geocoderOpts_geocoder_dafbd2433e4aec510f61b1619a406a23[&quot;provider&quot;];\n",
       "\n",
       "            var customGeocoder_geocoder_dafbd2433e4aec510f61b1619a406a23 = L.Control.Geocoder[ geocoderName_geocoder_dafbd2433e4aec510f61b1619a406a23 ](\n",
       "                geocoderOpts_geocoder_dafbd2433e4aec510f61b1619a406a23[&#x27;providerOptions&#x27;]\n",
       "            );\n",
       "            geocoderOpts_geocoder_dafbd2433e4aec510f61b1619a406a23[&quot;geocoder&quot;] = customGeocoder_geocoder_dafbd2433e4aec510f61b1619a406a23;\n",
       "\n",
       "            L.Control.geocoder(\n",
       "                geocoderOpts_geocoder_dafbd2433e4aec510f61b1619a406a23\n",
       "            ).on(&#x27;markgeocode&#x27;, function(e) {\n",
       "                var zoom = geocoderOpts_geocoder_dafbd2433e4aec510f61b1619a406a23[&#x27;zoom&#x27;] || map_8e1e077fd6844b9740816a019aa03785.getZoom();\n",
       "                map_8e1e077fd6844b9740816a019aa03785.setView(e.geocode.center, zoom);\n",
       "            }).addTo(map_8e1e077fd6844b9740816a019aa03785);\n",
       "\n",
       "        \n",
       "    \n",
       "            map_8e1e077fd6844b9740816a019aa03785.fitBounds(\n",
       "                [[20, 0], [20, 0]],\n",
       "                {&quot;maxZoom&quot;: 2}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var tile_layer_5d3514fae7d3afcb1ff644a4a1782b5a = L.tileLayer(\n",
       "                &quot;http://localhost:50110/api/tiles/{z}/{x}/{y}.png?\\u0026filename=d%3A%5Cgee%5CLabelraster_Manual.tif\\u0026colormap=tab20&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 30,\n",
       "  &quot;maxNativeZoom&quot;: 30,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;Raster file served by \\u003ca href=\\u0027https://github.com/banesullivan/localtileserver\\u0027 target=\\u0027_blank\\u0027\\u003elocaltileserver\\u003c/a\\u003e.&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1.0,\n",
       "  &quot;bounds&quot;: [[33.986465, 71.73165], [34.04837, 71.815998]],\n",
       "  &quot;zoomToLayer&quot;: true,\n",
       "  &quot;visible&quot;: true,\n",
       "  &quot;corsAll&quot;: false,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_5d3514fae7d3afcb1ff644a4a1782b5a.addTo(map_8e1e077fd6844b9740816a019aa03785);\n",
       "        \n",
       "    \n",
       "            map_8e1e077fd6844b9740816a019aa03785.fitBounds(\n",
       "                [[33.986465, 71.73165], [34.04837, 71.815998]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var layer_control_8d15a9bc5db1a7d93bec63bb1f67dc28_layers = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_5f3ec94110bee92ea211ec01c679003e,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Raster&quot; : tile_layer_5d3514fae7d3afcb1ff644a4a1782b5a,\n",
       "                },\n",
       "            };\n",
       "            let layer_control_8d15a9bc5db1a7d93bec63bb1f67dc28 = L.control.layers(\n",
       "                layer_control_8d15a9bc5db1a7d93bec63bb1f67dc28_layers.base_layers,\n",
       "                layer_control_8d15a9bc5db1a7d93bec63bb1f67dc28_layers.overlays,\n",
       "                {\n",
       "  &quot;position&quot;: &quot;topright&quot;,\n",
       "  &quot;collapsed&quot;: true,\n",
       "  &quot;autoZIndex&quot;: true,\n",
       "}\n",
       "            ).addTo(map_8e1e077fd6844b9740816a019aa03785);\n",
       "\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" width=\"100%\" height=\"600\"style=\"border:none !important;\" \"allowfullscreen\" \"webkitallowfullscreen\" \"mozallowfullscreen\"></iframe>"
      ],
      "text/plain": [
       "<leafmap.foliumap.Map at 0x17cb1f8cb60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoai.view_raster('Labelraster_Manual.tif', cmap='tab20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52ef2d",
   "metadata": {},
   "source": [
    "# Unet Part to create image tiles / patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b048255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_path = 'temp_cleaned_vector.geojson'\n",
    "labeled_raster_path = 'labelraster_Manual.tif'\n",
    "out_folder = 'landcover_pabbi_satellite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18575b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected in_class_data as raster: labelraster_Manual.tif\n",
      "Raster CRS: EPSG:4326\n",
      "Raster dimensions: 31447 x 23080\n",
      "\n",
      "Raster info for ./pabbi_satellite_image_COG.tif:\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 31447 x 23080\n",
      "  Resolution: (2.6822089999998085e-06, 2.682208999999812e-06)\n",
      "  Bands: 3\n",
      "  Bounds: BoundingBox(left=71.731650084257, bottom=33.986464888201006, right=71.81599751067999, top=34.048370271921)\n",
      "Found 6 unique classes in raster: [1 2 3 4 5 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated: 4477, With features: 4477: 100%|██████████| 10980/10980 [03:04<00:00, 59.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Export Summary -------\n",
      "Total tiles exported: 4477\n",
      "Tiles with features: 4477 (100.0%)\n",
      "Average feature pixels per tile: 440491.3\n",
      "Output saved to: landcover_pabbi_satellite\n",
      "\n",
      "------- Georeference Verification -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tiles = geoai.export_geotiff_tiles(\n",
    "    in_raster = satellite_imagery,\n",
    "    out_folder= out_folder,\n",
    "    in_class_data= labeled_raster_path,\n",
    "    #class_value_field= 'labels',\n",
    "    tile_size=512,\n",
    "    stride=256,\n",
    "    buffer_radius=0,\n",
    "    skip_empty_tiles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 4477 image files and 4477 label files\n",
      "Training on 3581 images, validating on 896 images\n",
      "Starting training with unet + resnet34\n",
      "Model parameters: 24,441,245\n",
      "Epoch: 0, Batch: 0/896, Loss: 2.5749, Time: 30.16s\n",
      "Epoch: 0, Batch: 10/896, Loss: 1.7424, Time: 3.97s\n",
      "Epoch: 0, Batch: 20/896, Loss: 1.6876, Time: 4.00s\n",
      "Epoch: 0, Batch: 30/896, Loss: 1.3818, Time: 3.96s\n",
      "Epoch: 0, Batch: 40/896, Loss: 1.7097, Time: 3.98s\n",
      "Epoch: 0, Batch: 50/896, Loss: 0.7771, Time: 3.98s\n",
      "Epoch: 0, Batch: 60/896, Loss: 0.8404, Time: 3.98s\n",
      "Epoch: 0, Batch: 70/896, Loss: 0.8106, Time: 4.00s\n",
      "Epoch: 0, Batch: 80/896, Loss: 0.2984, Time: 3.98s\n",
      "Epoch: 0, Batch: 90/896, Loss: 1.3713, Time: 4.01s\n",
      "Epoch: 0, Batch: 100/896, Loss: 0.3584, Time: 4.01s\n",
      "Epoch: 0, Batch: 110/896, Loss: 1.1237, Time: 4.00s\n",
      "Epoch: 0, Batch: 120/896, Loss: 0.8955, Time: 4.00s\n",
      "Epoch: 0, Batch: 130/896, Loss: 1.3193, Time: 4.03s\n",
      "Epoch: 0, Batch: 140/896, Loss: 1.3070, Time: 4.01s\n",
      "Epoch: 0, Batch: 150/896, Loss: 0.6727, Time: 3.96s\n",
      "Epoch: 0, Batch: 160/896, Loss: 0.7060, Time: 3.97s\n",
      "Epoch: 0, Batch: 170/896, Loss: 1.0214, Time: 3.98s\n",
      "Epoch: 0, Batch: 180/896, Loss: 0.7672, Time: 3.98s\n",
      "Epoch: 0, Batch: 190/896, Loss: 0.8847, Time: 3.99s\n",
      "Epoch: 0, Batch: 200/896, Loss: 0.5839, Time: 3.98s\n",
      "Epoch: 0, Batch: 210/896, Loss: 0.7900, Time: 4.02s\n",
      "Epoch: 0, Batch: 220/896, Loss: 2.0986, Time: 4.01s\n",
      "Epoch: 0, Batch: 230/896, Loss: 1.1893, Time: 4.00s\n",
      "Epoch: 0, Batch: 240/896, Loss: 0.8839, Time: 4.01s\n",
      "Epoch: 0, Batch: 250/896, Loss: 1.2099, Time: 4.02s\n",
      "Epoch: 0, Batch: 260/896, Loss: 0.7400, Time: 4.00s\n",
      "Epoch: 0, Batch: 270/896, Loss: 0.5176, Time: 4.01s\n",
      "Epoch: 0, Batch: 280/896, Loss: 1.6965, Time: 4.01s\n",
      "Epoch: 0, Batch: 290/896, Loss: 1.7222, Time: 4.02s\n",
      "Epoch: 0, Batch: 300/896, Loss: 1.7993, Time: 4.02s\n",
      "Epoch: 0, Batch: 310/896, Loss: 0.9511, Time: 4.00s\n",
      "Epoch: 0, Batch: 320/896, Loss: 0.8754, Time: 4.02s\n",
      "Epoch: 0, Batch: 330/896, Loss: 1.5421, Time: 4.00s\n",
      "Epoch: 0, Batch: 340/896, Loss: 0.9259, Time: 4.02s\n",
      "Epoch: 0, Batch: 350/896, Loss: 0.5517, Time: 3.99s\n",
      "Epoch: 0, Batch: 360/896, Loss: 0.6852, Time: 3.99s\n",
      "Epoch: 0, Batch: 370/896, Loss: 0.4531, Time: 4.00s\n",
      "Epoch: 0, Batch: 380/896, Loss: 1.1194, Time: 4.00s\n",
      "Epoch: 0, Batch: 390/896, Loss: 0.4728, Time: 4.01s\n",
      "Epoch: 0, Batch: 400/896, Loss: 0.8368, Time: 4.01s\n",
      "Epoch: 0, Batch: 410/896, Loss: 0.9796, Time: 4.01s\n",
      "Epoch: 0, Batch: 420/896, Loss: 0.9002, Time: 4.02s\n",
      "Epoch: 0, Batch: 430/896, Loss: 1.1205, Time: 4.00s\n",
      "Epoch: 0, Batch: 440/896, Loss: 1.1932, Time: 4.02s\n",
      "Epoch: 0, Batch: 450/896, Loss: 0.7456, Time: 4.02s\n",
      "Epoch: 0, Batch: 460/896, Loss: 0.7459, Time: 4.02s\n",
      "Epoch: 0, Batch: 470/896, Loss: 0.5394, Time: 4.02s\n",
      "Epoch: 0, Batch: 480/896, Loss: 0.4607, Time: 4.02s\n",
      "Epoch: 0, Batch: 490/896, Loss: 1.3963, Time: 4.02s\n",
      "Epoch: 0, Batch: 500/896, Loss: 0.7269, Time: 4.01s\n",
      "Epoch: 0, Batch: 510/896, Loss: 0.8088, Time: 4.02s\n",
      "Epoch: 0, Batch: 520/896, Loss: 0.5108, Time: 4.03s\n",
      "Epoch: 0, Batch: 530/896, Loss: 0.6967, Time: 4.03s\n",
      "Epoch: 0, Batch: 540/896, Loss: 1.9476, Time: 4.02s\n",
      "Epoch: 0, Batch: 550/896, Loss: 0.8152, Time: 4.02s\n",
      "Epoch: 0, Batch: 560/896, Loss: 0.9962, Time: 4.02s\n",
      "Epoch: 0, Batch: 570/896, Loss: 0.8398, Time: 4.02s\n",
      "Epoch: 0, Batch: 580/896, Loss: 1.1896, Time: 4.02s\n",
      "Epoch: 0, Batch: 590/896, Loss: 1.6112, Time: 4.02s\n",
      "Epoch: 0, Batch: 600/896, Loss: 0.6048, Time: 4.02s\n",
      "Epoch: 0, Batch: 610/896, Loss: 0.4674, Time: 4.01s\n",
      "Epoch: 0, Batch: 620/896, Loss: 0.6020, Time: 4.02s\n",
      "Epoch: 0, Batch: 630/896, Loss: 1.1408, Time: 4.02s\n",
      "Epoch: 0, Batch: 640/896, Loss: 0.8213, Time: 4.02s\n",
      "Epoch: 0, Batch: 650/896, Loss: 0.5238, Time: 4.02s\n",
      "Epoch: 0, Batch: 660/896, Loss: 1.1823, Time: 4.02s\n",
      "Epoch: 0, Batch: 670/896, Loss: 0.7213, Time: 4.06s\n",
      "Epoch: 0, Batch: 680/896, Loss: 0.7161, Time: 4.02s\n",
      "Epoch: 0, Batch: 690/896, Loss: 1.5826, Time: 4.02s\n",
      "Epoch: 0, Batch: 700/896, Loss: 0.9237, Time: 4.02s\n",
      "Epoch: 0, Batch: 710/896, Loss: 1.5748, Time: 4.02s\n",
      "Epoch: 0, Batch: 720/896, Loss: 0.8058, Time: 4.02s\n",
      "Epoch: 0, Batch: 730/896, Loss: 0.5594, Time: 4.01s\n",
      "Epoch: 0, Batch: 740/896, Loss: 1.1610, Time: 4.02s\n",
      "Epoch: 0, Batch: 750/896, Loss: 1.0355, Time: 4.02s\n",
      "Epoch: 0, Batch: 760/896, Loss: 0.7737, Time: 4.02s\n",
      "Epoch: 0, Batch: 770/896, Loss: 0.8556, Time: 4.02s\n",
      "Epoch: 0, Batch: 780/896, Loss: 0.4249, Time: 4.02s\n",
      "Epoch: 0, Batch: 790/896, Loss: 0.9082, Time: 4.02s\n",
      "Epoch: 0, Batch: 800/896, Loss: 0.7310, Time: 4.04s\n",
      "Epoch: 0, Batch: 810/896, Loss: 1.6239, Time: 4.02s\n",
      "Epoch: 0, Batch: 820/896, Loss: 0.9827, Time: 4.03s\n",
      "Epoch: 0, Batch: 830/896, Loss: 0.5476, Time: 4.02s\n",
      "Epoch: 0, Batch: 840/896, Loss: 1.1257, Time: 4.02s\n",
      "Epoch: 0, Batch: 850/896, Loss: 0.3753, Time: 4.01s\n",
      "Epoch: 0, Batch: 860/896, Loss: 1.3294, Time: 4.02s\n",
      "Epoch: 0, Batch: 870/896, Loss: 1.1899, Time: 4.01s\n",
      "Epoch: 0, Batch: 880/896, Loss: 0.7908, Time: 4.02s\n",
      "Epoch: 0, Batch: 890/896, Loss: 1.3486, Time: 4.02s\n",
      "Epoch 1/50: Train Loss: 0.9212, Val Loss: 0.8828, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Saving best model with IoU: 0.3632\n",
      "Epoch: 1, Batch: 0/896, Loss: 0.4330, Time: 28.78s\n",
      "Epoch: 1, Batch: 10/896, Loss: 1.0560, Time: 3.98s\n",
      "Epoch: 1, Batch: 20/896, Loss: 0.9047, Time: 3.96s\n",
      "Epoch: 1, Batch: 30/896, Loss: 0.4844, Time: 3.99s\n",
      "Epoch: 1, Batch: 40/896, Loss: 0.9288, Time: 3.99s\n",
      "Epoch: 1, Batch: 50/896, Loss: 0.7319, Time: 3.98s\n",
      "Epoch: 1, Batch: 60/896, Loss: 1.5378, Time: 3.97s\n",
      "Epoch: 1, Batch: 70/896, Loss: 0.8710, Time: 4.00s\n",
      "Epoch: 1, Batch: 80/896, Loss: 1.4790, Time: 3.98s\n",
      "Epoch: 1, Batch: 90/896, Loss: 0.5921, Time: 3.97s\n",
      "Epoch: 1, Batch: 100/896, Loss: 1.2425, Time: 3.97s\n",
      "Epoch: 1, Batch: 110/896, Loss: 0.8875, Time: 3.99s\n",
      "Epoch: 1, Batch: 120/896, Loss: 0.4450, Time: 3.99s\n",
      "Epoch: 1, Batch: 130/896, Loss: 0.6029, Time: 3.97s\n",
      "Epoch: 1, Batch: 140/896, Loss: 2.0481, Time: 3.98s\n",
      "Epoch: 1, Batch: 150/896, Loss: 1.0189, Time: 4.01s\n",
      "Epoch: 1, Batch: 160/896, Loss: 0.8617, Time: 3.99s\n",
      "Epoch: 1, Batch: 170/896, Loss: 0.5635, Time: 4.00s\n",
      "Epoch: 1, Batch: 180/896, Loss: 0.5498, Time: 4.02s\n",
      "Epoch: 1, Batch: 190/896, Loss: 1.4526, Time: 3.98s\n",
      "Epoch: 1, Batch: 200/896, Loss: 0.9489, Time: 4.00s\n",
      "Epoch: 1, Batch: 210/896, Loss: 0.7762, Time: 4.01s\n",
      "Epoch: 1, Batch: 220/896, Loss: 0.7362, Time: 4.02s\n",
      "Epoch: 1, Batch: 230/896, Loss: 1.1908, Time: 4.02s\n",
      "Epoch: 1, Batch: 240/896, Loss: 0.4382, Time: 4.00s\n",
      "Epoch: 1, Batch: 250/896, Loss: 1.1487, Time: 4.02s\n",
      "Epoch: 1, Batch: 260/896, Loss: 0.6923, Time: 4.00s\n",
      "Epoch: 1, Batch: 270/896, Loss: 1.1359, Time: 4.00s\n",
      "Epoch: 1, Batch: 280/896, Loss: 0.9770, Time: 3.99s\n",
      "Epoch: 1, Batch: 290/896, Loss: 0.8767, Time: 4.00s\n",
      "Epoch: 1, Batch: 300/896, Loss: 0.8337, Time: 4.00s\n",
      "Epoch: 1, Batch: 310/896, Loss: 0.7121, Time: 4.02s\n",
      "Epoch: 1, Batch: 320/896, Loss: 1.0650, Time: 4.02s\n",
      "Epoch: 1, Batch: 330/896, Loss: 1.0773, Time: 4.00s\n",
      "Epoch: 1, Batch: 340/896, Loss: 0.7498, Time: 4.01s\n",
      "Epoch: 1, Batch: 350/896, Loss: 0.7870, Time: 4.02s\n",
      "Epoch: 1, Batch: 360/896, Loss: 0.7071, Time: 4.01s\n",
      "Epoch: 1, Batch: 370/896, Loss: 0.5023, Time: 4.00s\n",
      "Epoch: 1, Batch: 380/896, Loss: 0.7260, Time: 4.01s\n",
      "Epoch: 1, Batch: 390/896, Loss: 0.8459, Time: 4.02s\n",
      "Epoch: 1, Batch: 400/896, Loss: 0.5860, Time: 4.02s\n",
      "Epoch: 1, Batch: 410/896, Loss: 0.6287, Time: 4.02s\n",
      "Epoch: 1, Batch: 420/896, Loss: 1.7318, Time: 4.02s\n",
      "Epoch: 1, Batch: 430/896, Loss: 0.4944, Time: 4.02s\n",
      "Epoch: 1, Batch: 440/896, Loss: 0.8175, Time: 4.02s\n",
      "Epoch: 1, Batch: 450/896, Loss: 0.3542, Time: 4.02s\n",
      "Epoch: 1, Batch: 460/896, Loss: 0.5617, Time: 4.02s\n",
      "Epoch: 1, Batch: 470/896, Loss: 0.6347, Time: 4.03s\n",
      "Epoch: 1, Batch: 480/896, Loss: 1.1492, Time: 4.02s\n",
      "Epoch: 1, Batch: 490/896, Loss: 0.8688, Time: 4.02s\n",
      "Epoch: 1, Batch: 500/896, Loss: 0.8284, Time: 4.02s\n",
      "Epoch: 1, Batch: 510/896, Loss: 0.9074, Time: 4.02s\n",
      "Epoch: 1, Batch: 520/896, Loss: 1.7476, Time: 4.02s\n",
      "Epoch: 1, Batch: 530/896, Loss: 0.6844, Time: 4.02s\n",
      "Epoch: 1, Batch: 540/896, Loss: 0.4649, Time: 4.04s\n",
      "Epoch: 1, Batch: 550/896, Loss: 0.4362, Time: 4.01s\n",
      "Epoch: 1, Batch: 560/896, Loss: 0.6485, Time: 4.02s\n",
      "Epoch: 1, Batch: 570/896, Loss: 0.8496, Time: 4.02s\n",
      "Epoch: 1, Batch: 580/896, Loss: 0.8080, Time: 4.02s\n",
      "Epoch: 1, Batch: 590/896, Loss: 1.7635, Time: 4.02s\n",
      "Epoch: 1, Batch: 600/896, Loss: 1.0837, Time: 4.01s\n",
      "Epoch: 1, Batch: 610/896, Loss: 0.7917, Time: 4.03s\n",
      "Epoch: 1, Batch: 620/896, Loss: 1.0359, Time: 4.04s\n",
      "Epoch: 1, Batch: 630/896, Loss: 1.7399, Time: 4.01s\n",
      "Epoch: 1, Batch: 640/896, Loss: 0.4232, Time: 4.02s\n",
      "Epoch: 1, Batch: 650/896, Loss: 0.6996, Time: 4.02s\n",
      "Epoch: 1, Batch: 660/896, Loss: 0.5615, Time: 4.01s\n",
      "Epoch: 1, Batch: 670/896, Loss: 1.1362, Time: 4.02s\n",
      "Epoch: 1, Batch: 680/896, Loss: 0.6797, Time: 4.04s\n",
      "Epoch: 1, Batch: 690/896, Loss: 0.4265, Time: 4.04s\n",
      "Epoch: 1, Batch: 700/896, Loss: 0.4654, Time: 4.01s\n",
      "Epoch: 1, Batch: 710/896, Loss: 0.7556, Time: 4.04s\n",
      "Epoch: 1, Batch: 720/896, Loss: 0.7988, Time: 4.03s\n",
      "Epoch: 1, Batch: 730/896, Loss: 0.8709, Time: 4.01s\n",
      "Epoch: 1, Batch: 740/896, Loss: 0.7690, Time: 4.04s\n",
      "Epoch: 1, Batch: 750/896, Loss: 0.6946, Time: 4.03s\n",
      "Epoch: 1, Batch: 760/896, Loss: 0.6326, Time: 4.03s\n",
      "Epoch: 1, Batch: 770/896, Loss: 1.1088, Time: 4.03s\n",
      "Epoch: 1, Batch: 780/896, Loss: 0.8528, Time: 4.03s\n",
      "Epoch: 1, Batch: 790/896, Loss: 0.8819, Time: 4.01s\n",
      "Epoch: 1, Batch: 800/896, Loss: 0.3380, Time: 4.02s\n",
      "Epoch: 1, Batch: 810/896, Loss: 1.3386, Time: 4.03s\n",
      "Epoch: 1, Batch: 820/896, Loss: 0.5683, Time: 4.03s\n",
      "Epoch: 1, Batch: 830/896, Loss: 1.2456, Time: 4.03s\n",
      "Epoch: 1, Batch: 840/896, Loss: 1.1068, Time: 4.03s\n",
      "Epoch: 1, Batch: 850/896, Loss: 1.1072, Time: 4.03s\n",
      "Epoch: 1, Batch: 860/896, Loss: 0.8049, Time: 4.02s\n",
      "Epoch: 1, Batch: 870/896, Loss: 1.0405, Time: 4.03s\n",
      "Epoch: 1, Batch: 880/896, Loss: 0.5828, Time: 4.19s\n",
      "Epoch: 1, Batch: 890/896, Loss: 0.9332, Time: 4.12s\n",
      "Epoch 2/50: Train Loss: 0.8768, Val Loss: 0.8833, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 2, Batch: 0/896, Loss: 0.5051, Time: 29.58s\n",
      "Epoch: 2, Batch: 10/896, Loss: 0.7048, Time: 4.04s\n",
      "Epoch: 2, Batch: 20/896, Loss: 0.9211, Time: 4.00s\n",
      "Epoch: 2, Batch: 30/896, Loss: 1.2002, Time: 3.99s\n",
      "Epoch: 2, Batch: 40/896, Loss: 1.7811, Time: 4.01s\n",
      "Epoch: 2, Batch: 50/896, Loss: 0.9205, Time: 3.99s\n",
      "Epoch: 2, Batch: 60/896, Loss: 0.9029, Time: 4.01s\n",
      "Epoch: 2, Batch: 70/896, Loss: 0.8142, Time: 4.01s\n",
      "Epoch: 2, Batch: 80/896, Loss: 0.5693, Time: 4.01s\n",
      "Epoch: 2, Batch: 90/896, Loss: 0.9231, Time: 4.02s\n",
      "Epoch: 2, Batch: 100/896, Loss: 1.5615, Time: 4.02s\n",
      "Epoch: 2, Batch: 110/896, Loss: 1.4605, Time: 4.03s\n",
      "Epoch: 2, Batch: 120/896, Loss: 1.1497, Time: 4.07s\n",
      "Epoch: 2, Batch: 130/896, Loss: 0.5099, Time: 4.06s\n",
      "Epoch: 2, Batch: 140/896, Loss: 0.5744, Time: 4.00s\n",
      "Epoch: 2, Batch: 150/896, Loss: 0.6198, Time: 3.98s\n",
      "Epoch: 2, Batch: 160/896, Loss: 0.8018, Time: 4.00s\n",
      "Epoch: 2, Batch: 170/896, Loss: 2.1278, Time: 3.98s\n",
      "Epoch: 2, Batch: 180/896, Loss: 0.3666, Time: 3.98s\n",
      "Epoch: 2, Batch: 190/896, Loss: 1.3309, Time: 3.98s\n",
      "Epoch: 2, Batch: 200/896, Loss: 0.7640, Time: 3.98s\n",
      "Epoch: 2, Batch: 210/896, Loss: 0.5350, Time: 3.99s\n",
      "Epoch: 2, Batch: 220/896, Loss: 0.8131, Time: 3.99s\n",
      "Epoch: 2, Batch: 230/896, Loss: 1.9598, Time: 4.03s\n",
      "Epoch: 2, Batch: 240/896, Loss: 1.0150, Time: 4.08s\n",
      "Epoch: 2, Batch: 250/896, Loss: 0.6664, Time: 4.05s\n",
      "Epoch: 2, Batch: 260/896, Loss: 1.3474, Time: 4.04s\n",
      "Epoch: 2, Batch: 270/896, Loss: 0.6065, Time: 4.05s\n",
      "Epoch: 2, Batch: 280/896, Loss: 1.3533, Time: 4.05s\n",
      "Epoch: 2, Batch: 290/896, Loss: 1.5241, Time: 4.09s\n",
      "Epoch: 2, Batch: 300/896, Loss: 0.3594, Time: 4.04s\n",
      "Epoch: 2, Batch: 310/896, Loss: 1.1390, Time: 4.10s\n",
      "Epoch: 2, Batch: 320/896, Loss: 1.1273, Time: 4.09s\n",
      "Epoch: 2, Batch: 330/896, Loss: 0.8248, Time: 4.04s\n",
      "Epoch: 2, Batch: 340/896, Loss: 1.1406, Time: 4.05s\n",
      "Epoch: 2, Batch: 350/896, Loss: 0.8945, Time: 4.02s\n",
      "Epoch: 2, Batch: 360/896, Loss: 1.3664, Time: 4.01s\n",
      "Epoch: 2, Batch: 370/896, Loss: 0.7667, Time: 4.02s\n",
      "Epoch: 2, Batch: 380/896, Loss: 1.0676, Time: 4.05s\n",
      "Epoch: 2, Batch: 390/896, Loss: 0.7570, Time: 4.06s\n",
      "Epoch: 2, Batch: 400/896, Loss: 0.5037, Time: 4.02s\n",
      "Epoch: 2, Batch: 410/896, Loss: 0.9089, Time: 4.02s\n",
      "Epoch: 2, Batch: 420/896, Loss: 0.3498, Time: 4.02s\n",
      "Epoch: 2, Batch: 430/896, Loss: 1.4107, Time: 4.00s\n",
      "Epoch: 2, Batch: 440/896, Loss: 0.7028, Time: 4.01s\n",
      "Epoch: 2, Batch: 450/896, Loss: 0.8178, Time: 4.02s\n",
      "Epoch: 2, Batch: 460/896, Loss: 0.7037, Time: 4.05s\n",
      "Epoch: 2, Batch: 470/896, Loss: 0.3815, Time: 4.03s\n",
      "Epoch: 2, Batch: 480/896, Loss: 0.7572, Time: 4.02s\n",
      "Epoch: 2, Batch: 490/896, Loss: 0.5966, Time: 4.02s\n",
      "Epoch: 2, Batch: 500/896, Loss: 0.6741, Time: 4.03s\n",
      "Epoch: 2, Batch: 510/896, Loss: 0.6923, Time: 4.00s\n",
      "Epoch: 2, Batch: 520/896, Loss: 0.4847, Time: 4.01s\n",
      "Epoch: 2, Batch: 530/896, Loss: 1.6074, Time: 4.02s\n",
      "Epoch: 2, Batch: 540/896, Loss: 1.3390, Time: 4.00s\n",
      "Epoch: 2, Batch: 550/896, Loss: 1.0337, Time: 4.02s\n",
      "Epoch: 2, Batch: 560/896, Loss: 1.0979, Time: 4.02s\n",
      "Epoch: 2, Batch: 570/896, Loss: 0.9858, Time: 4.03s\n",
      "Epoch: 2, Batch: 580/896, Loss: 0.7102, Time: 4.01s\n",
      "Epoch: 2, Batch: 590/896, Loss: 0.7278, Time: 4.01s\n",
      "Epoch: 2, Batch: 600/896, Loss: 0.6828, Time: 4.02s\n",
      "Epoch: 2, Batch: 610/896, Loss: 1.2261, Time: 4.02s\n",
      "Epoch: 2, Batch: 620/896, Loss: 0.6123, Time: 4.01s\n",
      "Epoch: 2, Batch: 630/896, Loss: 1.2602, Time: 4.01s\n",
      "Epoch: 2, Batch: 640/896, Loss: 0.9100, Time: 4.02s\n",
      "Epoch: 2, Batch: 650/896, Loss: 0.4083, Time: 4.01s\n",
      "Epoch: 2, Batch: 660/896, Loss: 0.5802, Time: 4.03s\n",
      "Epoch: 2, Batch: 670/896, Loss: 0.6043, Time: 4.02s\n",
      "Epoch: 2, Batch: 680/896, Loss: 0.4070, Time: 4.02s\n",
      "Epoch: 2, Batch: 690/896, Loss: 0.4598, Time: 4.03s\n",
      "Epoch: 2, Batch: 700/896, Loss: 0.6801, Time: 4.02s\n",
      "Epoch: 2, Batch: 710/896, Loss: 1.3127, Time: 4.05s\n",
      "Epoch: 2, Batch: 720/896, Loss: 1.4173, Time: 4.09s\n",
      "Epoch: 2, Batch: 730/896, Loss: 0.8741, Time: 4.11s\n",
      "Epoch: 2, Batch: 740/896, Loss: 0.5899, Time: 4.09s\n",
      "Epoch: 2, Batch: 750/896, Loss: 0.9815, Time: 4.08s\n",
      "Epoch: 2, Batch: 760/896, Loss: 0.6435, Time: 4.09s\n",
      "Epoch: 2, Batch: 770/896, Loss: 0.7218, Time: 4.06s\n",
      "Epoch: 2, Batch: 780/896, Loss: 0.9157, Time: 4.07s\n",
      "Epoch: 2, Batch: 790/896, Loss: 1.6038, Time: 4.06s\n",
      "Epoch: 2, Batch: 800/896, Loss: 1.5577, Time: 4.04s\n",
      "Epoch: 2, Batch: 810/896, Loss: 0.7961, Time: 4.08s\n",
      "Epoch: 2, Batch: 820/896, Loss: 0.4470, Time: 4.11s\n",
      "Epoch: 2, Batch: 830/896, Loss: 1.0108, Time: 4.04s\n",
      "Epoch: 2, Batch: 840/896, Loss: 0.3068, Time: 4.02s\n",
      "Epoch: 2, Batch: 850/896, Loss: 0.9165, Time: 4.04s\n",
      "Epoch: 2, Batch: 860/896, Loss: 0.6690, Time: 4.03s\n",
      "Epoch: 2, Batch: 870/896, Loss: 0.6928, Time: 4.03s\n",
      "Epoch: 2, Batch: 880/896, Loss: 0.5796, Time: 4.04s\n",
      "Epoch: 2, Batch: 890/896, Loss: 1.2196, Time: 4.02s\n",
      "Epoch 3/50: Train Loss: 0.8709, Val Loss: 0.8722, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 3, Batch: 0/896, Loss: 0.3828, Time: 28.70s\n",
      "Epoch: 3, Batch: 10/896, Loss: 1.4882, Time: 3.95s\n",
      "Epoch: 3, Batch: 20/896, Loss: 1.4580, Time: 3.97s\n",
      "Epoch: 3, Batch: 30/896, Loss: 0.6618, Time: 3.95s\n",
      "Epoch: 3, Batch: 40/896, Loss: 1.0756, Time: 3.98s\n",
      "Epoch: 3, Batch: 50/896, Loss: 0.9502, Time: 3.97s\n",
      "Epoch: 3, Batch: 60/896, Loss: 1.3450, Time: 3.99s\n",
      "Epoch: 3, Batch: 70/896, Loss: 1.4742, Time: 3.99s\n",
      "Epoch: 3, Batch: 80/896, Loss: 1.4238, Time: 3.99s\n",
      "Epoch: 3, Batch: 90/896, Loss: 0.6399, Time: 3.97s\n",
      "Epoch: 3, Batch: 100/896, Loss: 0.9113, Time: 3.99s\n",
      "Epoch: 3, Batch: 110/896, Loss: 1.0666, Time: 3.99s\n",
      "Epoch: 3, Batch: 120/896, Loss: 0.6830, Time: 3.97s\n",
      "Epoch: 3, Batch: 130/896, Loss: 0.7293, Time: 4.00s\n",
      "Epoch: 3, Batch: 140/896, Loss: 0.9165, Time: 4.00s\n",
      "Epoch: 3, Batch: 150/896, Loss: 1.0606, Time: 4.00s\n",
      "Epoch: 3, Batch: 160/896, Loss: 0.6849, Time: 3.99s\n",
      "Epoch: 3, Batch: 170/896, Loss: 0.6707, Time: 4.00s\n",
      "Epoch: 3, Batch: 180/896, Loss: 0.6456, Time: 3.99s\n",
      "Epoch: 3, Batch: 190/896, Loss: 0.6210, Time: 4.00s\n",
      "Epoch: 3, Batch: 200/896, Loss: 0.5292, Time: 4.00s\n",
      "Epoch: 3, Batch: 210/896, Loss: 0.6642, Time: 4.00s\n",
      "Epoch: 3, Batch: 220/896, Loss: 0.8739, Time: 4.01s\n",
      "Epoch: 3, Batch: 230/896, Loss: 0.7725, Time: 4.01s\n",
      "Epoch: 3, Batch: 240/896, Loss: 1.2146, Time: 4.00s\n",
      "Epoch: 3, Batch: 250/896, Loss: 1.1498, Time: 4.03s\n",
      "Epoch: 3, Batch: 260/896, Loss: 1.0287, Time: 4.00s\n",
      "Epoch: 3, Batch: 270/896, Loss: 0.6459, Time: 4.02s\n",
      "Epoch: 3, Batch: 280/896, Loss: 0.2906, Time: 4.02s\n",
      "Epoch: 3, Batch: 290/896, Loss: 0.4430, Time: 4.02s\n",
      "Epoch: 3, Batch: 300/896, Loss: 1.3263, Time: 4.02s\n",
      "Epoch: 3, Batch: 310/896, Loss: 1.2317, Time: 4.02s\n",
      "Epoch: 3, Batch: 320/896, Loss: 0.7629, Time: 4.01s\n",
      "Epoch: 3, Batch: 330/896, Loss: 0.6956, Time: 4.01s\n",
      "Epoch: 3, Batch: 340/896, Loss: 0.7648, Time: 4.02s\n",
      "Epoch: 3, Batch: 350/896, Loss: 1.4252, Time: 4.01s\n",
      "Epoch: 3, Batch: 360/896, Loss: 1.2610, Time: 4.01s\n",
      "Epoch: 3, Batch: 370/896, Loss: 0.2946, Time: 4.02s\n",
      "Epoch: 3, Batch: 380/896, Loss: 0.7760, Time: 4.02s\n",
      "Epoch: 3, Batch: 390/896, Loss: 0.6607, Time: 4.02s\n",
      "Epoch: 3, Batch: 400/896, Loss: 1.2823, Time: 4.02s\n",
      "Epoch: 3, Batch: 410/896, Loss: 0.6056, Time: 4.02s\n",
      "Epoch: 3, Batch: 420/896, Loss: 0.4734, Time: 4.02s\n",
      "Epoch: 3, Batch: 430/896, Loss: 0.4217, Time: 4.00s\n",
      "Epoch: 3, Batch: 440/896, Loss: 0.7210, Time: 4.01s\n",
      "Epoch: 3, Batch: 450/896, Loss: 0.9844, Time: 4.01s\n",
      "Epoch: 3, Batch: 460/896, Loss: 0.9432, Time: 4.02s\n",
      "Epoch: 3, Batch: 470/896, Loss: 0.3835, Time: 4.02s\n",
      "Epoch: 3, Batch: 480/896, Loss: 0.5750, Time: 4.00s\n",
      "Epoch: 3, Batch: 490/896, Loss: 1.4377, Time: 4.00s\n",
      "Epoch: 3, Batch: 500/896, Loss: 0.8230, Time: 4.01s\n",
      "Epoch: 3, Batch: 510/896, Loss: 0.7469, Time: 4.02s\n",
      "Epoch: 3, Batch: 520/896, Loss: 1.5325, Time: 4.00s\n",
      "Epoch: 3, Batch: 530/896, Loss: 1.2087, Time: 4.00s\n",
      "Epoch: 3, Batch: 540/896, Loss: 1.9195, Time: 4.01s\n",
      "Epoch: 3, Batch: 550/896, Loss: 0.5936, Time: 4.02s\n",
      "Epoch: 3, Batch: 560/896, Loss: 1.0097, Time: 4.00s\n",
      "Epoch: 3, Batch: 570/896, Loss: 0.4114, Time: 4.02s\n",
      "Epoch: 3, Batch: 580/896, Loss: 0.4474, Time: 4.01s\n",
      "Epoch: 3, Batch: 590/896, Loss: 0.7519, Time: 4.01s\n",
      "Epoch: 3, Batch: 600/896, Loss: 0.5629, Time: 4.01s\n",
      "Epoch: 3, Batch: 610/896, Loss: 0.7871, Time: 4.00s\n",
      "Epoch: 3, Batch: 620/896, Loss: 1.0097, Time: 4.01s\n",
      "Epoch: 3, Batch: 630/896, Loss: 0.9203, Time: 4.00s\n",
      "Epoch: 3, Batch: 640/896, Loss: 0.5319, Time: 4.02s\n",
      "Epoch: 3, Batch: 650/896, Loss: 1.2112, Time: 4.02s\n",
      "Epoch: 3, Batch: 660/896, Loss: 0.9023, Time: 4.02s\n",
      "Epoch: 3, Batch: 670/896, Loss: 0.4562, Time: 4.00s\n",
      "Epoch: 3, Batch: 680/896, Loss: 0.7395, Time: 4.02s\n",
      "Epoch: 3, Batch: 690/896, Loss: 0.4896, Time: 4.01s\n",
      "Epoch: 3, Batch: 700/896, Loss: 0.8861, Time: 4.00s\n",
      "Epoch: 3, Batch: 710/896, Loss: 0.9572, Time: 4.02s\n",
      "Epoch: 3, Batch: 720/896, Loss: 0.8124, Time: 4.02s\n",
      "Epoch: 3, Batch: 730/896, Loss: 1.1923, Time: 4.01s\n",
      "Epoch: 3, Batch: 740/896, Loss: 1.0337, Time: 4.02s\n",
      "Epoch: 3, Batch: 750/896, Loss: 0.5475, Time: 4.00s\n",
      "Epoch: 3, Batch: 760/896, Loss: 1.0917, Time: 4.02s\n",
      "Epoch: 3, Batch: 770/896, Loss: 1.1258, Time: 4.00s\n",
      "Epoch: 3, Batch: 780/896, Loss: 0.7940, Time: 4.02s\n",
      "Epoch: 3, Batch: 790/896, Loss: 0.7160, Time: 4.00s\n",
      "Epoch: 3, Batch: 800/896, Loss: 0.6465, Time: 4.00s\n",
      "Epoch: 3, Batch: 810/896, Loss: 0.8528, Time: 4.02s\n",
      "Epoch: 3, Batch: 820/896, Loss: 0.8909, Time: 4.01s\n",
      "Epoch: 3, Batch: 830/896, Loss: 0.6036, Time: 4.00s\n",
      "Epoch: 3, Batch: 840/896, Loss: 1.1229, Time: 4.00s\n",
      "Epoch: 3, Batch: 850/896, Loss: 0.6416, Time: 3.99s\n",
      "Epoch: 3, Batch: 860/896, Loss: 0.3983, Time: 4.00s\n",
      "Epoch: 3, Batch: 870/896, Loss: 0.9011, Time: 4.00s\n",
      "Epoch: 3, Batch: 880/896, Loss: 0.7257, Time: 3.99s\n",
      "Epoch: 3, Batch: 890/896, Loss: 0.8187, Time: 3.98s\n",
      "Epoch 4/50: Train Loss: 0.8693, Val Loss: 0.8754, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 4, Batch: 0/896, Loss: 0.5929, Time: 29.15s\n",
      "Epoch: 4, Batch: 10/896, Loss: 0.8693, Time: 3.90s\n",
      "Epoch: 4, Batch: 20/896, Loss: 0.9511, Time: 3.91s\n",
      "Epoch: 4, Batch: 30/896, Loss: 1.4038, Time: 3.93s\n",
      "Epoch: 4, Batch: 40/896, Loss: 0.6702, Time: 3.92s\n",
      "Epoch: 4, Batch: 50/896, Loss: 1.6655, Time: 3.93s\n",
      "Epoch: 4, Batch: 60/896, Loss: 1.0387, Time: 3.94s\n",
      "Epoch: 4, Batch: 70/896, Loss: 0.5015, Time: 3.95s\n",
      "Epoch: 4, Batch: 80/896, Loss: 0.4283, Time: 3.94s\n",
      "Epoch: 4, Batch: 90/896, Loss: 0.4187, Time: 3.96s\n",
      "Epoch: 4, Batch: 100/896, Loss: 0.9996, Time: 3.96s\n",
      "Epoch: 4, Batch: 110/896, Loss: 0.4690, Time: 3.95s\n",
      "Epoch: 4, Batch: 120/896, Loss: 0.8501, Time: 3.97s\n",
      "Epoch: 4, Batch: 130/896, Loss: 0.4283, Time: 3.97s\n",
      "Epoch: 4, Batch: 140/896, Loss: 1.0665, Time: 3.96s\n",
      "Epoch: 4, Batch: 150/896, Loss: 1.0070, Time: 3.96s\n",
      "Epoch: 4, Batch: 160/896, Loss: 0.5502, Time: 3.97s\n",
      "Epoch: 4, Batch: 170/896, Loss: 0.4005, Time: 3.96s\n",
      "Epoch: 4, Batch: 180/896, Loss: 1.4540, Time: 3.97s\n",
      "Epoch: 4, Batch: 190/896, Loss: 0.5891, Time: 3.96s\n",
      "Epoch: 4, Batch: 200/896, Loss: 0.7853, Time: 3.96s\n",
      "Epoch: 4, Batch: 210/896, Loss: 0.2780, Time: 3.96s\n",
      "Epoch: 4, Batch: 220/896, Loss: 0.8377, Time: 3.96s\n",
      "Epoch: 4, Batch: 230/896, Loss: 0.5610, Time: 3.96s\n",
      "Epoch: 4, Batch: 240/896, Loss: 0.5963, Time: 3.97s\n",
      "Epoch: 4, Batch: 250/896, Loss: 0.3698, Time: 3.96s\n",
      "Epoch: 4, Batch: 260/896, Loss: 0.8103, Time: 3.97s\n",
      "Epoch: 4, Batch: 270/896, Loss: 0.7398, Time: 3.96s\n",
      "Epoch: 4, Batch: 280/896, Loss: 1.3019, Time: 3.97s\n",
      "Epoch: 4, Batch: 290/896, Loss: 2.0480, Time: 3.96s\n",
      "Epoch: 4, Batch: 300/896, Loss: 0.4670, Time: 3.98s\n",
      "Epoch: 4, Batch: 310/896, Loss: 0.8300, Time: 3.98s\n",
      "Epoch: 4, Batch: 320/896, Loss: 0.5643, Time: 3.97s\n",
      "Epoch: 4, Batch: 330/896, Loss: 1.3457, Time: 3.96s\n",
      "Epoch: 4, Batch: 340/896, Loss: 0.6976, Time: 3.98s\n",
      "Epoch: 4, Batch: 350/896, Loss: 0.9683, Time: 3.99s\n",
      "Epoch: 4, Batch: 360/896, Loss: 1.2066, Time: 3.96s\n",
      "Epoch: 4, Batch: 370/896, Loss: 0.9760, Time: 3.99s\n",
      "Epoch: 4, Batch: 380/896, Loss: 1.3215, Time: 3.98s\n",
      "Epoch: 4, Batch: 390/896, Loss: 0.6730, Time: 3.97s\n",
      "Epoch: 4, Batch: 400/896, Loss: 0.3510, Time: 3.98s\n",
      "Epoch: 4, Batch: 410/896, Loss: 0.2798, Time: 3.97s\n",
      "Epoch: 4, Batch: 420/896, Loss: 1.5731, Time: 3.96s\n",
      "Epoch: 4, Batch: 430/896, Loss: 1.5819, Time: 3.98s\n",
      "Epoch: 4, Batch: 440/896, Loss: 0.9732, Time: 3.98s\n",
      "Epoch: 4, Batch: 450/896, Loss: 0.9028, Time: 3.96s\n",
      "Epoch: 4, Batch: 460/896, Loss: 1.5503, Time: 3.97s\n",
      "Epoch: 4, Batch: 470/896, Loss: 0.9289, Time: 3.97s\n",
      "Epoch: 4, Batch: 480/896, Loss: 0.7786, Time: 3.96s\n",
      "Epoch: 4, Batch: 490/896, Loss: 0.8896, Time: 3.97s\n",
      "Epoch: 4, Batch: 500/896, Loss: 1.4473, Time: 3.96s\n",
      "Epoch: 4, Batch: 510/896, Loss: 0.9052, Time: 3.96s\n",
      "Epoch: 4, Batch: 520/896, Loss: 0.8593, Time: 3.98s\n",
      "Epoch: 4, Batch: 530/896, Loss: 0.6575, Time: 3.96s\n",
      "Epoch: 4, Batch: 540/896, Loss: 0.6351, Time: 3.98s\n",
      "Epoch: 4, Batch: 550/896, Loss: 1.1508, Time: 3.98s\n",
      "Epoch: 4, Batch: 560/896, Loss: 0.3436, Time: 3.98s\n",
      "Epoch: 4, Batch: 570/896, Loss: 0.7826, Time: 3.97s\n",
      "Epoch: 4, Batch: 580/896, Loss: 0.8474, Time: 3.97s\n",
      "Epoch: 4, Batch: 590/896, Loss: 0.7169, Time: 3.97s\n",
      "Epoch: 4, Batch: 600/896, Loss: 0.3292, Time: 3.96s\n",
      "Epoch: 4, Batch: 610/896, Loss: 0.5683, Time: 3.98s\n",
      "Epoch: 4, Batch: 620/896, Loss: 0.2810, Time: 3.96s\n",
      "Epoch: 4, Batch: 630/896, Loss: 1.8755, Time: 3.97s\n",
      "Epoch: 4, Batch: 640/896, Loss: 0.5133, Time: 3.96s\n",
      "Epoch: 4, Batch: 650/896, Loss: 0.7177, Time: 3.98s\n",
      "Epoch: 4, Batch: 660/896, Loss: 0.9161, Time: 3.98s\n",
      "Epoch: 4, Batch: 670/896, Loss: 1.0391, Time: 3.96s\n",
      "Epoch: 4, Batch: 680/896, Loss: 0.4483, Time: 3.95s\n",
      "Epoch: 4, Batch: 690/896, Loss: 0.9119, Time: 3.96s\n",
      "Epoch: 4, Batch: 700/896, Loss: 0.4716, Time: 3.96s\n",
      "Epoch: 4, Batch: 710/896, Loss: 1.3903, Time: 3.98s\n",
      "Epoch: 4, Batch: 720/896, Loss: 0.8736, Time: 3.96s\n",
      "Epoch: 4, Batch: 730/896, Loss: 0.6500, Time: 3.98s\n",
      "Epoch: 4, Batch: 740/896, Loss: 0.6068, Time: 3.96s\n",
      "Epoch: 4, Batch: 750/896, Loss: 0.5350, Time: 3.96s\n",
      "Epoch: 4, Batch: 760/896, Loss: 0.6257, Time: 3.97s\n",
      "Epoch: 4, Batch: 770/896, Loss: 1.0084, Time: 3.96s\n",
      "Epoch: 4, Batch: 780/896, Loss: 0.4048, Time: 3.97s\n",
      "Epoch: 4, Batch: 790/896, Loss: 0.4809, Time: 3.95s\n",
      "Epoch: 4, Batch: 800/896, Loss: 0.8614, Time: 3.95s\n",
      "Epoch: 4, Batch: 810/896, Loss: 0.9962, Time: 3.96s\n",
      "Epoch: 4, Batch: 820/896, Loss: 0.8464, Time: 3.96s\n",
      "Epoch: 4, Batch: 830/896, Loss: 1.0037, Time: 3.95s\n",
      "Epoch: 4, Batch: 840/896, Loss: 1.0777, Time: 3.95s\n",
      "Epoch: 4, Batch: 850/896, Loss: 0.7016, Time: 3.94s\n",
      "Epoch: 4, Batch: 860/896, Loss: 1.1362, Time: 3.96s\n",
      "Epoch: 4, Batch: 870/896, Loss: 0.8576, Time: 3.95s\n",
      "Epoch: 4, Batch: 880/896, Loss: 0.6513, Time: 3.95s\n",
      "Epoch: 4, Batch: 890/896, Loss: 0.5941, Time: 3.95s\n",
      "Epoch 5/50: Train Loss: 0.8595, Val Loss: 0.9797, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 5, Batch: 0/896, Loss: 0.5432, Time: 28.88s\n",
      "Epoch: 5, Batch: 10/896, Loss: 0.3676, Time: 3.87s\n",
      "Epoch: 5, Batch: 20/896, Loss: 0.8978, Time: 3.88s\n",
      "Epoch: 5, Batch: 30/896, Loss: 0.5157, Time: 3.86s\n",
      "Epoch: 5, Batch: 40/896, Loss: 2.2932, Time: 3.88s\n",
      "Epoch: 5, Batch: 50/896, Loss: 1.1634, Time: 3.87s\n",
      "Epoch: 5, Batch: 60/896, Loss: 1.0069, Time: 3.88s\n",
      "Epoch: 5, Batch: 70/896, Loss: 0.8813, Time: 3.89s\n",
      "Epoch: 5, Batch: 80/896, Loss: 1.3183, Time: 3.87s\n",
      "Epoch: 5, Batch: 90/896, Loss: 0.6942, Time: 3.90s\n",
      "Epoch: 5, Batch: 100/896, Loss: 0.5894, Time: 3.90s\n",
      "Epoch: 5, Batch: 110/896, Loss: 1.5355, Time: 3.88s\n",
      "Epoch: 5, Batch: 120/896, Loss: 0.9350, Time: 3.92s\n",
      "Epoch: 5, Batch: 130/896, Loss: 0.5635, Time: 3.92s\n",
      "Epoch: 5, Batch: 140/896, Loss: 1.7416, Time: 3.92s\n",
      "Epoch: 5, Batch: 150/896, Loss: 1.7377, Time: 3.90s\n",
      "Epoch: 5, Batch: 160/896, Loss: 0.7850, Time: 3.90s\n",
      "Epoch: 5, Batch: 170/896, Loss: 0.9050, Time: 3.89s\n",
      "Epoch: 5, Batch: 180/896, Loss: 0.6073, Time: 3.92s\n",
      "Epoch: 5, Batch: 190/896, Loss: 0.8699, Time: 3.92s\n",
      "Epoch: 5, Batch: 200/896, Loss: 1.2254, Time: 3.92s\n",
      "Epoch: 5, Batch: 210/896, Loss: 0.9708, Time: 3.91s\n",
      "Epoch: 5, Batch: 220/896, Loss: 1.2161, Time: 3.92s\n",
      "Epoch: 5, Batch: 230/896, Loss: 0.7887, Time: 3.91s\n",
      "Epoch: 5, Batch: 240/896, Loss: 0.2938, Time: 3.93s\n",
      "Epoch: 5, Batch: 250/896, Loss: 1.2403, Time: 3.93s\n",
      "Epoch: 5, Batch: 260/896, Loss: 0.7476, Time: 3.89s\n",
      "Epoch: 5, Batch: 270/896, Loss: 1.2600, Time: 3.93s\n",
      "Epoch: 5, Batch: 280/896, Loss: 1.1315, Time: 3.91s\n",
      "Epoch: 5, Batch: 290/896, Loss: 0.5711, Time: 3.92s\n",
      "Epoch: 5, Batch: 300/896, Loss: 1.1997, Time: 3.93s\n",
      "Epoch: 5, Batch: 310/896, Loss: 0.8849, Time: 3.92s\n",
      "Epoch: 5, Batch: 320/896, Loss: 1.5794, Time: 3.91s\n",
      "Epoch: 5, Batch: 330/896, Loss: 0.8918, Time: 3.92s\n",
      "Epoch: 5, Batch: 340/896, Loss: 0.3634, Time: 3.91s\n",
      "Epoch: 5, Batch: 350/896, Loss: 0.8792, Time: 3.91s\n",
      "Epoch: 5, Batch: 360/896, Loss: 0.6966, Time: 3.92s\n",
      "Epoch: 5, Batch: 370/896, Loss: 0.4826, Time: 3.92s\n",
      "Epoch: 5, Batch: 380/896, Loss: 0.4824, Time: 3.92s\n",
      "Epoch: 5, Batch: 390/896, Loss: 1.3502, Time: 3.92s\n",
      "Epoch: 5, Batch: 400/896, Loss: 0.8154, Time: 3.93s\n",
      "Epoch: 5, Batch: 410/896, Loss: 1.5509, Time: 3.92s\n",
      "Epoch: 5, Batch: 420/896, Loss: 0.7956, Time: 3.91s\n",
      "Epoch: 5, Batch: 430/896, Loss: 0.7556, Time: 3.92s\n",
      "Epoch: 5, Batch: 440/896, Loss: 0.4870, Time: 3.91s\n",
      "Epoch: 5, Batch: 450/896, Loss: 0.7684, Time: 3.93s\n",
      "Epoch: 5, Batch: 460/896, Loss: 0.7794, Time: 3.91s\n",
      "Epoch: 5, Batch: 470/896, Loss: 0.4208, Time: 3.91s\n",
      "Epoch: 5, Batch: 480/896, Loss: 0.6986, Time: 3.93s\n",
      "Epoch: 5, Batch: 490/896, Loss: 0.2908, Time: 3.91s\n",
      "Epoch: 5, Batch: 500/896, Loss: 1.1365, Time: 3.90s\n",
      "Epoch: 5, Batch: 510/896, Loss: 1.0024, Time: 3.95s\n",
      "Epoch: 5, Batch: 520/896, Loss: 0.2905, Time: 3.90s\n",
      "Epoch: 5, Batch: 530/896, Loss: 0.7515, Time: 3.91s\n",
      "Epoch: 5, Batch: 540/896, Loss: 1.1884, Time: 3.92s\n",
      "Epoch: 5, Batch: 550/896, Loss: 0.9927, Time: 3.91s\n",
      "Epoch: 5, Batch: 560/896, Loss: 1.6469, Time: 3.91s\n",
      "Epoch: 5, Batch: 570/896, Loss: 1.1528, Time: 3.92s\n",
      "Epoch: 5, Batch: 580/896, Loss: 1.0413, Time: 3.91s\n",
      "Epoch: 5, Batch: 590/896, Loss: 1.0575, Time: 3.91s\n",
      "Epoch: 5, Batch: 600/896, Loss: 0.6433, Time: 3.92s\n",
      "Epoch: 5, Batch: 610/896, Loss: 0.5942, Time: 3.91s\n",
      "Epoch: 5, Batch: 620/896, Loss: 0.5234, Time: 3.92s\n",
      "Epoch: 5, Batch: 630/896, Loss: 0.4354, Time: 3.92s\n",
      "Epoch: 5, Batch: 640/896, Loss: 0.4036, Time: 3.92s\n",
      "Epoch: 5, Batch: 650/896, Loss: 0.6875, Time: 3.91s\n",
      "Epoch: 5, Batch: 660/896, Loss: 0.5863, Time: 3.91s\n",
      "Epoch: 5, Batch: 670/896, Loss: 1.0787, Time: 3.92s\n",
      "Epoch: 5, Batch: 680/896, Loss: 0.9990, Time: 3.92s\n",
      "Epoch: 5, Batch: 690/896, Loss: 0.8304, Time: 3.91s\n",
      "Epoch: 5, Batch: 700/896, Loss: 0.6697, Time: 3.92s\n",
      "Epoch: 5, Batch: 710/896, Loss: 2.1181, Time: 3.91s\n",
      "Epoch: 5, Batch: 720/896, Loss: 0.8328, Time: 3.92s\n",
      "Epoch: 5, Batch: 730/896, Loss: 0.5246, Time: 3.91s\n",
      "Epoch: 5, Batch: 740/896, Loss: 0.8710, Time: 3.92s\n",
      "Epoch: 5, Batch: 750/896, Loss: 0.5234, Time: 3.91s\n",
      "Epoch: 5, Batch: 760/896, Loss: 0.9337, Time: 3.92s\n",
      "Epoch: 5, Batch: 770/896, Loss: 0.9242, Time: 3.90s\n",
      "Epoch: 5, Batch: 780/896, Loss: 0.4912, Time: 3.91s\n",
      "Epoch: 5, Batch: 790/896, Loss: 1.2339, Time: 3.90s\n",
      "Epoch: 5, Batch: 800/896, Loss: 0.5775, Time: 3.91s\n",
      "Epoch: 5, Batch: 810/896, Loss: 0.5261, Time: 3.90s\n",
      "Epoch: 5, Batch: 820/896, Loss: 0.8068, Time: 3.90s\n",
      "Epoch: 5, Batch: 830/896, Loss: 1.0386, Time: 3.91s\n",
      "Epoch: 5, Batch: 840/896, Loss: 0.9080, Time: 3.91s\n",
      "Epoch: 5, Batch: 850/896, Loss: 1.4220, Time: 3.91s\n",
      "Epoch: 5, Batch: 860/896, Loss: 1.4163, Time: 3.92s\n",
      "Epoch: 5, Batch: 870/896, Loss: 1.1564, Time: 3.92s\n",
      "Epoch: 5, Batch: 880/896, Loss: 0.5297, Time: 3.90s\n",
      "Epoch: 5, Batch: 890/896, Loss: 0.6021, Time: 3.91s\n",
      "Epoch 6/50: Train Loss: 0.8564, Val Loss: 0.8639, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 6, Batch: 0/896, Loss: 0.5362, Time: 28.94s\n",
      "Epoch: 6, Batch: 10/896, Loss: 0.6268, Time: 3.82s\n",
      "Epoch: 6, Batch: 20/896, Loss: 0.8119, Time: 3.84s\n",
      "Epoch: 6, Batch: 30/896, Loss: 1.1866, Time: 3.82s\n",
      "Epoch: 6, Batch: 40/896, Loss: 0.9763, Time: 3.83s\n",
      "Epoch: 6, Batch: 50/896, Loss: 1.3874, Time: 3.84s\n",
      "Epoch: 6, Batch: 60/896, Loss: 0.5430, Time: 3.84s\n",
      "Epoch: 6, Batch: 70/896, Loss: 0.9539, Time: 3.83s\n",
      "Epoch: 6, Batch: 80/896, Loss: 0.5025, Time: 3.84s\n",
      "Epoch: 6, Batch: 90/896, Loss: 1.4408, Time: 3.84s\n",
      "Epoch: 6, Batch: 100/896, Loss: 0.5556, Time: 3.86s\n",
      "Epoch: 6, Batch: 110/896, Loss: 1.7424, Time: 3.86s\n",
      "Epoch: 6, Batch: 120/896, Loss: 0.7761, Time: 3.86s\n",
      "Epoch: 6, Batch: 130/896, Loss: 0.9103, Time: 3.86s\n",
      "Epoch: 6, Batch: 140/896, Loss: 0.6869, Time: 3.86s\n",
      "Epoch: 6, Batch: 150/896, Loss: 0.6261, Time: 3.86s\n",
      "Epoch: 6, Batch: 160/896, Loss: 0.6148, Time: 3.86s\n",
      "Epoch: 6, Batch: 170/896, Loss: 1.6364, Time: 3.86s\n",
      "Epoch: 6, Batch: 180/896, Loss: 0.5359, Time: 3.86s\n",
      "Epoch: 6, Batch: 190/896, Loss: 1.3962, Time: 3.86s\n",
      "Epoch: 6, Batch: 200/896, Loss: 0.7314, Time: 3.88s\n",
      "Epoch: 6, Batch: 210/896, Loss: 0.9383, Time: 3.86s\n",
      "Epoch: 6, Batch: 220/896, Loss: 0.4334, Time: 3.86s\n",
      "Epoch: 6, Batch: 230/896, Loss: 0.4750, Time: 3.89s\n",
      "Epoch: 6, Batch: 240/896, Loss: 1.1744, Time: 3.86s\n",
      "Epoch: 6, Batch: 250/896, Loss: 1.2767, Time: 3.86s\n",
      "Epoch: 6, Batch: 260/896, Loss: 1.3486, Time: 3.86s\n",
      "Epoch: 6, Batch: 270/896, Loss: 0.8160, Time: 3.87s\n",
      "Epoch: 6, Batch: 280/896, Loss: 0.4923, Time: 3.88s\n",
      "Epoch: 6, Batch: 290/896, Loss: 0.5181, Time: 3.88s\n",
      "Epoch: 6, Batch: 300/896, Loss: 1.1206, Time: 3.88s\n",
      "Epoch: 6, Batch: 310/896, Loss: 0.8727, Time: 3.88s\n",
      "Epoch: 6, Batch: 320/896, Loss: 0.7675, Time: 3.88s\n",
      "Epoch: 6, Batch: 330/896, Loss: 0.5815, Time: 3.89s\n",
      "Epoch: 6, Batch: 340/896, Loss: 0.5379, Time: 3.88s\n",
      "Epoch: 6, Batch: 350/896, Loss: 0.7485, Time: 3.88s\n",
      "Epoch: 6, Batch: 360/896, Loss: 0.7668, Time: 3.87s\n",
      "Epoch: 6, Batch: 370/896, Loss: 1.1510, Time: 3.87s\n",
      "Epoch: 6, Batch: 380/896, Loss: 1.2233, Time: 3.88s\n",
      "Epoch: 6, Batch: 390/896, Loss: 0.9205, Time: 3.89s\n",
      "Epoch: 6, Batch: 400/896, Loss: 0.8960, Time: 3.89s\n",
      "Epoch: 6, Batch: 410/896, Loss: 0.4058, Time: 3.88s\n",
      "Epoch: 6, Batch: 420/896, Loss: 1.0052, Time: 3.87s\n",
      "Epoch: 6, Batch: 430/896, Loss: 1.4375, Time: 3.87s\n",
      "Epoch: 6, Batch: 440/896, Loss: 0.7904, Time: 3.88s\n",
      "Epoch: 6, Batch: 450/896, Loss: 0.4786, Time: 3.86s\n",
      "Epoch: 6, Batch: 460/896, Loss: 0.7954, Time: 3.88s\n",
      "Epoch: 6, Batch: 470/896, Loss: 0.7150, Time: 3.90s\n",
      "Epoch: 6, Batch: 480/896, Loss: 0.6447, Time: 3.89s\n",
      "Epoch: 6, Batch: 490/896, Loss: 0.7332, Time: 3.88s\n",
      "Epoch: 6, Batch: 500/896, Loss: 1.4544, Time: 3.88s\n",
      "Epoch: 6, Batch: 510/896, Loss: 0.3651, Time: 3.89s\n",
      "Epoch: 6, Batch: 520/896, Loss: 0.8705, Time: 3.89s\n",
      "Epoch: 6, Batch: 530/896, Loss: 1.0793, Time: 3.88s\n",
      "Epoch: 6, Batch: 540/896, Loss: 1.0433, Time: 3.88s\n",
      "Epoch: 6, Batch: 550/896, Loss: 0.4604, Time: 3.89s\n",
      "Epoch: 6, Batch: 560/896, Loss: 0.5821, Time: 3.88s\n",
      "Epoch: 6, Batch: 570/896, Loss: 0.4656, Time: 3.89s\n",
      "Epoch: 6, Batch: 580/896, Loss: 0.7287, Time: 3.88s\n",
      "Epoch: 6, Batch: 590/896, Loss: 0.6985, Time: 3.88s\n",
      "Epoch: 6, Batch: 600/896, Loss: 0.7153, Time: 3.87s\n",
      "Epoch: 6, Batch: 610/896, Loss: 0.4306, Time: 3.88s\n",
      "Epoch: 6, Batch: 620/896, Loss: 1.3418, Time: 3.88s\n",
      "Epoch: 6, Batch: 630/896, Loss: 0.8769, Time: 3.89s\n",
      "Epoch: 6, Batch: 640/896, Loss: 1.0466, Time: 3.87s\n",
      "Epoch: 6, Batch: 650/896, Loss: 1.1447, Time: 3.87s\n",
      "Epoch: 6, Batch: 660/896, Loss: 0.6865, Time: 3.87s\n",
      "Epoch: 6, Batch: 670/896, Loss: 0.8333, Time: 3.86s\n",
      "Epoch: 6, Batch: 680/896, Loss: 1.2861, Time: 3.87s\n",
      "Epoch: 6, Batch: 690/896, Loss: 1.4388, Time: 3.86s\n",
      "Epoch: 6, Batch: 700/896, Loss: 0.7841, Time: 3.86s\n",
      "Epoch: 6, Batch: 710/896, Loss: 1.0985, Time: 3.87s\n",
      "Epoch: 6, Batch: 720/896, Loss: 0.4029, Time: 3.88s\n",
      "Epoch: 6, Batch: 730/896, Loss: 1.5281, Time: 3.87s\n",
      "Epoch: 6, Batch: 740/896, Loss: 1.3058, Time: 3.88s\n",
      "Epoch: 6, Batch: 750/896, Loss: 0.8471, Time: 3.88s\n",
      "Epoch: 6, Batch: 760/896, Loss: 0.4900, Time: 3.87s\n",
      "Epoch: 6, Batch: 770/896, Loss: 0.3784, Time: 3.88s\n",
      "Epoch: 6, Batch: 780/896, Loss: 0.8383, Time: 3.87s\n",
      "Epoch: 6, Batch: 790/896, Loss: 1.4322, Time: 3.86s\n",
      "Epoch: 6, Batch: 800/896, Loss: 0.5758, Time: 3.86s\n",
      "Epoch: 6, Batch: 810/896, Loss: 0.9276, Time: 3.86s\n",
      "Epoch: 6, Batch: 820/896, Loss: 0.9828, Time: 3.87s\n",
      "Epoch: 6, Batch: 830/896, Loss: 0.6369, Time: 3.87s\n",
      "Epoch: 6, Batch: 840/896, Loss: 0.6897, Time: 3.87s\n",
      "Epoch: 6, Batch: 850/896, Loss: 1.1803, Time: 3.86s\n",
      "Epoch: 6, Batch: 860/896, Loss: 0.4236, Time: 3.87s\n",
      "Epoch: 6, Batch: 870/896, Loss: 0.6348, Time: 3.87s\n",
      "Epoch: 6, Batch: 880/896, Loss: 0.7787, Time: 3.89s\n",
      "Epoch: 6, Batch: 890/896, Loss: 1.2215, Time: 3.87s\n",
      "Epoch 7/50: Train Loss: 0.8458, Val Loss: 0.8781, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 7, Batch: 0/896, Loss: 0.4396, Time: 28.79s\n",
      "Epoch: 7, Batch: 10/896, Loss: 1.1774, Time: 3.81s\n",
      "Epoch: 7, Batch: 20/896, Loss: 0.4961, Time: 3.80s\n",
      "Epoch: 7, Batch: 30/896, Loss: 0.7175, Time: 3.80s\n",
      "Epoch: 7, Batch: 40/896, Loss: 0.9214, Time: 3.82s\n",
      "Epoch: 7, Batch: 50/896, Loss: 1.3699, Time: 3.81s\n",
      "Epoch: 7, Batch: 60/896, Loss: 0.6861, Time: 3.81s\n",
      "Epoch: 7, Batch: 70/896, Loss: 0.7162, Time: 3.82s\n",
      "Epoch: 7, Batch: 80/896, Loss: 0.6699, Time: 3.82s\n",
      "Epoch: 7, Batch: 90/896, Loss: 0.5983, Time: 3.82s\n",
      "Epoch: 7, Batch: 100/896, Loss: 0.5690, Time: 3.82s\n",
      "Epoch: 7, Batch: 110/896, Loss: 0.8249, Time: 3.82s\n",
      "Epoch: 7, Batch: 120/896, Loss: 0.9230, Time: 3.83s\n",
      "Epoch: 7, Batch: 130/896, Loss: 0.3787, Time: 3.84s\n",
      "Epoch: 7, Batch: 140/896, Loss: 0.8348, Time: 3.84s\n",
      "Epoch: 7, Batch: 150/896, Loss: 0.6811, Time: 3.83s\n",
      "Epoch: 7, Batch: 160/896, Loss: 0.9227, Time: 3.83s\n",
      "Epoch: 7, Batch: 170/896, Loss: 0.5118, Time: 3.85s\n",
      "Epoch: 7, Batch: 180/896, Loss: 0.3561, Time: 3.85s\n",
      "Epoch: 7, Batch: 190/896, Loss: 0.6829, Time: 3.82s\n",
      "Epoch: 7, Batch: 200/896, Loss: 1.0255, Time: 3.84s\n",
      "Epoch: 7, Batch: 210/896, Loss: 0.6056, Time: 3.83s\n",
      "Epoch: 7, Batch: 220/896, Loss: 1.0020, Time: 3.85s\n",
      "Epoch: 7, Batch: 230/896, Loss: 1.1708, Time: 3.85s\n",
      "Epoch: 7, Batch: 240/896, Loss: 1.1770, Time: 3.84s\n",
      "Epoch: 7, Batch: 250/896, Loss: 0.4033, Time: 3.83s\n",
      "Epoch: 7, Batch: 260/896, Loss: 0.3728, Time: 3.85s\n",
      "Epoch: 7, Batch: 270/896, Loss: 0.7867, Time: 3.84s\n",
      "Epoch: 7, Batch: 280/896, Loss: 0.4708, Time: 3.84s\n",
      "Epoch: 7, Batch: 290/896, Loss: 0.7999, Time: 3.86s\n",
      "Epoch: 7, Batch: 300/896, Loss: 0.9959, Time: 3.84s\n",
      "Epoch: 7, Batch: 310/896, Loss: 1.0165, Time: 3.85s\n",
      "Epoch: 7, Batch: 320/896, Loss: 0.9108, Time: 3.84s\n",
      "Epoch: 7, Batch: 330/896, Loss: 0.6758, Time: 3.84s\n",
      "Epoch: 7, Batch: 340/896, Loss: 0.7035, Time: 3.85s\n",
      "Epoch: 7, Batch: 350/896, Loss: 1.4076, Time: 3.85s\n",
      "Epoch: 7, Batch: 360/896, Loss: 0.8362, Time: 3.84s\n",
      "Epoch: 7, Batch: 370/896, Loss: 0.8598, Time: 3.84s\n",
      "Epoch: 7, Batch: 380/896, Loss: 1.0788, Time: 3.85s\n",
      "Epoch: 7, Batch: 390/896, Loss: 0.6621, Time: 3.86s\n",
      "Epoch: 7, Batch: 400/896, Loss: 1.1483, Time: 3.85s\n",
      "Epoch: 7, Batch: 410/896, Loss: 0.6681, Time: 3.85s\n",
      "Epoch: 7, Batch: 420/896, Loss: 0.5315, Time: 3.84s\n",
      "Epoch: 7, Batch: 430/896, Loss: 1.0415, Time: 3.84s\n",
      "Epoch: 7, Batch: 440/896, Loss: 0.7259, Time: 3.85s\n",
      "Epoch: 7, Batch: 450/896, Loss: 0.7175, Time: 3.86s\n",
      "Epoch: 7, Batch: 460/896, Loss: 0.7766, Time: 3.85s\n",
      "Epoch: 7, Batch: 470/896, Loss: 0.5757, Time: 3.85s\n",
      "Epoch: 7, Batch: 480/896, Loss: 0.9288, Time: 3.83s\n",
      "Epoch: 7, Batch: 490/896, Loss: 0.3974, Time: 3.85s\n",
      "Epoch: 7, Batch: 500/896, Loss: 0.4069, Time: 3.85s\n",
      "Epoch: 7, Batch: 510/896, Loss: 0.5679, Time: 3.85s\n",
      "Epoch: 7, Batch: 520/896, Loss: 0.7574, Time: 3.84s\n",
      "Epoch: 7, Batch: 530/896, Loss: 0.5437, Time: 3.86s\n",
      "Epoch: 7, Batch: 540/896, Loss: 0.8710, Time: 3.84s\n",
      "Epoch: 7, Batch: 550/896, Loss: 1.2425, Time: 3.84s\n",
      "Epoch: 7, Batch: 560/896, Loss: 0.8992, Time: 3.85s\n",
      "Epoch: 7, Batch: 570/896, Loss: 0.5672, Time: 3.85s\n",
      "Epoch: 7, Batch: 580/896, Loss: 0.6227, Time: 3.85s\n",
      "Epoch: 7, Batch: 590/896, Loss: 1.5458, Time: 3.84s\n",
      "Epoch: 7, Batch: 600/896, Loss: 0.4441, Time: 3.85s\n",
      "Epoch: 7, Batch: 610/896, Loss: 0.7695, Time: 3.85s\n",
      "Epoch: 7, Batch: 620/896, Loss: 0.9503, Time: 3.84s\n",
      "Epoch: 7, Batch: 630/896, Loss: 1.0813, Time: 3.85s\n",
      "Epoch: 7, Batch: 640/896, Loss: 0.4502, Time: 3.84s\n",
      "Epoch: 7, Batch: 650/896, Loss: 1.0857, Time: 3.85s\n",
      "Epoch: 7, Batch: 660/896, Loss: 0.4560, Time: 3.86s\n",
      "Epoch: 7, Batch: 670/896, Loss: 1.6373, Time: 3.85s\n",
      "Epoch: 7, Batch: 680/896, Loss: 0.5402, Time: 3.85s\n",
      "Epoch: 7, Batch: 690/896, Loss: 0.9089, Time: 3.85s\n",
      "Epoch: 7, Batch: 700/896, Loss: 1.3399, Time: 3.84s\n",
      "Epoch: 7, Batch: 710/896, Loss: 0.8447, Time: 3.85s\n",
      "Epoch: 7, Batch: 720/896, Loss: 0.4881, Time: 3.86s\n",
      "Epoch: 7, Batch: 730/896, Loss: 1.4011, Time: 3.84s\n",
      "Epoch: 7, Batch: 740/896, Loss: 1.3202, Time: 3.85s\n",
      "Epoch: 7, Batch: 750/896, Loss: 0.8316, Time: 3.85s\n",
      "Epoch: 7, Batch: 760/896, Loss: 1.0636, Time: 3.85s\n",
      "Epoch: 7, Batch: 770/896, Loss: 1.1803, Time: 3.84s\n",
      "Epoch: 7, Batch: 780/896, Loss: 0.9290, Time: 3.85s\n",
      "Epoch: 7, Batch: 790/896, Loss: 0.8658, Time: 3.85s\n",
      "Epoch: 7, Batch: 800/896, Loss: 1.0914, Time: 3.85s\n",
      "Epoch: 7, Batch: 810/896, Loss: 0.6614, Time: 3.84s\n",
      "Epoch: 7, Batch: 820/896, Loss: 0.4766, Time: 3.86s\n",
      "Epoch: 7, Batch: 830/896, Loss: 0.5773, Time: 3.85s\n",
      "Epoch: 7, Batch: 840/896, Loss: 0.5420, Time: 3.85s\n",
      "Epoch: 7, Batch: 850/896, Loss: 0.5944, Time: 3.85s\n",
      "Epoch: 7, Batch: 860/896, Loss: 0.3913, Time: 3.85s\n",
      "Epoch: 7, Batch: 870/896, Loss: 1.4939, Time: 3.84s\n",
      "Epoch: 7, Batch: 880/896, Loss: 0.8311, Time: 3.85s\n",
      "Epoch: 7, Batch: 890/896, Loss: 1.1370, Time: 3.85s\n",
      "Epoch 8/50: Train Loss: 0.8415, Val Loss: 0.8595, Val IoU: 0.3550, Val Dice: 0.3786\n",
      "Epoch: 8, Batch: 0/896, Loss: 0.7258, Time: 28.78s\n",
      "Epoch: 8, Batch: 10/896, Loss: 0.8390, Time: 3.78s\n",
      "Epoch: 8, Batch: 20/896, Loss: 1.4544, Time: 3.78s\n",
      "Epoch: 8, Batch: 30/896, Loss: 0.6050, Time: 3.78s\n",
      "Epoch: 8, Batch: 40/896, Loss: 0.5563, Time: 3.78s\n",
      "Epoch: 8, Batch: 50/896, Loss: 1.4756, Time: 3.78s\n",
      "Epoch: 8, Batch: 60/896, Loss: 0.7427, Time: 3.80s\n",
      "Epoch: 8, Batch: 70/896, Loss: 1.0041, Time: 3.80s\n",
      "Epoch: 8, Batch: 80/896, Loss: 1.2363, Time: 3.80s\n",
      "Epoch: 8, Batch: 90/896, Loss: 1.0086, Time: 3.78s\n",
      "Epoch: 8, Batch: 100/896, Loss: 1.1136, Time: 3.80s\n",
      "Epoch: 8, Batch: 110/896, Loss: 0.8474, Time: 3.79s\n",
      "Epoch: 8, Batch: 120/896, Loss: 1.2755, Time: 3.81s\n",
      "Epoch: 8, Batch: 130/896, Loss: 0.4964, Time: 3.82s\n",
      "Epoch: 8, Batch: 140/896, Loss: 1.2300, Time: 3.82s\n",
      "Epoch: 8, Batch: 150/896, Loss: 0.6159, Time: 3.82s\n",
      "Epoch: 8, Batch: 160/896, Loss: 0.5794, Time: 3.82s\n",
      "Epoch: 8, Batch: 170/896, Loss: 0.5697, Time: 3.81s\n",
      "Epoch: 8, Batch: 180/896, Loss: 0.5073, Time: 3.81s\n",
      "Epoch: 8, Batch: 190/896, Loss: 0.5898, Time: 3.82s\n",
      "Epoch: 8, Batch: 200/896, Loss: 0.5617, Time: 3.82s\n",
      "Epoch: 8, Batch: 210/896, Loss: 1.0514, Time: 3.81s\n",
      "Epoch: 8, Batch: 220/896, Loss: 0.3461, Time: 3.82s\n",
      "Epoch: 8, Batch: 230/896, Loss: 0.9349, Time: 3.82s\n",
      "Epoch: 8, Batch: 240/896, Loss: 0.4669, Time: 3.81s\n",
      "Epoch: 8, Batch: 250/896, Loss: 0.7110, Time: 3.82s\n",
      "Epoch: 8, Batch: 260/896, Loss: 0.6099, Time: 3.82s\n",
      "Epoch: 8, Batch: 270/896, Loss: 2.4108, Time: 3.81s\n",
      "Epoch: 8, Batch: 280/896, Loss: 0.7212, Time: 3.82s\n",
      "Epoch: 8, Batch: 290/896, Loss: 1.1940, Time: 3.82s\n",
      "Epoch: 8, Batch: 300/896, Loss: 0.5979, Time: 3.81s\n",
      "Epoch: 8, Batch: 310/896, Loss: 0.6786, Time: 3.83s\n",
      "Epoch: 8, Batch: 320/896, Loss: 0.7317, Time: 3.81s\n",
      "Epoch: 8, Batch: 330/896, Loss: 0.7607, Time: 3.82s\n",
      "Epoch: 8, Batch: 340/896, Loss: 0.6898, Time: 3.82s\n",
      "Epoch: 8, Batch: 350/896, Loss: 0.8394, Time: 3.81s\n",
      "Epoch: 8, Batch: 360/896, Loss: 0.8328, Time: 3.82s\n",
      "Epoch: 8, Batch: 370/896, Loss: 0.6208, Time: 3.82s\n",
      "Epoch: 8, Batch: 380/896, Loss: 1.0971, Time: 3.82s\n",
      "Epoch: 8, Batch: 390/896, Loss: 1.0041, Time: 3.82s\n",
      "Epoch: 8, Batch: 400/896, Loss: 0.6982, Time: 3.82s\n",
      "Epoch: 8, Batch: 410/896, Loss: 0.6709, Time: 3.83s\n",
      "Epoch: 8, Batch: 420/896, Loss: 0.8035, Time: 3.82s\n",
      "Epoch: 8, Batch: 430/896, Loss: 0.6111, Time: 3.83s\n",
      "Epoch: 8, Batch: 440/896, Loss: 1.3266, Time: 3.82s\n",
      "Epoch: 8, Batch: 450/896, Loss: 1.1290, Time: 3.81s\n",
      "Epoch: 8, Batch: 460/896, Loss: 0.3893, Time: 3.83s\n",
      "Epoch: 8, Batch: 470/896, Loss: 0.9264, Time: 3.83s\n",
      "Epoch: 8, Batch: 480/896, Loss: 0.5663, Time: 3.83s\n",
      "Epoch: 8, Batch: 490/896, Loss: 1.1493, Time: 3.82s\n",
      "Epoch: 8, Batch: 500/896, Loss: 1.6180, Time: 3.81s\n",
      "Epoch: 8, Batch: 510/896, Loss: 0.6577, Time: 3.83s\n",
      "Epoch: 8, Batch: 520/896, Loss: 0.3817, Time: 3.84s\n",
      "Epoch: 8, Batch: 530/896, Loss: 0.9443, Time: 3.84s\n",
      "Epoch: 8, Batch: 540/896, Loss: 1.0933, Time: 3.83s\n",
      "Epoch: 8, Batch: 550/896, Loss: 0.3471, Time: 3.82s\n",
      "Epoch: 8, Batch: 560/896, Loss: 0.4553, Time: 3.82s\n",
      "Epoch: 8, Batch: 570/896, Loss: 0.9978, Time: 3.83s\n",
      "Epoch: 8, Batch: 580/896, Loss: 0.8798, Time: 3.83s\n",
      "Epoch: 8, Batch: 590/896, Loss: 0.6854, Time: 3.83s\n",
      "Epoch: 8, Batch: 600/896, Loss: 0.6575, Time: 3.82s\n",
      "Epoch: 8, Batch: 610/896, Loss: 0.7745, Time: 3.82s\n",
      "Epoch: 8, Batch: 620/896, Loss: 0.6833, Time: 3.82s\n",
      "Epoch: 8, Batch: 630/896, Loss: 0.4687, Time: 3.83s\n",
      "Epoch: 8, Batch: 640/896, Loss: 1.1522, Time: 3.82s\n",
      "Epoch: 8, Batch: 650/896, Loss: 0.8778, Time: 3.81s\n",
      "Epoch: 8, Batch: 660/896, Loss: 0.4902, Time: 3.82s\n",
      "Epoch: 8, Batch: 670/896, Loss: 1.3832, Time: 3.82s\n",
      "Epoch: 8, Batch: 680/896, Loss: 0.5672, Time: 3.82s\n",
      "Epoch: 8, Batch: 690/896, Loss: 0.8911, Time: 3.83s\n",
      "Epoch: 8, Batch: 700/896, Loss: 1.0988, Time: 3.83s\n",
      "Epoch: 8, Batch: 710/896, Loss: 1.3197, Time: 3.82s\n",
      "Epoch: 8, Batch: 720/896, Loss: 0.7076, Time: 3.83s\n",
      "Epoch: 8, Batch: 730/896, Loss: 0.8112, Time: 3.82s\n",
      "Epoch: 8, Batch: 740/896, Loss: 0.4914, Time: 3.83s\n",
      "Epoch: 8, Batch: 750/896, Loss: 0.8441, Time: 3.82s\n",
      "Epoch: 8, Batch: 760/896, Loss: 0.5522, Time: 3.82s\n",
      "Epoch: 8, Batch: 770/896, Loss: 0.9234, Time: 3.82s\n",
      "Epoch: 8, Batch: 780/896, Loss: 0.5171, Time: 3.82s\n",
      "Epoch: 8, Batch: 790/896, Loss: 0.9802, Time: 3.82s\n",
      "Epoch: 8, Batch: 800/896, Loss: 0.4684, Time: 3.82s\n",
      "Epoch: 8, Batch: 810/896, Loss: 0.6386, Time: 3.83s\n",
      "Epoch: 8, Batch: 820/896, Loss: 0.8403, Time: 3.82s\n",
      "Epoch: 8, Batch: 830/896, Loss: 1.1638, Time: 3.83s\n",
      "Epoch: 8, Batch: 840/896, Loss: 0.5305, Time: 3.82s\n",
      "Epoch: 8, Batch: 850/896, Loss: 1.5294, Time: 3.82s\n",
      "Epoch: 8, Batch: 860/896, Loss: 1.1741, Time: 3.83s\n",
      "Epoch: 8, Batch: 870/896, Loss: 0.7352, Time: 3.82s\n",
      "Epoch: 8, Batch: 880/896, Loss: 1.0289, Time: 3.82s\n",
      "Epoch: 8, Batch: 890/896, Loss: 0.6990, Time: 3.81s\n",
      "Epoch 9/50: Train Loss: 0.8343, Val Loss: 0.8582, Val IoU: 0.3667, Val Dice: 0.3900\n",
      "Saving best model with IoU: 0.3667\n",
      "Epoch: 9, Batch: 0/896, Loss: 1.6383, Time: 28.92s\n",
      "Epoch: 9, Batch: 10/896, Loss: 0.8831, Time: 3.77s\n",
      "Epoch: 9, Batch: 20/896, Loss: 1.2357, Time: 3.77s\n",
      "Epoch: 9, Batch: 30/896, Loss: 1.3577, Time: 3.75s\n",
      "Epoch: 9, Batch: 40/896, Loss: 0.5887, Time: 3.76s\n",
      "Epoch: 9, Batch: 50/896, Loss: 0.3771, Time: 3.79s\n",
      "Epoch: 9, Batch: 60/896, Loss: 1.2493, Time: 3.77s\n",
      "Epoch: 9, Batch: 70/896, Loss: 1.3248, Time: 3.77s\n",
      "Epoch: 9, Batch: 80/896, Loss: 0.9386, Time: 3.78s\n",
      "Epoch: 9, Batch: 90/896, Loss: 1.5224, Time: 3.78s\n",
      "Epoch: 9, Batch: 100/896, Loss: 0.3628, Time: 3.78s\n",
      "Epoch: 9, Batch: 110/896, Loss: 0.3177, Time: 3.78s\n",
      "Epoch: 9, Batch: 120/896, Loss: 1.0561, Time: 3.80s\n",
      "Epoch: 9, Batch: 130/896, Loss: 0.7534, Time: 3.77s\n",
      "Epoch: 9, Batch: 140/896, Loss: 0.5989, Time: 3.79s\n",
      "Epoch: 9, Batch: 150/896, Loss: 1.5340, Time: 3.81s\n",
      "Epoch: 9, Batch: 160/896, Loss: 1.2569, Time: 3.80s\n",
      "Epoch: 9, Batch: 170/896, Loss: 0.6690, Time: 3.81s\n",
      "Epoch: 9, Batch: 180/896, Loss: 1.1487, Time: 3.81s\n",
      "Epoch: 9, Batch: 190/896, Loss: 0.8119, Time: 3.80s\n",
      "Epoch: 9, Batch: 200/896, Loss: 0.5330, Time: 3.81s\n",
      "Epoch: 9, Batch: 210/896, Loss: 0.3389, Time: 3.80s\n",
      "Epoch: 9, Batch: 220/896, Loss: 0.6123, Time: 3.81s\n",
      "Epoch: 9, Batch: 230/896, Loss: 0.5639, Time: 3.80s\n",
      "Epoch: 9, Batch: 240/896, Loss: 0.2562, Time: 3.81s\n",
      "Epoch: 9, Batch: 250/896, Loss: 1.3224, Time: 3.80s\n",
      "Epoch: 9, Batch: 260/896, Loss: 0.3127, Time: 3.81s\n",
      "Epoch: 9, Batch: 270/896, Loss: 1.0572, Time: 3.82s\n",
      "Epoch: 9, Batch: 280/896, Loss: 0.7387, Time: 3.79s\n",
      "Epoch: 9, Batch: 290/896, Loss: 0.8998, Time: 3.81s\n",
      "Epoch: 9, Batch: 300/896, Loss: 1.4789, Time: 3.81s\n",
      "Epoch: 9, Batch: 310/896, Loss: 0.9846, Time: 3.82s\n",
      "Epoch: 9, Batch: 320/896, Loss: 0.9674, Time: 3.81s\n",
      "Epoch: 9, Batch: 330/896, Loss: 0.6217, Time: 3.81s\n",
      "Epoch: 9, Batch: 340/896, Loss: 0.4286, Time: 3.82s\n",
      "Epoch: 9, Batch: 350/896, Loss: 0.6087, Time: 3.82s\n",
      "Epoch: 9, Batch: 360/896, Loss: 0.4082, Time: 3.82s\n",
      "Epoch: 9, Batch: 370/896, Loss: 0.5263, Time: 3.82s\n",
      "Epoch: 9, Batch: 380/896, Loss: 0.4725, Time: 3.81s\n",
      "Epoch: 9, Batch: 390/896, Loss: 0.9557, Time: 3.81s\n",
      "Epoch: 9, Batch: 400/896, Loss: 0.4134, Time: 3.81s\n",
      "Epoch: 9, Batch: 410/896, Loss: 0.5550, Time: 3.82s\n",
      "Epoch: 9, Batch: 420/896, Loss: 0.5518, Time: 3.83s\n",
      "Epoch: 9, Batch: 430/896, Loss: 0.7528, Time: 3.82s\n",
      "Epoch: 9, Batch: 440/896, Loss: 0.5172, Time: 3.82s\n",
      "Epoch: 9, Batch: 450/896, Loss: 0.7026, Time: 3.82s\n",
      "Epoch: 9, Batch: 460/896, Loss: 1.2288, Time: 3.82s\n",
      "Epoch: 9, Batch: 470/896, Loss: 0.5701, Time: 3.82s\n",
      "Epoch: 9, Batch: 480/896, Loss: 0.3628, Time: 3.82s\n",
      "Epoch: 9, Batch: 490/896, Loss: 0.7134, Time: 3.81s\n",
      "Epoch: 9, Batch: 500/896, Loss: 0.3078, Time: 3.82s\n",
      "Epoch: 9, Batch: 510/896, Loss: 0.7614, Time: 3.80s\n",
      "Epoch: 9, Batch: 520/896, Loss: 1.2722, Time: 3.81s\n",
      "Epoch: 9, Batch: 530/896, Loss: 1.0183, Time: 3.82s\n",
      "Epoch: 9, Batch: 540/896, Loss: 0.5587, Time: 3.82s\n",
      "Epoch: 9, Batch: 550/896, Loss: 0.7188, Time: 3.81s\n",
      "Epoch: 9, Batch: 560/896, Loss: 1.4432, Time: 3.81s\n",
      "Epoch: 9, Batch: 570/896, Loss: 0.5642, Time: 3.82s\n",
      "Epoch: 9, Batch: 580/896, Loss: 0.9082, Time: 3.82s\n",
      "Epoch: 9, Batch: 590/896, Loss: 0.7148, Time: 3.82s\n",
      "Epoch: 9, Batch: 600/896, Loss: 0.6010, Time: 3.82s\n",
      "Epoch: 9, Batch: 610/896, Loss: 0.7726, Time: 3.82s\n",
      "Epoch: 9, Batch: 620/896, Loss: 0.8070, Time: 3.82s\n",
      "Epoch: 9, Batch: 630/896, Loss: 1.1764, Time: 3.82s\n",
      "Epoch: 9, Batch: 640/896, Loss: 1.8443, Time: 3.80s\n",
      "Epoch: 9, Batch: 650/896, Loss: 0.6975, Time: 3.82s\n",
      "Epoch: 9, Batch: 660/896, Loss: 0.5712, Time: 3.82s\n",
      "Epoch: 9, Batch: 670/896, Loss: 0.4697, Time: 3.80s\n",
      "Epoch: 9, Batch: 680/896, Loss: 1.4443, Time: 3.82s\n",
      "Epoch: 9, Batch: 690/896, Loss: 1.3447, Time: 3.82s\n",
      "Epoch: 9, Batch: 700/896, Loss: 1.1276, Time: 3.82s\n",
      "Epoch: 9, Batch: 710/896, Loss: 0.5906, Time: 3.81s\n",
      "Epoch: 9, Batch: 720/896, Loss: 0.4953, Time: 3.82s\n",
      "Epoch: 9, Batch: 730/896, Loss: 0.6398, Time: 3.82s\n",
      "Epoch: 9, Batch: 740/896, Loss: 0.5830, Time: 3.82s\n",
      "Epoch: 9, Batch: 750/896, Loss: 0.3095, Time: 3.81s\n",
      "Epoch: 9, Batch: 760/896, Loss: 1.0685, Time: 3.82s\n",
      "Epoch: 9, Batch: 770/896, Loss: 0.5952, Time: 3.82s\n",
      "Epoch: 9, Batch: 780/896, Loss: 1.1298, Time: 3.82s\n",
      "Epoch: 9, Batch: 790/896, Loss: 0.8581, Time: 3.83s\n",
      "Epoch: 9, Batch: 800/896, Loss: 1.1173, Time: 3.82s\n",
      "Epoch: 9, Batch: 810/896, Loss: 0.6502, Time: 3.82s\n",
      "Epoch: 9, Batch: 820/896, Loss: 0.8243, Time: 3.82s\n",
      "Epoch: 9, Batch: 830/896, Loss: 0.7312, Time: 3.82s\n",
      "Epoch: 9, Batch: 840/896, Loss: 1.1078, Time: 3.81s\n",
      "Epoch: 9, Batch: 850/896, Loss: 0.9614, Time: 3.83s\n",
      "Epoch: 9, Batch: 860/896, Loss: 1.2759, Time: 3.81s\n",
      "Epoch: 9, Batch: 870/896, Loss: 0.7208, Time: 3.82s\n",
      "Epoch: 9, Batch: 880/896, Loss: 0.4381, Time: 3.81s\n",
      "Epoch: 9, Batch: 890/896, Loss: 0.6853, Time: 3.81s\n",
      "Epoch 10/50: Train Loss: 0.8285, Val Loss: 0.8408, Val IoU: 0.3715, Val Dice: 0.3946\n",
      "Saving best model with IoU: 0.3715\n",
      "Epoch: 10, Batch: 0/896, Loss: 0.9011, Time: 28.81s\n",
      "Epoch: 10, Batch: 10/896, Loss: 0.5648, Time: 3.75s\n",
      "Epoch: 10, Batch: 20/896, Loss: 0.3498, Time: 3.75s\n",
      "Epoch: 10, Batch: 30/896, Loss: 0.6157, Time: 3.76s\n",
      "Epoch: 10, Batch: 40/896, Loss: 1.1185, Time: 3.77s\n",
      "Epoch: 10, Batch: 50/896, Loss: 0.4060, Time: 3.76s\n",
      "Epoch: 10, Batch: 60/896, Loss: 0.6804, Time: 3.77s\n",
      "Epoch: 10, Batch: 70/896, Loss: 0.5003, Time: 3.77s\n",
      "Epoch: 10, Batch: 80/896, Loss: 0.6387, Time: 3.76s\n",
      "Epoch: 10, Batch: 90/896, Loss: 0.9492, Time: 3.79s\n",
      "Epoch: 10, Batch: 100/896, Loss: 0.6510, Time: 3.78s\n",
      "Epoch: 10, Batch: 110/896, Loss: 1.4871, Time: 3.78s\n",
      "Epoch: 10, Batch: 120/896, Loss: 0.4650, Time: 3.77s\n",
      "Epoch: 10, Batch: 130/896, Loss: 1.3267, Time: 3.79s\n",
      "Epoch: 10, Batch: 140/896, Loss: 0.3966, Time: 3.78s\n",
      "Epoch: 10, Batch: 150/896, Loss: 0.5363, Time: 3.78s\n",
      "Epoch: 10, Batch: 160/896, Loss: 1.2261, Time: 3.79s\n",
      "Epoch: 10, Batch: 170/896, Loss: 1.0761, Time: 3.78s\n",
      "Epoch: 10, Batch: 180/896, Loss: 0.5977, Time: 3.78s\n",
      "Epoch: 10, Batch: 190/896, Loss: 1.5368, Time: 3.78s\n",
      "Epoch: 10, Batch: 200/896, Loss: 0.9552, Time: 3.81s\n",
      "Epoch: 10, Batch: 210/896, Loss: 0.7605, Time: 3.80s\n",
      "Epoch: 10, Batch: 220/896, Loss: 0.8561, Time: 3.81s\n",
      "Epoch: 10, Batch: 230/896, Loss: 0.5248, Time: 3.79s\n",
      "Epoch: 10, Batch: 240/896, Loss: 0.4800, Time: 3.80s\n",
      "Epoch: 10, Batch: 250/896, Loss: 1.3147, Time: 3.80s\n",
      "Epoch: 10, Batch: 260/896, Loss: 0.9257, Time: 3.80s\n",
      "Epoch: 10, Batch: 270/896, Loss: 0.5861, Time: 3.79s\n",
      "Epoch: 10, Batch: 280/896, Loss: 1.1175, Time: 3.80s\n",
      "Epoch: 10, Batch: 290/896, Loss: 0.6934, Time: 3.80s\n",
      "Epoch: 10, Batch: 300/896, Loss: 1.0453, Time: 3.80s\n",
      "Epoch: 10, Batch: 310/896, Loss: 0.6539, Time: 3.81s\n",
      "Epoch: 10, Batch: 320/896, Loss: 0.8657, Time: 3.81s\n",
      "Epoch: 10, Batch: 330/896, Loss: 0.9594, Time: 3.80s\n",
      "Epoch: 10, Batch: 340/896, Loss: 0.8932, Time: 3.82s\n",
      "Epoch: 10, Batch: 350/896, Loss: 1.4824, Time: 3.81s\n",
      "Epoch: 10, Batch: 360/896, Loss: 1.3687, Time: 3.79s\n",
      "Epoch: 10, Batch: 370/896, Loss: 0.7796, Time: 3.80s\n",
      "Epoch: 10, Batch: 380/896, Loss: 1.0926, Time: 3.81s\n",
      "Epoch: 10, Batch: 390/896, Loss: 0.5919, Time: 3.81s\n",
      "Epoch: 10, Batch: 400/896, Loss: 1.1754, Time: 3.82s\n",
      "Epoch: 10, Batch: 410/896, Loss: 0.7844, Time: 3.81s\n",
      "Epoch: 10, Batch: 420/896, Loss: 0.4902, Time: 3.81s\n",
      "Epoch: 10, Batch: 430/896, Loss: 0.9248, Time: 3.82s\n",
      "Epoch: 10, Batch: 440/896, Loss: 0.6352, Time: 3.81s\n",
      "Epoch: 10, Batch: 450/896, Loss: 0.8010, Time: 3.82s\n",
      "Epoch: 10, Batch: 460/896, Loss: 0.3399, Time: 3.81s\n",
      "Epoch: 10, Batch: 470/896, Loss: 1.1317, Time: 3.81s\n",
      "Epoch: 10, Batch: 480/896, Loss: 1.3603, Time: 3.80s\n",
      "Epoch: 10, Batch: 490/896, Loss: 0.4809, Time: 3.82s\n",
      "Epoch: 10, Batch: 500/896, Loss: 0.7529, Time: 3.82s\n",
      "Epoch: 10, Batch: 510/896, Loss: 0.9088, Time: 3.81s\n",
      "Epoch: 10, Batch: 520/896, Loss: 1.5413, Time: 3.82s\n",
      "Epoch: 10, Batch: 530/896, Loss: 1.1217, Time: 3.81s\n",
      "Epoch: 10, Batch: 540/896, Loss: 0.7790, Time: 3.81s\n",
      "Epoch: 10, Batch: 550/896, Loss: 0.3951, Time: 3.81s\n",
      "Epoch: 10, Batch: 560/896, Loss: 0.5844, Time: 3.81s\n",
      "Epoch: 10, Batch: 570/896, Loss: 0.9158, Time: 3.81s\n",
      "Epoch: 10, Batch: 580/896, Loss: 0.7298, Time: 3.79s\n",
      "Epoch: 10, Batch: 590/896, Loss: 0.7944, Time: 3.82s\n",
      "Epoch: 10, Batch: 600/896, Loss: 0.9652, Time: 3.82s\n",
      "Epoch: 10, Batch: 610/896, Loss: 0.8495, Time: 3.82s\n",
      "Epoch: 10, Batch: 620/896, Loss: 0.6638, Time: 3.82s\n",
      "Epoch: 10, Batch: 630/896, Loss: 2.0228, Time: 3.81s\n",
      "Epoch: 10, Batch: 640/896, Loss: 0.6213, Time: 3.81s\n",
      "Epoch: 10, Batch: 650/896, Loss: 0.9133, Time: 3.82s\n",
      "Epoch: 10, Batch: 660/896, Loss: 0.7803, Time: 3.81s\n",
      "Epoch: 10, Batch: 670/896, Loss: 0.9988, Time: 3.81s\n",
      "Epoch: 10, Batch: 680/896, Loss: 0.3876, Time: 3.82s\n",
      "Epoch: 10, Batch: 690/896, Loss: 0.6536, Time: 3.82s\n",
      "Epoch: 10, Batch: 700/896, Loss: 0.9570, Time: 3.82s\n",
      "Epoch: 10, Batch: 710/896, Loss: 0.7480, Time: 3.82s\n",
      "Epoch: 10, Batch: 720/896, Loss: 0.6466, Time: 3.81s\n",
      "Epoch: 10, Batch: 730/896, Loss: 0.9199, Time: 3.79s\n",
      "Epoch: 10, Batch: 740/896, Loss: 0.6051, Time: 3.82s\n",
      "Epoch: 10, Batch: 750/896, Loss: 0.6808, Time: 3.82s\n",
      "Epoch: 10, Batch: 760/896, Loss: 0.5989, Time: 3.82s\n",
      "Epoch: 10, Batch: 770/896, Loss: 0.6161, Time: 3.81s\n",
      "Epoch: 10, Batch: 780/896, Loss: 0.4796, Time: 3.81s\n",
      "Epoch: 10, Batch: 790/896, Loss: 0.9004, Time: 3.82s\n",
      "Epoch: 10, Batch: 800/896, Loss: 0.3000, Time: 3.81s\n",
      "Epoch: 10, Batch: 810/896, Loss: 0.9343, Time: 3.81s\n",
      "Epoch: 10, Batch: 820/896, Loss: 1.0620, Time: 3.81s\n",
      "Epoch: 10, Batch: 830/896, Loss: 0.5785, Time: 3.80s\n",
      "Epoch: 10, Batch: 840/896, Loss: 1.0117, Time: 3.82s\n",
      "Epoch: 10, Batch: 850/896, Loss: 1.0012, Time: 3.82s\n",
      "Epoch: 10, Batch: 860/896, Loss: 0.4927, Time: 3.80s\n",
      "Epoch: 10, Batch: 870/896, Loss: 0.4909, Time: 3.82s\n",
      "Epoch: 10, Batch: 880/896, Loss: 1.0578, Time: 3.82s\n",
      "Epoch: 10, Batch: 890/896, Loss: 0.7521, Time: 3.81s\n",
      "Epoch 11/50: Train Loss: 0.8215, Val Loss: 0.8584, Val IoU: 0.3636, Val Dice: 0.3860\n",
      "Epoch: 11, Batch: 0/896, Loss: 1.2539, Time: 28.74s\n",
      "Epoch: 11, Batch: 10/896, Loss: 0.6499, Time: 3.74s\n",
      "Epoch: 11, Batch: 20/896, Loss: 0.5959, Time: 3.74s\n",
      "Epoch: 11, Batch: 30/896, Loss: 1.1060, Time: 3.77s\n",
      "Epoch: 11, Batch: 40/896, Loss: 0.7284, Time: 3.74s\n",
      "Epoch: 11, Batch: 50/896, Loss: 0.9197, Time: 3.77s\n",
      "Epoch: 11, Batch: 60/896, Loss: 0.8084, Time: 3.76s\n",
      "Epoch: 11, Batch: 70/896, Loss: 0.6177, Time: 3.76s\n",
      "Epoch: 11, Batch: 80/896, Loss: 1.3259, Time: 3.77s\n",
      "Epoch: 11, Batch: 90/896, Loss: 1.0903, Time: 3.78s\n",
      "Epoch: 11, Batch: 100/896, Loss: 0.3158, Time: 3.77s\n",
      "Epoch: 11, Batch: 110/896, Loss: 0.3619, Time: 3.78s\n",
      "Epoch: 11, Batch: 120/896, Loss: 0.9311, Time: 3.77s\n",
      "Epoch: 11, Batch: 130/896, Loss: 0.5710, Time: 3.79s\n",
      "Epoch: 11, Batch: 140/896, Loss: 0.7369, Time: 3.78s\n",
      "Epoch: 11, Batch: 150/896, Loss: 0.6735, Time: 3.77s\n",
      "Epoch: 11, Batch: 160/896, Loss: 1.0515, Time: 3.77s\n",
      "Epoch: 11, Batch: 170/896, Loss: 0.5244, Time: 3.79s\n",
      "Epoch: 11, Batch: 180/896, Loss: 0.9609, Time: 3.78s\n",
      "Epoch: 11, Batch: 190/896, Loss: 0.5602, Time: 3.80s\n",
      "Epoch: 11, Batch: 200/896, Loss: 0.5191, Time: 3.78s\n",
      "Epoch: 11, Batch: 210/896, Loss: 0.5725, Time: 3.79s\n",
      "Epoch: 11, Batch: 220/896, Loss: 0.6773, Time: 3.80s\n",
      "Epoch: 11, Batch: 230/896, Loss: 0.9207, Time: 3.79s\n",
      "Epoch: 11, Batch: 240/896, Loss: 1.4525, Time: 3.81s\n",
      "Epoch: 11, Batch: 250/896, Loss: 0.5781, Time: 3.79s\n",
      "Epoch: 11, Batch: 260/896, Loss: 0.5843, Time: 3.79s\n",
      "Epoch: 11, Batch: 270/896, Loss: 1.4063, Time: 3.80s\n",
      "Epoch: 11, Batch: 280/896, Loss: 0.3153, Time: 3.79s\n",
      "Epoch: 11, Batch: 290/896, Loss: 0.7952, Time: 3.80s\n",
      "Epoch: 11, Batch: 300/896, Loss: 0.6223, Time: 3.78s\n",
      "Epoch: 11, Batch: 310/896, Loss: 0.7989, Time: 3.80s\n",
      "Epoch: 11, Batch: 320/896, Loss: 0.9195, Time: 3.79s\n",
      "Epoch: 11, Batch: 330/896, Loss: 1.0080, Time: 3.81s\n",
      "Epoch: 11, Batch: 340/896, Loss: 0.7660, Time: 3.81s\n",
      "Epoch: 11, Batch: 350/896, Loss: 1.2216, Time: 3.82s\n",
      "Epoch: 11, Batch: 360/896, Loss: 0.9896, Time: 3.80s\n",
      "Epoch: 11, Batch: 370/896, Loss: 0.9018, Time: 3.79s\n",
      "Epoch: 11, Batch: 380/896, Loss: 0.7854, Time: 3.81s\n",
      "Epoch: 11, Batch: 390/896, Loss: 1.5797, Time: 3.80s\n",
      "Epoch: 11, Batch: 400/896, Loss: 1.1899, Time: 3.81s\n",
      "Epoch: 11, Batch: 410/896, Loss: 0.7457, Time: 3.81s\n",
      "Epoch: 11, Batch: 420/896, Loss: 1.1384, Time: 3.81s\n",
      "Epoch: 11, Batch: 430/896, Loss: 1.1352, Time: 3.82s\n",
      "Epoch: 11, Batch: 440/896, Loss: 0.6900, Time: 3.81s\n",
      "Epoch: 11, Batch: 450/896, Loss: 1.0541, Time: 3.80s\n",
      "Epoch: 11, Batch: 460/896, Loss: 0.6620, Time: 3.81s\n",
      "Epoch: 11, Batch: 470/896, Loss: 0.4311, Time: 3.80s\n",
      "Epoch: 11, Batch: 480/896, Loss: 0.3361, Time: 3.82s\n",
      "Epoch: 11, Batch: 490/896, Loss: 1.0256, Time: 3.81s\n",
      "Epoch: 11, Batch: 500/896, Loss: 0.5215, Time: 3.80s\n",
      "Epoch: 11, Batch: 510/896, Loss: 0.6259, Time: 3.81s\n",
      "Epoch: 11, Batch: 520/896, Loss: 0.7123, Time: 3.81s\n",
      "Epoch: 11, Batch: 530/896, Loss: 0.4688, Time: 3.80s\n",
      "Epoch: 11, Batch: 540/896, Loss: 0.4000, Time: 3.80s\n",
      "Epoch: 11, Batch: 550/896, Loss: 0.7461, Time: 3.81s\n",
      "Epoch: 11, Batch: 560/896, Loss: 0.9746, Time: 3.79s\n",
      "Epoch: 11, Batch: 570/896, Loss: 1.1185, Time: 3.82s\n",
      "Epoch: 11, Batch: 580/896, Loss: 0.9573, Time: 3.82s\n",
      "Epoch: 11, Batch: 590/896, Loss: 0.6662, Time: 3.81s\n",
      "Epoch: 11, Batch: 600/896, Loss: 1.1275, Time: 3.81s\n",
      "Epoch: 11, Batch: 610/896, Loss: 0.7771, Time: 3.82s\n",
      "Epoch: 11, Batch: 620/896, Loss: 0.6163, Time: 3.82s\n",
      "Epoch: 11, Batch: 630/896, Loss: 0.7906, Time: 3.79s\n",
      "Epoch: 11, Batch: 640/896, Loss: 0.3937, Time: 3.80s\n",
      "Epoch: 11, Batch: 650/896, Loss: 0.7658, Time: 3.82s\n",
      "Epoch: 11, Batch: 660/896, Loss: 0.8389, Time: 3.80s\n",
      "Epoch: 11, Batch: 670/896, Loss: 0.7905, Time: 3.81s\n",
      "Epoch: 11, Batch: 680/896, Loss: 0.4054, Time: 3.81s\n",
      "Epoch: 11, Batch: 690/896, Loss: 1.0407, Time: 3.80s\n",
      "Epoch: 11, Batch: 700/896, Loss: 1.0210, Time: 3.81s\n",
      "Epoch: 11, Batch: 710/896, Loss: 0.4787, Time: 3.81s\n",
      "Epoch: 11, Batch: 720/896, Loss: 0.7091, Time: 3.80s\n",
      "Epoch: 11, Batch: 730/896, Loss: 0.5734, Time: 3.82s\n",
      "Epoch: 11, Batch: 740/896, Loss: 0.9390, Time: 3.82s\n",
      "Epoch: 11, Batch: 750/896, Loss: 0.9809, Time: 3.80s\n",
      "Epoch: 11, Batch: 760/896, Loss: 0.5161, Time: 3.81s\n",
      "Epoch: 11, Batch: 770/896, Loss: 0.7554, Time: 3.80s\n",
      "Epoch: 11, Batch: 780/896, Loss: 0.4203, Time: 3.82s\n",
      "Epoch: 11, Batch: 790/896, Loss: 0.9131, Time: 3.80s\n",
      "Epoch: 11, Batch: 800/896, Loss: 0.6950, Time: 3.81s\n",
      "Epoch: 11, Batch: 810/896, Loss: 1.0845, Time: 3.80s\n",
      "Epoch: 11, Batch: 820/896, Loss: 0.8840, Time: 3.82s\n",
      "Epoch: 11, Batch: 830/896, Loss: 0.8004, Time: 3.80s\n",
      "Epoch: 11, Batch: 840/896, Loss: 0.4022, Time: 3.80s\n",
      "Epoch: 11, Batch: 850/896, Loss: 0.4606, Time: 3.81s\n",
      "Epoch: 11, Batch: 860/896, Loss: 0.8164, Time: 3.82s\n",
      "Epoch: 11, Batch: 870/896, Loss: 0.9056, Time: 3.81s\n",
      "Epoch: 11, Batch: 880/896, Loss: 0.4726, Time: 3.81s\n",
      "Epoch: 11, Batch: 890/896, Loss: 0.8651, Time: 3.82s\n",
      "Epoch 12/50: Train Loss: 0.8194, Val Loss: 0.8440, Val IoU: 0.3679, Val Dice: 0.3914\n",
      "Epoch: 12, Batch: 0/896, Loss: 0.5678, Time: 28.93s\n",
      "Epoch: 12, Batch: 10/896, Loss: 0.9735, Time: 3.74s\n",
      "Epoch: 12, Batch: 20/896, Loss: 0.7722, Time: 3.74s\n",
      "Epoch: 12, Batch: 30/896, Loss: 1.2305, Time: 3.76s\n",
      "Epoch: 12, Batch: 40/896, Loss: 0.8413, Time: 3.75s\n",
      "Epoch: 12, Batch: 50/896, Loss: 0.4635, Time: 3.75s\n",
      "Epoch: 12, Batch: 60/896, Loss: 0.5939, Time: 3.75s\n",
      "Epoch: 12, Batch: 70/896, Loss: 0.4100, Time: 3.77s\n",
      "Epoch: 12, Batch: 80/896, Loss: 0.4332, Time: 3.78s\n",
      "Epoch: 12, Batch: 90/896, Loss: 0.7643, Time: 3.78s\n",
      "Epoch: 12, Batch: 100/896, Loss: 0.7263, Time: 3.77s\n",
      "Epoch: 12, Batch: 110/896, Loss: 0.4951, Time: 3.79s\n",
      "Epoch: 12, Batch: 120/896, Loss: 0.4057, Time: 3.77s\n",
      "Epoch: 12, Batch: 130/896, Loss: 0.4417, Time: 3.78s\n",
      "Epoch: 12, Batch: 140/896, Loss: 0.7593, Time: 3.77s\n",
      "Epoch: 12, Batch: 150/896, Loss: 0.6793, Time: 3.78s\n",
      "Epoch: 12, Batch: 160/896, Loss: 0.6113, Time: 3.78s\n",
      "Epoch: 12, Batch: 170/896, Loss: 1.1946, Time: 3.77s\n",
      "Epoch: 12, Batch: 180/896, Loss: 0.7722, Time: 3.78s\n",
      "Epoch: 12, Batch: 190/896, Loss: 0.5187, Time: 3.78s\n",
      "Epoch: 12, Batch: 200/896, Loss: 0.8928, Time: 3.78s\n",
      "Epoch: 12, Batch: 210/896, Loss: 0.4198, Time: 3.79s\n",
      "Epoch: 12, Batch: 220/896, Loss: 0.8367, Time: 3.80s\n",
      "Epoch: 12, Batch: 230/896, Loss: 0.4394, Time: 3.79s\n",
      "Epoch: 12, Batch: 240/896, Loss: 0.7881, Time: 3.81s\n",
      "Epoch: 12, Batch: 250/896, Loss: 0.5775, Time: 3.80s\n",
      "Epoch: 12, Batch: 260/896, Loss: 0.6535, Time: 3.80s\n",
      "Epoch: 12, Batch: 270/896, Loss: 0.8895, Time: 3.80s\n",
      "Epoch: 12, Batch: 280/896, Loss: 1.1316, Time: 3.78s\n",
      "Epoch: 12, Batch: 290/896, Loss: 0.3871, Time: 3.79s\n",
      "Epoch: 12, Batch: 300/896, Loss: 1.2156, Time: 3.79s\n",
      "Epoch: 12, Batch: 310/896, Loss: 0.2576, Time: 3.79s\n",
      "Epoch: 12, Batch: 320/896, Loss: 1.0425, Time: 3.79s\n",
      "Epoch: 12, Batch: 330/896, Loss: 0.4811, Time: 3.79s\n",
      "Epoch: 12, Batch: 340/896, Loss: 0.5276, Time: 3.79s\n",
      "Epoch: 12, Batch: 350/896, Loss: 0.8077, Time: 3.79s\n",
      "Epoch: 12, Batch: 360/896, Loss: 1.4789, Time: 3.79s\n",
      "Epoch: 12, Batch: 370/896, Loss: 1.3306, Time: 3.82s\n",
      "Epoch: 12, Batch: 380/896, Loss: 1.2205, Time: 3.80s\n",
      "Epoch: 12, Batch: 390/896, Loss: 1.1708, Time: 3.81s\n",
      "Epoch: 12, Batch: 400/896, Loss: 0.7032, Time: 3.81s\n",
      "Epoch: 12, Batch: 410/896, Loss: 1.0467, Time: 3.80s\n",
      "Epoch: 12, Batch: 420/896, Loss: 0.4101, Time: 3.80s\n",
      "Epoch: 12, Batch: 430/896, Loss: 1.3367, Time: 3.80s\n",
      "Epoch: 12, Batch: 440/896, Loss: 0.7364, Time: 3.80s\n",
      "Epoch: 12, Batch: 450/896, Loss: 0.8596, Time: 3.80s\n",
      "Epoch: 12, Batch: 460/896, Loss: 0.4211, Time: 3.81s\n",
      "Epoch: 12, Batch: 470/896, Loss: 0.4939, Time: 3.79s\n",
      "Epoch: 12, Batch: 480/896, Loss: 1.1888, Time: 3.81s\n",
      "Epoch: 12, Batch: 490/896, Loss: 0.5938, Time: 3.81s\n",
      "Epoch: 12, Batch: 500/896, Loss: 0.7544, Time: 3.80s\n",
      "Epoch: 12, Batch: 510/896, Loss: 1.6860, Time: 3.79s\n",
      "Epoch: 12, Batch: 520/896, Loss: 0.5122, Time: 3.81s\n",
      "Epoch: 12, Batch: 530/896, Loss: 0.8230, Time: 3.81s\n",
      "Epoch: 12, Batch: 540/896, Loss: 0.8383, Time: 3.81s\n",
      "Epoch: 12, Batch: 550/896, Loss: 0.6450, Time: 3.80s\n",
      "Epoch: 12, Batch: 560/896, Loss: 0.9185, Time: 3.82s\n",
      "Epoch: 12, Batch: 570/896, Loss: 1.1928, Time: 3.82s\n",
      "Epoch: 12, Batch: 580/896, Loss: 0.6906, Time: 3.80s\n",
      "Epoch: 12, Batch: 590/896, Loss: 0.5460, Time: 3.81s\n",
      "Epoch: 12, Batch: 600/896, Loss: 0.4930, Time: 3.80s\n",
      "Epoch: 12, Batch: 610/896, Loss: 0.8474, Time: 3.80s\n",
      "Epoch: 12, Batch: 620/896, Loss: 0.7979, Time: 3.81s\n",
      "Epoch: 12, Batch: 630/896, Loss: 1.4031, Time: 3.81s\n",
      "Epoch: 12, Batch: 640/896, Loss: 0.7217, Time: 3.79s\n",
      "Epoch: 12, Batch: 650/896, Loss: 1.0275, Time: 3.81s\n",
      "Epoch: 12, Batch: 660/896, Loss: 0.7767, Time: 3.81s\n",
      "Epoch: 12, Batch: 670/896, Loss: 0.3488, Time: 3.80s\n",
      "Epoch: 12, Batch: 680/896, Loss: 1.4712, Time: 3.81s\n",
      "Epoch: 12, Batch: 690/896, Loss: 1.6146, Time: 3.79s\n",
      "Epoch: 12, Batch: 700/896, Loss: 0.7344, Time: 3.81s\n",
      "Epoch: 12, Batch: 710/896, Loss: 0.3412, Time: 3.82s\n",
      "Epoch: 12, Batch: 720/896, Loss: 0.3088, Time: 3.80s\n",
      "Epoch: 12, Batch: 730/896, Loss: 1.1987, Time: 3.80s\n",
      "Epoch: 12, Batch: 740/896, Loss: 0.3525, Time: 3.81s\n",
      "Epoch: 12, Batch: 750/896, Loss: 0.5564, Time: 3.82s\n",
      "Epoch: 12, Batch: 760/896, Loss: 0.8403, Time: 3.81s\n",
      "Epoch: 12, Batch: 770/896, Loss: 1.4957, Time: 3.82s\n",
      "Epoch: 12, Batch: 780/896, Loss: 0.5370, Time: 3.80s\n",
      "Epoch: 12, Batch: 790/896, Loss: 0.5982, Time: 3.82s\n",
      "Epoch: 12, Batch: 800/896, Loss: 1.1562, Time: 3.80s\n",
      "Epoch: 12, Batch: 810/896, Loss: 1.1515, Time: 3.82s\n",
      "Epoch: 12, Batch: 820/896, Loss: 0.5765, Time: 3.81s\n",
      "Epoch: 12, Batch: 830/896, Loss: 1.3313, Time: 3.81s\n",
      "Epoch: 12, Batch: 840/896, Loss: 0.6435, Time: 3.81s\n",
      "Epoch: 12, Batch: 850/896, Loss: 0.4256, Time: 3.79s\n",
      "Epoch: 12, Batch: 860/896, Loss: 0.4812, Time: 3.81s\n",
      "Epoch: 12, Batch: 870/896, Loss: 0.8897, Time: 3.82s\n",
      "Epoch: 12, Batch: 880/896, Loss: 0.5538, Time: 3.81s\n",
      "Epoch: 12, Batch: 890/896, Loss: 0.6907, Time: 3.81s\n",
      "Epoch 13/50: Train Loss: 0.8152, Val Loss: 0.8516, Val IoU: 0.3633, Val Dice: 0.3856\n",
      "Epoch: 13, Batch: 0/896, Loss: 1.3084, Time: 28.73s\n",
      "Epoch: 13, Batch: 10/896, Loss: 0.9875, Time: 3.74s\n",
      "Epoch: 13, Batch: 20/896, Loss: 0.8095, Time: 3.75s\n",
      "Epoch: 13, Batch: 30/896, Loss: 1.1194, Time: 3.75s\n",
      "Epoch: 13, Batch: 40/896, Loss: 1.3527, Time: 3.76s\n",
      "Epoch: 13, Batch: 50/896, Loss: 0.3478, Time: 3.77s\n",
      "Epoch: 13, Batch: 60/896, Loss: 0.7742, Time: 3.75s\n",
      "Epoch: 13, Batch: 70/896, Loss: 0.5715, Time: 3.76s\n",
      "Epoch: 13, Batch: 80/896, Loss: 0.5013, Time: 3.77s\n",
      "Epoch: 13, Batch: 90/896, Loss: 0.5303, Time: 3.77s\n",
      "Epoch: 13, Batch: 100/896, Loss: 0.9410, Time: 3.76s\n",
      "Epoch: 13, Batch: 110/896, Loss: 0.7729, Time: 3.76s\n",
      "Epoch: 13, Batch: 120/896, Loss: 1.0638, Time: 3.77s\n",
      "Epoch: 13, Batch: 130/896, Loss: 1.0355, Time: 3.78s\n",
      "Epoch: 13, Batch: 140/896, Loss: 1.2297, Time: 3.79s\n",
      "Epoch: 13, Batch: 150/896, Loss: 0.6318, Time: 3.78s\n",
      "Epoch: 13, Batch: 160/896, Loss: 0.9995, Time: 3.78s\n",
      "Epoch: 13, Batch: 170/896, Loss: 0.4472, Time: 3.78s\n",
      "Epoch: 13, Batch: 180/896, Loss: 1.0553, Time: 3.78s\n",
      "Epoch: 13, Batch: 190/896, Loss: 1.1121, Time: 3.80s\n",
      "Epoch: 13, Batch: 200/896, Loss: 0.7481, Time: 3.79s\n",
      "Epoch: 13, Batch: 210/896, Loss: 1.0101, Time: 3.79s\n",
      "Epoch: 13, Batch: 220/896, Loss: 1.6798, Time: 3.80s\n",
      "Epoch: 13, Batch: 230/896, Loss: 1.6715, Time: 3.80s\n",
      "Epoch: 13, Batch: 240/896, Loss: 0.9035, Time: 3.79s\n",
      "Epoch: 13, Batch: 250/896, Loss: 0.5003, Time: 3.77s\n",
      "Epoch: 13, Batch: 260/896, Loss: 0.5383, Time: 3.80s\n",
      "Epoch: 13, Batch: 270/896, Loss: 0.3633, Time: 3.79s\n",
      "Epoch: 13, Batch: 280/896, Loss: 0.3862, Time: 3.78s\n",
      "Epoch: 13, Batch: 290/896, Loss: 0.9694, Time: 3.79s\n",
      "Epoch: 13, Batch: 300/896, Loss: 0.3828, Time: 3.80s\n",
      "Epoch: 13, Batch: 310/896, Loss: 0.6444, Time: 3.80s\n",
      "Epoch: 13, Batch: 320/896, Loss: 0.6549, Time: 3.81s\n",
      "Epoch: 13, Batch: 330/896, Loss: 0.3754, Time: 3.79s\n",
      "Epoch: 13, Batch: 340/896, Loss: 0.6189, Time: 3.80s\n",
      "Epoch: 13, Batch: 350/896, Loss: 0.7572, Time: 3.80s\n",
      "Epoch: 13, Batch: 360/896, Loss: 0.7585, Time: 3.80s\n",
      "Epoch: 13, Batch: 370/896, Loss: 0.6645, Time: 3.79s\n",
      "Epoch: 13, Batch: 380/896, Loss: 0.7217, Time: 3.80s\n",
      "Epoch: 13, Batch: 390/896, Loss: 0.7400, Time: 3.79s\n",
      "Epoch: 13, Batch: 400/896, Loss: 0.6291, Time: 3.80s\n",
      "Epoch: 13, Batch: 410/896, Loss: 0.9248, Time: 3.80s\n",
      "Epoch: 13, Batch: 420/896, Loss: 0.6133, Time: 3.80s\n",
      "Epoch: 13, Batch: 430/896, Loss: 0.6006, Time: 3.80s\n",
      "Epoch: 13, Batch: 440/896, Loss: 0.9237, Time: 3.81s\n",
      "Epoch: 13, Batch: 450/896, Loss: 1.7332, Time: 3.79s\n",
      "Epoch: 13, Batch: 460/896, Loss: 1.5729, Time: 3.81s\n",
      "Epoch: 13, Batch: 470/896, Loss: 0.5305, Time: 3.81s\n",
      "Epoch: 13, Batch: 480/896, Loss: 1.4634, Time: 3.80s\n",
      "Epoch: 13, Batch: 490/896, Loss: 0.5366, Time: 3.80s\n",
      "Epoch: 13, Batch: 500/896, Loss: 0.9568, Time: 3.81s\n",
      "Epoch: 13, Batch: 510/896, Loss: 0.6992, Time: 3.81s\n",
      "Epoch: 13, Batch: 520/896, Loss: 0.4988, Time: 3.80s\n",
      "Epoch: 13, Batch: 530/896, Loss: 1.0095, Time: 3.81s\n",
      "Epoch: 13, Batch: 540/896, Loss: 0.4584, Time: 3.80s\n",
      "Epoch: 13, Batch: 550/896, Loss: 1.1265, Time: 3.82s\n",
      "Epoch: 13, Batch: 560/896, Loss: 0.7637, Time: 3.81s\n",
      "Epoch: 13, Batch: 570/896, Loss: 0.9000, Time: 3.82s\n",
      "Epoch: 13, Batch: 580/896, Loss: 1.5776, Time: 3.80s\n",
      "Epoch: 13, Batch: 590/896, Loss: 0.8109, Time: 3.81s\n",
      "Epoch: 13, Batch: 600/896, Loss: 0.9467, Time: 3.81s\n",
      "Epoch: 13, Batch: 610/896, Loss: 0.3522, Time: 3.80s\n",
      "Epoch: 13, Batch: 620/896, Loss: 0.7865, Time: 3.81s\n",
      "Epoch: 13, Batch: 630/896, Loss: 0.6356, Time: 3.82s\n",
      "Epoch: 13, Batch: 640/896, Loss: 0.6862, Time: 3.82s\n",
      "Epoch: 13, Batch: 650/896, Loss: 0.6816, Time: 3.80s\n",
      "Epoch: 13, Batch: 660/896, Loss: 1.0851, Time: 3.81s\n",
      "Epoch: 13, Batch: 670/896, Loss: 0.4752, Time: 3.82s\n",
      "Epoch: 13, Batch: 680/896, Loss: 0.8898, Time: 3.80s\n",
      "Epoch: 13, Batch: 690/896, Loss: 1.5086, Time: 3.81s\n",
      "Epoch: 13, Batch: 700/896, Loss: 0.4072, Time: 3.80s\n",
      "Epoch: 13, Batch: 710/896, Loss: 0.8608, Time: 3.81s\n",
      "Epoch: 13, Batch: 720/896, Loss: 0.5593, Time: 3.80s\n",
      "Epoch: 13, Batch: 730/896, Loss: 0.7103, Time: 3.81s\n",
      "Epoch: 13, Batch: 740/896, Loss: 0.7469, Time: 3.82s\n",
      "Epoch: 13, Batch: 750/896, Loss: 0.8023, Time: 3.81s\n",
      "Epoch: 13, Batch: 760/896, Loss: 1.0554, Time: 3.81s\n",
      "Epoch: 13, Batch: 770/896, Loss: 1.2211, Time: 3.80s\n",
      "Epoch: 13, Batch: 780/896, Loss: 1.4127, Time: 3.81s\n",
      "Epoch: 13, Batch: 790/896, Loss: 0.5639, Time: 3.82s\n",
      "Epoch: 13, Batch: 800/896, Loss: 0.3925, Time: 3.82s\n",
      "Epoch: 13, Batch: 810/896, Loss: 1.5268, Time: 3.81s\n",
      "Epoch: 13, Batch: 820/896, Loss: 1.0791, Time: 3.81s\n",
      "Epoch: 13, Batch: 830/896, Loss: 0.7120, Time: 3.80s\n",
      "Epoch: 13, Batch: 840/896, Loss: 1.3519, Time: 3.82s\n",
      "Epoch: 13, Batch: 850/896, Loss: 1.2044, Time: 3.80s\n",
      "Epoch: 13, Batch: 860/896, Loss: 0.3890, Time: 3.82s\n",
      "Epoch: 13, Batch: 870/896, Loss: 1.0253, Time: 3.81s\n",
      "Epoch: 13, Batch: 880/896, Loss: 1.3737, Time: 3.82s\n",
      "Epoch: 13, Batch: 890/896, Loss: 1.0953, Time: 3.80s\n",
      "Epoch 14/50: Train Loss: 0.8138, Val Loss: 0.8424, Val IoU: 0.3700, Val Dice: 0.3941\n",
      "Epoch: 14, Batch: 0/896, Loss: 0.5069, Time: 28.94s\n",
      "Epoch: 14, Batch: 10/896, Loss: 0.9322, Time: 3.75s\n",
      "Epoch: 14, Batch: 20/896, Loss: 0.7627, Time: 3.76s\n",
      "Epoch: 14, Batch: 30/896, Loss: 0.5365, Time: 3.75s\n",
      "Epoch: 14, Batch: 40/896, Loss: 0.5749, Time: 3.75s\n",
      "Epoch: 14, Batch: 50/896, Loss: 0.8834, Time: 3.76s\n",
      "Epoch: 14, Batch: 60/896, Loss: 0.5531, Time: 3.76s\n",
      "Epoch: 14, Batch: 70/896, Loss: 1.4534, Time: 3.76s\n",
      "Epoch: 14, Batch: 80/896, Loss: 0.7659, Time: 3.77s\n",
      "Epoch: 14, Batch: 90/896, Loss: 0.8198, Time: 3.78s\n",
      "Epoch: 14, Batch: 100/896, Loss: 0.4187, Time: 3.77s\n",
      "Epoch: 14, Batch: 110/896, Loss: 0.4078, Time: 3.77s\n",
      "Epoch: 14, Batch: 120/896, Loss: 0.4489, Time: 3.78s\n",
      "Epoch: 14, Batch: 130/896, Loss: 2.4795, Time: 3.77s\n",
      "Epoch: 14, Batch: 140/896, Loss: 0.7462, Time: 3.77s\n",
      "Epoch: 14, Batch: 150/896, Loss: 0.3561, Time: 3.78s\n",
      "Epoch: 14, Batch: 160/896, Loss: 0.8337, Time: 3.77s\n",
      "Epoch: 14, Batch: 170/896, Loss: 1.1625, Time: 3.80s\n",
      "Epoch: 14, Batch: 180/896, Loss: 0.4762, Time: 3.78s\n",
      "Epoch: 14, Batch: 190/896, Loss: 0.8867, Time: 3.79s\n",
      "Epoch: 14, Batch: 200/896, Loss: 0.8649, Time: 3.78s\n",
      "Epoch: 14, Batch: 210/896, Loss: 1.0254, Time: 3.79s\n",
      "Epoch: 14, Batch: 220/896, Loss: 0.7750, Time: 3.80s\n",
      "Epoch: 14, Batch: 230/896, Loss: 0.8227, Time: 3.79s\n",
      "Epoch: 14, Batch: 240/896, Loss: 0.5573, Time: 3.80s\n",
      "Epoch: 14, Batch: 250/896, Loss: 0.9874, Time: 3.81s\n",
      "Epoch: 14, Batch: 260/896, Loss: 0.4224, Time: 3.79s\n",
      "Epoch: 14, Batch: 270/896, Loss: 1.8304, Time: 3.80s\n",
      "Epoch: 14, Batch: 280/896, Loss: 1.4980, Time: 3.80s\n",
      "Epoch: 14, Batch: 290/896, Loss: 1.0826, Time: 3.80s\n",
      "Epoch: 14, Batch: 300/896, Loss: 1.0056, Time: 3.80s\n",
      "Epoch: 14, Batch: 310/896, Loss: 1.0974, Time: 3.80s\n",
      "Epoch: 14, Batch: 320/896, Loss: 0.8519, Time: 3.79s\n",
      "Epoch: 14, Batch: 330/896, Loss: 0.4546, Time: 3.80s\n",
      "Epoch: 14, Batch: 340/896, Loss: 0.6266, Time: 3.79s\n",
      "Epoch: 14, Batch: 350/896, Loss: 0.7096, Time: 3.79s\n",
      "Epoch: 14, Batch: 360/896, Loss: 0.4344, Time: 3.80s\n",
      "Epoch: 14, Batch: 370/896, Loss: 0.3377, Time: 3.80s\n",
      "Epoch: 14, Batch: 380/896, Loss: 0.5709, Time: 3.81s\n",
      "Epoch: 14, Batch: 390/896, Loss: 1.1810, Time: 3.80s\n",
      "Epoch: 14, Batch: 400/896, Loss: 1.1190, Time: 3.80s\n",
      "Epoch: 14, Batch: 410/896, Loss: 0.5314, Time: 3.79s\n",
      "Epoch: 14, Batch: 420/896, Loss: 1.0401, Time: 3.80s\n",
      "Epoch: 14, Batch: 430/896, Loss: 0.6752, Time: 3.82s\n",
      "Epoch: 14, Batch: 440/896, Loss: 1.0110, Time: 3.82s\n",
      "Epoch: 14, Batch: 450/896, Loss: 1.0552, Time: 3.80s\n",
      "Epoch: 14, Batch: 460/896, Loss: 0.8307, Time: 3.81s\n",
      "Epoch: 14, Batch: 470/896, Loss: 0.4415, Time: 3.81s\n",
      "Epoch: 14, Batch: 480/896, Loss: 0.7065, Time: 3.81s\n",
      "Epoch: 14, Batch: 490/896, Loss: 0.7178, Time: 3.81s\n",
      "Epoch: 14, Batch: 500/896, Loss: 0.3730, Time: 3.81s\n",
      "Epoch: 14, Batch: 510/896, Loss: 0.8048, Time: 3.82s\n",
      "Epoch: 14, Batch: 520/896, Loss: 0.5178, Time: 3.81s\n",
      "Epoch: 14, Batch: 530/896, Loss: 0.7661, Time: 3.81s\n",
      "Epoch: 14, Batch: 540/896, Loss: 0.9804, Time: 3.80s\n",
      "Epoch: 14, Batch: 550/896, Loss: 0.6432, Time: 3.81s\n",
      "Epoch: 14, Batch: 560/896, Loss: 0.7042, Time: 3.81s\n",
      "Epoch: 14, Batch: 570/896, Loss: 0.4142, Time: 3.81s\n",
      "Epoch: 14, Batch: 580/896, Loss: 1.1477, Time: 3.80s\n",
      "Epoch: 14, Batch: 590/896, Loss: 0.8537, Time: 3.82s\n",
      "Epoch: 14, Batch: 600/896, Loss: 0.7842, Time: 3.81s\n",
      "Epoch: 14, Batch: 610/896, Loss: 1.0063, Time: 3.81s\n",
      "Epoch: 14, Batch: 620/896, Loss: 0.7460, Time: 3.80s\n",
      "Epoch: 14, Batch: 630/896, Loss: 1.0803, Time: 3.82s\n",
      "Epoch: 14, Batch: 640/896, Loss: 0.9723, Time: 3.80s\n",
      "Epoch: 14, Batch: 650/896, Loss: 0.3874, Time: 3.81s\n",
      "Epoch: 14, Batch: 660/896, Loss: 1.2044, Time: 3.81s\n",
      "Epoch: 14, Batch: 670/896, Loss: 0.4786, Time: 3.81s\n",
      "Epoch: 14, Batch: 680/896, Loss: 0.5180, Time: 3.80s\n",
      "Epoch: 14, Batch: 690/896, Loss: 0.7384, Time: 3.81s\n",
      "Epoch: 14, Batch: 700/896, Loss: 0.4882, Time: 3.80s\n",
      "Epoch: 14, Batch: 710/896, Loss: 1.1263, Time: 3.82s\n",
      "Epoch: 14, Batch: 720/896, Loss: 0.6524, Time: 3.81s\n",
      "Epoch: 14, Batch: 730/896, Loss: 0.7234, Time: 3.80s\n",
      "Epoch: 14, Batch: 740/896, Loss: 1.2344, Time: 3.81s\n",
      "Epoch: 14, Batch: 750/896, Loss: 0.5206, Time: 3.81s\n",
      "Epoch: 14, Batch: 760/896, Loss: 1.1407, Time: 3.82s\n",
      "Epoch: 14, Batch: 770/896, Loss: 1.0228, Time: 3.80s\n",
      "Epoch: 14, Batch: 780/896, Loss: 0.6982, Time: 3.81s\n",
      "Epoch: 14, Batch: 790/896, Loss: 0.7362, Time: 3.81s\n",
      "Epoch: 14, Batch: 800/896, Loss: 0.3790, Time: 3.80s\n",
      "Epoch: 14, Batch: 810/896, Loss: 1.2352, Time: 3.81s\n",
      "Epoch: 14, Batch: 820/896, Loss: 0.5454, Time: 3.80s\n",
      "Epoch: 14, Batch: 830/896, Loss: 0.6795, Time: 3.82s\n",
      "Epoch: 14, Batch: 840/896, Loss: 1.4204, Time: 3.80s\n",
      "Epoch: 14, Batch: 850/896, Loss: 0.4712, Time: 3.81s\n",
      "Epoch: 14, Batch: 860/896, Loss: 0.5416, Time: 3.80s\n",
      "Epoch: 14, Batch: 870/896, Loss: 0.8542, Time: 3.81s\n",
      "Epoch: 14, Batch: 880/896, Loss: 0.5801, Time: 3.81s\n",
      "Epoch: 14, Batch: 890/896, Loss: 0.3156, Time: 3.81s\n",
      "Epoch 15/50: Train Loss: 0.8110, Val Loss: 0.8350, Val IoU: 0.3682, Val Dice: 0.3919\n",
      "Epoch: 15, Batch: 0/896, Loss: 1.4474, Time: 28.97s\n",
      "Epoch: 15, Batch: 10/896, Loss: 0.6680, Time: 3.75s\n",
      "Epoch: 15, Batch: 20/896, Loss: 0.9241, Time: 3.75s\n",
      "Epoch: 15, Batch: 30/896, Loss: 1.4598, Time: 3.76s\n",
      "Epoch: 15, Batch: 40/896, Loss: 0.6695, Time: 3.75s\n",
      "Epoch: 15, Batch: 50/896, Loss: 0.7973, Time: 3.76s\n",
      "Epoch: 15, Batch: 60/896, Loss: 0.4903, Time: 3.76s\n",
      "Epoch: 15, Batch: 70/896, Loss: 1.1161, Time: 3.78s\n",
      "Epoch: 15, Batch: 80/896, Loss: 0.4327, Time: 3.76s\n",
      "Epoch: 15, Batch: 90/896, Loss: 0.6418, Time: 3.76s\n",
      "Epoch: 15, Batch: 100/896, Loss: 1.0730, Time: 3.76s\n",
      "Epoch: 15, Batch: 110/896, Loss: 1.2473, Time: 3.78s\n",
      "Epoch: 15, Batch: 120/896, Loss: 0.4467, Time: 3.78s\n",
      "Epoch: 15, Batch: 130/896, Loss: 0.5796, Time: 3.78s\n",
      "Epoch: 15, Batch: 140/896, Loss: 0.6051, Time: 3.77s\n",
      "Epoch: 15, Batch: 150/896, Loss: 0.3612, Time: 3.78s\n",
      "Epoch: 15, Batch: 160/896, Loss: 0.7401, Time: 3.77s\n",
      "Epoch: 15, Batch: 170/896, Loss: 1.9535, Time: 3.81s\n",
      "Epoch: 15, Batch: 180/896, Loss: 0.6291, Time: 3.77s\n",
      "Epoch: 15, Batch: 190/896, Loss: 0.7949, Time: 3.79s\n",
      "Epoch: 15, Batch: 200/896, Loss: 1.6905, Time: 3.80s\n",
      "Epoch: 15, Batch: 210/896, Loss: 0.7342, Time: 3.77s\n",
      "Epoch: 15, Batch: 220/896, Loss: 1.1997, Time: 3.80s\n",
      "Epoch: 15, Batch: 230/896, Loss: 0.5323, Time: 3.81s\n",
      "Epoch: 15, Batch: 240/896, Loss: 1.0109, Time: 3.80s\n",
      "Epoch: 15, Batch: 250/896, Loss: 0.5042, Time: 3.80s\n",
      "Epoch: 15, Batch: 260/896, Loss: 1.4735, Time: 3.81s\n",
      "Epoch: 15, Batch: 270/896, Loss: 0.9699, Time: 3.79s\n",
      "Epoch: 15, Batch: 280/896, Loss: 0.7373, Time: 3.80s\n",
      "Epoch: 15, Batch: 290/896, Loss: 1.0820, Time: 3.78s\n",
      "Epoch: 15, Batch: 300/896, Loss: 1.4005, Time: 3.80s\n",
      "Epoch: 15, Batch: 310/896, Loss: 0.8355, Time: 3.80s\n",
      "Epoch: 15, Batch: 320/896, Loss: 0.3876, Time: 3.81s\n",
      "Epoch: 15, Batch: 330/896, Loss: 1.0232, Time: 3.81s\n",
      "Epoch: 15, Batch: 340/896, Loss: 0.7011, Time: 3.80s\n",
      "Epoch: 15, Batch: 350/896, Loss: 0.4596, Time: 3.80s\n",
      "Epoch: 15, Batch: 360/896, Loss: 0.8102, Time: 3.81s\n",
      "Epoch: 15, Batch: 370/896, Loss: 0.5600, Time: 3.80s\n",
      "Epoch: 15, Batch: 380/896, Loss: 1.7327, Time: 3.81s\n",
      "Epoch: 15, Batch: 390/896, Loss: 0.7793, Time: 3.80s\n",
      "Epoch: 15, Batch: 400/896, Loss: 1.2032, Time: 3.81s\n",
      "Epoch: 15, Batch: 410/896, Loss: 0.3093, Time: 3.79s\n",
      "Epoch: 15, Batch: 420/896, Loss: 1.8348, Time: 3.80s\n",
      "Epoch: 15, Batch: 430/896, Loss: 1.6028, Time: 3.80s\n",
      "Epoch: 15, Batch: 440/896, Loss: 0.6940, Time: 3.80s\n",
      "Epoch: 15, Batch: 450/896, Loss: 0.7502, Time: 3.81s\n",
      "Epoch: 15, Batch: 460/896, Loss: 0.8852, Time: 3.82s\n",
      "Epoch: 15, Batch: 470/896, Loss: 0.4697, Time: 3.81s\n",
      "Epoch: 15, Batch: 480/896, Loss: 1.2912, Time: 3.81s\n",
      "Epoch: 15, Batch: 490/896, Loss: 0.9378, Time: 3.81s\n",
      "Epoch: 15, Batch: 500/896, Loss: 0.7348, Time: 3.80s\n",
      "Epoch: 15, Batch: 510/896, Loss: 1.1601, Time: 3.81s\n",
      "Epoch: 15, Batch: 520/896, Loss: 0.7755, Time: 3.81s\n",
      "Epoch: 15, Batch: 530/896, Loss: 1.3546, Time: 3.82s\n",
      "Epoch: 15, Batch: 540/896, Loss: 1.1591, Time: 3.81s\n",
      "Epoch: 15, Batch: 550/896, Loss: 0.4822, Time: 3.80s\n",
      "Epoch: 15, Batch: 560/896, Loss: 0.8272, Time: 3.82s\n",
      "Epoch: 15, Batch: 570/896, Loss: 1.1109, Time: 3.81s\n",
      "Epoch: 15, Batch: 580/896, Loss: 1.0754, Time: 3.80s\n",
      "Epoch: 15, Batch: 590/896, Loss: 0.6564, Time: 3.81s\n",
      "Epoch: 15, Batch: 600/896, Loss: 0.4800, Time: 3.81s\n",
      "Epoch: 15, Batch: 610/896, Loss: 1.4595, Time: 3.80s\n",
      "Epoch: 15, Batch: 620/896, Loss: 0.3641, Time: 3.81s\n",
      "Epoch: 15, Batch: 630/896, Loss: 0.5113, Time: 3.82s\n",
      "Epoch: 15, Batch: 640/896, Loss: 0.9129, Time: 3.80s\n",
      "Epoch: 15, Batch: 650/896, Loss: 0.8045, Time: 3.80s\n",
      "Epoch: 15, Batch: 660/896, Loss: 1.5412, Time: 3.81s\n",
      "Epoch: 15, Batch: 670/896, Loss: 0.6081, Time: 3.80s\n",
      "Epoch: 15, Batch: 680/896, Loss: 0.6956, Time: 3.81s\n",
      "Epoch: 15, Batch: 690/896, Loss: 0.8834, Time: 3.82s\n",
      "Epoch: 15, Batch: 700/896, Loss: 0.6442, Time: 3.81s\n",
      "Epoch: 15, Batch: 710/896, Loss: 0.4979, Time: 3.80s\n",
      "Epoch: 15, Batch: 720/896, Loss: 1.1764, Time: 3.81s\n",
      "Epoch: 15, Batch: 730/896, Loss: 1.3998, Time: 3.82s\n",
      "Epoch: 15, Batch: 740/896, Loss: 0.7397, Time: 3.80s\n",
      "Epoch: 15, Batch: 750/896, Loss: 0.4230, Time: 3.80s\n",
      "Epoch: 15, Batch: 760/896, Loss: 1.2299, Time: 3.81s\n",
      "Epoch: 15, Batch: 770/896, Loss: 0.6779, Time: 3.81s\n",
      "Epoch: 15, Batch: 780/896, Loss: 0.4628, Time: 3.80s\n",
      "Epoch: 15, Batch: 790/896, Loss: 0.6165, Time: 3.81s\n",
      "Epoch: 15, Batch: 800/896, Loss: 0.8130, Time: 3.81s\n",
      "Epoch: 15, Batch: 810/896, Loss: 0.7543, Time: 3.81s\n",
      "Epoch: 15, Batch: 820/896, Loss: 0.2934, Time: 3.81s\n",
      "Epoch: 15, Batch: 830/896, Loss: 0.9726, Time: 3.80s\n",
      "Epoch: 15, Batch: 840/896, Loss: 0.9780, Time: 3.81s\n",
      "Epoch: 15, Batch: 850/896, Loss: 1.0932, Time: 3.81s\n",
      "Epoch: 15, Batch: 860/896, Loss: 0.6621, Time: 3.80s\n",
      "Epoch: 15, Batch: 870/896, Loss: 0.4496, Time: 3.81s\n",
      "Epoch: 15, Batch: 880/896, Loss: 0.9845, Time: 3.81s\n",
      "Epoch: 15, Batch: 890/896, Loss: 0.7444, Time: 3.81s\n",
      "Epoch 16/50: Train Loss: 0.8128, Val Loss: 0.8486, Val IoU: 0.3655, Val Dice: 0.3888\n",
      "Epoch: 16, Batch: 0/896, Loss: 0.4909, Time: 28.82s\n",
      "Epoch: 16, Batch: 10/896, Loss: 1.1078, Time: 3.75s\n",
      "Epoch: 16, Batch: 20/896, Loss: 0.6247, Time: 3.74s\n",
      "Epoch: 16, Batch: 30/896, Loss: 1.5350, Time: 3.74s\n",
      "Epoch: 16, Batch: 40/896, Loss: 0.6507, Time: 3.75s\n",
      "Epoch: 16, Batch: 50/896, Loss: 0.6048, Time: 3.75s\n",
      "Epoch: 16, Batch: 60/896, Loss: 0.5347, Time: 3.76s\n",
      "Epoch: 16, Batch: 70/896, Loss: 0.9645, Time: 3.77s\n",
      "Epoch: 16, Batch: 80/896, Loss: 0.5471, Time: 3.77s\n",
      "Epoch: 16, Batch: 90/896, Loss: 0.5329, Time: 3.76s\n",
      "Epoch: 16, Batch: 100/896, Loss: 0.4927, Time: 3.77s\n",
      "Epoch: 16, Batch: 110/896, Loss: 0.7072, Time: 3.78s\n",
      "Epoch: 16, Batch: 120/896, Loss: 0.4461, Time: 3.77s\n",
      "Epoch: 16, Batch: 130/896, Loss: 0.6194, Time: 3.78s\n",
      "Epoch: 16, Batch: 140/896, Loss: 1.8661, Time: 3.78s\n",
      "Epoch: 16, Batch: 150/896, Loss: 0.7747, Time: 3.78s\n",
      "Epoch: 16, Batch: 160/896, Loss: 0.8516, Time: 3.79s\n",
      "Epoch: 16, Batch: 170/896, Loss: 0.3106, Time: 3.79s\n",
      "Epoch: 16, Batch: 180/896, Loss: 0.8112, Time: 3.78s\n",
      "Epoch: 16, Batch: 190/896, Loss: 0.9389, Time: 3.80s\n",
      "Epoch: 16, Batch: 200/896, Loss: 0.9171, Time: 3.78s\n",
      "Epoch: 16, Batch: 210/896, Loss: 0.9982, Time: 3.79s\n",
      "Epoch: 16, Batch: 220/896, Loss: 0.7521, Time: 3.79s\n",
      "Epoch: 16, Batch: 230/896, Loss: 0.6550, Time: 3.79s\n",
      "Epoch: 16, Batch: 240/896, Loss: 0.8760, Time: 3.80s\n",
      "Epoch: 16, Batch: 250/896, Loss: 0.6470, Time: 3.80s\n",
      "Epoch: 16, Batch: 260/896, Loss: 0.4927, Time: 3.79s\n",
      "Epoch: 16, Batch: 270/896, Loss: 0.9455, Time: 3.79s\n",
      "Epoch: 16, Batch: 280/896, Loss: 0.9009, Time: 3.79s\n",
      "Epoch: 16, Batch: 290/896, Loss: 0.7892, Time: 3.80s\n",
      "Epoch: 16, Batch: 300/896, Loss: 0.4464, Time: 3.79s\n",
      "Epoch: 16, Batch: 310/896, Loss: 0.5138, Time: 3.79s\n",
      "Epoch: 16, Batch: 320/896, Loss: 0.8695, Time: 3.80s\n",
      "Epoch: 16, Batch: 330/896, Loss: 0.6781, Time: 3.80s\n",
      "Epoch: 16, Batch: 340/896, Loss: 1.1438, Time: 3.80s\n",
      "Epoch: 16, Batch: 350/896, Loss: 1.1726, Time: 3.82s\n",
      "Epoch: 16, Batch: 360/896, Loss: 0.7323, Time: 3.80s\n",
      "Epoch: 16, Batch: 370/896, Loss: 1.4236, Time: 3.80s\n",
      "Epoch: 16, Batch: 380/896, Loss: 0.3658, Time: 3.81s\n",
      "Epoch: 16, Batch: 390/896, Loss: 0.9748, Time: 3.80s\n",
      "Epoch: 16, Batch: 400/896, Loss: 0.5074, Time: 3.81s\n",
      "Epoch: 16, Batch: 410/896, Loss: 0.5082, Time: 3.81s\n",
      "Epoch: 16, Batch: 420/896, Loss: 0.4430, Time: 3.80s\n",
      "Epoch: 16, Batch: 430/896, Loss: 0.2929, Time: 3.80s\n",
      "Epoch: 16, Batch: 440/896, Loss: 0.2949, Time: 3.80s\n",
      "Epoch: 16, Batch: 450/896, Loss: 1.2030, Time: 3.81s\n",
      "Epoch: 16, Batch: 460/896, Loss: 0.4904, Time: 3.80s\n",
      "Epoch: 16, Batch: 470/896, Loss: 0.3531, Time: 3.80s\n",
      "Epoch: 16, Batch: 480/896, Loss: 0.5365, Time: 3.81s\n",
      "Epoch: 16, Batch: 490/896, Loss: 1.2409, Time: 3.80s\n",
      "Epoch: 16, Batch: 500/896, Loss: 1.3418, Time: 3.80s\n",
      "Epoch: 16, Batch: 510/896, Loss: 0.6519, Time: 3.80s\n",
      "Epoch: 16, Batch: 520/896, Loss: 0.3981, Time: 3.81s\n",
      "Epoch: 16, Batch: 530/896, Loss: 0.7943, Time: 3.81s\n",
      "Epoch: 16, Batch: 540/896, Loss: 0.8828, Time: 3.80s\n",
      "Epoch: 16, Batch: 550/896, Loss: 1.1447, Time: 3.81s\n",
      "Epoch: 16, Batch: 560/896, Loss: 0.3393, Time: 3.80s\n",
      "Epoch: 16, Batch: 570/896, Loss: 0.5975, Time: 3.81s\n",
      "Epoch: 16, Batch: 580/896, Loss: 0.9066, Time: 3.80s\n",
      "Epoch: 16, Batch: 590/896, Loss: 1.1265, Time: 3.82s\n",
      "Epoch: 16, Batch: 600/896, Loss: 0.7108, Time: 3.80s\n",
      "Epoch: 16, Batch: 610/896, Loss: 1.2224, Time: 3.82s\n",
      "Epoch: 16, Batch: 620/896, Loss: 1.3191, Time: 3.81s\n",
      "Epoch: 16, Batch: 630/896, Loss: 1.1498, Time: 3.81s\n",
      "Epoch: 16, Batch: 640/896, Loss: 1.2538, Time: 3.80s\n",
      "Epoch: 16, Batch: 650/896, Loss: 0.6648, Time: 3.81s\n",
      "Epoch: 16, Batch: 660/896, Loss: 0.4435, Time: 3.82s\n",
      "Epoch: 16, Batch: 670/896, Loss: 0.8925, Time: 3.82s\n",
      "Epoch: 16, Batch: 680/896, Loss: 0.7949, Time: 3.80s\n",
      "Epoch: 16, Batch: 690/896, Loss: 1.0890, Time: 3.80s\n",
      "Epoch: 16, Batch: 700/896, Loss: 0.5648, Time: 3.81s\n",
      "Epoch: 16, Batch: 710/896, Loss: 0.5526, Time: 3.82s\n",
      "Epoch: 16, Batch: 720/896, Loss: 1.1525, Time: 3.81s\n",
      "Epoch: 16, Batch: 730/896, Loss: 0.3620, Time: 3.81s\n",
      "Epoch: 16, Batch: 740/896, Loss: 0.9944, Time: 3.81s\n",
      "Epoch: 16, Batch: 750/896, Loss: 0.7654, Time: 3.82s\n",
      "Epoch: 16, Batch: 760/896, Loss: 0.8855, Time: 3.81s\n",
      "Epoch: 16, Batch: 770/896, Loss: 0.8222, Time: 3.80s\n",
      "Epoch: 16, Batch: 780/896, Loss: 1.3113, Time: 3.80s\n",
      "Epoch: 16, Batch: 790/896, Loss: 0.4300, Time: 3.80s\n",
      "Epoch: 16, Batch: 800/896, Loss: 0.4049, Time: 3.81s\n",
      "Epoch: 16, Batch: 810/896, Loss: 0.7468, Time: 3.81s\n",
      "Epoch: 16, Batch: 820/896, Loss: 0.7329, Time: 3.82s\n",
      "Epoch: 16, Batch: 830/896, Loss: 0.8581, Time: 3.81s\n",
      "Epoch: 16, Batch: 840/896, Loss: 0.7222, Time: 3.80s\n",
      "Epoch: 16, Batch: 850/896, Loss: 1.8323, Time: 3.80s\n",
      "Epoch: 16, Batch: 860/896, Loss: 0.5737, Time: 3.80s\n",
      "Epoch: 16, Batch: 870/896, Loss: 0.7103, Time: 3.81s\n",
      "Epoch: 16, Batch: 880/896, Loss: 1.1567, Time: 3.82s\n",
      "Epoch: 16, Batch: 890/896, Loss: 0.9788, Time: 3.80s\n",
      "Epoch 17/50: Train Loss: 0.8100, Val Loss: 0.8477, Val IoU: 0.3683, Val Dice: 0.3922\n",
      "Epoch: 17, Batch: 0/896, Loss: 0.8432, Time: 28.73s\n",
      "Epoch: 17, Batch: 10/896, Loss: 0.6267, Time: 3.74s\n",
      "Epoch: 17, Batch: 20/896, Loss: 0.6166, Time: 3.75s\n",
      "Epoch: 17, Batch: 30/896, Loss: 0.3705, Time: 3.75s\n",
      "Epoch: 17, Batch: 40/896, Loss: 1.1206, Time: 3.75s\n",
      "Epoch: 17, Batch: 50/896, Loss: 0.5053, Time: 3.76s\n",
      "Epoch: 17, Batch: 60/896, Loss: 0.4740, Time: 3.76s\n",
      "Epoch: 17, Batch: 70/896, Loss: 1.2678, Time: 3.76s\n",
      "Epoch: 17, Batch: 80/896, Loss: 1.0936, Time: 3.77s\n",
      "Epoch: 17, Batch: 90/896, Loss: 0.3674, Time: 3.77s\n",
      "Epoch: 17, Batch: 100/896, Loss: 0.7832, Time: 3.77s\n",
      "Epoch: 17, Batch: 110/896, Loss: 1.2726, Time: 3.77s\n",
      "Epoch: 17, Batch: 120/896, Loss: 0.7506, Time: 3.77s\n",
      "Epoch: 17, Batch: 130/896, Loss: 0.5334, Time: 3.77s\n",
      "Epoch: 17, Batch: 140/896, Loss: 0.5807, Time: 3.78s\n",
      "Epoch: 17, Batch: 150/896, Loss: 1.0881, Time: 3.76s\n",
      "Epoch: 17, Batch: 160/896, Loss: 0.8437, Time: 3.79s\n",
      "Epoch: 17, Batch: 170/896, Loss: 0.3924, Time: 3.77s\n",
      "Epoch: 17, Batch: 180/896, Loss: 0.7955, Time: 3.77s\n",
      "Epoch: 17, Batch: 190/896, Loss: 1.0259, Time: 3.79s\n",
      "Epoch: 17, Batch: 200/896, Loss: 0.5777, Time: 3.78s\n",
      "Epoch: 17, Batch: 210/896, Loss: 0.8357, Time: 3.78s\n",
      "Epoch: 17, Batch: 220/896, Loss: 1.6430, Time: 3.79s\n",
      "Epoch: 17, Batch: 230/896, Loss: 0.5184, Time: 3.79s\n",
      "Epoch: 17, Batch: 240/896, Loss: 0.5824, Time: 3.78s\n",
      "Epoch: 17, Batch: 250/896, Loss: 1.2788, Time: 3.80s\n",
      "Epoch: 17, Batch: 260/896, Loss: 1.6312, Time: 3.79s\n",
      "Epoch: 17, Batch: 270/896, Loss: 1.3111, Time: 3.80s\n",
      "Epoch: 17, Batch: 280/896, Loss: 1.1121, Time: 3.79s\n",
      "Epoch: 17, Batch: 290/896, Loss: 0.6120, Time: 3.81s\n",
      "Epoch: 17, Batch: 300/896, Loss: 0.8109, Time: 3.79s\n",
      "Epoch: 17, Batch: 310/896, Loss: 0.9298, Time: 3.80s\n",
      "Epoch: 17, Batch: 320/896, Loss: 0.4893, Time: 3.80s\n",
      "Epoch: 17, Batch: 330/896, Loss: 0.4094, Time: 3.80s\n",
      "Epoch: 17, Batch: 340/896, Loss: 1.2661, Time: 3.80s\n",
      "Epoch: 17, Batch: 350/896, Loss: 0.3823, Time: 3.80s\n",
      "Epoch: 17, Batch: 360/896, Loss: 1.2855, Time: 3.80s\n",
      "Epoch: 17, Batch: 370/896, Loss: 0.5734, Time: 3.80s\n",
      "Epoch: 17, Batch: 380/896, Loss: 0.8676, Time: 3.81s\n",
      "Epoch: 17, Batch: 390/896, Loss: 1.2202, Time: 3.80s\n",
      "Epoch: 17, Batch: 400/896, Loss: 0.5129, Time: 3.80s\n",
      "Epoch: 17, Batch: 410/896, Loss: 0.3765, Time: 3.79s\n",
      "Epoch: 17, Batch: 420/896, Loss: 0.3721, Time: 3.80s\n",
      "Epoch: 17, Batch: 430/896, Loss: 0.6951, Time: 3.80s\n",
      "Epoch: 17, Batch: 440/896, Loss: 0.7719, Time: 3.80s\n",
      "Epoch: 17, Batch: 450/896, Loss: 0.6203, Time: 3.81s\n",
      "Epoch: 17, Batch: 460/896, Loss: 0.8152, Time: 3.80s\n",
      "Epoch: 17, Batch: 470/896, Loss: 0.6153, Time: 3.80s\n",
      "Epoch: 17, Batch: 480/896, Loss: 0.8531, Time: 3.81s\n",
      "Epoch: 17, Batch: 490/896, Loss: 0.8652, Time: 3.80s\n",
      "Epoch: 17, Batch: 500/896, Loss: 0.2536, Time: 3.80s\n",
      "Epoch: 17, Batch: 510/896, Loss: 1.1956, Time: 3.80s\n",
      "Epoch: 17, Batch: 520/896, Loss: 0.9235, Time: 3.81s\n",
      "Epoch: 17, Batch: 530/896, Loss: 0.8048, Time: 3.80s\n",
      "Epoch: 17, Batch: 540/896, Loss: 0.3133, Time: 3.82s\n",
      "Epoch: 17, Batch: 550/896, Loss: 0.8112, Time: 3.81s\n",
      "Epoch: 17, Batch: 560/896, Loss: 0.9978, Time: 3.81s\n",
      "Epoch: 17, Batch: 570/896, Loss: 0.6066, Time: 3.81s\n",
      "Epoch: 17, Batch: 580/896, Loss: 0.6332, Time: 3.81s\n",
      "Epoch: 17, Batch: 590/896, Loss: 0.4054, Time: 3.79s\n",
      "Epoch: 17, Batch: 600/896, Loss: 0.4352, Time: 3.81s\n",
      "Epoch: 17, Batch: 610/896, Loss: 1.0546, Time: 3.81s\n",
      "Epoch: 17, Batch: 620/896, Loss: 0.9457, Time: 3.80s\n",
      "Epoch: 17, Batch: 630/896, Loss: 0.6338, Time: 3.80s\n",
      "Epoch: 17, Batch: 640/896, Loss: 0.7121, Time: 3.81s\n",
      "Epoch: 17, Batch: 650/896, Loss: 1.2956, Time: 3.82s\n",
      "Epoch: 17, Batch: 660/896, Loss: 1.0878, Time: 3.81s\n",
      "Epoch: 17, Batch: 670/896, Loss: 0.9733, Time: 3.81s\n",
      "Epoch: 17, Batch: 680/896, Loss: 1.4086, Time: 3.80s\n",
      "Epoch: 17, Batch: 690/896, Loss: 0.9001, Time: 3.79s\n",
      "Epoch: 17, Batch: 700/896, Loss: 1.4069, Time: 3.81s\n",
      "Epoch: 17, Batch: 710/896, Loss: 0.8057, Time: 3.80s\n",
      "Epoch: 17, Batch: 720/896, Loss: 0.6288, Time: 3.81s\n",
      "Epoch: 17, Batch: 730/896, Loss: 0.5839, Time: 3.80s\n",
      "Epoch: 17, Batch: 740/896, Loss: 1.0897, Time: 3.81s\n",
      "Epoch: 17, Batch: 750/896, Loss: 0.7101, Time: 3.82s\n",
      "Epoch: 17, Batch: 760/896, Loss: 1.0970, Time: 3.82s\n",
      "Epoch: 17, Batch: 770/896, Loss: 0.6795, Time: 3.81s\n",
      "Epoch: 17, Batch: 780/896, Loss: 0.6778, Time: 3.81s\n",
      "Epoch: 17, Batch: 790/896, Loss: 0.3785, Time: 3.82s\n",
      "Epoch: 17, Batch: 800/896, Loss: 0.4039, Time: 3.80s\n",
      "Epoch: 17, Batch: 810/896, Loss: 0.4790, Time: 3.81s\n",
      "Epoch: 17, Batch: 820/896, Loss: 1.2972, Time: 3.81s\n",
      "Epoch: 17, Batch: 830/896, Loss: 0.5371, Time: 3.81s\n",
      "Epoch: 17, Batch: 840/896, Loss: 0.4426, Time: 3.81s\n",
      "Epoch: 17, Batch: 850/896, Loss: 0.5882, Time: 3.80s\n",
      "Epoch: 17, Batch: 860/896, Loss: 0.8256, Time: 3.81s\n",
      "Epoch: 17, Batch: 870/896, Loss: 0.8284, Time: 3.81s\n",
      "Epoch: 17, Batch: 880/896, Loss: 0.3824, Time: 3.81s\n",
      "Epoch: 17, Batch: 890/896, Loss: 0.4632, Time: 3.81s\n",
      "Epoch 18/50: Train Loss: 0.8053, Val Loss: 0.8494, Val IoU: 0.3717, Val Dice: 0.3959\n",
      "Saving best model with IoU: 0.3717\n",
      "Epoch: 18, Batch: 0/896, Loss: 1.2007, Time: 28.84s\n",
      "Epoch: 18, Batch: 10/896, Loss: 0.7317, Time: 3.75s\n",
      "Epoch: 18, Batch: 20/896, Loss: 0.5772, Time: 3.74s\n",
      "Epoch: 18, Batch: 30/896, Loss: 0.8310, Time: 3.75s\n",
      "Epoch: 18, Batch: 40/896, Loss: 0.6304, Time: 3.75s\n",
      "Epoch: 18, Batch: 50/896, Loss: 1.5285, Time: 3.75s\n",
      "Epoch: 18, Batch: 60/896, Loss: 0.6118, Time: 3.75s\n",
      "Epoch: 18, Batch: 70/896, Loss: 0.8089, Time: 3.78s\n",
      "Epoch: 18, Batch: 80/896, Loss: 0.9843, Time: 3.77s\n",
      "Epoch: 18, Batch: 90/896, Loss: 0.7346, Time: 3.77s\n",
      "Epoch: 18, Batch: 100/896, Loss: 0.4425, Time: 3.76s\n",
      "Epoch: 18, Batch: 110/896, Loss: 0.7617, Time: 3.77s\n",
      "Epoch: 18, Batch: 120/896, Loss: 0.7497, Time: 3.78s\n",
      "Epoch: 18, Batch: 130/896, Loss: 0.5549, Time: 3.77s\n",
      "Epoch: 18, Batch: 140/896, Loss: 0.9227, Time: 3.77s\n",
      "Epoch: 18, Batch: 150/896, Loss: 0.5188, Time: 3.77s\n",
      "Epoch: 18, Batch: 160/896, Loss: 0.5540, Time: 3.78s\n",
      "Epoch: 18, Batch: 170/896, Loss: 0.8628, Time: 3.77s\n",
      "Epoch: 18, Batch: 180/896, Loss: 0.4878, Time: 3.78s\n",
      "Epoch: 18, Batch: 190/896, Loss: 0.9541, Time: 3.78s\n",
      "Epoch: 18, Batch: 200/896, Loss: 2.0440, Time: 3.78s\n",
      "Epoch: 18, Batch: 210/896, Loss: 1.4663, Time: 3.79s\n",
      "Epoch: 18, Batch: 220/896, Loss: 0.5626, Time: 3.78s\n",
      "Epoch: 18, Batch: 230/896, Loss: 0.5915, Time: 3.79s\n",
      "Epoch: 18, Batch: 240/896, Loss: 1.2235, Time: 3.80s\n",
      "Epoch: 18, Batch: 250/896, Loss: 0.5795, Time: 3.78s\n",
      "Epoch: 18, Batch: 260/896, Loss: 1.1387, Time: 3.80s\n",
      "Epoch: 18, Batch: 270/896, Loss: 0.5176, Time: 3.78s\n",
      "Epoch: 18, Batch: 280/896, Loss: 0.8210, Time: 3.80s\n",
      "Epoch: 18, Batch: 290/896, Loss: 0.4184, Time: 3.80s\n",
      "Epoch: 18, Batch: 300/896, Loss: 0.4155, Time: 3.81s\n",
      "Epoch: 18, Batch: 310/896, Loss: 0.5513, Time: 3.81s\n",
      "Epoch: 18, Batch: 320/896, Loss: 0.9918, Time: 3.81s\n",
      "Epoch: 18, Batch: 330/896, Loss: 0.8180, Time: 3.80s\n",
      "Epoch: 18, Batch: 340/896, Loss: 0.9867, Time: 3.80s\n",
      "Epoch: 18, Batch: 350/896, Loss: 0.6996, Time: 3.80s\n",
      "Epoch: 18, Batch: 360/896, Loss: 0.5019, Time: 3.81s\n",
      "Epoch: 18, Batch: 370/896, Loss: 0.9905, Time: 3.80s\n",
      "Epoch: 18, Batch: 380/896, Loss: 0.6668, Time: 3.81s\n",
      "Epoch: 18, Batch: 390/896, Loss: 1.3498, Time: 3.82s\n",
      "Epoch: 18, Batch: 400/896, Loss: 0.5372, Time: 3.81s\n",
      "Epoch: 18, Batch: 410/896, Loss: 0.7933, Time: 3.81s\n",
      "Epoch: 18, Batch: 420/896, Loss: 0.9380, Time: 3.81s\n",
      "Epoch: 18, Batch: 430/896, Loss: 0.5931, Time: 3.80s\n",
      "Epoch: 18, Batch: 440/896, Loss: 0.6962, Time: 3.81s\n",
      "Epoch: 18, Batch: 450/896, Loss: 0.6767, Time: 3.80s\n",
      "Epoch: 18, Batch: 460/896, Loss: 1.1523, Time: 3.81s\n",
      "Epoch: 18, Batch: 470/896, Loss: 0.9118, Time: 3.80s\n",
      "Epoch: 18, Batch: 480/896, Loss: 0.6394, Time: 3.80s\n",
      "Epoch: 18, Batch: 490/896, Loss: 1.4710, Time: 3.81s\n",
      "Epoch: 18, Batch: 500/896, Loss: 0.8978, Time: 3.81s\n",
      "Epoch: 18, Batch: 510/896, Loss: 0.4178, Time: 3.80s\n",
      "Epoch: 18, Batch: 520/896, Loss: 0.9516, Time: 3.80s\n",
      "Epoch: 18, Batch: 530/896, Loss: 0.9986, Time: 3.80s\n",
      "Epoch: 18, Batch: 540/896, Loss: 0.5940, Time: 3.80s\n",
      "Epoch: 18, Batch: 550/896, Loss: 0.3531, Time: 3.82s\n",
      "Epoch: 18, Batch: 560/896, Loss: 0.3296, Time: 3.80s\n",
      "Epoch: 18, Batch: 570/896, Loss: 0.7245, Time: 3.82s\n",
      "Epoch: 18, Batch: 580/896, Loss: 0.5232, Time: 3.81s\n",
      "Epoch: 18, Batch: 590/896, Loss: 1.1903, Time: 3.81s\n",
      "Epoch: 18, Batch: 600/896, Loss: 0.8745, Time: 3.80s\n",
      "Epoch: 18, Batch: 610/896, Loss: 0.5679, Time: 3.81s\n",
      "Epoch: 18, Batch: 620/896, Loss: 0.8599, Time: 3.79s\n",
      "Epoch: 18, Batch: 630/896, Loss: 0.7706, Time: 3.81s\n",
      "Epoch: 18, Batch: 640/896, Loss: 1.0816, Time: 3.81s\n",
      "Epoch: 18, Batch: 650/896, Loss: 0.8118, Time: 3.82s\n",
      "Epoch: 18, Batch: 660/896, Loss: 1.9637, Time: 3.80s\n",
      "Epoch: 18, Batch: 670/896, Loss: 0.4952, Time: 3.81s\n",
      "Epoch: 18, Batch: 680/896, Loss: 0.4729, Time: 3.81s\n",
      "Epoch: 18, Batch: 690/896, Loss: 1.2269, Time: 3.79s\n",
      "Epoch: 18, Batch: 700/896, Loss: 0.8439, Time: 3.81s\n",
      "Epoch: 18, Batch: 710/896, Loss: 0.5138, Time: 3.80s\n",
      "Epoch: 18, Batch: 720/896, Loss: 0.5704, Time: 3.81s\n",
      "Epoch: 18, Batch: 730/896, Loss: 0.3078, Time: 3.81s\n",
      "Epoch: 18, Batch: 740/896, Loss: 0.8499, Time: 3.81s\n",
      "Epoch: 18, Batch: 750/896, Loss: 1.6201, Time: 3.82s\n",
      "Epoch: 18, Batch: 760/896, Loss: 0.8351, Time: 3.80s\n",
      "Epoch: 18, Batch: 770/896, Loss: 0.5245, Time: 3.82s\n",
      "Epoch: 18, Batch: 780/896, Loss: 1.0258, Time: 3.81s\n",
      "Epoch: 18, Batch: 790/896, Loss: 0.8188, Time: 3.80s\n",
      "Epoch: 18, Batch: 800/896, Loss: 0.5345, Time: 3.81s\n",
      "Epoch: 18, Batch: 810/896, Loss: 0.6587, Time: 3.81s\n",
      "Epoch: 18, Batch: 820/896, Loss: 1.1195, Time: 3.82s\n",
      "Epoch: 18, Batch: 830/896, Loss: 0.3440, Time: 3.82s\n",
      "Epoch: 18, Batch: 840/896, Loss: 0.7107, Time: 3.82s\n",
      "Epoch: 18, Batch: 850/896, Loss: 1.0413, Time: 3.82s\n",
      "Epoch: 18, Batch: 860/896, Loss: 0.6707, Time: 3.82s\n",
      "Epoch: 18, Batch: 870/896, Loss: 1.0237, Time: 3.82s\n",
      "Epoch: 18, Batch: 880/896, Loss: 1.3656, Time: 3.81s\n",
      "Epoch: 18, Batch: 890/896, Loss: 1.1219, Time: 3.82s\n",
      "Epoch 19/50: Train Loss: 0.8070, Val Loss: 0.8454, Val IoU: 0.3635, Val Dice: 0.3864\n",
      "Epoch: 19, Batch: 0/896, Loss: 0.7497, Time: 28.79s\n",
      "Epoch: 19, Batch: 10/896, Loss: 1.0457, Time: 3.75s\n",
      "Epoch: 19, Batch: 20/896, Loss: 0.5498, Time: 3.75s\n",
      "Epoch: 19, Batch: 30/896, Loss: 0.6807, Time: 3.74s\n",
      "Epoch: 19, Batch: 40/896, Loss: 1.6036, Time: 3.75s\n",
      "Epoch: 19, Batch: 50/896, Loss: 0.3748, Time: 3.76s\n",
      "Epoch: 19, Batch: 60/896, Loss: 0.7892, Time: 3.77s\n",
      "Epoch: 19, Batch: 70/896, Loss: 0.8222, Time: 3.77s\n",
      "Epoch: 19, Batch: 80/896, Loss: 0.5863, Time: 3.77s\n",
      "Epoch: 19, Batch: 90/896, Loss: 0.8572, Time: 3.77s\n",
      "Epoch: 19, Batch: 100/896, Loss: 0.8032, Time: 3.77s\n",
      "Epoch: 19, Batch: 110/896, Loss: 1.0448, Time: 3.77s\n",
      "Epoch: 19, Batch: 120/896, Loss: 0.7944, Time: 3.77s\n",
      "Epoch: 19, Batch: 130/896, Loss: 1.1425, Time: 3.77s\n",
      "Epoch: 19, Batch: 140/896, Loss: 1.0871, Time: 3.78s\n",
      "Epoch: 19, Batch: 150/896, Loss: 0.4217, Time: 3.78s\n",
      "Epoch: 19, Batch: 160/896, Loss: 0.8597, Time: 3.77s\n",
      "Epoch: 19, Batch: 170/896, Loss: 0.6272, Time: 3.79s\n",
      "Epoch: 19, Batch: 180/896, Loss: 0.5679, Time: 3.79s\n",
      "Epoch: 19, Batch: 190/896, Loss: 0.5496, Time: 3.79s\n",
      "Epoch: 19, Batch: 200/896, Loss: 0.5432, Time: 3.79s\n",
      "Epoch: 19, Batch: 210/896, Loss: 1.0414, Time: 3.80s\n",
      "Epoch: 19, Batch: 220/896, Loss: 0.4665, Time: 3.80s\n",
      "Epoch: 19, Batch: 230/896, Loss: 0.5935, Time: 3.79s\n",
      "Epoch: 19, Batch: 240/896, Loss: 1.0918, Time: 3.79s\n",
      "Epoch: 19, Batch: 250/896, Loss: 0.4564, Time: 3.80s\n",
      "Epoch: 19, Batch: 260/896, Loss: 0.9446, Time: 3.79s\n",
      "Epoch: 19, Batch: 270/896, Loss: 0.5136, Time: 3.80s\n",
      "Epoch: 19, Batch: 280/896, Loss: 0.7401, Time: 3.79s\n",
      "Epoch: 19, Batch: 290/896, Loss: 0.6833, Time: 3.80s\n",
      "Epoch: 19, Batch: 300/896, Loss: 1.1651, Time: 3.80s\n",
      "Epoch: 19, Batch: 310/896, Loss: 1.5282, Time: 3.80s\n",
      "Epoch: 19, Batch: 320/896, Loss: 1.0681, Time: 3.79s\n",
      "Epoch: 19, Batch: 330/896, Loss: 0.8774, Time: 3.80s\n",
      "Epoch: 19, Batch: 340/896, Loss: 0.7955, Time: 3.80s\n",
      "Epoch: 19, Batch: 350/896, Loss: 0.9277, Time: 3.81s\n",
      "Epoch: 19, Batch: 360/896, Loss: 1.5420, Time: 3.80s\n",
      "Epoch: 19, Batch: 370/896, Loss: 0.3919, Time: 3.81s\n",
      "Epoch: 19, Batch: 380/896, Loss: 1.0687, Time: 3.80s\n",
      "Epoch: 19, Batch: 390/896, Loss: 0.9240, Time: 3.80s\n",
      "Epoch: 19, Batch: 400/896, Loss: 0.6769, Time: 3.80s\n",
      "Epoch: 19, Batch: 410/896, Loss: 0.7837, Time: 3.80s\n",
      "Epoch: 19, Batch: 420/896, Loss: 0.5931, Time: 3.81s\n",
      "Epoch: 19, Batch: 430/896, Loss: 1.2431, Time: 3.81s\n",
      "Epoch: 19, Batch: 440/896, Loss: 0.4611, Time: 3.80s\n",
      "Epoch: 19, Batch: 450/896, Loss: 0.9552, Time: 3.79s\n",
      "Epoch: 19, Batch: 460/896, Loss: 0.5741, Time: 3.79s\n",
      "Epoch: 19, Batch: 470/896, Loss: 0.5411, Time: 3.81s\n",
      "Epoch: 19, Batch: 480/896, Loss: 1.0690, Time: 3.81s\n",
      "Epoch: 19, Batch: 490/896, Loss: 0.6972, Time: 3.80s\n",
      "Epoch: 19, Batch: 500/896, Loss: 0.7559, Time: 3.81s\n",
      "Epoch: 19, Batch: 510/896, Loss: 0.7451, Time: 3.80s\n",
      "Epoch: 19, Batch: 520/896, Loss: 0.9895, Time: 3.80s\n",
      "Epoch: 19, Batch: 530/896, Loss: 1.1198, Time: 3.80s\n",
      "Epoch: 19, Batch: 540/896, Loss: 0.9312, Time: 3.82s\n",
      "Epoch: 19, Batch: 550/896, Loss: 0.8320, Time: 3.81s\n",
      "Epoch: 19, Batch: 560/896, Loss: 2.6081, Time: 3.81s\n",
      "Epoch: 19, Batch: 570/896, Loss: 0.2957, Time: 3.80s\n",
      "Epoch: 19, Batch: 580/896, Loss: 1.2113, Time: 3.81s\n",
      "Epoch: 19, Batch: 590/896, Loss: 1.5390, Time: 3.80s\n",
      "Epoch: 19, Batch: 600/896, Loss: 0.8516, Time: 3.80s\n",
      "Epoch: 19, Batch: 610/896, Loss: 0.5759, Time: 3.81s\n",
      "Epoch: 19, Batch: 620/896, Loss: 1.0371, Time: 3.80s\n",
      "Epoch: 19, Batch: 630/896, Loss: 1.8473, Time: 3.80s\n",
      "Epoch: 19, Batch: 640/896, Loss: 0.5365, Time: 3.81s\n",
      "Epoch: 19, Batch: 650/896, Loss: 0.4630, Time: 3.81s\n",
      "Epoch: 19, Batch: 660/896, Loss: 0.9110, Time: 3.81s\n",
      "Epoch: 19, Batch: 670/896, Loss: 0.7252, Time: 3.82s\n",
      "Epoch: 19, Batch: 680/896, Loss: 0.9232, Time: 3.81s\n",
      "Epoch: 19, Batch: 690/896, Loss: 0.4192, Time: 3.80s\n",
      "Epoch: 19, Batch: 700/896, Loss: 0.7287, Time: 3.82s\n",
      "Epoch: 19, Batch: 710/896, Loss: 0.6044, Time: 3.81s\n",
      "Epoch: 19, Batch: 720/896, Loss: 1.0674, Time: 3.80s\n",
      "Epoch: 19, Batch: 730/896, Loss: 1.5309, Time: 3.81s\n",
      "Epoch: 19, Batch: 740/896, Loss: 0.8532, Time: 3.82s\n",
      "Epoch: 19, Batch: 750/896, Loss: 0.7562, Time: 3.82s\n",
      "Epoch: 19, Batch: 760/896, Loss: 0.4934, Time: 3.81s\n",
      "Epoch: 19, Batch: 770/896, Loss: 0.3755, Time: 3.80s\n",
      "Epoch: 19, Batch: 780/896, Loss: 0.5634, Time: 3.81s\n",
      "Epoch: 19, Batch: 790/896, Loss: 0.9087, Time: 3.81s\n",
      "Epoch: 19, Batch: 800/896, Loss: 0.7300, Time: 3.81s\n",
      "Epoch: 19, Batch: 810/896, Loss: 0.3576, Time: 3.80s\n",
      "Epoch: 19, Batch: 820/896, Loss: 0.3774, Time: 3.82s\n",
      "Epoch: 19, Batch: 830/896, Loss: 0.6591, Time: 3.80s\n",
      "Epoch: 19, Batch: 840/896, Loss: 0.6999, Time: 3.80s\n",
      "Epoch: 19, Batch: 850/896, Loss: 0.7362, Time: 3.79s\n",
      "Epoch: 19, Batch: 860/896, Loss: 0.2880, Time: 3.82s\n",
      "Epoch: 19, Batch: 870/896, Loss: 0.6668, Time: 3.81s\n",
      "Epoch: 19, Batch: 880/896, Loss: 0.4747, Time: 3.81s\n",
      "Epoch: 19, Batch: 890/896, Loss: 0.3348, Time: 3.79s\n",
      "Epoch 20/50: Train Loss: 0.8037, Val Loss: 0.8295, Val IoU: 0.3773, Val Dice: 0.4009\n",
      "Saving best model with IoU: 0.3773\n",
      "Epoch: 20, Batch: 0/896, Loss: 1.2219, Time: 28.79s\n",
      "Epoch: 20, Batch: 10/896, Loss: 0.6745, Time: 3.74s\n",
      "Epoch: 20, Batch: 20/896, Loss: 1.2968, Time: 3.74s\n",
      "Epoch: 20, Batch: 30/896, Loss: 0.9517, Time: 3.75s\n",
      "Epoch: 20, Batch: 40/896, Loss: 0.5484, Time: 3.75s\n",
      "Epoch: 20, Batch: 50/896, Loss: 0.3334, Time: 3.76s\n",
      "Epoch: 20, Batch: 60/896, Loss: 1.1603, Time: 3.76s\n",
      "Epoch: 20, Batch: 70/896, Loss: 0.8403, Time: 3.77s\n",
      "Epoch: 20, Batch: 80/896, Loss: 0.4904, Time: 3.75s\n",
      "Epoch: 20, Batch: 90/896, Loss: 0.5498, Time: 3.77s\n",
      "Epoch: 20, Batch: 100/896, Loss: 0.6315, Time: 3.77s\n",
      "Epoch: 20, Batch: 110/896, Loss: 0.7728, Time: 3.78s\n",
      "Epoch: 20, Batch: 120/896, Loss: 0.7112, Time: 3.77s\n",
      "Epoch: 20, Batch: 130/896, Loss: 1.1791, Time: 3.78s\n",
      "Epoch: 20, Batch: 140/896, Loss: 0.4948, Time: 3.77s\n",
      "Epoch: 20, Batch: 150/896, Loss: 0.7565, Time: 3.77s\n",
      "Epoch: 20, Batch: 160/896, Loss: 1.0960, Time: 3.78s\n",
      "Epoch: 20, Batch: 170/896, Loss: 0.8485, Time: 3.77s\n",
      "Epoch: 20, Batch: 180/896, Loss: 0.8698, Time: 3.77s\n",
      "Epoch: 20, Batch: 190/896, Loss: 0.8889, Time: 3.78s\n",
      "Epoch: 20, Batch: 200/896, Loss: 1.0323, Time: 3.79s\n",
      "Epoch: 20, Batch: 210/896, Loss: 1.2717, Time: 3.79s\n",
      "Epoch: 20, Batch: 220/896, Loss: 0.8844, Time: 3.80s\n",
      "Epoch: 20, Batch: 230/896, Loss: 0.9840, Time: 3.80s\n",
      "Epoch: 20, Batch: 240/896, Loss: 1.0575, Time: 3.79s\n",
      "Epoch: 20, Batch: 250/896, Loss: 1.5351, Time: 3.80s\n",
      "Epoch: 20, Batch: 260/896, Loss: 1.5875, Time: 3.80s\n",
      "Epoch: 20, Batch: 270/896, Loss: 0.4958, Time: 3.79s\n",
      "Epoch: 20, Batch: 280/896, Loss: 0.4424, Time: 3.79s\n",
      "Epoch: 20, Batch: 290/896, Loss: 1.0798, Time: 3.81s\n",
      "Epoch: 20, Batch: 300/896, Loss: 0.6520, Time: 3.80s\n",
      "Epoch: 20, Batch: 310/896, Loss: 0.5537, Time: 3.80s\n",
      "Epoch: 20, Batch: 320/896, Loss: 0.7437, Time: 3.80s\n",
      "Epoch: 20, Batch: 330/896, Loss: 0.5346, Time: 3.80s\n",
      "Epoch: 20, Batch: 340/896, Loss: 0.8254, Time: 3.80s\n",
      "Epoch: 20, Batch: 350/896, Loss: 0.6520, Time: 3.79s\n",
      "Epoch: 20, Batch: 360/896, Loss: 0.7309, Time: 3.79s\n",
      "Epoch: 20, Batch: 370/896, Loss: 0.9728, Time: 3.80s\n",
      "Epoch: 20, Batch: 380/896, Loss: 0.4403, Time: 3.80s\n",
      "Epoch: 20, Batch: 390/896, Loss: 1.0534, Time: 3.80s\n",
      "Epoch: 20, Batch: 400/896, Loss: 0.8029, Time: 3.80s\n",
      "Epoch: 20, Batch: 410/896, Loss: 1.5589, Time: 3.81s\n",
      "Epoch: 20, Batch: 420/896, Loss: 0.4268, Time: 3.81s\n",
      "Epoch: 20, Batch: 430/896, Loss: 1.0560, Time: 3.81s\n",
      "Epoch: 20, Batch: 440/896, Loss: 0.7076, Time: 3.81s\n",
      "Epoch: 20, Batch: 450/896, Loss: 0.6924, Time: 3.80s\n",
      "Epoch: 20, Batch: 460/896, Loss: 1.1594, Time: 3.81s\n",
      "Epoch: 20, Batch: 470/896, Loss: 0.4904, Time: 3.80s\n",
      "Epoch: 20, Batch: 480/896, Loss: 0.6263, Time: 3.80s\n",
      "Epoch: 20, Batch: 490/896, Loss: 1.1243, Time: 3.81s\n",
      "Epoch: 20, Batch: 500/896, Loss: 0.6068, Time: 3.81s\n",
      "Epoch: 20, Batch: 510/896, Loss: 0.7835, Time: 3.80s\n",
      "Epoch: 20, Batch: 520/896, Loss: 1.0832, Time: 3.80s\n",
      "Epoch: 20, Batch: 530/896, Loss: 0.8927, Time: 3.81s\n",
      "Epoch: 20, Batch: 540/896, Loss: 0.4806, Time: 3.80s\n",
      "Epoch: 20, Batch: 550/896, Loss: 0.9919, Time: 3.80s\n",
      "Epoch: 20, Batch: 560/896, Loss: 0.6903, Time: 3.82s\n",
      "Epoch: 20, Batch: 570/896, Loss: 1.3642, Time: 3.80s\n",
      "Epoch: 20, Batch: 580/896, Loss: 1.3469, Time: 3.81s\n",
      "Epoch: 20, Batch: 590/896, Loss: 0.7496, Time: 3.80s\n",
      "Epoch: 20, Batch: 600/896, Loss: 0.5431, Time: 3.79s\n",
      "Epoch: 20, Batch: 610/896, Loss: 1.0408, Time: 3.81s\n",
      "Epoch: 20, Batch: 620/896, Loss: 0.6121, Time: 3.81s\n",
      "Epoch: 20, Batch: 630/896, Loss: 0.6973, Time: 3.82s\n",
      "Epoch: 20, Batch: 640/896, Loss: 1.0464, Time: 3.79s\n",
      "Epoch: 20, Batch: 650/896, Loss: 0.3777, Time: 3.81s\n",
      "Epoch: 20, Batch: 660/896, Loss: 1.1028, Time: 3.80s\n",
      "Epoch: 20, Batch: 670/896, Loss: 0.7992, Time: 3.80s\n",
      "Epoch: 20, Batch: 680/896, Loss: 1.1909, Time: 3.80s\n",
      "Epoch: 20, Batch: 690/896, Loss: 0.4351, Time: 3.81s\n",
      "Epoch: 20, Batch: 700/896, Loss: 0.5586, Time: 3.81s\n",
      "Epoch: 20, Batch: 710/896, Loss: 0.5551, Time: 3.81s\n",
      "Epoch: 20, Batch: 720/896, Loss: 0.9934, Time: 3.81s\n",
      "Epoch: 20, Batch: 730/896, Loss: 1.1441, Time: 3.80s\n",
      "Epoch: 20, Batch: 740/896, Loss: 0.3461, Time: 3.80s\n",
      "Epoch: 20, Batch: 750/896, Loss: 0.5592, Time: 3.80s\n",
      "Epoch: 20, Batch: 760/896, Loss: 0.4140, Time: 3.82s\n",
      "Epoch: 20, Batch: 770/896, Loss: 0.5550, Time: 3.80s\n",
      "Epoch: 20, Batch: 780/896, Loss: 0.8827, Time: 3.81s\n",
      "Epoch: 20, Batch: 790/896, Loss: 0.4753, Time: 3.81s\n",
      "Epoch: 20, Batch: 800/896, Loss: 0.6916, Time: 3.81s\n",
      "Epoch: 20, Batch: 810/896, Loss: 0.9277, Time: 3.80s\n",
      "Epoch: 20, Batch: 820/896, Loss: 1.4740, Time: 3.81s\n",
      "Epoch: 20, Batch: 830/896, Loss: 0.9542, Time: 3.80s\n",
      "Epoch: 20, Batch: 840/896, Loss: 0.3636, Time: 3.80s\n",
      "Epoch: 20, Batch: 850/896, Loss: 0.6825, Time: 3.80s\n",
      "Epoch: 20, Batch: 860/896, Loss: 0.6127, Time: 3.81s\n",
      "Epoch: 20, Batch: 870/896, Loss: 1.4696, Time: 3.80s\n",
      "Epoch: 20, Batch: 880/896, Loss: 1.1814, Time: 3.81s\n",
      "Epoch: 20, Batch: 890/896, Loss: 0.5411, Time: 3.81s\n",
      "Epoch 21/50: Train Loss: 0.8046, Val Loss: 0.8709, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 21, Batch: 0/896, Loss: 0.4888, Time: 28.87s\n",
      "Epoch: 21, Batch: 10/896, Loss: 0.8088, Time: 3.75s\n",
      "Epoch: 21, Batch: 20/896, Loss: 0.6799, Time: 3.75s\n",
      "Epoch: 21, Batch: 30/896, Loss: 0.5006, Time: 3.74s\n",
      "Epoch: 21, Batch: 40/896, Loss: 0.6217, Time: 3.74s\n",
      "Epoch: 21, Batch: 50/896, Loss: 0.8872, Time: 3.75s\n",
      "Epoch: 21, Batch: 60/896, Loss: 0.4649, Time: 3.76s\n",
      "Epoch: 21, Batch: 70/896, Loss: 0.5682, Time: 3.77s\n",
      "Epoch: 21, Batch: 80/896, Loss: 0.9095, Time: 3.76s\n",
      "Epoch: 21, Batch: 90/896, Loss: 1.2363, Time: 3.76s\n",
      "Epoch: 21, Batch: 100/896, Loss: 0.6868, Time: 3.78s\n",
      "Epoch: 21, Batch: 110/896, Loss: 0.7833, Time: 3.77s\n",
      "Epoch: 21, Batch: 120/896, Loss: 1.0842, Time: 3.78s\n",
      "Epoch: 21, Batch: 130/896, Loss: 1.3219, Time: 3.77s\n",
      "Epoch: 21, Batch: 140/896, Loss: 0.3542, Time: 3.78s\n",
      "Epoch: 21, Batch: 150/896, Loss: 1.2139, Time: 3.77s\n",
      "Epoch: 21, Batch: 160/896, Loss: 0.6057, Time: 3.79s\n",
      "Epoch: 21, Batch: 170/896, Loss: 0.9927, Time: 3.77s\n",
      "Epoch: 21, Batch: 180/896, Loss: 1.0236, Time: 3.79s\n",
      "Epoch: 21, Batch: 190/896, Loss: 0.3386, Time: 3.80s\n",
      "Epoch: 21, Batch: 200/896, Loss: 0.4030, Time: 3.77s\n",
      "Epoch: 21, Batch: 210/896, Loss: 1.1278, Time: 3.79s\n",
      "Epoch: 21, Batch: 220/896, Loss: 0.7155, Time: 3.78s\n",
      "Epoch: 21, Batch: 230/896, Loss: 0.7846, Time: 3.79s\n",
      "Epoch: 21, Batch: 240/896, Loss: 0.7506, Time: 3.78s\n",
      "Epoch: 21, Batch: 250/896, Loss: 0.6913, Time: 3.79s\n",
      "Epoch: 21, Batch: 260/896, Loss: 0.7098, Time: 3.79s\n",
      "Epoch: 21, Batch: 270/896, Loss: 0.2763, Time: 3.78s\n",
      "Epoch: 21, Batch: 280/896, Loss: 0.4381, Time: 3.79s\n",
      "Epoch: 21, Batch: 290/896, Loss: 0.8328, Time: 3.80s\n",
      "Epoch: 21, Batch: 300/896, Loss: 1.2281, Time: 3.78s\n",
      "Epoch: 21, Batch: 310/896, Loss: 1.5077, Time: 3.80s\n",
      "Epoch: 21, Batch: 320/896, Loss: 0.7704, Time: 3.79s\n",
      "Epoch: 21, Batch: 330/896, Loss: 1.3948, Time: 3.81s\n",
      "Epoch: 21, Batch: 340/896, Loss: 0.7851, Time: 3.78s\n",
      "Epoch: 21, Batch: 350/896, Loss: 0.7907, Time: 3.80s\n",
      "Epoch: 21, Batch: 360/896, Loss: 0.6598, Time: 3.79s\n",
      "Epoch: 21, Batch: 370/896, Loss: 1.1944, Time: 3.79s\n",
      "Epoch: 21, Batch: 380/896, Loss: 1.0232, Time: 3.80s\n",
      "Epoch: 21, Batch: 390/896, Loss: 0.8061, Time: 3.81s\n",
      "Epoch: 21, Batch: 400/896, Loss: 0.6935, Time: 3.79s\n",
      "Epoch: 21, Batch: 410/896, Loss: 0.6739, Time: 3.80s\n",
      "Epoch: 21, Batch: 420/896, Loss: 0.7885, Time: 3.80s\n",
      "Epoch: 21, Batch: 430/896, Loss: 0.7015, Time: 3.80s\n",
      "Epoch: 21, Batch: 440/896, Loss: 0.5377, Time: 3.80s\n",
      "Epoch: 21, Batch: 450/896, Loss: 0.4791, Time: 3.80s\n",
      "Epoch: 21, Batch: 460/896, Loss: 0.6221, Time: 3.79s\n",
      "Epoch: 21, Batch: 470/896, Loss: 1.6604, Time: 3.79s\n",
      "Epoch: 21, Batch: 480/896, Loss: 0.6163, Time: 3.80s\n",
      "Epoch: 21, Batch: 490/896, Loss: 0.8607, Time: 3.80s\n",
      "Epoch: 21, Batch: 500/896, Loss: 0.5087, Time: 3.80s\n",
      "Epoch: 21, Batch: 510/896, Loss: 0.8382, Time: 3.81s\n",
      "Epoch: 21, Batch: 520/896, Loss: 0.6661, Time: 3.80s\n",
      "Epoch: 21, Batch: 530/896, Loss: 1.1676, Time: 3.81s\n",
      "Epoch: 21, Batch: 540/896, Loss: 1.0679, Time: 3.80s\n",
      "Epoch: 21, Batch: 550/896, Loss: 0.5199, Time: 3.80s\n",
      "Epoch: 21, Batch: 560/896, Loss: 0.5084, Time: 3.81s\n",
      "Epoch: 21, Batch: 570/896, Loss: 0.5571, Time: 3.80s\n",
      "Epoch: 21, Batch: 580/896, Loss: 2.0333, Time: 3.80s\n",
      "Epoch: 21, Batch: 590/896, Loss: 1.1070, Time: 3.81s\n",
      "Epoch: 21, Batch: 600/896, Loss: 0.9976, Time: 3.79s\n",
      "Epoch: 21, Batch: 610/896, Loss: 0.3962, Time: 3.81s\n",
      "Epoch: 21, Batch: 620/896, Loss: 0.6389, Time: 3.82s\n",
      "Epoch: 21, Batch: 630/896, Loss: 0.5245, Time: 3.81s\n",
      "Epoch: 21, Batch: 640/896, Loss: 0.6324, Time: 3.79s\n",
      "Epoch: 21, Batch: 650/896, Loss: 1.1788, Time: 3.80s\n",
      "Epoch: 21, Batch: 660/896, Loss: 0.5268, Time: 3.81s\n",
      "Epoch: 21, Batch: 670/896, Loss: 1.3343, Time: 3.81s\n",
      "Epoch: 21, Batch: 680/896, Loss: 0.9111, Time: 3.81s\n",
      "Epoch: 21, Batch: 690/896, Loss: 0.3907, Time: 3.80s\n",
      "Epoch: 21, Batch: 700/896, Loss: 1.2230, Time: 3.80s\n",
      "Epoch: 21, Batch: 710/896, Loss: 0.7884, Time: 3.79s\n",
      "Epoch: 21, Batch: 720/896, Loss: 0.7227, Time: 3.81s\n",
      "Epoch: 21, Batch: 730/896, Loss: 0.7215, Time: 3.82s\n",
      "Epoch: 21, Batch: 740/896, Loss: 1.1828, Time: 3.81s\n",
      "Epoch: 21, Batch: 750/896, Loss: 0.4983, Time: 3.81s\n",
      "Epoch: 21, Batch: 760/896, Loss: 0.5838, Time: 3.80s\n",
      "Epoch: 21, Batch: 770/896, Loss: 1.6252, Time: 3.80s\n",
      "Epoch: 21, Batch: 780/896, Loss: 0.6021, Time: 3.81s\n",
      "Epoch: 21, Batch: 790/896, Loss: 0.7057, Time: 3.80s\n",
      "Epoch: 21, Batch: 800/896, Loss: 0.4061, Time: 3.80s\n",
      "Epoch: 21, Batch: 810/896, Loss: 2.0695, Time: 3.82s\n",
      "Epoch: 21, Batch: 820/896, Loss: 0.4532, Time: 3.81s\n",
      "Epoch: 21, Batch: 830/896, Loss: 0.4421, Time: 3.80s\n",
      "Epoch: 21, Batch: 840/896, Loss: 1.2176, Time: 3.80s\n",
      "Epoch: 21, Batch: 850/896, Loss: 0.9680, Time: 3.82s\n",
      "Epoch: 21, Batch: 860/896, Loss: 0.9717, Time: 3.82s\n",
      "Epoch: 21, Batch: 870/896, Loss: 0.3507, Time: 3.80s\n",
      "Epoch: 21, Batch: 880/896, Loss: 0.2330, Time: 3.81s\n",
      "Epoch: 21, Batch: 890/896, Loss: 0.9159, Time: 3.80s\n",
      "Epoch 22/50: Train Loss: 0.8009, Val Loss: 0.8642, Val IoU: 0.3484, Val Dice: 0.3720\n",
      "Epoch: 22, Batch: 0/896, Loss: 0.8188, Time: 28.73s\n",
      "Epoch: 22, Batch: 10/896, Loss: 0.2906, Time: 3.74s\n",
      "Epoch: 22, Batch: 20/896, Loss: 0.5112, Time: 3.74s\n",
      "Epoch: 22, Batch: 30/896, Loss: 0.3357, Time: 3.74s\n",
      "Epoch: 22, Batch: 40/896, Loss: 1.8904, Time: 3.76s\n",
      "Epoch: 22, Batch: 50/896, Loss: 0.2870, Time: 3.75s\n",
      "Epoch: 22, Batch: 60/896, Loss: 1.3678, Time: 3.76s\n",
      "Epoch: 22, Batch: 70/896, Loss: 0.5809, Time: 3.75s\n",
      "Epoch: 22, Batch: 80/896, Loss: 0.5370, Time: 3.76s\n",
      "Epoch: 22, Batch: 90/896, Loss: 0.5413, Time: 3.75s\n",
      "Epoch: 22, Batch: 100/896, Loss: 0.5822, Time: 3.76s\n",
      "Epoch: 22, Batch: 110/896, Loss: 0.4808, Time: 3.77s\n",
      "Epoch: 22, Batch: 120/896, Loss: 0.8602, Time: 3.77s\n",
      "Epoch: 22, Batch: 130/896, Loss: 0.8599, Time: 3.76s\n",
      "Epoch: 22, Batch: 140/896, Loss: 0.9731, Time: 3.76s\n",
      "Epoch: 22, Batch: 150/896, Loss: 1.0075, Time: 3.77s\n",
      "Epoch: 22, Batch: 160/896, Loss: 0.6300, Time: 3.77s\n",
      "Epoch: 22, Batch: 170/896, Loss: 1.6914, Time: 3.78s\n",
      "Epoch: 22, Batch: 180/896, Loss: 0.7528, Time: 3.76s\n",
      "Epoch: 22, Batch: 190/896, Loss: 0.6993, Time: 3.78s\n",
      "Epoch: 22, Batch: 200/896, Loss: 1.6638, Time: 3.77s\n",
      "Epoch: 22, Batch: 210/896, Loss: 0.4844, Time: 3.78s\n",
      "Epoch: 22, Batch: 220/896, Loss: 0.8274, Time: 3.79s\n",
      "Epoch: 22, Batch: 230/896, Loss: 0.4258, Time: 3.78s\n",
      "Epoch: 22, Batch: 240/896, Loss: 0.6603, Time: 3.78s\n",
      "Epoch: 22, Batch: 250/896, Loss: 0.8244, Time: 3.79s\n",
      "Epoch: 22, Batch: 260/896, Loss: 0.8163, Time: 3.79s\n",
      "Epoch: 22, Batch: 270/896, Loss: 1.2705, Time: 3.78s\n",
      "Epoch: 22, Batch: 280/896, Loss: 0.7293, Time: 3.80s\n",
      "Epoch: 22, Batch: 290/896, Loss: 1.3200, Time: 3.79s\n",
      "Epoch: 22, Batch: 300/896, Loss: 0.6879, Time: 3.79s\n",
      "Epoch: 22, Batch: 310/896, Loss: 1.0680, Time: 3.79s\n",
      "Epoch: 22, Batch: 320/896, Loss: 1.3863, Time: 3.80s\n",
      "Epoch: 22, Batch: 330/896, Loss: 0.5523, Time: 3.80s\n",
      "Epoch: 22, Batch: 340/896, Loss: 0.5572, Time: 3.80s\n",
      "Epoch: 22, Batch: 350/896, Loss: 1.0167, Time: 3.79s\n",
      "Epoch: 22, Batch: 360/896, Loss: 1.0783, Time: 3.80s\n",
      "Epoch: 22, Batch: 370/896, Loss: 0.5163, Time: 3.78s\n",
      "Epoch: 22, Batch: 380/896, Loss: 0.9491, Time: 3.79s\n",
      "Epoch: 22, Batch: 390/896, Loss: 1.1125, Time: 3.79s\n",
      "Epoch: 22, Batch: 400/896, Loss: 1.4407, Time: 3.78s\n",
      "Epoch: 22, Batch: 410/896, Loss: 0.7740, Time: 3.80s\n",
      "Epoch: 22, Batch: 420/896, Loss: 0.4885, Time: 3.80s\n",
      "Epoch: 22, Batch: 430/896, Loss: 0.8953, Time: 3.81s\n",
      "Epoch: 22, Batch: 440/896, Loss: 1.3700, Time: 3.79s\n",
      "Epoch: 22, Batch: 450/896, Loss: 0.6909, Time: 3.79s\n",
      "Epoch: 22, Batch: 460/896, Loss: 0.9855, Time: 3.79s\n",
      "Epoch: 22, Batch: 470/896, Loss: 0.5916, Time: 3.80s\n",
      "Epoch: 22, Batch: 480/896, Loss: 0.5521, Time: 3.80s\n",
      "Epoch: 22, Batch: 490/896, Loss: 0.3307, Time: 3.79s\n",
      "Epoch: 22, Batch: 500/896, Loss: 0.4876, Time: 3.80s\n",
      "Epoch: 22, Batch: 510/896, Loss: 0.6699, Time: 3.79s\n",
      "Epoch: 22, Batch: 520/896, Loss: 1.0966, Time: 3.81s\n",
      "Epoch: 22, Batch: 530/896, Loss: 0.7073, Time: 3.79s\n",
      "Epoch: 22, Batch: 540/896, Loss: 0.6524, Time: 3.79s\n",
      "Epoch: 22, Batch: 550/896, Loss: 0.9161, Time: 3.80s\n",
      "Epoch: 22, Batch: 560/896, Loss: 0.5150, Time: 3.80s\n",
      "Epoch: 22, Batch: 570/896, Loss: 1.3887, Time: 3.80s\n",
      "Epoch: 22, Batch: 580/896, Loss: 1.1286, Time: 3.81s\n",
      "Epoch: 22, Batch: 590/896, Loss: 0.3776, Time: 3.80s\n",
      "Epoch: 22, Batch: 600/896, Loss: 0.7332, Time: 3.81s\n",
      "Epoch: 22, Batch: 610/896, Loss: 1.2658, Time: 3.81s\n",
      "Epoch: 22, Batch: 620/896, Loss: 0.9981, Time: 3.81s\n",
      "Epoch: 22, Batch: 630/896, Loss: 1.4358, Time: 3.80s\n",
      "Epoch: 22, Batch: 640/896, Loss: 1.2560, Time: 3.80s\n",
      "Epoch: 22, Batch: 650/896, Loss: 0.7209, Time: 3.81s\n",
      "Epoch: 22, Batch: 660/896, Loss: 0.7142, Time: 3.80s\n",
      "Epoch: 22, Batch: 670/896, Loss: 0.7043, Time: 3.81s\n",
      "Epoch: 22, Batch: 680/896, Loss: 0.5314, Time: 3.80s\n",
      "Epoch: 22, Batch: 690/896, Loss: 1.1109, Time: 3.80s\n",
      "Epoch: 22, Batch: 700/896, Loss: 0.8739, Time: 3.81s\n",
      "Epoch: 22, Batch: 710/896, Loss: 0.4476, Time: 3.81s\n",
      "Epoch: 22, Batch: 720/896, Loss: 0.8400, Time: 3.80s\n",
      "Epoch: 22, Batch: 730/896, Loss: 1.0715, Time: 3.79s\n",
      "Epoch: 22, Batch: 740/896, Loss: 0.9786, Time: 3.80s\n",
      "Epoch: 22, Batch: 750/896, Loss: 0.5537, Time: 3.82s\n",
      "Epoch: 22, Batch: 760/896, Loss: 0.8884, Time: 3.80s\n",
      "Epoch: 22, Batch: 770/896, Loss: 0.4330, Time: 3.80s\n",
      "Epoch: 22, Batch: 780/896, Loss: 0.8183, Time: 3.80s\n",
      "Epoch: 22, Batch: 790/896, Loss: 0.6831, Time: 3.81s\n",
      "Epoch: 22, Batch: 800/896, Loss: 0.4765, Time: 3.82s\n",
      "Epoch: 22, Batch: 810/896, Loss: 0.9515, Time: 3.80s\n",
      "Epoch: 22, Batch: 820/896, Loss: 0.8176, Time: 3.80s\n",
      "Epoch: 22, Batch: 830/896, Loss: 1.0475, Time: 3.81s\n",
      "Epoch: 22, Batch: 840/896, Loss: 1.1011, Time: 3.81s\n",
      "Epoch: 22, Batch: 850/896, Loss: 0.4718, Time: 3.81s\n",
      "Epoch: 22, Batch: 860/896, Loss: 0.6159, Time: 3.80s\n",
      "Epoch: 22, Batch: 870/896, Loss: 0.8001, Time: 3.81s\n",
      "Epoch: 22, Batch: 880/896, Loss: 0.7364, Time: 3.80s\n",
      "Epoch: 22, Batch: 890/896, Loss: 0.8027, Time: 3.80s\n",
      "Epoch 23/50: Train Loss: 0.8037, Val Loss: 0.8326, Val IoU: 0.3720, Val Dice: 0.3962\n",
      "Epoch: 23, Batch: 0/896, Loss: 0.8052, Time: 28.87s\n",
      "Epoch: 23, Batch: 10/896, Loss: 0.8751, Time: 3.73s\n",
      "Epoch: 23, Batch: 20/896, Loss: 0.8001, Time: 3.73s\n",
      "Epoch: 23, Batch: 30/896, Loss: 0.4274, Time: 3.73s\n",
      "Epoch: 23, Batch: 40/896, Loss: 0.9137, Time: 3.74s\n",
      "Epoch: 23, Batch: 50/896, Loss: 0.9615, Time: 3.74s\n",
      "Epoch: 23, Batch: 60/896, Loss: 0.6268, Time: 3.76s\n",
      "Epoch: 23, Batch: 70/896, Loss: 0.2712, Time: 3.74s\n",
      "Epoch: 23, Batch: 80/896, Loss: 0.9355, Time: 3.77s\n",
      "Epoch: 23, Batch: 90/896, Loss: 0.8362, Time: 3.77s\n",
      "Epoch: 23, Batch: 100/896, Loss: 0.5204, Time: 3.76s\n",
      "Epoch: 23, Batch: 110/896, Loss: 1.1332, Time: 3.76s\n",
      "Epoch: 23, Batch: 120/896, Loss: 0.7889, Time: 3.77s\n",
      "Epoch: 23, Batch: 130/896, Loss: 0.6414, Time: 3.78s\n",
      "Epoch: 23, Batch: 140/896, Loss: 0.3389, Time: 3.78s\n",
      "Epoch: 23, Batch: 150/896, Loss: 0.7215, Time: 3.77s\n",
      "Epoch: 23, Batch: 160/896, Loss: 0.9303, Time: 3.76s\n",
      "Epoch: 23, Batch: 170/896, Loss: 0.3959, Time: 3.78s\n",
      "Epoch: 23, Batch: 180/896, Loss: 1.0144, Time: 3.78s\n",
      "Epoch: 23, Batch: 190/896, Loss: 0.5953, Time: 3.78s\n",
      "Epoch: 23, Batch: 200/896, Loss: 0.4226, Time: 3.77s\n",
      "Epoch: 23, Batch: 210/896, Loss: 1.3004, Time: 3.78s\n",
      "Epoch: 23, Batch: 220/896, Loss: 0.4698, Time: 3.78s\n",
      "Epoch: 23, Batch: 230/896, Loss: 0.7717, Time: 3.78s\n",
      "Epoch: 23, Batch: 240/896, Loss: 0.6223, Time: 3.78s\n",
      "Epoch: 23, Batch: 250/896, Loss: 0.3469, Time: 3.79s\n",
      "Epoch: 23, Batch: 260/896, Loss: 0.6961, Time: 3.79s\n",
      "Epoch: 23, Batch: 270/896, Loss: 0.5017, Time: 3.77s\n",
      "Epoch: 23, Batch: 280/896, Loss: 0.3589, Time: 3.78s\n",
      "Epoch: 23, Batch: 290/896, Loss: 1.2771, Time: 3.79s\n",
      "Epoch: 23, Batch: 300/896, Loss: 0.7681, Time: 3.78s\n",
      "Epoch: 23, Batch: 310/896, Loss: 0.8554, Time: 3.79s\n",
      "Epoch: 23, Batch: 320/896, Loss: 0.9777, Time: 3.79s\n",
      "Epoch: 23, Batch: 330/896, Loss: 1.0960, Time: 3.78s\n",
      "Epoch: 23, Batch: 340/896, Loss: 0.5649, Time: 3.79s\n",
      "Epoch: 23, Batch: 350/896, Loss: 0.8589, Time: 3.79s\n",
      "Epoch: 23, Batch: 360/896, Loss: 1.2373, Time: 3.79s\n",
      "Epoch: 23, Batch: 370/896, Loss: 0.4577, Time: 3.79s\n",
      "Epoch: 23, Batch: 380/896, Loss: 0.4815, Time: 3.80s\n",
      "Epoch: 23, Batch: 390/896, Loss: 0.7235, Time: 3.79s\n",
      "Epoch: 23, Batch: 400/896, Loss: 0.8003, Time: 3.79s\n",
      "Epoch: 23, Batch: 410/896, Loss: 0.8187, Time: 3.81s\n",
      "Epoch: 23, Batch: 420/896, Loss: 1.0142, Time: 3.79s\n",
      "Epoch: 23, Batch: 430/896, Loss: 0.8117, Time: 3.81s\n",
      "Epoch: 23, Batch: 440/896, Loss: 0.9234, Time: 3.80s\n",
      "Epoch: 23, Batch: 450/896, Loss: 0.6440, Time: 3.80s\n",
      "Epoch: 23, Batch: 460/896, Loss: 1.0215, Time: 3.79s\n",
      "Epoch: 23, Batch: 470/896, Loss: 0.4154, Time: 3.81s\n",
      "Epoch: 23, Batch: 480/896, Loss: 0.6200, Time: 3.80s\n",
      "Epoch: 23, Batch: 490/896, Loss: 0.4014, Time: 3.80s\n",
      "Epoch: 23, Batch: 500/896, Loss: 0.8887, Time: 3.79s\n",
      "Epoch: 23, Batch: 510/896, Loss: 0.3625, Time: 3.80s\n",
      "Epoch: 23, Batch: 520/896, Loss: 0.8710, Time: 3.78s\n",
      "Epoch: 23, Batch: 530/896, Loss: 0.5103, Time: 3.80s\n",
      "Epoch: 23, Batch: 540/896, Loss: 1.2525, Time: 3.79s\n",
      "Epoch: 23, Batch: 550/896, Loss: 0.7689, Time: 3.79s\n",
      "Epoch: 23, Batch: 560/896, Loss: 1.8253, Time: 3.79s\n",
      "Epoch: 23, Batch: 570/896, Loss: 0.9593, Time: 3.80s\n",
      "Epoch: 23, Batch: 580/896, Loss: 1.2519, Time: 3.79s\n",
      "Epoch: 23, Batch: 590/896, Loss: 0.4707, Time: 3.79s\n",
      "Epoch: 23, Batch: 600/896, Loss: 0.4242, Time: 3.80s\n",
      "Epoch: 23, Batch: 610/896, Loss: 0.6692, Time: 3.79s\n",
      "Epoch: 23, Batch: 620/896, Loss: 0.5404, Time: 3.80s\n",
      "Epoch: 23, Batch: 630/896, Loss: 0.4581, Time: 3.80s\n",
      "Epoch: 23, Batch: 640/896, Loss: 0.8201, Time: 3.80s\n",
      "Epoch: 23, Batch: 650/896, Loss: 0.6262, Time: 3.80s\n",
      "Epoch: 23, Batch: 660/896, Loss: 0.6965, Time: 3.80s\n",
      "Epoch: 23, Batch: 670/896, Loss: 1.2615, Time: 3.80s\n",
      "Epoch: 23, Batch: 680/896, Loss: 0.6705, Time: 3.79s\n",
      "Epoch: 23, Batch: 690/896, Loss: 0.3935, Time: 3.79s\n",
      "Epoch: 23, Batch: 700/896, Loss: 0.8186, Time: 3.81s\n",
      "Epoch: 23, Batch: 710/896, Loss: 0.6707, Time: 3.79s\n",
      "Epoch: 23, Batch: 720/896, Loss: 2.0123, Time: 3.81s\n",
      "Epoch: 23, Batch: 730/896, Loss: 0.6135, Time: 3.81s\n",
      "Epoch: 23, Batch: 740/896, Loss: 0.3078, Time: 3.78s\n",
      "Epoch: 23, Batch: 750/896, Loss: 1.5278, Time: 3.81s\n",
      "Epoch: 23, Batch: 760/896, Loss: 0.3870, Time: 3.80s\n",
      "Epoch: 23, Batch: 770/896, Loss: 0.6430, Time: 3.80s\n",
      "Epoch: 23, Batch: 780/896, Loss: 0.8795, Time: 3.80s\n",
      "Epoch: 23, Batch: 790/896, Loss: 1.1807, Time: 3.79s\n",
      "Epoch: 23, Batch: 800/896, Loss: 0.3879, Time: 3.79s\n",
      "Epoch: 23, Batch: 810/896, Loss: 0.8924, Time: 3.80s\n",
      "Epoch: 23, Batch: 820/896, Loss: 1.0291, Time: 3.79s\n",
      "Epoch: 23, Batch: 830/896, Loss: 0.7233, Time: 3.81s\n",
      "Epoch: 23, Batch: 840/896, Loss: 0.7011, Time: 3.80s\n",
      "Epoch: 23, Batch: 850/896, Loss: 0.7562, Time: 3.81s\n",
      "Epoch: 23, Batch: 860/896, Loss: 0.6461, Time: 3.80s\n",
      "Epoch: 23, Batch: 870/896, Loss: 0.6487, Time: 3.81s\n",
      "Epoch: 23, Batch: 880/896, Loss: 0.4676, Time: 3.79s\n",
      "Epoch: 23, Batch: 890/896, Loss: 0.4321, Time: 3.81s\n",
      "Epoch 24/50: Train Loss: 0.8001, Val Loss: 0.8530, Val IoU: 0.3638, Val Dice: 0.3865\n",
      "Epoch: 24, Batch: 0/896, Loss: 1.7430, Time: 28.74s\n",
      "Epoch: 24, Batch: 10/896, Loss: 0.8324, Time: 3.74s\n",
      "Epoch: 24, Batch: 20/896, Loss: 1.1503, Time: 3.74s\n",
      "Epoch: 24, Batch: 30/896, Loss: 0.6289, Time: 3.74s\n",
      "Epoch: 24, Batch: 40/896, Loss: 1.3746, Time: 3.75s\n",
      "Epoch: 24, Batch: 50/896, Loss: 0.6288, Time: 3.75s\n",
      "Epoch: 24, Batch: 60/896, Loss: 1.2878, Time: 3.74s\n",
      "Epoch: 24, Batch: 70/896, Loss: 1.1370, Time: 3.75s\n",
      "Epoch: 24, Batch: 80/896, Loss: 0.5725, Time: 3.75s\n",
      "Epoch: 24, Batch: 90/896, Loss: 1.4330, Time: 3.76s\n",
      "Epoch: 24, Batch: 100/896, Loss: 1.1109, Time: 3.77s\n",
      "Epoch: 24, Batch: 110/896, Loss: 0.8423, Time: 3.76s\n",
      "Epoch: 24, Batch: 120/896, Loss: 0.8080, Time: 3.75s\n",
      "Epoch: 24, Batch: 130/896, Loss: 0.4950, Time: 3.77s\n",
      "Epoch: 24, Batch: 140/896, Loss: 0.7553, Time: 3.76s\n",
      "Epoch: 24, Batch: 150/896, Loss: 1.6447, Time: 3.78s\n",
      "Epoch: 24, Batch: 160/896, Loss: 0.9582, Time: 3.78s\n",
      "Epoch: 24, Batch: 170/896, Loss: 0.5629, Time: 3.77s\n",
      "Epoch: 24, Batch: 180/896, Loss: 0.3794, Time: 3.78s\n",
      "Epoch: 24, Batch: 190/896, Loss: 0.3942, Time: 3.78s\n",
      "Epoch: 24, Batch: 200/896, Loss: 1.7776, Time: 3.77s\n",
      "Epoch: 24, Batch: 210/896, Loss: 0.5370, Time: 3.78s\n",
      "Epoch: 24, Batch: 220/896, Loss: 0.4081, Time: 3.77s\n",
      "Epoch: 24, Batch: 230/896, Loss: 0.8447, Time: 3.78s\n",
      "Epoch: 24, Batch: 240/896, Loss: 1.6716, Time: 3.78s\n",
      "Epoch: 24, Batch: 250/896, Loss: 1.1415, Time: 3.79s\n",
      "Epoch: 24, Batch: 260/896, Loss: 0.5142, Time: 3.78s\n",
      "Epoch: 24, Batch: 270/896, Loss: 1.1295, Time: 3.78s\n",
      "Epoch: 24, Batch: 280/896, Loss: 1.1661, Time: 3.78s\n",
      "Epoch: 24, Batch: 290/896, Loss: 0.5298, Time: 3.78s\n",
      "Epoch: 24, Batch: 300/896, Loss: 0.8695, Time: 3.78s\n",
      "Epoch: 24, Batch: 310/896, Loss: 0.7779, Time: 3.78s\n",
      "Epoch: 24, Batch: 320/896, Loss: 1.4790, Time: 3.79s\n",
      "Epoch: 24, Batch: 330/896, Loss: 0.2935, Time: 3.79s\n",
      "Epoch: 24, Batch: 340/896, Loss: 1.1026, Time: 3.79s\n",
      "Epoch: 24, Batch: 350/896, Loss: 0.8872, Time: 3.80s\n",
      "Epoch: 24, Batch: 360/896, Loss: 0.5108, Time: 3.78s\n",
      "Epoch: 24, Batch: 370/896, Loss: 0.4219, Time: 3.78s\n",
      "Epoch: 24, Batch: 380/896, Loss: 0.7644, Time: 3.79s\n",
      "Epoch: 24, Batch: 390/896, Loss: 1.1435, Time: 3.79s\n",
      "Epoch: 24, Batch: 400/896, Loss: 0.8093, Time: 3.79s\n",
      "Epoch: 24, Batch: 410/896, Loss: 0.9740, Time: 3.78s\n",
      "Epoch: 24, Batch: 420/896, Loss: 0.4384, Time: 3.79s\n",
      "Epoch: 24, Batch: 430/896, Loss: 0.4567, Time: 3.80s\n",
      "Epoch: 24, Batch: 440/896, Loss: 0.4010, Time: 3.80s\n",
      "Epoch: 24, Batch: 450/896, Loss: 1.5026, Time: 3.80s\n",
      "Epoch: 24, Batch: 460/896, Loss: 0.3719, Time: 3.79s\n",
      "Epoch: 24, Batch: 470/896, Loss: 1.6227, Time: 3.79s\n",
      "Epoch: 24, Batch: 480/896, Loss: 0.9565, Time: 3.80s\n",
      "Epoch: 24, Batch: 490/896, Loss: 0.7505, Time: 3.79s\n",
      "Epoch: 24, Batch: 500/896, Loss: 0.3626, Time: 3.80s\n",
      "Epoch: 24, Batch: 510/896, Loss: 1.2312, Time: 3.80s\n",
      "Epoch: 24, Batch: 520/896, Loss: 0.9685, Time: 3.80s\n",
      "Epoch: 24, Batch: 530/896, Loss: 1.5850, Time: 3.80s\n",
      "Epoch: 24, Batch: 540/896, Loss: 0.5497, Time: 3.80s\n",
      "Epoch: 24, Batch: 550/896, Loss: 1.3686, Time: 3.80s\n",
      "Epoch: 24, Batch: 560/896, Loss: 0.3368, Time: 3.81s\n",
      "Epoch: 24, Batch: 570/896, Loss: 0.7361, Time: 3.80s\n",
      "Epoch: 24, Batch: 580/896, Loss: 0.6323, Time: 3.80s\n",
      "Epoch: 24, Batch: 590/896, Loss: 0.5933, Time: 3.80s\n",
      "Epoch: 24, Batch: 600/896, Loss: 0.7030, Time: 3.79s\n",
      "Epoch: 24, Batch: 610/896, Loss: 0.3778, Time: 3.80s\n",
      "Epoch: 24, Batch: 620/896, Loss: 0.4194, Time: 3.80s\n",
      "Epoch: 24, Batch: 630/896, Loss: 0.5980, Time: 3.79s\n",
      "Epoch: 24, Batch: 640/896, Loss: 0.3597, Time: 3.81s\n",
      "Epoch: 24, Batch: 650/896, Loss: 0.4315, Time: 3.80s\n",
      "Epoch: 24, Batch: 660/896, Loss: 0.5906, Time: 3.80s\n",
      "Epoch: 24, Batch: 670/896, Loss: 1.0569, Time: 3.80s\n",
      "Epoch: 24, Batch: 680/896, Loss: 0.6490, Time: 3.79s\n",
      "Epoch: 24, Batch: 690/896, Loss: 0.6397, Time: 3.80s\n",
      "Epoch: 24, Batch: 700/896, Loss: 0.8025, Time: 3.80s\n",
      "Epoch: 24, Batch: 710/896, Loss: 0.7507, Time: 3.81s\n",
      "Epoch: 24, Batch: 720/896, Loss: 0.7655, Time: 3.80s\n",
      "Epoch: 24, Batch: 730/896, Loss: 0.6816, Time: 3.80s\n",
      "Epoch: 24, Batch: 740/896, Loss: 0.3987, Time: 3.80s\n",
      "Epoch: 24, Batch: 750/896, Loss: 0.7388, Time: 3.80s\n",
      "Epoch: 24, Batch: 760/896, Loss: 1.4472, Time: 3.80s\n",
      "Epoch: 24, Batch: 770/896, Loss: 0.8996, Time: 3.80s\n",
      "Epoch: 24, Batch: 780/896, Loss: 0.3031, Time: 3.80s\n",
      "Epoch: 24, Batch: 790/896, Loss: 0.8994, Time: 3.80s\n",
      "Epoch: 24, Batch: 800/896, Loss: 0.7509, Time: 3.80s\n",
      "Epoch: 24, Batch: 810/896, Loss: 1.9192, Time: 3.81s\n",
      "Epoch: 24, Batch: 820/896, Loss: 0.4476, Time: 3.81s\n",
      "Epoch: 24, Batch: 830/896, Loss: 0.6915, Time: 3.80s\n",
      "Epoch: 24, Batch: 840/896, Loss: 0.8012, Time: 3.80s\n",
      "Epoch: 24, Batch: 850/896, Loss: 0.5900, Time: 3.80s\n",
      "Epoch: 24, Batch: 860/896, Loss: 0.8804, Time: 3.78s\n",
      "Epoch: 24, Batch: 870/896, Loss: 0.6080, Time: 3.80s\n",
      "Epoch: 24, Batch: 880/896, Loss: 1.0751, Time: 3.78s\n",
      "Epoch: 24, Batch: 890/896, Loss: 0.2982, Time: 3.80s\n",
      "Epoch 25/50: Train Loss: 0.7994, Val Loss: 0.8881, Val IoU: 0.3637, Val Dice: 0.3862\n",
      "Epoch: 25, Batch: 0/896, Loss: 0.5578, Time: 28.72s\n",
      "Epoch: 25, Batch: 10/896, Loss: 0.7522, Time: 3.74s\n",
      "Epoch: 25, Batch: 20/896, Loss: 0.4882, Time: 3.73s\n",
      "Epoch: 25, Batch: 30/896, Loss: 0.9228, Time: 3.73s\n",
      "Epoch: 25, Batch: 40/896, Loss: 1.4654, Time: 3.74s\n",
      "Epoch: 25, Batch: 50/896, Loss: 0.5627, Time: 3.74s\n",
      "Epoch: 25, Batch: 60/896, Loss: 1.1211, Time: 3.75s\n",
      "Epoch: 25, Batch: 70/896, Loss: 0.9082, Time: 3.76s\n",
      "Epoch: 25, Batch: 80/896, Loss: 1.0338, Time: 3.77s\n",
      "Epoch: 25, Batch: 90/896, Loss: 1.3058, Time: 3.76s\n",
      "Epoch: 25, Batch: 100/896, Loss: 0.5053, Time: 3.77s\n",
      "Epoch: 25, Batch: 110/896, Loss: 0.4642, Time: 3.77s\n",
      "Epoch: 25, Batch: 120/896, Loss: 0.5459, Time: 3.77s\n",
      "Epoch: 25, Batch: 130/896, Loss: 0.9218, Time: 3.77s\n",
      "Epoch: 25, Batch: 140/896, Loss: 0.7281, Time: 3.77s\n",
      "Epoch: 25, Batch: 150/896, Loss: 1.0158, Time: 3.77s\n",
      "Epoch: 25, Batch: 160/896, Loss: 0.8576, Time: 3.77s\n",
      "Epoch: 25, Batch: 170/896, Loss: 0.6669, Time: 3.77s\n",
      "Epoch: 25, Batch: 180/896, Loss: 1.5323, Time: 3.77s\n",
      "Epoch: 25, Batch: 190/896, Loss: 0.9413, Time: 3.78s\n",
      "Epoch: 25, Batch: 200/896, Loss: 0.9081, Time: 3.78s\n",
      "Epoch: 25, Batch: 210/896, Loss: 0.6831, Time: 3.78s\n",
      "Epoch: 25, Batch: 220/896, Loss: 0.5082, Time: 3.78s\n",
      "Epoch: 25, Batch: 230/896, Loss: 1.4692, Time: 3.78s\n",
      "Epoch: 25, Batch: 240/896, Loss: 0.8901, Time: 3.77s\n",
      "Epoch: 25, Batch: 250/896, Loss: 0.6866, Time: 3.78s\n",
      "Epoch: 25, Batch: 260/896, Loss: 1.2333, Time: 3.78s\n",
      "Epoch: 25, Batch: 270/896, Loss: 1.1082, Time: 3.80s\n",
      "Epoch: 25, Batch: 280/896, Loss: 0.8336, Time: 3.79s\n",
      "Epoch: 25, Batch: 290/896, Loss: 0.7606, Time: 3.78s\n",
      "Epoch: 25, Batch: 300/896, Loss: 0.7992, Time: 3.79s\n",
      "Epoch: 25, Batch: 310/896, Loss: 0.9736, Time: 3.78s\n",
      "Epoch: 25, Batch: 320/896, Loss: 0.9502, Time: 3.78s\n",
      "Epoch: 25, Batch: 330/896, Loss: 0.5608, Time: 3.80s\n",
      "Epoch: 25, Batch: 340/896, Loss: 1.1908, Time: 3.78s\n",
      "Epoch: 25, Batch: 350/896, Loss: 1.0339, Time: 3.78s\n",
      "Epoch: 25, Batch: 360/896, Loss: 0.5538, Time: 3.79s\n",
      "Epoch: 25, Batch: 370/896, Loss: 1.0758, Time: 3.79s\n",
      "Epoch: 25, Batch: 380/896, Loss: 0.3134, Time: 3.81s\n",
      "Epoch: 25, Batch: 390/896, Loss: 0.5854, Time: 3.79s\n",
      "Epoch: 25, Batch: 400/896, Loss: 0.8906, Time: 3.80s\n",
      "Epoch: 25, Batch: 410/896, Loss: 1.4738, Time: 3.79s\n",
      "Epoch: 25, Batch: 420/896, Loss: 0.8229, Time: 3.80s\n",
      "Epoch: 25, Batch: 430/896, Loss: 0.5298, Time: 3.78s\n",
      "Epoch: 25, Batch: 440/896, Loss: 0.5986, Time: 3.79s\n",
      "Epoch: 25, Batch: 450/896, Loss: 0.9141, Time: 3.80s\n",
      "Epoch: 25, Batch: 460/896, Loss: 0.3961, Time: 3.80s\n",
      "Epoch: 25, Batch: 470/896, Loss: 0.6498, Time: 3.79s\n",
      "Epoch: 25, Batch: 480/896, Loss: 0.5419, Time: 3.80s\n",
      "Epoch: 25, Batch: 490/896, Loss: 1.0732, Time: 3.80s\n",
      "Epoch: 25, Batch: 500/896, Loss: 0.5121, Time: 3.79s\n",
      "Epoch: 25, Batch: 510/896, Loss: 0.7374, Time: 3.79s\n",
      "Epoch: 25, Batch: 520/896, Loss: 0.6855, Time: 3.79s\n",
      "Epoch: 25, Batch: 530/896, Loss: 0.5431, Time: 3.79s\n",
      "Epoch: 25, Batch: 540/896, Loss: 0.8780, Time: 3.79s\n",
      "Epoch: 25, Batch: 550/896, Loss: 0.8384, Time: 3.79s\n",
      "Epoch: 25, Batch: 560/896, Loss: 0.6233, Time: 3.80s\n",
      "Epoch: 25, Batch: 570/896, Loss: 0.5032, Time: 3.80s\n",
      "Epoch: 25, Batch: 580/896, Loss: 1.3294, Time: 3.79s\n",
      "Epoch: 25, Batch: 590/896, Loss: 0.4251, Time: 3.80s\n",
      "Epoch: 25, Batch: 600/896, Loss: 0.3380, Time: 3.81s\n",
      "Epoch: 25, Batch: 610/896, Loss: 0.8349, Time: 3.80s\n",
      "Epoch: 25, Batch: 620/896, Loss: 0.6085, Time: 3.81s\n",
      "Epoch: 25, Batch: 630/896, Loss: 0.5348, Time: 3.80s\n",
      "Epoch: 25, Batch: 640/896, Loss: 1.1333, Time: 3.79s\n",
      "Epoch: 25, Batch: 650/896, Loss: 1.4291, Time: 3.79s\n",
      "Epoch: 25, Batch: 660/896, Loss: 0.4475, Time: 3.80s\n",
      "Epoch: 25, Batch: 670/896, Loss: 0.3931, Time: 3.80s\n",
      "Epoch: 25, Batch: 680/896, Loss: 1.2451, Time: 3.79s\n",
      "Epoch: 25, Batch: 690/896, Loss: 0.9930, Time: 3.80s\n",
      "Epoch: 25, Batch: 700/896, Loss: 1.2017, Time: 3.81s\n",
      "Epoch: 25, Batch: 710/896, Loss: 0.6806, Time: 3.81s\n",
      "Epoch: 25, Batch: 720/896, Loss: 0.7846, Time: 3.80s\n",
      "Epoch: 25, Batch: 730/896, Loss: 1.1924, Time: 3.79s\n",
      "Epoch: 25, Batch: 740/896, Loss: 0.7678, Time: 3.81s\n",
      "Epoch: 25, Batch: 750/896, Loss: 0.2986, Time: 3.81s\n",
      "Epoch: 25, Batch: 760/896, Loss: 0.6394, Time: 3.80s\n",
      "Epoch: 25, Batch: 770/896, Loss: 0.7932, Time: 3.80s\n",
      "Epoch: 25, Batch: 780/896, Loss: 0.9023, Time: 3.79s\n",
      "Epoch: 25, Batch: 790/896, Loss: 0.4735, Time: 3.80s\n",
      "Epoch: 25, Batch: 800/896, Loss: 1.5472, Time: 3.79s\n",
      "Epoch: 25, Batch: 810/896, Loss: 0.3605, Time: 3.80s\n",
      "Epoch: 25, Batch: 820/896, Loss: 0.7030, Time: 3.80s\n",
      "Epoch: 25, Batch: 830/896, Loss: 1.2554, Time: 3.79s\n",
      "Epoch: 25, Batch: 840/896, Loss: 0.3827, Time: 3.80s\n",
      "Epoch: 25, Batch: 850/896, Loss: 1.1683, Time: 3.79s\n",
      "Epoch: 25, Batch: 860/896, Loss: 0.6963, Time: 3.80s\n",
      "Epoch: 25, Batch: 870/896, Loss: 0.7137, Time: 3.79s\n",
      "Epoch: 25, Batch: 880/896, Loss: 0.6220, Time: 3.80s\n",
      "Epoch: 25, Batch: 890/896, Loss: 1.1489, Time: 3.79s\n",
      "Epoch 26/50: Train Loss: 0.7992, Val Loss: 0.8209, Val IoU: 0.3734, Val Dice: 0.3973\n",
      "Epoch: 26, Batch: 0/896, Loss: 0.9781, Time: 28.76s\n",
      "Epoch: 26, Batch: 10/896, Loss: 0.7565, Time: 3.72s\n",
      "Epoch: 26, Batch: 20/896, Loss: 0.7177, Time: 3.73s\n",
      "Epoch: 26, Batch: 30/896, Loss: 0.7187, Time: 3.74s\n",
      "Epoch: 26, Batch: 40/896, Loss: 1.0118, Time: 3.73s\n",
      "Epoch: 26, Batch: 50/896, Loss: 0.8025, Time: 3.76s\n",
      "Epoch: 26, Batch: 60/896, Loss: 0.6565, Time: 3.75s\n",
      "Epoch: 26, Batch: 70/896, Loss: 1.0121, Time: 3.75s\n",
      "Epoch: 26, Batch: 80/896, Loss: 0.7074, Time: 3.76s\n",
      "Epoch: 26, Batch: 90/896, Loss: 0.7429, Time: 3.75s\n",
      "Epoch: 26, Batch: 100/896, Loss: 0.8556, Time: 3.76s\n",
      "Epoch: 26, Batch: 110/896, Loss: 1.4000, Time: 3.76s\n",
      "Epoch: 26, Batch: 120/896, Loss: 0.6017, Time: 3.76s\n",
      "Epoch: 26, Batch: 130/896, Loss: 0.6249, Time: 3.76s\n",
      "Epoch: 26, Batch: 140/896, Loss: 0.6156, Time: 3.77s\n",
      "Epoch: 26, Batch: 150/896, Loss: 0.8723, Time: 3.78s\n",
      "Epoch: 26, Batch: 160/896, Loss: 0.6761, Time: 3.78s\n",
      "Epoch: 26, Batch: 170/896, Loss: 0.9382, Time: 3.78s\n",
      "Epoch: 26, Batch: 180/896, Loss: 0.6754, Time: 3.76s\n",
      "Epoch: 26, Batch: 190/896, Loss: 0.8228, Time: 3.78s\n",
      "Epoch: 26, Batch: 200/896, Loss: 0.5412, Time: 3.77s\n",
      "Epoch: 26, Batch: 210/896, Loss: 0.7395, Time: 3.77s\n",
      "Epoch: 26, Batch: 220/896, Loss: 0.6146, Time: 3.78s\n",
      "Epoch: 26, Batch: 230/896, Loss: 0.6238, Time: 3.78s\n",
      "Epoch: 26, Batch: 240/896, Loss: 0.4877, Time: 3.77s\n",
      "Epoch: 26, Batch: 250/896, Loss: 1.0944, Time: 3.79s\n",
      "Epoch: 26, Batch: 260/896, Loss: 0.9798, Time: 3.77s\n",
      "Epoch: 26, Batch: 270/896, Loss: 0.5234, Time: 3.78s\n",
      "Epoch: 26, Batch: 280/896, Loss: 0.7789, Time: 3.79s\n",
      "Epoch: 26, Batch: 290/896, Loss: 1.1713, Time: 3.77s\n",
      "Epoch: 26, Batch: 300/896, Loss: 0.7779, Time: 3.78s\n",
      "Epoch: 26, Batch: 310/896, Loss: 0.4591, Time: 3.79s\n",
      "Epoch: 26, Batch: 320/896, Loss: 0.3232, Time: 3.79s\n",
      "Epoch: 26, Batch: 330/896, Loss: 0.8245, Time: 3.79s\n",
      "Epoch: 26, Batch: 340/896, Loss: 1.3160, Time: 3.79s\n",
      "Epoch: 26, Batch: 350/896, Loss: 0.6780, Time: 3.79s\n",
      "Epoch: 26, Batch: 360/896, Loss: 1.2312, Time: 3.79s\n",
      "Epoch: 26, Batch: 370/896, Loss: 0.5367, Time: 3.79s\n",
      "Epoch: 26, Batch: 380/896, Loss: 0.9275, Time: 3.79s\n",
      "Epoch: 26, Batch: 390/896, Loss: 0.7003, Time: 3.80s\n",
      "Epoch: 26, Batch: 400/896, Loss: 0.3625, Time: 3.79s\n",
      "Epoch: 26, Batch: 410/896, Loss: 1.1098, Time: 3.80s\n",
      "Epoch: 26, Batch: 420/896, Loss: 0.6931, Time: 3.79s\n",
      "Epoch: 26, Batch: 430/896, Loss: 0.3196, Time: 3.80s\n",
      "Epoch: 26, Batch: 440/896, Loss: 1.1652, Time: 3.79s\n",
      "Epoch: 26, Batch: 450/896, Loss: 0.7138, Time: 3.81s\n",
      "Epoch: 26, Batch: 460/896, Loss: 0.4810, Time: 3.79s\n",
      "Epoch: 26, Batch: 470/896, Loss: 1.5619, Time: 3.80s\n",
      "Epoch: 26, Batch: 480/896, Loss: 0.6866, Time: 3.78s\n",
      "Epoch: 26, Batch: 490/896, Loss: 0.5144, Time: 3.80s\n",
      "Epoch: 26, Batch: 500/896, Loss: 1.0394, Time: 3.79s\n",
      "Epoch: 26, Batch: 510/896, Loss: 0.7503, Time: 3.79s\n",
      "Epoch: 26, Batch: 520/896, Loss: 0.4508, Time: 3.80s\n",
      "Epoch: 26, Batch: 530/896, Loss: 1.0044, Time: 3.79s\n",
      "Epoch: 26, Batch: 540/896, Loss: 0.7775, Time: 3.79s\n",
      "Epoch: 26, Batch: 550/896, Loss: 0.8064, Time: 3.80s\n",
      "Epoch: 26, Batch: 560/896, Loss: 0.3774, Time: 3.79s\n",
      "Epoch: 26, Batch: 570/896, Loss: 1.4887, Time: 3.79s\n",
      "Epoch: 26, Batch: 580/896, Loss: 1.3966, Time: 3.79s\n",
      "Epoch: 26, Batch: 590/896, Loss: 0.4476, Time: 3.79s\n",
      "Epoch: 26, Batch: 600/896, Loss: 0.6416, Time: 3.81s\n",
      "Epoch: 26, Batch: 610/896, Loss: 1.2860, Time: 3.79s\n",
      "Epoch: 26, Batch: 620/896, Loss: 1.1451, Time: 3.80s\n",
      "Epoch: 26, Batch: 630/896, Loss: 0.7779, Time: 3.80s\n",
      "Epoch: 26, Batch: 640/896, Loss: 0.7468, Time: 3.81s\n",
      "Epoch: 26, Batch: 650/896, Loss: 0.9997, Time: 3.79s\n",
      "Epoch: 26, Batch: 660/896, Loss: 0.3435, Time: 3.80s\n",
      "Epoch: 26, Batch: 670/896, Loss: 1.1493, Time: 3.79s\n",
      "Epoch: 26, Batch: 680/896, Loss: 0.7094, Time: 3.81s\n",
      "Epoch: 26, Batch: 690/896, Loss: 1.1211, Time: 3.78s\n",
      "Epoch: 26, Batch: 700/896, Loss: 0.6828, Time: 3.80s\n",
      "Epoch: 26, Batch: 710/896, Loss: 1.6044, Time: 3.80s\n",
      "Epoch: 26, Batch: 720/896, Loss: 0.5163, Time: 3.80s\n",
      "Epoch: 26, Batch: 730/896, Loss: 1.4282, Time: 3.80s\n",
      "Epoch: 26, Batch: 740/896, Loss: 0.9013, Time: 3.81s\n",
      "Epoch: 26, Batch: 750/896, Loss: 0.4950, Time: 3.79s\n",
      "Epoch: 26, Batch: 760/896, Loss: 1.4423, Time: 3.80s\n",
      "Epoch: 26, Batch: 770/896, Loss: 0.4432, Time: 3.79s\n",
      "Epoch: 26, Batch: 780/896, Loss: 0.4934, Time: 3.80s\n",
      "Epoch: 26, Batch: 790/896, Loss: 0.9731, Time: 3.80s\n",
      "Epoch: 26, Batch: 800/896, Loss: 1.4274, Time: 3.80s\n",
      "Epoch: 26, Batch: 810/896, Loss: 0.6970, Time: 3.79s\n",
      "Epoch: 26, Batch: 820/896, Loss: 1.1456, Time: 3.80s\n",
      "Epoch: 26, Batch: 830/896, Loss: 0.5740, Time: 3.79s\n",
      "Epoch: 26, Batch: 840/896, Loss: 0.9545, Time: 3.81s\n",
      "Epoch: 26, Batch: 850/896, Loss: 1.0557, Time: 3.81s\n",
      "Epoch: 26, Batch: 860/896, Loss: 0.4797, Time: 3.79s\n",
      "Epoch: 26, Batch: 870/896, Loss: 1.0146, Time: 3.79s\n",
      "Epoch: 26, Batch: 880/896, Loss: 0.6893, Time: 3.80s\n",
      "Epoch: 26, Batch: 890/896, Loss: 1.0712, Time: 3.79s\n",
      "Epoch 27/50: Train Loss: 0.7983, Val Loss: 0.8404, Val IoU: 0.3648, Val Dice: 0.3878\n",
      "Epoch: 27, Batch: 0/896, Loss: 0.5314, Time: 28.71s\n",
      "Epoch: 27, Batch: 10/896, Loss: 0.4320, Time: 3.73s\n",
      "Epoch: 27, Batch: 20/896, Loss: 0.4853, Time: 3.73s\n",
      "Epoch: 27, Batch: 30/896, Loss: 0.7826, Time: 3.74s\n",
      "Epoch: 27, Batch: 40/896, Loss: 0.6450, Time: 3.74s\n",
      "Epoch: 27, Batch: 50/896, Loss: 0.7026, Time: 3.74s\n",
      "Epoch: 27, Batch: 60/896, Loss: 0.7602, Time: 3.74s\n",
      "Epoch: 27, Batch: 70/896, Loss: 1.2152, Time: 3.76s\n",
      "Epoch: 27, Batch: 80/896, Loss: 0.5702, Time: 3.75s\n",
      "Epoch: 27, Batch: 90/896, Loss: 0.7915, Time: 3.76s\n",
      "Epoch: 27, Batch: 100/896, Loss: 0.9346, Time: 3.75s\n",
      "Epoch: 27, Batch: 110/896, Loss: 0.4270, Time: 3.76s\n",
      "Epoch: 27, Batch: 120/896, Loss: 0.7153, Time: 3.75s\n",
      "Epoch: 27, Batch: 130/896, Loss: 1.4508, Time: 3.77s\n",
      "Epoch: 27, Batch: 140/896, Loss: 0.9105, Time: 3.77s\n",
      "Epoch: 27, Batch: 150/896, Loss: 1.5510, Time: 3.77s\n",
      "Epoch: 27, Batch: 160/896, Loss: 0.4100, Time: 3.78s\n",
      "Epoch: 27, Batch: 170/896, Loss: 0.9407, Time: 3.77s\n",
      "Epoch: 27, Batch: 180/896, Loss: 1.3680, Time: 3.78s\n",
      "Epoch: 27, Batch: 190/896, Loss: 0.8773, Time: 3.77s\n",
      "Epoch: 27, Batch: 200/896, Loss: 0.6595, Time: 3.78s\n",
      "Epoch: 27, Batch: 210/896, Loss: 0.9953, Time: 3.78s\n",
      "Epoch: 27, Batch: 220/896, Loss: 0.8194, Time: 3.78s\n",
      "Epoch: 27, Batch: 230/896, Loss: 0.6408, Time: 3.77s\n",
      "Epoch: 27, Batch: 240/896, Loss: 0.4238, Time: 3.78s\n",
      "Epoch: 27, Batch: 250/896, Loss: 0.3763, Time: 3.79s\n",
      "Epoch: 27, Batch: 260/896, Loss: 0.3820, Time: 3.78s\n",
      "Epoch: 27, Batch: 270/896, Loss: 0.7689, Time: 3.77s\n",
      "Epoch: 27, Batch: 280/896, Loss: 0.7331, Time: 3.77s\n",
      "Epoch: 27, Batch: 290/896, Loss: 0.6096, Time: 3.77s\n",
      "Epoch: 27, Batch: 300/896, Loss: 0.6900, Time: 3.78s\n",
      "Epoch: 27, Batch: 310/896, Loss: 0.6285, Time: 3.78s\n",
      "Epoch: 27, Batch: 320/896, Loss: 0.8250, Time: 3.78s\n",
      "Epoch: 27, Batch: 330/896, Loss: 0.4530, Time: 3.78s\n",
      "Epoch: 27, Batch: 340/896, Loss: 0.9539, Time: 3.78s\n",
      "Epoch: 27, Batch: 350/896, Loss: 0.9121, Time: 3.77s\n",
      "Epoch: 27, Batch: 360/896, Loss: 0.8424, Time: 3.81s\n",
      "Epoch: 27, Batch: 370/896, Loss: 0.7892, Time: 3.79s\n",
      "Epoch: 27, Batch: 380/896, Loss: 0.4789, Time: 3.77s\n",
      "Epoch: 27, Batch: 390/896, Loss: 0.4278, Time: 3.81s\n",
      "Epoch: 27, Batch: 400/896, Loss: 0.7391, Time: 3.79s\n",
      "Epoch: 27, Batch: 410/896, Loss: 1.0191, Time: 3.80s\n",
      "Epoch: 27, Batch: 420/896, Loss: 1.3652, Time: 3.80s\n",
      "Epoch: 27, Batch: 430/896, Loss: 0.3193, Time: 3.78s\n",
      "Epoch: 27, Batch: 440/896, Loss: 1.1311, Time: 3.80s\n",
      "Epoch: 27, Batch: 450/896, Loss: 0.7927, Time: 3.79s\n",
      "Epoch: 27, Batch: 460/896, Loss: 0.8427, Time: 3.80s\n",
      "Epoch: 27, Batch: 470/896, Loss: 1.0441, Time: 3.79s\n",
      "Epoch: 27, Batch: 480/896, Loss: 0.6404, Time: 3.80s\n",
      "Epoch: 27, Batch: 490/896, Loss: 1.3393, Time: 3.79s\n",
      "Epoch: 27, Batch: 500/896, Loss: 1.0501, Time: 3.80s\n",
      "Epoch: 27, Batch: 510/896, Loss: 0.6266, Time: 3.79s\n",
      "Epoch: 27, Batch: 520/896, Loss: 0.7126, Time: 3.79s\n",
      "Epoch: 27, Batch: 530/896, Loss: 0.6659, Time: 3.79s\n",
      "Epoch: 27, Batch: 540/896, Loss: 0.6745, Time: 3.80s\n",
      "Epoch: 27, Batch: 550/896, Loss: 0.5843, Time: 3.80s\n",
      "Epoch: 27, Batch: 560/896, Loss: 0.5954, Time: 3.79s\n",
      "Epoch: 27, Batch: 570/896, Loss: 1.1390, Time: 3.80s\n",
      "Epoch: 27, Batch: 580/896, Loss: 0.5686, Time: 3.78s\n",
      "Epoch: 27, Batch: 590/896, Loss: 0.7278, Time: 3.79s\n",
      "Epoch: 27, Batch: 600/896, Loss: 0.6158, Time: 3.79s\n",
      "Epoch: 27, Batch: 610/896, Loss: 1.0179, Time: 3.79s\n",
      "Epoch: 27, Batch: 620/896, Loss: 1.2950, Time: 3.80s\n",
      "Epoch: 27, Batch: 630/896, Loss: 0.9007, Time: 3.79s\n",
      "Epoch: 27, Batch: 640/896, Loss: 0.4064, Time: 3.79s\n",
      "Epoch: 27, Batch: 650/896, Loss: 0.6394, Time: 3.80s\n",
      "Epoch: 27, Batch: 660/896, Loss: 0.4029, Time: 3.79s\n",
      "Epoch: 27, Batch: 670/896, Loss: 0.4358, Time: 3.80s\n",
      "Epoch: 27, Batch: 680/896, Loss: 0.7368, Time: 3.81s\n",
      "Epoch: 27, Batch: 690/896, Loss: 0.9227, Time: 3.80s\n",
      "Epoch: 27, Batch: 700/896, Loss: 0.3794, Time: 3.80s\n",
      "Epoch: 27, Batch: 710/896, Loss: 1.0843, Time: 3.80s\n",
      "Epoch: 27, Batch: 720/896, Loss: 0.7112, Time: 3.80s\n",
      "Epoch: 27, Batch: 730/896, Loss: 0.4621, Time: 3.80s\n",
      "Epoch: 27, Batch: 740/896, Loss: 0.4214, Time: 3.80s\n",
      "Epoch: 27, Batch: 750/896, Loss: 0.5844, Time: 3.79s\n",
      "Epoch: 27, Batch: 760/896, Loss: 0.8143, Time: 3.80s\n",
      "Epoch: 27, Batch: 770/896, Loss: 0.2628, Time: 3.81s\n",
      "Epoch: 27, Batch: 780/896, Loss: 1.7087, Time: 3.80s\n",
      "Epoch: 27, Batch: 790/896, Loss: 0.7547, Time: 3.79s\n",
      "Epoch: 27, Batch: 800/896, Loss: 0.9556, Time: 3.80s\n",
      "Epoch: 27, Batch: 810/896, Loss: 0.7225, Time: 3.80s\n",
      "Epoch: 27, Batch: 820/896, Loss: 0.4479, Time: 3.80s\n",
      "Epoch: 27, Batch: 830/896, Loss: 0.6084, Time: 3.79s\n",
      "Epoch: 27, Batch: 840/896, Loss: 0.9865, Time: 3.80s\n",
      "Epoch: 27, Batch: 850/896, Loss: 0.7993, Time: 3.80s\n",
      "Epoch: 27, Batch: 860/896, Loss: 1.6037, Time: 3.79s\n",
      "Epoch: 27, Batch: 870/896, Loss: 1.1429, Time: 3.80s\n",
      "Epoch: 27, Batch: 880/896, Loss: 0.8749, Time: 3.81s\n",
      "Epoch: 27, Batch: 890/896, Loss: 0.3616, Time: 3.79s\n",
      "Epoch 28/50: Train Loss: 0.7971, Val Loss: 0.8279, Val IoU: 0.3729, Val Dice: 0.3971\n",
      "Epoch: 28, Batch: 0/896, Loss: 0.6437, Time: 28.89s\n",
      "Epoch: 28, Batch: 10/896, Loss: 1.1843, Time: 3.73s\n",
      "Epoch: 28, Batch: 20/896, Loss: 1.4329, Time: 3.72s\n",
      "Epoch: 28, Batch: 30/896, Loss: 0.4533, Time: 3.73s\n",
      "Epoch: 28, Batch: 40/896, Loss: 0.6021, Time: 3.74s\n",
      "Epoch: 28, Batch: 50/896, Loss: 1.4509, Time: 3.74s\n",
      "Epoch: 28, Batch: 60/896, Loss: 1.1653, Time: 3.74s\n",
      "Epoch: 28, Batch: 70/896, Loss: 0.5552, Time: 3.75s\n",
      "Epoch: 28, Batch: 80/896, Loss: 0.8224, Time: 3.76s\n",
      "Epoch: 28, Batch: 90/896, Loss: 0.5411, Time: 3.75s\n",
      "Epoch: 28, Batch: 100/896, Loss: 0.8210, Time: 3.76s\n",
      "Epoch: 28, Batch: 110/896, Loss: 0.7233, Time: 3.77s\n",
      "Epoch: 28, Batch: 120/896, Loss: 0.9845, Time: 3.77s\n",
      "Epoch: 28, Batch: 130/896, Loss: 0.5450, Time: 3.76s\n",
      "Epoch: 28, Batch: 140/896, Loss: 0.4828, Time: 3.76s\n",
      "Epoch: 28, Batch: 150/896, Loss: 0.8303, Time: 3.77s\n",
      "Epoch: 28, Batch: 160/896, Loss: 0.5439, Time: 3.77s\n",
      "Epoch: 28, Batch: 170/896, Loss: 0.7061, Time: 3.76s\n",
      "Epoch: 28, Batch: 180/896, Loss: 0.4659, Time: 3.77s\n",
      "Epoch: 28, Batch: 190/896, Loss: 0.7367, Time: 3.77s\n",
      "Epoch: 28, Batch: 200/896, Loss: 1.2446, Time: 3.78s\n",
      "Epoch: 28, Batch: 210/896, Loss: 0.5684, Time: 3.77s\n",
      "Epoch: 28, Batch: 220/896, Loss: 0.8564, Time: 3.79s\n",
      "Epoch: 28, Batch: 230/896, Loss: 0.3724, Time: 3.77s\n",
      "Epoch: 28, Batch: 240/896, Loss: 0.4971, Time: 3.78s\n",
      "Epoch: 28, Batch: 250/896, Loss: 1.1409, Time: 3.77s\n",
      "Epoch: 28, Batch: 260/896, Loss: 1.3705, Time: 3.78s\n",
      "Epoch: 28, Batch: 270/896, Loss: 0.3964, Time: 3.79s\n",
      "Epoch: 28, Batch: 280/896, Loss: 0.5762, Time: 3.78s\n",
      "Epoch: 28, Batch: 290/896, Loss: 0.6666, Time: 3.78s\n",
      "Epoch: 28, Batch: 300/896, Loss: 0.5799, Time: 3.79s\n",
      "Epoch: 28, Batch: 310/896, Loss: 1.1614, Time: 3.78s\n",
      "Epoch: 28, Batch: 320/896, Loss: 0.4811, Time: 3.79s\n",
      "Epoch: 28, Batch: 330/896, Loss: 0.6915, Time: 3.80s\n",
      "Epoch: 28, Batch: 340/896, Loss: 0.3471, Time: 3.79s\n",
      "Epoch: 28, Batch: 350/896, Loss: 1.5330, Time: 3.78s\n",
      "Epoch: 28, Batch: 360/896, Loss: 0.3620, Time: 3.78s\n",
      "Epoch: 28, Batch: 370/896, Loss: 0.4331, Time: 3.79s\n",
      "Epoch: 28, Batch: 380/896, Loss: 0.5401, Time: 3.77s\n",
      "Epoch: 28, Batch: 390/896, Loss: 0.5431, Time: 3.78s\n",
      "Epoch: 28, Batch: 400/896, Loss: 1.3303, Time: 3.80s\n",
      "Epoch: 28, Batch: 410/896, Loss: 0.8310, Time: 3.79s\n",
      "Epoch: 28, Batch: 420/896, Loss: 0.5173, Time: 3.79s\n",
      "Epoch: 28, Batch: 430/896, Loss: 0.6522, Time: 3.79s\n",
      "Epoch: 28, Batch: 440/896, Loss: 1.4593, Time: 3.79s\n",
      "Epoch: 28, Batch: 450/896, Loss: 0.9493, Time: 3.80s\n",
      "Epoch: 28, Batch: 460/896, Loss: 1.1308, Time: 3.79s\n",
      "Epoch: 28, Batch: 470/896, Loss: 0.4919, Time: 3.80s\n",
      "Epoch: 28, Batch: 480/896, Loss: 0.6904, Time: 3.79s\n",
      "Epoch: 28, Batch: 490/896, Loss: 0.5901, Time: 3.79s\n",
      "Epoch: 28, Batch: 500/896, Loss: 1.1482, Time: 3.79s\n",
      "Epoch: 28, Batch: 510/896, Loss: 0.8819, Time: 3.80s\n",
      "Epoch: 28, Batch: 520/896, Loss: 1.0141, Time: 3.80s\n",
      "Epoch: 28, Batch: 530/896, Loss: 0.3948, Time: 3.79s\n",
      "Epoch: 28, Batch: 540/896, Loss: 0.8012, Time: 3.79s\n",
      "Epoch: 28, Batch: 550/896, Loss: 0.5085, Time: 3.79s\n",
      "Epoch: 28, Batch: 560/896, Loss: 0.3197, Time: 3.81s\n",
      "Epoch: 28, Batch: 570/896, Loss: 0.8575, Time: 3.79s\n",
      "Epoch: 28, Batch: 580/896, Loss: 1.3600, Time: 3.80s\n",
      "Epoch: 28, Batch: 590/896, Loss: 1.1700, Time: 3.78s\n",
      "Epoch: 28, Batch: 600/896, Loss: 0.7368, Time: 3.80s\n",
      "Epoch: 28, Batch: 610/896, Loss: 1.0741, Time: 3.79s\n",
      "Epoch: 28, Batch: 620/896, Loss: 0.3948, Time: 3.80s\n",
      "Epoch: 28, Batch: 630/896, Loss: 0.7608, Time: 3.79s\n",
      "Epoch: 28, Batch: 640/896, Loss: 0.8643, Time: 3.78s\n",
      "Epoch: 28, Batch: 650/896, Loss: 1.3351, Time: 3.80s\n",
      "Epoch: 28, Batch: 660/896, Loss: 0.9658, Time: 3.79s\n",
      "Epoch: 28, Batch: 670/896, Loss: 0.8842, Time: 3.79s\n",
      "Epoch: 28, Batch: 680/896, Loss: 0.7952, Time: 3.79s\n",
      "Epoch: 28, Batch: 690/896, Loss: 1.0389, Time: 3.79s\n",
      "Epoch: 28, Batch: 700/896, Loss: 0.4814, Time: 3.78s\n",
      "Epoch: 28, Batch: 710/896, Loss: 0.3686, Time: 3.80s\n",
      "Epoch: 28, Batch: 720/896, Loss: 0.6667, Time: 3.79s\n",
      "Epoch: 28, Batch: 730/896, Loss: 0.8623, Time: 3.79s\n",
      "Epoch: 28, Batch: 740/896, Loss: 0.7613, Time: 3.79s\n",
      "Epoch: 28, Batch: 750/896, Loss: 0.6347, Time: 3.79s\n",
      "Epoch: 28, Batch: 760/896, Loss: 1.7754, Time: 3.79s\n",
      "Epoch: 28, Batch: 770/896, Loss: 1.2310, Time: 3.79s\n",
      "Epoch: 28, Batch: 780/896, Loss: 0.5682, Time: 3.80s\n",
      "Epoch: 28, Batch: 790/896, Loss: 1.2707, Time: 3.78s\n",
      "Epoch: 28, Batch: 800/896, Loss: 0.4493, Time: 3.79s\n",
      "Epoch: 28, Batch: 810/896, Loss: 0.6876, Time: 3.80s\n",
      "Epoch: 28, Batch: 820/896, Loss: 1.0460, Time: 3.78s\n",
      "Epoch: 28, Batch: 830/896, Loss: 0.4996, Time: 3.80s\n",
      "Epoch: 28, Batch: 840/896, Loss: 0.8658, Time: 3.79s\n",
      "Epoch: 28, Batch: 850/896, Loss: 0.7899, Time: 3.79s\n",
      "Epoch: 28, Batch: 860/896, Loss: 0.4534, Time: 3.79s\n",
      "Epoch: 28, Batch: 870/896, Loss: 0.5528, Time: 3.79s\n",
      "Epoch: 28, Batch: 880/896, Loss: 0.7749, Time: 3.80s\n",
      "Epoch: 28, Batch: 890/896, Loss: 0.8647, Time: 3.80s\n",
      "Epoch 29/50: Train Loss: 0.7947, Val Loss: 0.8323, Val IoU: 0.3730, Val Dice: 0.3967\n",
      "Epoch: 29, Batch: 0/896, Loss: 0.5659, Time: 28.73s\n",
      "Epoch: 29, Batch: 10/896, Loss: 1.7742, Time: 3.74s\n",
      "Epoch: 29, Batch: 20/896, Loss: 0.9576, Time: 3.73s\n",
      "Epoch: 29, Batch: 30/896, Loss: 0.6760, Time: 3.74s\n",
      "Epoch: 29, Batch: 40/896, Loss: 1.0402, Time: 3.73s\n",
      "Epoch: 29, Batch: 50/896, Loss: 0.5981, Time: 3.74s\n",
      "Epoch: 29, Batch: 60/896, Loss: 1.0819, Time: 3.75s\n",
      "Epoch: 29, Batch: 70/896, Loss: 0.9317, Time: 3.75s\n",
      "Epoch: 29, Batch: 80/896, Loss: 0.7049, Time: 3.75s\n",
      "Epoch: 29, Batch: 90/896, Loss: 0.4812, Time: 3.76s\n",
      "Epoch: 29, Batch: 100/896, Loss: 0.7723, Time: 3.75s\n",
      "Epoch: 29, Batch: 110/896, Loss: 1.0266, Time: 3.77s\n",
      "Epoch: 29, Batch: 120/896, Loss: 0.5362, Time: 3.76s\n",
      "Epoch: 29, Batch: 130/896, Loss: 0.7591, Time: 3.77s\n",
      "Epoch: 29, Batch: 140/896, Loss: 0.6255, Time: 3.76s\n",
      "Epoch: 29, Batch: 150/896, Loss: 1.0744, Time: 3.77s\n",
      "Epoch: 29, Batch: 160/896, Loss: 0.8966, Time: 3.77s\n",
      "Epoch: 29, Batch: 170/896, Loss: 0.3892, Time: 3.78s\n",
      "Epoch: 29, Batch: 180/896, Loss: 0.6016, Time: 3.78s\n",
      "Epoch: 29, Batch: 190/896, Loss: 0.5948, Time: 3.77s\n",
      "Epoch: 29, Batch: 200/896, Loss: 1.2104, Time: 3.77s\n",
      "Epoch: 29, Batch: 210/896, Loss: 0.4944, Time: 3.77s\n",
      "Epoch: 29, Batch: 220/896, Loss: 0.8588, Time: 3.79s\n",
      "Epoch: 29, Batch: 230/896, Loss: 0.9619, Time: 3.78s\n",
      "Epoch: 29, Batch: 240/896, Loss: 0.4480, Time: 3.78s\n",
      "Epoch: 29, Batch: 250/896, Loss: 1.0708, Time: 3.78s\n",
      "Epoch: 29, Batch: 260/896, Loss: 0.6965, Time: 3.78s\n",
      "Epoch: 29, Batch: 270/896, Loss: 0.4745, Time: 3.80s\n",
      "Epoch: 29, Batch: 280/896, Loss: 0.8809, Time: 3.78s\n",
      "Epoch: 29, Batch: 290/896, Loss: 0.5021, Time: 3.79s\n",
      "Epoch: 29, Batch: 300/896, Loss: 0.7578, Time: 3.78s\n",
      "Epoch: 29, Batch: 310/896, Loss: 0.4511, Time: 3.79s\n",
      "Epoch: 29, Batch: 320/896, Loss: 1.0172, Time: 3.78s\n",
      "Epoch: 29, Batch: 330/896, Loss: 0.7408, Time: 3.79s\n",
      "Epoch: 29, Batch: 340/896, Loss: 0.5399, Time: 3.79s\n",
      "Epoch: 29, Batch: 350/896, Loss: 0.6831, Time: 3.79s\n",
      "Epoch: 29, Batch: 360/896, Loss: 0.8713, Time: 3.78s\n",
      "Epoch: 29, Batch: 370/896, Loss: 0.4158, Time: 3.78s\n",
      "Epoch: 29, Batch: 380/896, Loss: 0.4576, Time: 3.78s\n",
      "Epoch: 29, Batch: 390/896, Loss: 0.8906, Time: 3.79s\n",
      "Epoch: 29, Batch: 400/896, Loss: 1.1572, Time: 3.79s\n",
      "Epoch: 29, Batch: 410/896, Loss: 0.9738, Time: 3.78s\n",
      "Epoch: 29, Batch: 420/896, Loss: 0.5848, Time: 3.79s\n",
      "Epoch: 29, Batch: 430/896, Loss: 0.6358, Time: 3.79s\n",
      "Epoch: 29, Batch: 440/896, Loss: 0.4527, Time: 3.79s\n",
      "Epoch: 29, Batch: 450/896, Loss: 0.5404, Time: 3.80s\n",
      "Epoch: 29, Batch: 460/896, Loss: 1.0389, Time: 3.80s\n",
      "Epoch: 29, Batch: 470/896, Loss: 1.8638, Time: 3.79s\n",
      "Epoch: 29, Batch: 480/896, Loss: 0.6630, Time: 3.79s\n",
      "Epoch: 29, Batch: 490/896, Loss: 0.8164, Time: 3.80s\n",
      "Epoch: 29, Batch: 500/896, Loss: 0.6613, Time: 3.78s\n",
      "Epoch: 29, Batch: 510/896, Loss: 1.0103, Time: 3.79s\n",
      "Epoch: 29, Batch: 520/896, Loss: 1.0657, Time: 3.79s\n",
      "Epoch: 29, Batch: 530/896, Loss: 1.2720, Time: 3.79s\n",
      "Epoch: 29, Batch: 540/896, Loss: 0.6300, Time: 3.79s\n",
      "Epoch: 29, Batch: 550/896, Loss: 0.4468, Time: 3.79s\n",
      "Epoch: 29, Batch: 560/896, Loss: 0.8010, Time: 3.80s\n",
      "Epoch: 29, Batch: 570/896, Loss: 0.8501, Time: 3.80s\n",
      "Epoch: 29, Batch: 580/896, Loss: 0.7948, Time: 3.80s\n",
      "Epoch: 29, Batch: 590/896, Loss: 0.7114, Time: 3.79s\n",
      "Epoch: 29, Batch: 600/896, Loss: 1.2370, Time: 3.79s\n",
      "Epoch: 29, Batch: 610/896, Loss: 1.0777, Time: 3.81s\n",
      "Epoch: 29, Batch: 620/896, Loss: 0.3231, Time: 3.79s\n",
      "Epoch: 29, Batch: 630/896, Loss: 0.5686, Time: 3.80s\n",
      "Epoch: 29, Batch: 640/896, Loss: 0.7801, Time: 3.80s\n",
      "Epoch: 29, Batch: 650/896, Loss: 1.0969, Time: 3.79s\n",
      "Epoch: 29, Batch: 660/896, Loss: 1.2675, Time: 3.80s\n",
      "Epoch: 29, Batch: 670/896, Loss: 0.8152, Time: 3.79s\n",
      "Epoch: 29, Batch: 680/896, Loss: 0.4166, Time: 3.81s\n",
      "Epoch: 29, Batch: 690/896, Loss: 0.8558, Time: 3.80s\n",
      "Epoch: 29, Batch: 700/896, Loss: 0.4524, Time: 3.80s\n",
      "Epoch: 29, Batch: 710/896, Loss: 1.1654, Time: 3.81s\n",
      "Epoch: 29, Batch: 720/896, Loss: 0.6984, Time: 3.80s\n",
      "Epoch: 29, Batch: 730/896, Loss: 0.8784, Time: 3.81s\n",
      "Epoch: 29, Batch: 740/896, Loss: 0.4645, Time: 3.79s\n",
      "Epoch: 29, Batch: 750/896, Loss: 0.4053, Time: 3.80s\n",
      "Epoch: 29, Batch: 760/896, Loss: 0.7243, Time: 3.81s\n",
      "Epoch: 29, Batch: 770/896, Loss: 0.5281, Time: 3.80s\n",
      "Epoch: 29, Batch: 780/896, Loss: 0.9183, Time: 3.80s\n",
      "Epoch: 29, Batch: 790/896, Loss: 0.7342, Time: 3.80s\n",
      "Epoch: 29, Batch: 800/896, Loss: 1.7202, Time: 3.79s\n",
      "Epoch: 29, Batch: 810/896, Loss: 0.9743, Time: 3.78s\n",
      "Epoch: 29, Batch: 820/896, Loss: 0.6166, Time: 3.81s\n",
      "Epoch: 29, Batch: 830/896, Loss: 0.6940, Time: 3.81s\n",
      "Epoch: 29, Batch: 840/896, Loss: 0.6022, Time: 3.81s\n",
      "Epoch: 29, Batch: 850/896, Loss: 0.3667, Time: 3.81s\n",
      "Epoch: 29, Batch: 860/896, Loss: 0.7023, Time: 3.79s\n",
      "Epoch: 29, Batch: 870/896, Loss: 1.1011, Time: 3.80s\n",
      "Epoch: 29, Batch: 880/896, Loss: 0.8607, Time: 3.80s\n",
      "Epoch: 29, Batch: 890/896, Loss: 0.6752, Time: 3.79s\n",
      "Epoch 30/50: Train Loss: 0.7954, Val Loss: 0.8634, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 30, Batch: 0/896, Loss: 0.6460, Time: 28.79s\n",
      "Epoch: 30, Batch: 10/896, Loss: 0.6641, Time: 3.72s\n",
      "Epoch: 30, Batch: 20/896, Loss: 1.2652, Time: 3.71s\n",
      "Epoch: 30, Batch: 30/896, Loss: 0.9109, Time: 3.74s\n",
      "Epoch: 30, Batch: 40/896, Loss: 0.8907, Time: 3.73s\n",
      "Epoch: 30, Batch: 50/896, Loss: 0.6106, Time: 3.73s\n",
      "Epoch: 30, Batch: 60/896, Loss: 1.5200, Time: 3.74s\n",
      "Epoch: 30, Batch: 70/896, Loss: 0.6406, Time: 3.74s\n",
      "Epoch: 30, Batch: 80/896, Loss: 0.8664, Time: 3.75s\n",
      "Epoch: 30, Batch: 90/896, Loss: 0.5979, Time: 3.75s\n",
      "Epoch: 30, Batch: 100/896, Loss: 0.8138, Time: 3.76s\n",
      "Epoch: 30, Batch: 110/896, Loss: 0.8934, Time: 3.75s\n",
      "Epoch: 30, Batch: 120/896, Loss: 0.7361, Time: 3.76s\n",
      "Epoch: 30, Batch: 130/896, Loss: 0.8220, Time: 3.75s\n",
      "Epoch: 30, Batch: 140/896, Loss: 1.2377, Time: 3.76s\n",
      "Epoch: 30, Batch: 150/896, Loss: 0.5228, Time: 3.78s\n",
      "Epoch: 30, Batch: 160/896, Loss: 1.1107, Time: 3.77s\n",
      "Epoch: 30, Batch: 170/896, Loss: 0.5787, Time: 3.77s\n",
      "Epoch: 30, Batch: 180/896, Loss: 0.6685, Time: 3.75s\n",
      "Epoch: 30, Batch: 190/896, Loss: 0.7256, Time: 3.77s\n",
      "Epoch: 30, Batch: 200/896, Loss: 1.1446, Time: 3.76s\n",
      "Epoch: 30, Batch: 210/896, Loss: 0.7086, Time: 3.78s\n",
      "Epoch: 30, Batch: 220/896, Loss: 0.4506, Time: 3.78s\n",
      "Epoch: 30, Batch: 230/896, Loss: 1.1912, Time: 3.78s\n",
      "Epoch: 30, Batch: 240/896, Loss: 0.6883, Time: 3.77s\n",
      "Epoch: 30, Batch: 250/896, Loss: 0.6689, Time: 3.79s\n",
      "Epoch: 30, Batch: 260/896, Loss: 0.6671, Time: 3.77s\n",
      "Epoch: 30, Batch: 270/896, Loss: 0.5842, Time: 3.79s\n",
      "Epoch: 30, Batch: 280/896, Loss: 0.8856, Time: 3.77s\n",
      "Epoch: 30, Batch: 290/896, Loss: 0.7373, Time: 3.78s\n",
      "Epoch: 30, Batch: 300/896, Loss: 0.4749, Time: 3.78s\n",
      "Epoch: 30, Batch: 310/896, Loss: 1.2169, Time: 3.79s\n",
      "Epoch: 30, Batch: 320/896, Loss: 1.5801, Time: 3.78s\n",
      "Epoch: 30, Batch: 330/896, Loss: 0.9852, Time: 3.78s\n",
      "Epoch: 30, Batch: 340/896, Loss: 0.6836, Time: 3.78s\n",
      "Epoch: 30, Batch: 350/896, Loss: 0.4494, Time: 3.80s\n",
      "Epoch: 30, Batch: 360/896, Loss: 0.6276, Time: 3.79s\n",
      "Epoch: 30, Batch: 370/896, Loss: 1.0639, Time: 3.77s\n",
      "Epoch: 30, Batch: 380/896, Loss: 1.0988, Time: 3.79s\n",
      "Epoch: 30, Batch: 390/896, Loss: 0.6547, Time: 3.79s\n",
      "Epoch: 30, Batch: 400/896, Loss: 0.9394, Time: 3.79s\n",
      "Epoch: 30, Batch: 410/896, Loss: 0.7900, Time: 3.81s\n",
      "Epoch: 30, Batch: 420/896, Loss: 0.5163, Time: 3.79s\n",
      "Epoch: 30, Batch: 430/896, Loss: 1.2891, Time: 3.80s\n",
      "Epoch: 30, Batch: 440/896, Loss: 0.6744, Time: 3.79s\n",
      "Epoch: 30, Batch: 450/896, Loss: 0.3968, Time: 3.79s\n",
      "Epoch: 30, Batch: 460/896, Loss: 0.6029, Time: 3.80s\n",
      "Epoch: 30, Batch: 470/896, Loss: 1.3714, Time: 3.79s\n",
      "Epoch: 30, Batch: 480/896, Loss: 0.7713, Time: 3.80s\n",
      "Epoch: 30, Batch: 490/896, Loss: 0.9000, Time: 3.80s\n",
      "Epoch: 30, Batch: 500/896, Loss: 0.7467, Time: 3.79s\n",
      "Epoch: 30, Batch: 510/896, Loss: 0.5488, Time: 3.80s\n",
      "Epoch: 30, Batch: 520/896, Loss: 0.4287, Time: 3.79s\n",
      "Epoch: 30, Batch: 530/896, Loss: 1.3247, Time: 3.79s\n",
      "Epoch: 30, Batch: 540/896, Loss: 1.4826, Time: 3.80s\n",
      "Epoch: 30, Batch: 550/896, Loss: 0.4455, Time: 3.79s\n",
      "Epoch: 30, Batch: 560/896, Loss: 0.7761, Time: 3.81s\n",
      "Epoch: 30, Batch: 570/896, Loss: 1.0857, Time: 3.78s\n",
      "Epoch: 30, Batch: 580/896, Loss: 1.5846, Time: 3.80s\n",
      "Epoch: 30, Batch: 590/896, Loss: 1.0150, Time: 3.78s\n",
      "Epoch: 30, Batch: 600/896, Loss: 1.2952, Time: 3.79s\n",
      "Epoch: 30, Batch: 610/896, Loss: 0.8721, Time: 3.79s\n",
      "Epoch: 30, Batch: 620/896, Loss: 0.5950, Time: 3.78s\n",
      "Epoch: 30, Batch: 630/896, Loss: 1.3056, Time: 3.79s\n",
      "Epoch: 30, Batch: 640/896, Loss: 0.9853, Time: 3.80s\n",
      "Epoch: 30, Batch: 650/896, Loss: 0.7596, Time: 3.79s\n",
      "Epoch: 30, Batch: 660/896, Loss: 1.2467, Time: 3.79s\n",
      "Epoch: 30, Batch: 670/896, Loss: 0.7854, Time: 3.79s\n",
      "Epoch: 30, Batch: 680/896, Loss: 1.1715, Time: 3.79s\n",
      "Epoch: 30, Batch: 690/896, Loss: 0.8414, Time: 3.79s\n",
      "Epoch: 30, Batch: 700/896, Loss: 0.5517, Time: 3.80s\n",
      "Epoch: 30, Batch: 710/896, Loss: 1.2689, Time: 3.79s\n",
      "Epoch: 30, Batch: 720/896, Loss: 0.9984, Time: 3.80s\n",
      "Epoch: 30, Batch: 730/896, Loss: 0.3907, Time: 3.79s\n",
      "Epoch: 30, Batch: 740/896, Loss: 1.1215, Time: 3.80s\n",
      "Epoch: 30, Batch: 750/896, Loss: 0.5037, Time: 3.80s\n",
      "Epoch: 30, Batch: 760/896, Loss: 0.4313, Time: 3.80s\n",
      "Epoch: 30, Batch: 770/896, Loss: 1.4786, Time: 3.79s\n",
      "Epoch: 30, Batch: 780/896, Loss: 0.8456, Time: 3.81s\n",
      "Epoch: 30, Batch: 790/896, Loss: 1.3156, Time: 3.80s\n",
      "Epoch: 30, Batch: 800/896, Loss: 0.6938, Time: 3.79s\n",
      "Epoch: 30, Batch: 810/896, Loss: 0.9561, Time: 3.80s\n",
      "Epoch: 30, Batch: 820/896, Loss: 0.6460, Time: 3.79s\n",
      "Epoch: 30, Batch: 830/896, Loss: 0.9298, Time: 3.81s\n",
      "Epoch: 30, Batch: 840/896, Loss: 0.5397, Time: 3.80s\n",
      "Epoch: 30, Batch: 850/896, Loss: 0.4894, Time: 3.80s\n",
      "Epoch: 30, Batch: 860/896, Loss: 0.8269, Time: 3.80s\n",
      "Epoch: 30, Batch: 870/896, Loss: 0.6812, Time: 3.78s\n",
      "Epoch: 30, Batch: 880/896, Loss: 0.4878, Time: 3.81s\n",
      "Epoch: 30, Batch: 890/896, Loss: 0.7965, Time: 3.79s\n",
      "Epoch 31/50: Train Loss: 0.7954, Val Loss: 0.8681, Val IoU: 0.3637, Val Dice: 0.3863\n",
      "Epoch: 31, Batch: 0/896, Loss: 0.5869, Time: 28.75s\n",
      "Epoch: 31, Batch: 10/896, Loss: 0.5111, Time: 3.73s\n",
      "Epoch: 31, Batch: 20/896, Loss: 0.2842, Time: 3.73s\n",
      "Epoch: 31, Batch: 30/896, Loss: 0.3860, Time: 3.73s\n",
      "Epoch: 31, Batch: 40/896, Loss: 0.8273, Time: 3.72s\n",
      "Epoch: 31, Batch: 50/896, Loss: 0.7456, Time: 3.73s\n",
      "Epoch: 31, Batch: 60/896, Loss: 0.6467, Time: 3.74s\n",
      "Epoch: 31, Batch: 70/896, Loss: 1.0824, Time: 3.75s\n",
      "Epoch: 31, Batch: 80/896, Loss: 0.5071, Time: 3.73s\n",
      "Epoch: 31, Batch: 90/896, Loss: 0.6198, Time: 3.75s\n",
      "Epoch: 31, Batch: 100/896, Loss: 0.9741, Time: 3.75s\n",
      "Epoch: 31, Batch: 110/896, Loss: 0.8727, Time: 3.75s\n",
      "Epoch: 31, Batch: 120/896, Loss: 0.6061, Time: 3.76s\n",
      "Epoch: 31, Batch: 130/896, Loss: 0.4891, Time: 3.76s\n",
      "Epoch: 31, Batch: 140/896, Loss: 0.6776, Time: 3.78s\n",
      "Epoch: 31, Batch: 150/896, Loss: 0.4746, Time: 3.76s\n",
      "Epoch: 31, Batch: 160/896, Loss: 0.3730, Time: 3.78s\n",
      "Epoch: 31, Batch: 170/896, Loss: 1.0351, Time: 3.77s\n",
      "Epoch: 31, Batch: 180/896, Loss: 0.5296, Time: 3.78s\n",
      "Epoch: 31, Batch: 190/896, Loss: 0.7202, Time: 3.77s\n",
      "Epoch: 31, Batch: 200/896, Loss: 0.6166, Time: 3.77s\n",
      "Epoch: 31, Batch: 210/896, Loss: 0.7428, Time: 3.77s\n",
      "Epoch: 31, Batch: 220/896, Loss: 0.8962, Time: 3.77s\n",
      "Epoch: 31, Batch: 230/896, Loss: 0.7172, Time: 3.78s\n",
      "Epoch: 31, Batch: 240/896, Loss: 0.5555, Time: 3.79s\n",
      "Epoch: 31, Batch: 250/896, Loss: 0.7211, Time: 3.77s\n",
      "Epoch: 31, Batch: 260/896, Loss: 0.7971, Time: 3.78s\n",
      "Epoch: 31, Batch: 270/896, Loss: 0.5552, Time: 3.77s\n",
      "Epoch: 31, Batch: 280/896, Loss: 0.4574, Time: 3.78s\n",
      "Epoch: 31, Batch: 290/896, Loss: 0.9049, Time: 3.77s\n",
      "Epoch: 31, Batch: 300/896, Loss: 0.4931, Time: 3.78s\n",
      "Epoch: 31, Batch: 310/896, Loss: 0.4123, Time: 3.78s\n",
      "Epoch: 31, Batch: 320/896, Loss: 0.7779, Time: 3.77s\n",
      "Epoch: 31, Batch: 330/896, Loss: 0.7464, Time: 3.78s\n",
      "Epoch: 31, Batch: 340/896, Loss: 1.0808, Time: 3.78s\n",
      "Epoch: 31, Batch: 350/896, Loss: 0.5533, Time: 3.78s\n",
      "Epoch: 31, Batch: 360/896, Loss: 0.9266, Time: 3.79s\n",
      "Epoch: 31, Batch: 370/896, Loss: 1.0442, Time: 3.78s\n",
      "Epoch: 31, Batch: 380/896, Loss: 1.1007, Time: 3.79s\n",
      "Epoch: 31, Batch: 390/896, Loss: 0.7207, Time: 3.77s\n",
      "Epoch: 31, Batch: 400/896, Loss: 1.5793, Time: 3.78s\n",
      "Epoch: 31, Batch: 410/896, Loss: 0.5131, Time: 3.79s\n",
      "Epoch: 31, Batch: 420/896, Loss: 0.3679, Time: 3.79s\n",
      "Epoch: 31, Batch: 430/896, Loss: 1.0785, Time: 3.79s\n",
      "Epoch: 31, Batch: 440/896, Loss: 0.9161, Time: 3.80s\n",
      "Epoch: 31, Batch: 450/896, Loss: 0.4137, Time: 3.79s\n",
      "Epoch: 31, Batch: 460/896, Loss: 1.0417, Time: 3.79s\n",
      "Epoch: 31, Batch: 470/896, Loss: 1.0559, Time: 3.79s\n",
      "Epoch: 31, Batch: 480/896, Loss: 0.8906, Time: 3.78s\n",
      "Epoch: 31, Batch: 490/896, Loss: 0.8003, Time: 3.79s\n",
      "Epoch: 31, Batch: 500/896, Loss: 0.9575, Time: 3.79s\n",
      "Epoch: 31, Batch: 510/896, Loss: 0.8060, Time: 3.78s\n",
      "Epoch: 31, Batch: 520/896, Loss: 0.8841, Time: 3.79s\n",
      "Epoch: 31, Batch: 530/896, Loss: 0.4483, Time: 3.79s\n",
      "Epoch: 31, Batch: 540/896, Loss: 0.4472, Time: 3.79s\n",
      "Epoch: 31, Batch: 550/896, Loss: 0.4733, Time: 3.80s\n",
      "Epoch: 31, Batch: 560/896, Loss: 0.7039, Time: 3.80s\n",
      "Epoch: 31, Batch: 570/896, Loss: 1.4306, Time: 3.80s\n",
      "Epoch: 31, Batch: 580/896, Loss: 0.6644, Time: 3.79s\n",
      "Epoch: 31, Batch: 590/896, Loss: 0.3297, Time: 3.80s\n",
      "Epoch: 31, Batch: 600/896, Loss: 0.5363, Time: 3.80s\n",
      "Epoch: 31, Batch: 610/896, Loss: 0.5434, Time: 3.80s\n",
      "Epoch: 31, Batch: 620/896, Loss: 0.3409, Time: 3.79s\n",
      "Epoch: 31, Batch: 630/896, Loss: 0.3308, Time: 3.80s\n",
      "Epoch: 31, Batch: 640/896, Loss: 0.8072, Time: 3.79s\n",
      "Epoch: 31, Batch: 650/896, Loss: 1.2506, Time: 3.80s\n",
      "Epoch: 31, Batch: 660/896, Loss: 0.4271, Time: 3.80s\n",
      "Epoch: 31, Batch: 670/896, Loss: 0.6283, Time: 3.80s\n",
      "Epoch: 31, Batch: 680/896, Loss: 0.7570, Time: 3.80s\n",
      "Epoch: 31, Batch: 690/896, Loss: 0.3803, Time: 3.79s\n",
      "Epoch: 31, Batch: 700/896, Loss: 0.6969, Time: 3.79s\n",
      "Epoch: 31, Batch: 710/896, Loss: 0.5323, Time: 3.80s\n",
      "Epoch: 31, Batch: 720/896, Loss: 1.2037, Time: 3.78s\n",
      "Epoch: 31, Batch: 730/896, Loss: 0.4640, Time: 3.80s\n",
      "Epoch: 31, Batch: 740/896, Loss: 0.4647, Time: 3.79s\n",
      "Epoch: 31, Batch: 750/896, Loss: 1.5633, Time: 3.80s\n",
      "Epoch: 31, Batch: 760/896, Loss: 1.1612, Time: 3.80s\n",
      "Epoch: 31, Batch: 770/896, Loss: 0.7688, Time: 3.80s\n",
      "Epoch: 31, Batch: 780/896, Loss: 0.4875, Time: 3.79s\n",
      "Epoch: 31, Batch: 790/896, Loss: 0.9714, Time: 3.80s\n",
      "Epoch: 31, Batch: 800/896, Loss: 0.6473, Time: 3.79s\n",
      "Epoch: 31, Batch: 810/896, Loss: 0.4524, Time: 3.79s\n",
      "Epoch: 31, Batch: 820/896, Loss: 0.7633, Time: 3.79s\n",
      "Epoch: 31, Batch: 830/896, Loss: 1.1030, Time: 3.80s\n",
      "Epoch: 31, Batch: 840/896, Loss: 0.6111, Time: 3.80s\n",
      "Epoch: 31, Batch: 850/896, Loss: 0.7145, Time: 3.79s\n",
      "Epoch: 31, Batch: 860/896, Loss: 1.1362, Time: 3.79s\n",
      "Epoch: 31, Batch: 870/896, Loss: 0.5766, Time: 3.80s\n",
      "Epoch: 31, Batch: 880/896, Loss: 0.9331, Time: 3.80s\n",
      "Epoch: 31, Batch: 890/896, Loss: 1.0492, Time: 3.79s\n",
      "Epoch 32/50: Train Loss: 0.7960, Val Loss: 0.9091, Val IoU: 0.3632, Val Dice: 0.3855\n",
      "Epoch: 32, Batch: 0/896, Loss: 1.0874, Time: 29.41s\n",
      "Epoch: 32, Batch: 10/896, Loss: 0.4333, Time: 3.77s\n",
      "Epoch: 32, Batch: 20/896, Loss: 0.4379, Time: 3.76s\n",
      "Epoch: 32, Batch: 30/896, Loss: 0.5964, Time: 3.76s\n",
      "Epoch: 32, Batch: 40/896, Loss: 0.5936, Time: 3.76s\n",
      "Epoch: 32, Batch: 50/896, Loss: 0.5256, Time: 3.76s\n",
      "Epoch: 32, Batch: 60/896, Loss: 0.3228, Time: 3.77s\n",
      "Epoch: 32, Batch: 70/896, Loss: 0.8364, Time: 3.78s\n",
      "Epoch: 32, Batch: 80/896, Loss: 0.5533, Time: 3.75s\n",
      "Epoch: 32, Batch: 90/896, Loss: 1.0623, Time: 3.77s\n",
      "Epoch: 32, Batch: 100/896, Loss: 0.7471, Time: 3.77s\n",
      "Epoch: 32, Batch: 110/896, Loss: 0.9803, Time: 3.77s\n",
      "Epoch: 32, Batch: 120/896, Loss: 0.5160, Time: 3.78s\n",
      "Epoch: 32, Batch: 130/896, Loss: 0.7613, Time: 3.77s\n",
      "Epoch: 32, Batch: 140/896, Loss: 0.8054, Time: 3.79s\n",
      "Epoch: 32, Batch: 150/896, Loss: 0.3494, Time: 3.80s\n",
      "Epoch: 32, Batch: 160/896, Loss: 0.6685, Time: 3.79s\n",
      "Epoch: 32, Batch: 170/896, Loss: 0.5687, Time: 3.79s\n",
      "Epoch: 32, Batch: 180/896, Loss: 0.8156, Time: 3.80s\n",
      "Epoch: 32, Batch: 190/896, Loss: 0.5032, Time: 3.80s\n",
      "Epoch: 32, Batch: 200/896, Loss: 0.6469, Time: 3.80s\n",
      "Epoch: 32, Batch: 210/896, Loss: 0.5372, Time: 3.81s\n",
      "Epoch: 32, Batch: 220/896, Loss: 0.6997, Time: 3.79s\n",
      "Epoch: 32, Batch: 230/896, Loss: 0.9243, Time: 3.81s\n",
      "Epoch: 32, Batch: 240/896, Loss: 1.9094, Time: 3.79s\n",
      "Epoch: 32, Batch: 250/896, Loss: 1.1341, Time: 3.81s\n",
      "Epoch: 32, Batch: 260/896, Loss: 0.7260, Time: 3.81s\n",
      "Epoch: 32, Batch: 270/896, Loss: 0.9913, Time: 3.80s\n",
      "Epoch: 32, Batch: 280/896, Loss: 0.7932, Time: 3.81s\n",
      "Epoch: 32, Batch: 290/896, Loss: 0.3833, Time: 3.80s\n",
      "Epoch: 32, Batch: 300/896, Loss: 1.3766, Time: 3.80s\n",
      "Epoch: 32, Batch: 310/896, Loss: 0.8762, Time: 3.81s\n",
      "Epoch: 32, Batch: 320/896, Loss: 0.4323, Time: 3.81s\n",
      "Epoch: 32, Batch: 330/896, Loss: 0.7138, Time: 3.81s\n",
      "Epoch: 32, Batch: 340/896, Loss: 1.0553, Time: 3.81s\n",
      "Epoch: 32, Batch: 350/896, Loss: 0.4041, Time: 3.81s\n",
      "Epoch: 32, Batch: 360/896, Loss: 0.7830, Time: 3.81s\n",
      "Epoch: 32, Batch: 370/896, Loss: 0.6968, Time: 3.81s\n",
      "Epoch: 32, Batch: 380/896, Loss: 0.5712, Time: 3.81s\n",
      "Epoch: 32, Batch: 390/896, Loss: 0.7671, Time: 3.81s\n",
      "Epoch: 32, Batch: 400/896, Loss: 1.1164, Time: 3.81s\n",
      "Epoch: 32, Batch: 410/896, Loss: 1.3613, Time: 3.82s\n",
      "Epoch: 32, Batch: 420/896, Loss: 0.5701, Time: 3.81s\n",
      "Epoch: 32, Batch: 430/896, Loss: 0.5274, Time: 3.83s\n",
      "Epoch: 32, Batch: 440/896, Loss: 0.7503, Time: 3.79s\n",
      "Epoch: 32, Batch: 450/896, Loss: 0.5264, Time: 3.75s\n",
      "Epoch: 32, Batch: 460/896, Loss: 1.1889, Time: 3.74s\n",
      "Epoch: 32, Batch: 470/896, Loss: 0.8429, Time: 3.75s\n",
      "Epoch: 32, Batch: 480/896, Loss: 0.9332, Time: 3.73s\n",
      "Epoch: 32, Batch: 490/896, Loss: 0.2759, Time: 3.76s\n",
      "Epoch: 32, Batch: 500/896, Loss: 1.6661, Time: 3.75s\n",
      "Epoch: 32, Batch: 510/896, Loss: 0.9673, Time: 3.73s\n",
      "Epoch: 32, Batch: 520/896, Loss: 0.5732, Time: 3.74s\n",
      "Epoch: 32, Batch: 530/896, Loss: 0.4412, Time: 3.75s\n",
      "Epoch: 32, Batch: 540/896, Loss: 0.5702, Time: 3.75s\n",
      "Epoch: 32, Batch: 550/896, Loss: 0.4232, Time: 3.75s\n",
      "Epoch: 32, Batch: 560/896, Loss: 0.7857, Time: 3.75s\n",
      "Epoch: 32, Batch: 570/896, Loss: 0.3898, Time: 3.74s\n",
      "Epoch: 32, Batch: 580/896, Loss: 0.5111, Time: 3.75s\n",
      "Epoch: 32, Batch: 590/896, Loss: 0.4751, Time: 3.75s\n",
      "Epoch: 32, Batch: 600/896, Loss: 0.6001, Time: 3.75s\n",
      "Epoch: 32, Batch: 610/896, Loss: 1.0475, Time: 3.75s\n",
      "Epoch: 32, Batch: 620/896, Loss: 0.8866, Time: 3.75s\n",
      "Epoch: 32, Batch: 630/896, Loss: 0.8315, Time: 3.75s\n",
      "Epoch: 32, Batch: 640/896, Loss: 0.4888, Time: 3.75s\n",
      "Epoch: 32, Batch: 650/896, Loss: 0.5773, Time: 3.75s\n",
      "Epoch: 32, Batch: 660/896, Loss: 0.3196, Time: 3.74s\n",
      "Epoch: 32, Batch: 670/896, Loss: 0.7402, Time: 3.74s\n",
      "Epoch: 32, Batch: 680/896, Loss: 0.4914, Time: 3.75s\n",
      "Epoch: 32, Batch: 690/896, Loss: 0.4260, Time: 3.75s\n",
      "Epoch: 32, Batch: 700/896, Loss: 0.6300, Time: 3.75s\n",
      "Epoch: 32, Batch: 710/896, Loss: 1.4238, Time: 3.75s\n",
      "Epoch: 32, Batch: 720/896, Loss: 0.8944, Time: 3.75s\n",
      "Epoch: 32, Batch: 730/896, Loss: 0.5110, Time: 3.75s\n",
      "Epoch: 32, Batch: 740/896, Loss: 0.4088, Time: 3.75s\n",
      "Epoch: 32, Batch: 750/896, Loss: 1.0647, Time: 3.76s\n",
      "Epoch: 32, Batch: 760/896, Loss: 0.8961, Time: 3.76s\n",
      "Epoch: 32, Batch: 770/896, Loss: 1.0294, Time: 3.74s\n",
      "Epoch: 32, Batch: 780/896, Loss: 0.3188, Time: 3.74s\n",
      "Epoch: 32, Batch: 790/896, Loss: 0.5247, Time: 3.74s\n",
      "Epoch: 32, Batch: 800/896, Loss: 0.5158, Time: 3.74s\n",
      "Epoch: 32, Batch: 810/896, Loss: 0.6266, Time: 3.74s\n",
      "Epoch: 32, Batch: 820/896, Loss: 0.3372, Time: 3.75s\n",
      "Epoch: 32, Batch: 830/896, Loss: 1.0986, Time: 3.74s\n",
      "Epoch: 32, Batch: 840/896, Loss: 0.7408, Time: 3.75s\n",
      "Epoch: 32, Batch: 850/896, Loss: 0.8595, Time: 3.74s\n",
      "Epoch: 32, Batch: 860/896, Loss: 0.9166, Time: 3.75s\n",
      "Epoch: 32, Batch: 870/896, Loss: 0.5236, Time: 3.75s\n",
      "Epoch: 32, Batch: 880/896, Loss: 0.8458, Time: 3.77s\n",
      "Epoch: 32, Batch: 890/896, Loss: 0.3750, Time: 3.75s\n",
      "Epoch 33/50: Train Loss: 0.7838, Val Loss: 0.8227, Val IoU: 0.3729, Val Dice: 0.3968\n",
      "Epoch: 33, Batch: 0/896, Loss: 0.4161, Time: 28.70s\n",
      "Epoch: 33, Batch: 10/896, Loss: 0.6432, Time: 3.69s\n",
      "Epoch: 33, Batch: 20/896, Loss: 0.6518, Time: 3.68s\n",
      "Epoch: 33, Batch: 30/896, Loss: 0.6230, Time: 3.69s\n",
      "Epoch: 33, Batch: 40/896, Loss: 1.5298, Time: 3.69s\n",
      "Epoch: 33, Batch: 50/896, Loss: 0.8317, Time: 3.70s\n",
      "Epoch: 33, Batch: 60/896, Loss: 0.6569, Time: 3.70s\n",
      "Epoch: 33, Batch: 70/896, Loss: 0.4438, Time: 3.70s\n",
      "Epoch: 33, Batch: 80/896, Loss: 0.9403, Time: 3.69s\n",
      "Epoch: 33, Batch: 90/896, Loss: 0.7700, Time: 3.71s\n",
      "Epoch: 33, Batch: 100/896, Loss: 0.7729, Time: 3.72s\n",
      "Epoch: 33, Batch: 110/896, Loss: 0.5071, Time: 3.71s\n",
      "Epoch: 33, Batch: 120/896, Loss: 0.7523, Time: 3.72s\n",
      "Epoch: 33, Batch: 130/896, Loss: 0.4540, Time: 3.71s\n",
      "Epoch: 33, Batch: 140/896, Loss: 1.3730, Time: 3.72s\n",
      "Epoch: 33, Batch: 150/896, Loss: 0.9087, Time: 3.71s\n",
      "Epoch: 33, Batch: 160/896, Loss: 0.7450, Time: 3.71s\n",
      "Epoch: 33, Batch: 170/896, Loss: 0.9106, Time: 3.72s\n",
      "Epoch: 33, Batch: 180/896, Loss: 0.5581, Time: 3.73s\n",
      "Epoch: 33, Batch: 190/896, Loss: 0.4397, Time: 3.72s\n",
      "Epoch: 33, Batch: 200/896, Loss: 0.5576, Time: 3.72s\n",
      "Epoch: 33, Batch: 210/896, Loss: 1.1010, Time: 3.73s\n",
      "Epoch: 33, Batch: 220/896, Loss: 0.4793, Time: 3.73s\n",
      "Epoch: 33, Batch: 230/896, Loss: 0.6300, Time: 3.74s\n",
      "Epoch: 33, Batch: 240/896, Loss: 0.5210, Time: 3.74s\n",
      "Epoch: 33, Batch: 250/896, Loss: 0.7095, Time: 3.75s\n",
      "Epoch: 33, Batch: 260/896, Loss: 0.4772, Time: 3.74s\n",
      "Epoch: 33, Batch: 270/896, Loss: 0.5923, Time: 3.73s\n",
      "Epoch: 33, Batch: 280/896, Loss: 0.4524, Time: 3.74s\n",
      "Epoch: 33, Batch: 290/896, Loss: 1.0622, Time: 3.75s\n",
      "Epoch: 33, Batch: 300/896, Loss: 0.6551, Time: 3.75s\n",
      "Epoch: 33, Batch: 310/896, Loss: 0.6892, Time: 3.74s\n",
      "Epoch: 33, Batch: 320/896, Loss: 1.0110, Time: 3.74s\n",
      "Epoch: 33, Batch: 330/896, Loss: 0.4148, Time: 3.74s\n",
      "Epoch: 33, Batch: 340/896, Loss: 0.8199, Time: 3.74s\n",
      "Epoch: 33, Batch: 350/896, Loss: 0.8135, Time: 3.74s\n",
      "Epoch: 33, Batch: 360/896, Loss: 0.3933, Time: 3.73s\n",
      "Epoch: 33, Batch: 370/896, Loss: 0.9883, Time: 3.73s\n",
      "Epoch: 33, Batch: 380/896, Loss: 0.3366, Time: 3.74s\n",
      "Epoch: 33, Batch: 390/896, Loss: 1.1942, Time: 3.74s\n",
      "Epoch: 33, Batch: 400/896, Loss: 0.8840, Time: 3.73s\n",
      "Epoch: 33, Batch: 410/896, Loss: 0.4330, Time: 3.74s\n",
      "Epoch: 33, Batch: 420/896, Loss: 0.4213, Time: 3.74s\n",
      "Epoch: 33, Batch: 430/896, Loss: 0.9353, Time: 3.74s\n",
      "Epoch: 33, Batch: 440/896, Loss: 0.9192, Time: 3.74s\n",
      "Epoch: 33, Batch: 450/896, Loss: 0.9246, Time: 3.74s\n",
      "Epoch: 33, Batch: 460/896, Loss: 1.2439, Time: 3.75s\n",
      "Epoch: 33, Batch: 470/896, Loss: 0.6686, Time: 3.74s\n",
      "Epoch: 33, Batch: 480/896, Loss: 0.7111, Time: 3.75s\n",
      "Epoch: 33, Batch: 490/896, Loss: 1.4023, Time: 3.74s\n",
      "Epoch: 33, Batch: 500/896, Loss: 0.6316, Time: 3.74s\n",
      "Epoch: 33, Batch: 510/896, Loss: 0.6944, Time: 3.74s\n",
      "Epoch: 33, Batch: 520/896, Loss: 0.5879, Time: 3.75s\n",
      "Epoch: 33, Batch: 530/896, Loss: 0.6191, Time: 3.74s\n",
      "Epoch: 33, Batch: 540/896, Loss: 0.8054, Time: 3.75s\n",
      "Epoch: 33, Batch: 550/896, Loss: 0.5961, Time: 3.76s\n",
      "Epoch: 33, Batch: 560/896, Loss: 0.9776, Time: 3.75s\n",
      "Epoch: 33, Batch: 570/896, Loss: 0.4371, Time: 3.75s\n",
      "Epoch: 33, Batch: 580/896, Loss: 1.2499, Time: 3.76s\n",
      "Epoch: 33, Batch: 590/896, Loss: 0.3920, Time: 3.73s\n",
      "Epoch: 33, Batch: 600/896, Loss: 1.3900, Time: 3.75s\n",
      "Epoch: 33, Batch: 610/896, Loss: 0.6335, Time: 3.77s\n",
      "Epoch: 33, Batch: 620/896, Loss: 0.7281, Time: 3.75s\n",
      "Epoch: 33, Batch: 630/896, Loss: 0.5589, Time: 3.74s\n",
      "Epoch: 33, Batch: 640/896, Loss: 0.9991, Time: 3.76s\n",
      "Epoch: 33, Batch: 650/896, Loss: 0.6629, Time: 3.75s\n",
      "Epoch: 33, Batch: 660/896, Loss: 0.4317, Time: 3.76s\n",
      "Epoch: 33, Batch: 670/896, Loss: 0.7500, Time: 3.76s\n",
      "Epoch: 33, Batch: 680/896, Loss: 1.7917, Time: 3.74s\n",
      "Epoch: 33, Batch: 690/896, Loss: 0.2696, Time: 3.74s\n",
      "Epoch: 33, Batch: 700/896, Loss: 0.8636, Time: 3.74s\n",
      "Epoch: 33, Batch: 710/896, Loss: 0.9791, Time: 3.75s\n",
      "Epoch: 33, Batch: 720/896, Loss: 0.5827, Time: 3.74s\n",
      "Epoch: 33, Batch: 730/896, Loss: 0.7269, Time: 3.76s\n",
      "Epoch: 33, Batch: 740/896, Loss: 0.4527, Time: 3.74s\n",
      "Epoch: 33, Batch: 750/896, Loss: 1.0024, Time: 3.76s\n",
      "Epoch: 33, Batch: 760/896, Loss: 1.3173, Time: 3.74s\n",
      "Epoch: 33, Batch: 770/896, Loss: 0.4169, Time: 3.75s\n",
      "Epoch: 33, Batch: 780/896, Loss: 0.6191, Time: 3.76s\n",
      "Epoch: 33, Batch: 790/896, Loss: 1.0139, Time: 3.74s\n",
      "Epoch: 33, Batch: 800/896, Loss: 0.3542, Time: 3.75s\n",
      "Epoch: 33, Batch: 810/896, Loss: 0.4438, Time: 3.75s\n",
      "Epoch: 33, Batch: 820/896, Loss: 0.6900, Time: 3.74s\n",
      "Epoch: 33, Batch: 830/896, Loss: 1.2016, Time: 3.74s\n",
      "Epoch: 33, Batch: 840/896, Loss: 0.3371, Time: 3.75s\n",
      "Epoch: 33, Batch: 850/896, Loss: 1.0044, Time: 3.75s\n",
      "Epoch: 33, Batch: 860/896, Loss: 0.6219, Time: 3.75s\n",
      "Epoch: 33, Batch: 870/896, Loss: 0.4032, Time: 3.76s\n",
      "Epoch: 33, Batch: 880/896, Loss: 0.7110, Time: 3.74s\n",
      "Epoch: 33, Batch: 890/896, Loss: 0.8099, Time: 3.77s\n",
      "Epoch 34/50: Train Loss: 0.7814, Val Loss: 0.8195, Val IoU: 0.3797, Val Dice: 0.4028\n",
      "Saving best model with IoU: 0.3797\n",
      "Epoch: 34, Batch: 0/896, Loss: 0.4602, Time: 28.61s\n",
      "Epoch: 34, Batch: 10/896, Loss: 0.6321, Time: 3.69s\n",
      "Epoch: 34, Batch: 20/896, Loss: 0.3229, Time: 3.69s\n",
      "Epoch: 34, Batch: 30/896, Loss: 0.7328, Time: 3.69s\n",
      "Epoch: 34, Batch: 40/896, Loss: 0.4753, Time: 3.68s\n",
      "Epoch: 34, Batch: 50/896, Loss: 0.3204, Time: 3.71s\n",
      "Epoch: 34, Batch: 60/896, Loss: 0.9366, Time: 3.70s\n",
      "Epoch: 34, Batch: 70/896, Loss: 0.4396, Time: 3.70s\n",
      "Epoch: 34, Batch: 80/896, Loss: 0.9446, Time: 3.71s\n",
      "Epoch: 34, Batch: 90/896, Loss: 1.5128, Time: 3.70s\n",
      "Epoch: 34, Batch: 100/896, Loss: 1.1819, Time: 3.70s\n",
      "Epoch: 34, Batch: 110/896, Loss: 0.9613, Time: 3.71s\n",
      "Epoch: 34, Batch: 120/896, Loss: 0.8300, Time: 3.72s\n",
      "Epoch: 34, Batch: 130/896, Loss: 1.0579, Time: 3.73s\n",
      "Epoch: 34, Batch: 140/896, Loss: 0.7160, Time: 3.71s\n",
      "Epoch: 34, Batch: 150/896, Loss: 0.8870, Time: 3.72s\n",
      "Epoch: 34, Batch: 160/896, Loss: 0.8346, Time: 3.72s\n",
      "Epoch: 34, Batch: 170/896, Loss: 0.7228, Time: 3.73s\n",
      "Epoch: 34, Batch: 180/896, Loss: 0.9865, Time: 3.73s\n",
      "Epoch: 34, Batch: 190/896, Loss: 0.6612, Time: 3.73s\n",
      "Epoch: 34, Batch: 200/896, Loss: 1.1638, Time: 3.73s\n",
      "Epoch: 34, Batch: 210/896, Loss: 0.4490, Time: 3.74s\n",
      "Epoch: 34, Batch: 220/896, Loss: 0.9698, Time: 3.74s\n",
      "Epoch: 34, Batch: 230/896, Loss: 0.4715, Time: 3.72s\n",
      "Epoch: 34, Batch: 240/896, Loss: 0.5031, Time: 3.74s\n",
      "Epoch: 34, Batch: 250/896, Loss: 0.5942, Time: 3.74s\n",
      "Epoch: 34, Batch: 260/896, Loss: 0.7136, Time: 3.73s\n",
      "Epoch: 34, Batch: 270/896, Loss: 0.9815, Time: 3.74s\n",
      "Epoch: 34, Batch: 280/896, Loss: 0.7053, Time: 3.74s\n",
      "Epoch: 34, Batch: 290/896, Loss: 0.6839, Time: 3.74s\n",
      "Epoch: 34, Batch: 300/896, Loss: 0.5213, Time: 3.75s\n",
      "Epoch: 34, Batch: 310/896, Loss: 1.0228, Time: 3.74s\n",
      "Epoch: 34, Batch: 320/896, Loss: 0.4548, Time: 3.75s\n",
      "Epoch: 34, Batch: 330/896, Loss: 1.2198, Time: 3.74s\n",
      "Epoch: 34, Batch: 340/896, Loss: 0.9722, Time: 3.74s\n",
      "Epoch: 34, Batch: 350/896, Loss: 0.4599, Time: 3.73s\n",
      "Epoch: 34, Batch: 360/896, Loss: 0.3526, Time: 3.75s\n",
      "Epoch: 34, Batch: 370/896, Loss: 1.0385, Time: 3.74s\n",
      "Epoch: 34, Batch: 380/896, Loss: 0.7544, Time: 3.74s\n",
      "Epoch: 34, Batch: 390/896, Loss: 0.9192, Time: 3.74s\n",
      "Epoch: 34, Batch: 400/896, Loss: 0.8180, Time: 3.74s\n",
      "Epoch: 34, Batch: 410/896, Loss: 0.7010, Time: 3.74s\n",
      "Epoch: 34, Batch: 420/896, Loss: 0.4590, Time: 3.75s\n",
      "Epoch: 34, Batch: 430/896, Loss: 0.2909, Time: 3.73s\n",
      "Epoch: 34, Batch: 440/896, Loss: 0.6205, Time: 3.74s\n",
      "Epoch: 34, Batch: 450/896, Loss: 0.7253, Time: 3.74s\n",
      "Epoch: 34, Batch: 460/896, Loss: 0.9235, Time: 3.75s\n",
      "Epoch: 34, Batch: 470/896, Loss: 0.8106, Time: 3.75s\n",
      "Epoch: 34, Batch: 480/896, Loss: 0.5178, Time: 3.74s\n",
      "Epoch: 34, Batch: 490/896, Loss: 0.5045, Time: 3.73s\n",
      "Epoch: 34, Batch: 500/896, Loss: 0.7026, Time: 3.75s\n",
      "Epoch: 34, Batch: 510/896, Loss: 0.6214, Time: 3.74s\n",
      "Epoch: 34, Batch: 520/896, Loss: 1.2886, Time: 3.75s\n",
      "Epoch: 34, Batch: 530/896, Loss: 0.5929, Time: 3.76s\n",
      "Epoch: 34, Batch: 540/896, Loss: 0.6200, Time: 3.75s\n",
      "Epoch: 34, Batch: 550/896, Loss: 0.3668, Time: 3.76s\n",
      "Epoch: 34, Batch: 560/896, Loss: 0.6951, Time: 3.74s\n",
      "Epoch: 34, Batch: 570/896, Loss: 0.5198, Time: 3.75s\n",
      "Epoch: 34, Batch: 580/896, Loss: 0.8319, Time: 3.75s\n",
      "Epoch: 34, Batch: 590/896, Loss: 0.7284, Time: 3.74s\n",
      "Epoch: 34, Batch: 600/896, Loss: 0.5743, Time: 3.74s\n",
      "Epoch: 34, Batch: 610/896, Loss: 0.4269, Time: 3.74s\n",
      "Epoch: 34, Batch: 620/896, Loss: 1.0081, Time: 3.75s\n",
      "Epoch: 34, Batch: 630/896, Loss: 0.7271, Time: 3.76s\n",
      "Epoch: 34, Batch: 640/896, Loss: 0.8621, Time: 3.74s\n",
      "Epoch: 34, Batch: 650/896, Loss: 1.3352, Time: 3.76s\n",
      "Epoch: 34, Batch: 660/896, Loss: 0.8538, Time: 3.76s\n",
      "Epoch: 34, Batch: 670/896, Loss: 0.8126, Time: 3.75s\n",
      "Epoch: 34, Batch: 680/896, Loss: 0.6656, Time: 3.75s\n",
      "Epoch: 34, Batch: 690/896, Loss: 0.8186, Time: 3.75s\n",
      "Epoch: 34, Batch: 700/896, Loss: 1.0531, Time: 3.74s\n",
      "Epoch: 34, Batch: 710/896, Loss: 0.7868, Time: 3.74s\n",
      "Epoch: 34, Batch: 720/896, Loss: 0.5038, Time: 3.76s\n",
      "Epoch: 34, Batch: 730/896, Loss: 0.4860, Time: 3.76s\n",
      "Epoch: 34, Batch: 740/896, Loss: 0.5763, Time: 3.75s\n",
      "Epoch: 34, Batch: 750/896, Loss: 1.4574, Time: 3.75s\n",
      "Epoch: 34, Batch: 760/896, Loss: 0.5441, Time: 3.76s\n",
      "Epoch: 34, Batch: 770/896, Loss: 0.4201, Time: 3.76s\n",
      "Epoch: 34, Batch: 780/896, Loss: 0.5525, Time: 3.74s\n",
      "Epoch: 34, Batch: 790/896, Loss: 1.3547, Time: 3.75s\n",
      "Epoch: 34, Batch: 800/896, Loss: 0.7300, Time: 3.75s\n",
      "Epoch: 34, Batch: 810/896, Loss: 0.5333, Time: 3.75s\n",
      "Epoch: 34, Batch: 820/896, Loss: 0.8322, Time: 3.75s\n",
      "Epoch: 34, Batch: 830/896, Loss: 0.3899, Time: 3.75s\n",
      "Epoch: 34, Batch: 840/896, Loss: 1.0056, Time: 3.74s\n",
      "Epoch: 34, Batch: 850/896, Loss: 1.3340, Time: 3.76s\n",
      "Epoch: 34, Batch: 860/896, Loss: 0.4775, Time: 3.76s\n",
      "Epoch: 34, Batch: 870/896, Loss: 0.8769, Time: 3.75s\n",
      "Epoch: 34, Batch: 880/896, Loss: 0.3917, Time: 3.75s\n",
      "Epoch: 34, Batch: 890/896, Loss: 0.9281, Time: 3.75s\n",
      "Epoch 35/50: Train Loss: 0.7809, Val Loss: 0.8362, Val IoU: 0.3767, Val Dice: 0.4005\n",
      "Epoch: 35, Batch: 0/896, Loss: 1.2439, Time: 28.67s\n",
      "Epoch: 35, Batch: 10/896, Loss: 0.7391, Time: 3.69s\n",
      "Epoch: 35, Batch: 20/896, Loss: 0.6669, Time: 3.69s\n",
      "Epoch: 35, Batch: 30/896, Loss: 0.4207, Time: 3.69s\n",
      "Epoch: 35, Batch: 40/896, Loss: 0.4686, Time: 3.70s\n",
      "Epoch: 35, Batch: 50/896, Loss: 0.4796, Time: 3.70s\n",
      "Epoch: 35, Batch: 60/896, Loss: 0.4168, Time: 3.71s\n",
      "Epoch: 35, Batch: 70/896, Loss: 0.7194, Time: 3.69s\n",
      "Epoch: 35, Batch: 80/896, Loss: 0.9440, Time: 3.72s\n",
      "Epoch: 35, Batch: 90/896, Loss: 0.8285, Time: 3.71s\n",
      "Epoch: 35, Batch: 100/896, Loss: 1.6963, Time: 3.71s\n",
      "Epoch: 35, Batch: 110/896, Loss: 0.5860, Time: 3.71s\n",
      "Epoch: 35, Batch: 120/896, Loss: 0.7155, Time: 3.72s\n",
      "Epoch: 35, Batch: 130/896, Loss: 0.6433, Time: 3.72s\n",
      "Epoch: 35, Batch: 140/896, Loss: 0.9576, Time: 3.72s\n",
      "Epoch: 35, Batch: 150/896, Loss: 1.1171, Time: 3.72s\n",
      "Epoch: 35, Batch: 160/896, Loss: 1.0020, Time: 3.72s\n",
      "Epoch: 35, Batch: 170/896, Loss: 0.6301, Time: 3.72s\n",
      "Epoch: 35, Batch: 180/896, Loss: 0.7049, Time: 3.73s\n",
      "Epoch: 35, Batch: 190/896, Loss: 0.7562, Time: 3.72s\n",
      "Epoch: 35, Batch: 200/896, Loss: 0.5131, Time: 3.74s\n",
      "Epoch: 35, Batch: 210/896, Loss: 0.4874, Time: 3.74s\n",
      "Epoch: 35, Batch: 220/896, Loss: 0.9220, Time: 3.73s\n",
      "Epoch: 35, Batch: 230/896, Loss: 0.7895, Time: 3.74s\n",
      "Epoch: 35, Batch: 240/896, Loss: 0.5163, Time: 3.74s\n",
      "Epoch: 35, Batch: 250/896, Loss: 0.8973, Time: 3.72s\n",
      "Epoch: 35, Batch: 260/896, Loss: 0.5829, Time: 3.73s\n",
      "Epoch: 35, Batch: 270/896, Loss: 0.6544, Time: 3.74s\n",
      "Epoch: 35, Batch: 280/896, Loss: 0.7536, Time: 3.74s\n",
      "Epoch: 35, Batch: 290/896, Loss: 1.5947, Time: 3.74s\n",
      "Epoch: 35, Batch: 300/896, Loss: 0.9352, Time: 3.74s\n",
      "Epoch: 35, Batch: 310/896, Loss: 0.6179, Time: 3.74s\n",
      "Epoch: 35, Batch: 320/896, Loss: 0.5006, Time: 3.75s\n",
      "Epoch: 35, Batch: 330/896, Loss: 1.5067, Time: 3.74s\n",
      "Epoch: 35, Batch: 340/896, Loss: 0.8228, Time: 3.73s\n",
      "Epoch: 35, Batch: 350/896, Loss: 0.4359, Time: 3.75s\n",
      "Epoch: 35, Batch: 360/896, Loss: 1.0374, Time: 3.74s\n",
      "Epoch: 35, Batch: 370/896, Loss: 0.8223, Time: 3.75s\n",
      "Epoch: 35, Batch: 380/896, Loss: 0.6752, Time: 3.74s\n",
      "Epoch: 35, Batch: 390/896, Loss: 0.6166, Time: 3.75s\n",
      "Epoch: 35, Batch: 400/896, Loss: 1.2983, Time: 3.73s\n",
      "Epoch: 35, Batch: 410/896, Loss: 0.6176, Time: 3.75s\n",
      "Epoch: 35, Batch: 420/896, Loss: 0.5747, Time: 3.75s\n",
      "Epoch: 35, Batch: 430/896, Loss: 0.9016, Time: 3.74s\n",
      "Epoch: 35, Batch: 440/896, Loss: 0.7185, Time: 3.74s\n",
      "Epoch: 35, Batch: 450/896, Loss: 1.4360, Time: 3.75s\n",
      "Epoch: 35, Batch: 460/896, Loss: 0.6518, Time: 3.74s\n",
      "Epoch: 35, Batch: 470/896, Loss: 0.7479, Time: 3.73s\n",
      "Epoch: 35, Batch: 480/896, Loss: 0.4576, Time: 3.74s\n",
      "Epoch: 35, Batch: 490/896, Loss: 1.2338, Time: 3.75s\n",
      "Epoch: 35, Batch: 500/896, Loss: 0.4108, Time: 3.74s\n",
      "Epoch: 35, Batch: 510/896, Loss: 0.5374, Time: 3.75s\n",
      "Epoch: 35, Batch: 520/896, Loss: 0.5955, Time: 3.74s\n",
      "Epoch: 35, Batch: 530/896, Loss: 0.8785, Time: 3.74s\n",
      "Epoch: 35, Batch: 540/896, Loss: 0.7505, Time: 3.74s\n",
      "Epoch: 35, Batch: 550/896, Loss: 0.6109, Time: 3.75s\n",
      "Epoch: 35, Batch: 560/896, Loss: 0.8895, Time: 3.74s\n",
      "Epoch: 35, Batch: 570/896, Loss: 1.7753, Time: 3.74s\n",
      "Epoch: 35, Batch: 580/896, Loss: 0.6618, Time: 3.74s\n",
      "Epoch: 35, Batch: 590/896, Loss: 0.5567, Time: 3.75s\n",
      "Epoch: 35, Batch: 600/896, Loss: 0.3903, Time: 3.73s\n",
      "Epoch: 35, Batch: 610/896, Loss: 0.8326, Time: 3.75s\n",
      "Epoch: 35, Batch: 620/896, Loss: 0.6879, Time: 3.75s\n",
      "Epoch: 35, Batch: 630/896, Loss: 0.7418, Time: 3.74s\n",
      "Epoch: 35, Batch: 640/896, Loss: 0.5589, Time: 3.76s\n",
      "Epoch: 35, Batch: 650/896, Loss: 0.4418, Time: 3.75s\n",
      "Epoch: 35, Batch: 660/896, Loss: 1.0505, Time: 3.74s\n",
      "Epoch: 35, Batch: 670/896, Loss: 0.3080, Time: 3.75s\n",
      "Epoch: 35, Batch: 680/896, Loss: 0.6120, Time: 3.76s\n",
      "Epoch: 35, Batch: 690/896, Loss: 0.6241, Time: 3.75s\n",
      "Epoch: 35, Batch: 700/896, Loss: 0.6873, Time: 3.74s\n",
      "Epoch: 35, Batch: 710/896, Loss: 0.9593, Time: 3.74s\n",
      "Epoch: 35, Batch: 720/896, Loss: 0.3719, Time: 3.75s\n",
      "Epoch: 35, Batch: 730/896, Loss: 0.8907, Time: 3.74s\n",
      "Epoch: 35, Batch: 740/896, Loss: 1.7372, Time: 3.75s\n",
      "Epoch: 35, Batch: 750/896, Loss: 0.4216, Time: 3.75s\n",
      "Epoch: 35, Batch: 760/896, Loss: 0.3753, Time: 3.75s\n",
      "Epoch: 35, Batch: 770/896, Loss: 0.5946, Time: 3.75s\n",
      "Epoch: 35, Batch: 780/896, Loss: 1.4733, Time: 3.75s\n",
      "Epoch: 35, Batch: 790/896, Loss: 0.3361, Time: 3.76s\n",
      "Epoch: 35, Batch: 800/896, Loss: 0.7320, Time: 3.75s\n",
      "Epoch: 35, Batch: 810/896, Loss: 0.5930, Time: 3.75s\n",
      "Epoch: 35, Batch: 820/896, Loss: 0.5844, Time: 3.75s\n",
      "Epoch: 35, Batch: 830/896, Loss: 0.6804, Time: 3.75s\n",
      "Epoch: 35, Batch: 840/896, Loss: 0.3307, Time: 3.74s\n",
      "Epoch: 35, Batch: 850/896, Loss: 1.4732, Time: 3.74s\n",
      "Epoch: 35, Batch: 860/896, Loss: 0.9303, Time: 3.75s\n",
      "Epoch: 35, Batch: 870/896, Loss: 0.3374, Time: 3.74s\n",
      "Epoch: 35, Batch: 880/896, Loss: 0.4065, Time: 3.75s\n",
      "Epoch: 35, Batch: 890/896, Loss: 0.6665, Time: 3.74s\n",
      "Epoch 36/50: Train Loss: 0.7785, Val Loss: 0.8372, Val IoU: 0.3739, Val Dice: 0.3977\n",
      "Epoch: 36, Batch: 0/896, Loss: 0.4215, Time: 28.69s\n",
      "Epoch: 36, Batch: 10/896, Loss: 0.9824, Time: 3.70s\n",
      "Epoch: 36, Batch: 20/896, Loss: 0.6822, Time: 3.67s\n",
      "Epoch: 36, Batch: 30/896, Loss: 0.7138, Time: 3.68s\n",
      "Epoch: 36, Batch: 40/896, Loss: 0.5222, Time: 3.69s\n",
      "Epoch: 36, Batch: 50/896, Loss: 0.6493, Time: 3.69s\n",
      "Epoch: 36, Batch: 60/896, Loss: 1.0655, Time: 3.70s\n",
      "Epoch: 36, Batch: 70/896, Loss: 0.6826, Time: 3.70s\n",
      "Epoch: 36, Batch: 80/896, Loss: 1.0337, Time: 3.71s\n",
      "Epoch: 36, Batch: 90/896, Loss: 0.8807, Time: 3.70s\n",
      "Epoch: 36, Batch: 100/896, Loss: 1.1346, Time: 3.72s\n",
      "Epoch: 36, Batch: 110/896, Loss: 0.8682, Time: 3.71s\n",
      "Epoch: 36, Batch: 120/896, Loss: 0.3924, Time: 3.71s\n",
      "Epoch: 36, Batch: 130/896, Loss: 0.5828, Time: 3.71s\n",
      "Epoch: 36, Batch: 140/896, Loss: 0.9657, Time: 3.73s\n",
      "Epoch: 36, Batch: 150/896, Loss: 0.5286, Time: 3.73s\n",
      "Epoch: 36, Batch: 160/896, Loss: 0.5893, Time: 3.72s\n",
      "Epoch: 36, Batch: 170/896, Loss: 0.4499, Time: 3.72s\n",
      "Epoch: 36, Batch: 180/896, Loss: 1.1436, Time: 3.73s\n",
      "Epoch: 36, Batch: 190/896, Loss: 0.6436, Time: 3.72s\n",
      "Epoch: 36, Batch: 200/896, Loss: 0.6576, Time: 3.72s\n",
      "Epoch: 36, Batch: 210/896, Loss: 1.0769, Time: 3.72s\n",
      "Epoch: 36, Batch: 220/896, Loss: 1.5646, Time: 3.73s\n",
      "Epoch: 36, Batch: 230/896, Loss: 0.5178, Time: 3.74s\n",
      "Epoch: 36, Batch: 240/896, Loss: 0.4112, Time: 3.74s\n",
      "Epoch: 36, Batch: 250/896, Loss: 0.6003, Time: 3.73s\n",
      "Epoch: 36, Batch: 260/896, Loss: 0.4822, Time: 3.74s\n",
      "Epoch: 36, Batch: 270/896, Loss: 1.1687, Time: 3.73s\n",
      "Epoch: 36, Batch: 280/896, Loss: 1.0814, Time: 3.74s\n",
      "Epoch: 36, Batch: 290/896, Loss: 1.1069, Time: 3.74s\n",
      "Epoch: 36, Batch: 300/896, Loss: 1.3085, Time: 3.74s\n",
      "Epoch: 36, Batch: 310/896, Loss: 0.6948, Time: 3.73s\n",
      "Epoch: 36, Batch: 320/896, Loss: 0.5281, Time: 3.75s\n",
      "Epoch: 36, Batch: 330/896, Loss: 0.9967, Time: 3.73s\n",
      "Epoch: 36, Batch: 340/896, Loss: 0.7725, Time: 3.73s\n",
      "Epoch: 36, Batch: 350/896, Loss: 1.0852, Time: 3.74s\n",
      "Epoch: 36, Batch: 360/896, Loss: 0.8050, Time: 3.75s\n",
      "Epoch: 36, Batch: 370/896, Loss: 0.4175, Time: 3.74s\n",
      "Epoch: 36, Batch: 380/896, Loss: 0.7293, Time: 3.73s\n",
      "Epoch: 36, Batch: 390/896, Loss: 0.9350, Time: 3.74s\n",
      "Epoch: 36, Batch: 400/896, Loss: 0.4660, Time: 3.74s\n",
      "Epoch: 36, Batch: 410/896, Loss: 0.4435, Time: 3.73s\n",
      "Epoch: 36, Batch: 420/896, Loss: 0.3771, Time: 3.74s\n",
      "Epoch: 36, Batch: 430/896, Loss: 0.9900, Time: 3.74s\n",
      "Epoch: 36, Batch: 440/896, Loss: 0.4507, Time: 3.74s\n",
      "Epoch: 36, Batch: 450/896, Loss: 0.2904, Time: 3.73s\n",
      "Epoch: 36, Batch: 460/896, Loss: 0.5007, Time: 3.75s\n",
      "Epoch: 36, Batch: 470/896, Loss: 0.4274, Time: 3.74s\n",
      "Epoch: 36, Batch: 480/896, Loss: 0.6285, Time: 3.74s\n",
      "Epoch: 36, Batch: 490/896, Loss: 0.5457, Time: 3.74s\n",
      "Epoch: 36, Batch: 500/896, Loss: 0.7261, Time: 3.74s\n",
      "Epoch: 36, Batch: 510/896, Loss: 0.5558, Time: 3.74s\n",
      "Epoch: 36, Batch: 520/896, Loss: 1.1051, Time: 3.74s\n",
      "Epoch: 36, Batch: 530/896, Loss: 1.3590, Time: 3.74s\n",
      "Epoch: 36, Batch: 540/896, Loss: 0.4082, Time: 3.74s\n",
      "Epoch: 36, Batch: 550/896, Loss: 0.6990, Time: 3.75s\n",
      "Epoch: 36, Batch: 560/896, Loss: 0.4057, Time: 3.75s\n",
      "Epoch: 36, Batch: 570/896, Loss: 0.3948, Time: 3.74s\n",
      "Epoch: 36, Batch: 580/896, Loss: 0.5867, Time: 3.74s\n",
      "Epoch: 36, Batch: 590/896, Loss: 0.8150, Time: 3.75s\n",
      "Epoch: 36, Batch: 600/896, Loss: 0.6793, Time: 3.74s\n",
      "Epoch: 36, Batch: 610/896, Loss: 0.6367, Time: 3.74s\n",
      "Epoch: 36, Batch: 620/896, Loss: 0.8512, Time: 3.75s\n",
      "Epoch: 36, Batch: 630/896, Loss: 0.6473, Time: 3.74s\n",
      "Epoch: 36, Batch: 640/896, Loss: 1.2304, Time: 3.75s\n",
      "Epoch: 36, Batch: 650/896, Loss: 0.9626, Time: 3.75s\n",
      "Epoch: 36, Batch: 660/896, Loss: 0.7156, Time: 3.74s\n",
      "Epoch: 36, Batch: 670/896, Loss: 0.5313, Time: 3.74s\n",
      "Epoch: 36, Batch: 680/896, Loss: 0.7031, Time: 3.75s\n",
      "Epoch: 36, Batch: 690/896, Loss: 0.5403, Time: 3.74s\n",
      "Epoch: 36, Batch: 700/896, Loss: 0.4296, Time: 3.75s\n",
      "Epoch: 36, Batch: 710/896, Loss: 1.6972, Time: 3.75s\n",
      "Epoch: 36, Batch: 720/896, Loss: 0.4735, Time: 3.73s\n",
      "Epoch: 36, Batch: 730/896, Loss: 1.8452, Time: 3.74s\n",
      "Epoch: 36, Batch: 740/896, Loss: 0.8760, Time: 3.75s\n",
      "Epoch: 36, Batch: 750/896, Loss: 0.7594, Time: 3.74s\n",
      "Epoch: 36, Batch: 760/896, Loss: 1.0541, Time: 3.74s\n",
      "Epoch: 36, Batch: 770/896, Loss: 1.2763, Time: 3.74s\n",
      "Epoch: 36, Batch: 780/896, Loss: 0.4366, Time: 3.76s\n",
      "Epoch: 36, Batch: 790/896, Loss: 0.4528, Time: 3.74s\n",
      "Epoch: 36, Batch: 800/896, Loss: 0.4541, Time: 3.77s\n",
      "Epoch: 36, Batch: 810/896, Loss: 0.4860, Time: 3.74s\n",
      "Epoch: 36, Batch: 820/896, Loss: 0.6534, Time: 3.75s\n",
      "Epoch: 36, Batch: 830/896, Loss: 0.7426, Time: 3.76s\n",
      "Epoch: 36, Batch: 840/896, Loss: 0.6888, Time: 3.74s\n",
      "Epoch: 36, Batch: 850/896, Loss: 0.4493, Time: 3.74s\n",
      "Epoch: 36, Batch: 860/896, Loss: 1.1977, Time: 3.74s\n",
      "Epoch: 36, Batch: 870/896, Loss: 0.8254, Time: 3.75s\n",
      "Epoch: 36, Batch: 880/896, Loss: 0.3861, Time: 3.74s\n",
      "Epoch: 36, Batch: 890/896, Loss: 1.3943, Time: 3.74s\n",
      "Epoch 37/50: Train Loss: 0.7786, Val Loss: 0.8145, Val IoU: 0.3775, Val Dice: 0.4011\n",
      "Epoch: 37, Batch: 0/896, Loss: 0.6391, Time: 28.58s\n",
      "Epoch: 37, Batch: 10/896, Loss: 1.3105, Time: 3.70s\n",
      "Epoch: 37, Batch: 20/896, Loss: 0.6939, Time: 3.68s\n",
      "Epoch: 37, Batch: 30/896, Loss: 0.9222, Time: 3.68s\n",
      "Epoch: 37, Batch: 40/896, Loss: 1.5215, Time: 3.69s\n",
      "Epoch: 37, Batch: 50/896, Loss: 0.5560, Time: 3.69s\n",
      "Epoch: 37, Batch: 60/896, Loss: 0.5078, Time: 3.69s\n",
      "Epoch: 37, Batch: 70/896, Loss: 0.5862, Time: 3.70s\n",
      "Epoch: 37, Batch: 80/896, Loss: 0.5658, Time: 3.70s\n",
      "Epoch: 37, Batch: 90/896, Loss: 0.9606, Time: 3.71s\n",
      "Epoch: 37, Batch: 100/896, Loss: 1.2181, Time: 3.70s\n",
      "Epoch: 37, Batch: 110/896, Loss: 1.3785, Time: 3.72s\n",
      "Epoch: 37, Batch: 120/896, Loss: 0.8422, Time: 3.71s\n",
      "Epoch: 37, Batch: 130/896, Loss: 0.4176, Time: 3.71s\n",
      "Epoch: 37, Batch: 140/896, Loss: 0.4870, Time: 3.72s\n",
      "Epoch: 37, Batch: 150/896, Loss: 0.3312, Time: 3.72s\n",
      "Epoch: 37, Batch: 160/896, Loss: 0.3829, Time: 3.71s\n",
      "Epoch: 37, Batch: 170/896, Loss: 0.4847, Time: 3.73s\n",
      "Epoch: 37, Batch: 180/896, Loss: 0.9871, Time: 3.72s\n",
      "Epoch: 37, Batch: 190/896, Loss: 0.3364, Time: 3.72s\n",
      "Epoch: 37, Batch: 200/896, Loss: 0.5094, Time: 3.73s\n",
      "Epoch: 37, Batch: 210/896, Loss: 0.6932, Time: 3.73s\n",
      "Epoch: 37, Batch: 220/896, Loss: 0.5756, Time: 3.74s\n",
      "Epoch: 37, Batch: 230/896, Loss: 0.9561, Time: 3.74s\n",
      "Epoch: 37, Batch: 240/896, Loss: 1.1512, Time: 3.73s\n",
      "Epoch: 37, Batch: 250/896, Loss: 1.4278, Time: 3.74s\n",
      "Epoch: 37, Batch: 260/896, Loss: 0.4840, Time: 3.74s\n",
      "Epoch: 37, Batch: 270/896, Loss: 0.6469, Time: 3.75s\n",
      "Epoch: 37, Batch: 280/896, Loss: 0.9496, Time: 3.73s\n",
      "Epoch: 37, Batch: 290/896, Loss: 0.8181, Time: 3.74s\n",
      "Epoch: 37, Batch: 300/896, Loss: 0.8166, Time: 3.75s\n",
      "Epoch: 37, Batch: 310/896, Loss: 0.4246, Time: 3.75s\n",
      "Epoch: 37, Batch: 320/896, Loss: 0.6945, Time: 3.74s\n",
      "Epoch: 37, Batch: 330/896, Loss: 0.8203, Time: 3.74s\n",
      "Epoch: 37, Batch: 340/896, Loss: 0.3718, Time: 3.73s\n",
      "Epoch: 37, Batch: 350/896, Loss: 1.0934, Time: 3.75s\n",
      "Epoch: 37, Batch: 360/896, Loss: 1.1892, Time: 3.75s\n",
      "Epoch: 37, Batch: 370/896, Loss: 0.8019, Time: 3.74s\n",
      "Epoch: 37, Batch: 380/896, Loss: 0.5668, Time: 3.74s\n",
      "Epoch: 37, Batch: 390/896, Loss: 0.8774, Time: 3.74s\n",
      "Epoch: 37, Batch: 400/896, Loss: 1.1976, Time: 3.74s\n",
      "Epoch: 37, Batch: 410/896, Loss: 0.7363, Time: 3.75s\n",
      "Epoch: 37, Batch: 420/896, Loss: 0.4602, Time: 3.74s\n",
      "Epoch: 37, Batch: 430/896, Loss: 0.2814, Time: 3.74s\n",
      "Epoch: 37, Batch: 440/896, Loss: 0.7371, Time: 3.74s\n",
      "Epoch: 37, Batch: 450/896, Loss: 1.0723, Time: 3.75s\n",
      "Epoch: 37, Batch: 460/896, Loss: 0.3630, Time: 3.74s\n",
      "Epoch: 37, Batch: 470/896, Loss: 0.5019, Time: 3.74s\n",
      "Epoch: 37, Batch: 480/896, Loss: 0.4724, Time: 3.74s\n",
      "Epoch: 37, Batch: 490/896, Loss: 1.0853, Time: 3.74s\n",
      "Epoch: 37, Batch: 500/896, Loss: 0.6556, Time: 3.74s\n",
      "Epoch: 37, Batch: 510/896, Loss: 0.4910, Time: 3.74s\n",
      "Epoch: 37, Batch: 520/896, Loss: 0.5135, Time: 3.74s\n",
      "Epoch: 37, Batch: 530/896, Loss: 0.6258, Time: 3.74s\n",
      "Epoch: 37, Batch: 540/896, Loss: 0.5973, Time: 3.74s\n",
      "Epoch: 37, Batch: 550/896, Loss: 0.8751, Time: 3.74s\n",
      "Epoch: 37, Batch: 560/896, Loss: 0.8934, Time: 3.74s\n",
      "Epoch: 37, Batch: 570/896, Loss: 1.2521, Time: 3.74s\n",
      "Epoch: 37, Batch: 580/896, Loss: 1.4989, Time: 3.75s\n",
      "Epoch: 37, Batch: 590/896, Loss: 0.9906, Time: 3.74s\n",
      "Epoch: 37, Batch: 600/896, Loss: 1.2375, Time: 3.75s\n",
      "Epoch: 37, Batch: 610/896, Loss: 0.5572, Time: 3.74s\n",
      "Epoch: 37, Batch: 620/896, Loss: 0.7146, Time: 3.75s\n",
      "Epoch: 37, Batch: 630/896, Loss: 1.1061, Time: 3.75s\n",
      "Epoch: 37, Batch: 640/896, Loss: 1.1826, Time: 3.74s\n",
      "Epoch: 37, Batch: 650/896, Loss: 0.5552, Time: 3.75s\n",
      "Epoch: 37, Batch: 660/896, Loss: 0.7603, Time: 3.75s\n",
      "Epoch: 37, Batch: 670/896, Loss: 0.7869, Time: 3.74s\n",
      "Epoch: 37, Batch: 680/896, Loss: 0.7609, Time: 3.74s\n",
      "Epoch: 37, Batch: 690/896, Loss: 0.7091, Time: 3.76s\n",
      "Epoch: 37, Batch: 700/896, Loss: 1.5161, Time: 3.74s\n",
      "Epoch: 37, Batch: 710/896, Loss: 0.6261, Time: 3.74s\n",
      "Epoch: 37, Batch: 720/896, Loss: 0.5608, Time: 3.74s\n",
      "Epoch: 37, Batch: 730/896, Loss: 0.8999, Time: 3.73s\n",
      "Epoch: 37, Batch: 740/896, Loss: 0.4413, Time: 3.75s\n",
      "Epoch: 37, Batch: 750/896, Loss: 0.9498, Time: 3.74s\n",
      "Epoch: 37, Batch: 760/896, Loss: 1.0723, Time: 3.76s\n",
      "Epoch: 37, Batch: 770/896, Loss: 0.6501, Time: 3.74s\n",
      "Epoch: 37, Batch: 780/896, Loss: 0.5697, Time: 3.76s\n",
      "Epoch: 37, Batch: 790/896, Loss: 0.3923, Time: 3.74s\n",
      "Epoch: 37, Batch: 800/896, Loss: 1.2616, Time: 3.76s\n",
      "Epoch: 37, Batch: 810/896, Loss: 0.9426, Time: 3.75s\n",
      "Epoch: 37, Batch: 820/896, Loss: 0.2978, Time: 3.74s\n",
      "Epoch: 37, Batch: 830/896, Loss: 0.8046, Time: 3.74s\n",
      "Epoch: 37, Batch: 840/896, Loss: 0.4946, Time: 3.75s\n",
      "Epoch: 37, Batch: 850/896, Loss: 0.4355, Time: 3.74s\n",
      "Epoch: 37, Batch: 860/896, Loss: 0.4642, Time: 3.75s\n",
      "Epoch: 37, Batch: 870/896, Loss: 0.4689, Time: 3.73s\n",
      "Epoch: 37, Batch: 880/896, Loss: 0.5656, Time: 3.74s\n",
      "Epoch: 37, Batch: 890/896, Loss: 0.3006, Time: 3.74s\n",
      "Epoch 38/50: Train Loss: 0.7756, Val Loss: 0.8350, Val IoU: 0.3733, Val Dice: 0.3973\n",
      "Epoch: 38, Batch: 0/896, Loss: 0.6008, Time: 28.76s\n",
      "Epoch: 38, Batch: 10/896, Loss: 0.9410, Time: 3.69s\n",
      "Epoch: 38, Batch: 20/896, Loss: 0.8389, Time: 3.67s\n",
      "Epoch: 38, Batch: 30/896, Loss: 1.2244, Time: 3.69s\n",
      "Epoch: 38, Batch: 40/896, Loss: 0.4541, Time: 3.68s\n",
      "Epoch: 38, Batch: 50/896, Loss: 0.9666, Time: 3.71s\n",
      "Epoch: 38, Batch: 60/896, Loss: 0.6837, Time: 3.70s\n",
      "Epoch: 38, Batch: 70/896, Loss: 0.8740, Time: 3.70s\n",
      "Epoch: 38, Batch: 80/896, Loss: 0.3364, Time: 3.71s\n",
      "Epoch: 38, Batch: 90/896, Loss: 0.8010, Time: 3.70s\n",
      "Epoch: 38, Batch: 100/896, Loss: 0.5202, Time: 3.70s\n",
      "Epoch: 38, Batch: 110/896, Loss: 0.9260, Time: 3.72s\n",
      "Epoch: 38, Batch: 120/896, Loss: 0.6747, Time: 3.72s\n",
      "Epoch: 38, Batch: 130/896, Loss: 0.5333, Time: 3.70s\n",
      "Epoch: 38, Batch: 140/896, Loss: 0.6232, Time: 3.72s\n",
      "Epoch: 38, Batch: 150/896, Loss: 0.6535, Time: 3.71s\n",
      "Epoch: 38, Batch: 160/896, Loss: 0.4117, Time: 3.72s\n",
      "Epoch: 38, Batch: 170/896, Loss: 0.8266, Time: 3.73s\n",
      "Epoch: 38, Batch: 180/896, Loss: 0.6630, Time: 3.72s\n",
      "Epoch: 38, Batch: 190/896, Loss: 0.8880, Time: 3.73s\n",
      "Epoch: 38, Batch: 200/896, Loss: 0.7831, Time: 3.73s\n",
      "Epoch: 38, Batch: 210/896, Loss: 0.9473, Time: 3.74s\n",
      "Epoch: 38, Batch: 220/896, Loss: 1.8990, Time: 3.72s\n",
      "Epoch: 38, Batch: 230/896, Loss: 0.8219, Time: 3.73s\n",
      "Epoch: 38, Batch: 240/896, Loss: 0.2959, Time: 3.72s\n",
      "Epoch: 38, Batch: 250/896, Loss: 0.5154, Time: 3.72s\n",
      "Epoch: 38, Batch: 260/896, Loss: 0.3775, Time: 3.72s\n",
      "Epoch: 38, Batch: 270/896, Loss: 0.4976, Time: 3.74s\n",
      "Epoch: 38, Batch: 280/896, Loss: 0.5751, Time: 3.74s\n",
      "Epoch: 38, Batch: 290/896, Loss: 0.7349, Time: 3.73s\n",
      "Epoch: 38, Batch: 300/896, Loss: 0.3890, Time: 3.74s\n",
      "Epoch: 38, Batch: 310/896, Loss: 0.7857, Time: 3.75s\n",
      "Epoch: 38, Batch: 320/896, Loss: 0.9454, Time: 3.72s\n",
      "Epoch: 38, Batch: 330/896, Loss: 1.5770, Time: 3.73s\n",
      "Epoch: 38, Batch: 340/896, Loss: 0.4600, Time: 3.75s\n",
      "Epoch: 38, Batch: 350/896, Loss: 0.8346, Time: 3.73s\n",
      "Epoch: 38, Batch: 360/896, Loss: 0.4625, Time: 3.74s\n",
      "Epoch: 38, Batch: 370/896, Loss: 0.8128, Time: 3.75s\n",
      "Epoch: 38, Batch: 380/896, Loss: 0.6058, Time: 3.73s\n",
      "Epoch: 38, Batch: 390/896, Loss: 1.0469, Time: 3.74s\n",
      "Epoch: 38, Batch: 400/896, Loss: 0.8758, Time: 3.81s\n",
      "Epoch: 38, Batch: 410/896, Loss: 1.1371, Time: 3.74s\n",
      "Epoch: 38, Batch: 420/896, Loss: 1.2269, Time: 3.75s\n",
      "Epoch: 38, Batch: 430/896, Loss: 0.7242, Time: 3.75s\n",
      "Epoch: 38, Batch: 440/896, Loss: 0.7760, Time: 3.74s\n",
      "Epoch: 38, Batch: 450/896, Loss: 0.7169, Time: 3.75s\n",
      "Epoch: 38, Batch: 460/896, Loss: 1.4803, Time: 3.75s\n",
      "Epoch: 38, Batch: 470/896, Loss: 1.2795, Time: 3.72s\n",
      "Epoch: 38, Batch: 480/896, Loss: 0.5795, Time: 3.83s\n",
      "Epoch: 38, Batch: 490/896, Loss: 0.2884, Time: 3.86s\n",
      "Epoch: 38, Batch: 500/896, Loss: 1.9494, Time: 3.75s\n",
      "Epoch: 38, Batch: 510/896, Loss: 0.3527, Time: 3.79s\n",
      "Epoch: 38, Batch: 520/896, Loss: 0.4457, Time: 3.82s\n",
      "Epoch: 38, Batch: 530/896, Loss: 1.7530, Time: 3.80s\n",
      "Epoch: 38, Batch: 540/896, Loss: 0.5654, Time: 3.82s\n",
      "Epoch: 38, Batch: 550/896, Loss: 0.5914, Time: 3.82s\n",
      "Epoch: 38, Batch: 560/896, Loss: 0.6884, Time: 3.81s\n",
      "Epoch: 38, Batch: 570/896, Loss: 0.8499, Time: 3.81s\n",
      "Epoch: 38, Batch: 580/896, Loss: 0.9334, Time: 3.82s\n",
      "Epoch: 38, Batch: 590/896, Loss: 1.2414, Time: 3.81s\n",
      "Epoch: 38, Batch: 600/896, Loss: 1.1647, Time: 3.83s\n",
      "Epoch: 38, Batch: 610/896, Loss: 0.7523, Time: 3.81s\n",
      "Epoch: 38, Batch: 620/896, Loss: 0.7482, Time: 3.82s\n",
      "Epoch: 38, Batch: 630/896, Loss: 0.4500, Time: 3.81s\n",
      "Epoch: 38, Batch: 640/896, Loss: 0.4317, Time: 3.82s\n",
      "Epoch: 38, Batch: 650/896, Loss: 1.3200, Time: 3.82s\n",
      "Epoch: 38, Batch: 660/896, Loss: 0.9008, Time: 3.82s\n",
      "Epoch: 38, Batch: 670/896, Loss: 1.5406, Time: 3.83s\n",
      "Epoch: 38, Batch: 680/896, Loss: 0.8793, Time: 3.83s\n",
      "Epoch: 38, Batch: 690/896, Loss: 0.4964, Time: 3.82s\n",
      "Epoch: 38, Batch: 700/896, Loss: 0.8567, Time: 3.83s\n",
      "Epoch: 38, Batch: 710/896, Loss: 0.7225, Time: 3.82s\n",
      "Epoch: 38, Batch: 720/896, Loss: 0.8048, Time: 3.84s\n",
      "Epoch: 38, Batch: 730/896, Loss: 0.5868, Time: 3.75s\n",
      "Epoch: 38, Batch: 740/896, Loss: 0.6841, Time: 3.75s\n",
      "Epoch: 38, Batch: 750/896, Loss: 0.3168, Time: 3.76s\n",
      "Epoch: 38, Batch: 760/896, Loss: 0.5532, Time: 3.74s\n",
      "Epoch: 38, Batch: 770/896, Loss: 0.9283, Time: 3.74s\n",
      "Epoch: 38, Batch: 780/896, Loss: 1.0769, Time: 3.74s\n",
      "Epoch: 38, Batch: 790/896, Loss: 0.3628, Time: 3.74s\n",
      "Epoch: 38, Batch: 800/896, Loss: 0.4304, Time: 3.75s\n",
      "Epoch: 38, Batch: 810/896, Loss: 0.8968, Time: 3.74s\n",
      "Epoch: 38, Batch: 820/896, Loss: 0.8148, Time: 3.74s\n",
      "Epoch: 38, Batch: 830/896, Loss: 0.4141, Time: 3.76s\n",
      "Epoch: 38, Batch: 840/896, Loss: 0.7038, Time: 3.74s\n",
      "Epoch: 38, Batch: 850/896, Loss: 1.6936, Time: 3.75s\n",
      "Epoch: 38, Batch: 860/896, Loss: 0.9065, Time: 3.75s\n",
      "Epoch: 38, Batch: 870/896, Loss: 1.7985, Time: 3.74s\n",
      "Epoch: 38, Batch: 880/896, Loss: 0.5600, Time: 3.75s\n",
      "Epoch: 38, Batch: 890/896, Loss: 0.4540, Time: 3.74s\n",
      "Epoch 39/50: Train Loss: 0.7766, Val Loss: 0.8322, Val IoU: 0.3732, Val Dice: 0.3970\n",
      "Epoch: 39, Batch: 0/896, Loss: 1.1610, Time: 28.77s\n",
      "Epoch: 39, Batch: 10/896, Loss: 0.9636, Time: 3.71s\n",
      "Epoch: 39, Batch: 20/896, Loss: 0.7270, Time: 3.68s\n",
      "Epoch: 39, Batch: 30/896, Loss: 0.4063, Time: 3.68s\n",
      "Epoch: 39, Batch: 40/896, Loss: 0.7474, Time: 3.69s\n",
      "Epoch: 39, Batch: 50/896, Loss: 0.7217, Time: 3.69s\n",
      "Epoch: 39, Batch: 60/896, Loss: 1.7358, Time: 3.70s\n",
      "Epoch: 39, Batch: 70/896, Loss: 0.4204, Time: 3.71s\n",
      "Epoch: 39, Batch: 80/896, Loss: 0.9830, Time: 3.70s\n",
      "Epoch: 39, Batch: 90/896, Loss: 0.8180, Time: 3.70s\n",
      "Epoch: 39, Batch: 100/896, Loss: 0.5476, Time: 3.71s\n",
      "Epoch: 39, Batch: 110/896, Loss: 0.8777, Time: 3.70s\n",
      "Epoch: 39, Batch: 120/896, Loss: 0.4250, Time: 3.71s\n",
      "Epoch: 39, Batch: 130/896, Loss: 0.4672, Time: 3.71s\n",
      "Epoch: 39, Batch: 140/896, Loss: 1.4605, Time: 3.72s\n",
      "Epoch: 39, Batch: 150/896, Loss: 0.6367, Time: 3.71s\n",
      "Epoch: 39, Batch: 160/896, Loss: 0.7018, Time: 3.71s\n",
      "Epoch: 39, Batch: 170/896, Loss: 0.7021, Time: 3.71s\n",
      "Epoch: 39, Batch: 180/896, Loss: 1.9243, Time: 3.72s\n",
      "Epoch: 39, Batch: 190/896, Loss: 0.7068, Time: 3.73s\n",
      "Epoch: 39, Batch: 200/896, Loss: 0.9181, Time: 3.73s\n",
      "Epoch: 39, Batch: 210/896, Loss: 0.5030, Time: 3.73s\n",
      "Epoch: 39, Batch: 220/896, Loss: 0.5257, Time: 3.72s\n",
      "Epoch: 39, Batch: 230/896, Loss: 0.3930, Time: 3.74s\n",
      "Epoch: 39, Batch: 240/896, Loss: 0.6305, Time: 3.73s\n",
      "Epoch: 39, Batch: 250/896, Loss: 0.4733, Time: 3.73s\n",
      "Epoch: 39, Batch: 260/896, Loss: 0.7836, Time: 3.73s\n",
      "Epoch: 39, Batch: 270/896, Loss: 0.5263, Time: 3.73s\n",
      "Epoch: 39, Batch: 280/896, Loss: 0.6551, Time: 3.73s\n",
      "Epoch: 39, Batch: 290/896, Loss: 0.5393, Time: 3.74s\n",
      "Epoch: 39, Batch: 300/896, Loss: 0.9469, Time: 3.74s\n",
      "Epoch: 39, Batch: 310/896, Loss: 0.8595, Time: 3.73s\n",
      "Epoch: 39, Batch: 320/896, Loss: 0.4278, Time: 3.74s\n",
      "Epoch: 39, Batch: 330/896, Loss: 0.6484, Time: 3.73s\n",
      "Epoch: 39, Batch: 340/896, Loss: 1.3454, Time: 3.73s\n",
      "Epoch: 39, Batch: 350/896, Loss: 0.6980, Time: 3.74s\n",
      "Epoch: 39, Batch: 360/896, Loss: 0.5721, Time: 3.74s\n",
      "Epoch: 39, Batch: 370/896, Loss: 0.4364, Time: 3.74s\n",
      "Epoch: 39, Batch: 380/896, Loss: 0.7274, Time: 3.73s\n",
      "Epoch: 39, Batch: 390/896, Loss: 1.2003, Time: 3.74s\n",
      "Epoch: 39, Batch: 400/896, Loss: 1.2313, Time: 3.75s\n",
      "Epoch: 39, Batch: 410/896, Loss: 0.6236, Time: 3.73s\n",
      "Epoch: 39, Batch: 420/896, Loss: 0.9134, Time: 3.74s\n",
      "Epoch: 39, Batch: 430/896, Loss: 0.6745, Time: 3.73s\n",
      "Epoch: 39, Batch: 440/896, Loss: 0.9468, Time: 3.74s\n",
      "Epoch: 39, Batch: 450/896, Loss: 0.5156, Time: 3.74s\n",
      "Epoch: 39, Batch: 460/896, Loss: 0.5142, Time: 3.74s\n",
      "Epoch: 39, Batch: 470/896, Loss: 0.4646, Time: 3.74s\n",
      "Epoch: 39, Batch: 480/896, Loss: 0.7631, Time: 3.75s\n",
      "Epoch: 39, Batch: 490/896, Loss: 0.5577, Time: 3.73s\n",
      "Epoch: 39, Batch: 500/896, Loss: 0.5389, Time: 3.74s\n",
      "Epoch: 39, Batch: 510/896, Loss: 0.4729, Time: 3.73s\n",
      "Epoch: 39, Batch: 520/896, Loss: 0.5096, Time: 3.74s\n",
      "Epoch: 39, Batch: 530/896, Loss: 0.4212, Time: 3.74s\n",
      "Epoch: 39, Batch: 540/896, Loss: 1.2831, Time: 3.74s\n",
      "Epoch: 39, Batch: 550/896, Loss: 0.5642, Time: 3.74s\n",
      "Epoch: 39, Batch: 560/896, Loss: 0.6253, Time: 3.74s\n",
      "Epoch: 39, Batch: 570/896, Loss: 0.9899, Time: 3.74s\n",
      "Epoch: 39, Batch: 580/896, Loss: 0.7228, Time: 3.74s\n",
      "Epoch: 39, Batch: 590/896, Loss: 0.5084, Time: 3.74s\n",
      "Epoch: 39, Batch: 600/896, Loss: 1.5209, Time: 3.75s\n",
      "Epoch: 39, Batch: 610/896, Loss: 0.7620, Time: 3.73s\n",
      "Epoch: 39, Batch: 620/896, Loss: 0.4555, Time: 3.74s\n",
      "Epoch: 39, Batch: 630/896, Loss: 0.8248, Time: 3.75s\n",
      "Epoch: 39, Batch: 640/896, Loss: 1.7219, Time: 3.74s\n",
      "Epoch: 39, Batch: 650/896, Loss: 0.7432, Time: 3.74s\n",
      "Epoch: 39, Batch: 660/896, Loss: 1.0067, Time: 3.76s\n",
      "Epoch: 39, Batch: 670/896, Loss: 0.6417, Time: 3.76s\n",
      "Epoch: 39, Batch: 680/896, Loss: 0.8724, Time: 3.81s\n",
      "Epoch: 39, Batch: 690/896, Loss: 0.9293, Time: 3.81s\n",
      "Epoch: 39, Batch: 700/896, Loss: 0.4493, Time: 3.81s\n",
      "Epoch: 39, Batch: 710/896, Loss: 0.5259, Time: 3.74s\n",
      "Epoch: 39, Batch: 720/896, Loss: 0.3700, Time: 3.74s\n",
      "Epoch: 39, Batch: 730/896, Loss: 0.7405, Time: 3.73s\n",
      "Epoch: 39, Batch: 740/896, Loss: 0.8606, Time: 3.75s\n",
      "Epoch: 39, Batch: 750/896, Loss: 1.0916, Time: 3.76s\n",
      "Epoch: 39, Batch: 760/896, Loss: 0.6069, Time: 3.83s\n",
      "Epoch: 39, Batch: 770/896, Loss: 1.1453, Time: 3.83s\n",
      "Epoch: 39, Batch: 780/896, Loss: 0.4247, Time: 3.85s\n",
      "Epoch: 39, Batch: 790/896, Loss: 1.7940, Time: 3.84s\n",
      "Epoch: 39, Batch: 800/896, Loss: 0.8061, Time: 3.81s\n",
      "Epoch: 39, Batch: 810/896, Loss: 0.5008, Time: 3.83s\n",
      "Epoch: 39, Batch: 820/896, Loss: 0.4634, Time: 3.82s\n",
      "Epoch: 39, Batch: 830/896, Loss: 0.6015, Time: 3.81s\n",
      "Epoch: 39, Batch: 840/896, Loss: 0.8961, Time: 3.82s\n",
      "Epoch: 39, Batch: 850/896, Loss: 0.5592, Time: 3.82s\n",
      "Epoch: 39, Batch: 860/896, Loss: 0.9544, Time: 3.83s\n",
      "Epoch: 39, Batch: 870/896, Loss: 0.6262, Time: 3.85s\n",
      "Epoch: 39, Batch: 880/896, Loss: 1.5781, Time: 3.79s\n",
      "Epoch: 39, Batch: 890/896, Loss: 1.1438, Time: 3.79s\n",
      "Epoch 40/50: Train Loss: 0.7749, Val Loss: 0.8283, Val IoU: 0.3755, Val Dice: 0.3991\n",
      "Epoch: 40, Batch: 0/896, Loss: 0.6622, Time: 29.23s\n",
      "Epoch: 40, Batch: 10/896, Loss: 0.7611, Time: 3.76s\n",
      "Epoch: 40, Batch: 20/896, Loss: 1.5295, Time: 3.76s\n",
      "Epoch: 40, Batch: 30/896, Loss: 0.7766, Time: 3.77s\n",
      "Epoch: 40, Batch: 40/896, Loss: 0.8780, Time: 3.78s\n",
      "Epoch: 40, Batch: 50/896, Loss: 0.8599, Time: 3.77s\n",
      "Epoch: 40, Batch: 60/896, Loss: 0.3573, Time: 3.76s\n",
      "Epoch: 40, Batch: 70/896, Loss: 0.3229, Time: 3.77s\n",
      "Epoch: 40, Batch: 80/896, Loss: 1.0650, Time: 3.77s\n",
      "Epoch: 40, Batch: 90/896, Loss: 0.4642, Time: 3.78s\n",
      "Epoch: 40, Batch: 100/896, Loss: 0.9051, Time: 3.75s\n",
      "Epoch: 40, Batch: 110/896, Loss: 0.6195, Time: 3.72s\n",
      "Epoch: 40, Batch: 120/896, Loss: 0.8667, Time: 3.74s\n",
      "Epoch: 40, Batch: 130/896, Loss: 0.9716, Time: 3.74s\n",
      "Epoch: 40, Batch: 140/896, Loss: 1.1957, Time: 3.75s\n",
      "Epoch: 40, Batch: 150/896, Loss: 0.6399, Time: 3.74s\n",
      "Epoch: 40, Batch: 160/896, Loss: 0.4192, Time: 3.73s\n",
      "Epoch: 40, Batch: 170/896, Loss: 0.7199, Time: 3.74s\n",
      "Epoch: 40, Batch: 180/896, Loss: 0.6257, Time: 3.74s\n",
      "Epoch: 40, Batch: 190/896, Loss: 0.8608, Time: 3.74s\n",
      "Epoch: 40, Batch: 200/896, Loss: 0.9267, Time: 3.74s\n",
      "Epoch: 40, Batch: 210/896, Loss: 0.3443, Time: 3.75s\n",
      "Epoch: 40, Batch: 220/896, Loss: 0.3614, Time: 3.75s\n",
      "Epoch: 40, Batch: 230/896, Loss: 0.2871, Time: 3.77s\n",
      "Epoch: 40, Batch: 240/896, Loss: 0.4803, Time: 3.77s\n",
      "Epoch: 40, Batch: 250/896, Loss: 1.0775, Time: 3.75s\n",
      "Epoch: 40, Batch: 260/896, Loss: 1.0314, Time: 3.75s\n",
      "Epoch: 40, Batch: 270/896, Loss: 0.8471, Time: 3.75s\n",
      "Epoch: 40, Batch: 280/896, Loss: 1.8076, Time: 3.76s\n",
      "Epoch: 40, Batch: 290/896, Loss: 0.5844, Time: 3.75s\n",
      "Epoch: 40, Batch: 300/896, Loss: 0.8423, Time: 3.77s\n",
      "Epoch: 40, Batch: 310/896, Loss: 1.1379, Time: 3.76s\n",
      "Epoch: 40, Batch: 320/896, Loss: 0.8124, Time: 3.75s\n",
      "Epoch: 40, Batch: 330/896, Loss: 0.7132, Time: 3.76s\n",
      "Epoch: 40, Batch: 340/896, Loss: 0.5476, Time: 3.75s\n",
      "Epoch: 40, Batch: 350/896, Loss: 0.7613, Time: 3.76s\n",
      "Epoch: 40, Batch: 360/896, Loss: 0.6403, Time: 3.77s\n",
      "Epoch: 40, Batch: 370/896, Loss: 0.7324, Time: 3.76s\n",
      "Epoch: 40, Batch: 380/896, Loss: 1.1180, Time: 3.75s\n",
      "Epoch: 40, Batch: 390/896, Loss: 0.5441, Time: 3.75s\n",
      "Epoch: 40, Batch: 400/896, Loss: 0.4138, Time: 3.76s\n",
      "Epoch: 40, Batch: 410/896, Loss: 0.9807, Time: 3.77s\n",
      "Epoch: 40, Batch: 420/896, Loss: 0.3838, Time: 3.77s\n",
      "Epoch: 40, Batch: 430/896, Loss: 0.5441, Time: 3.76s\n",
      "Epoch: 40, Batch: 440/896, Loss: 0.6965, Time: 3.75s\n",
      "Epoch: 40, Batch: 450/896, Loss: 0.6791, Time: 3.78s\n",
      "Epoch: 40, Batch: 460/896, Loss: 0.5552, Time: 3.78s\n",
      "Epoch: 40, Batch: 470/896, Loss: 0.6459, Time: 3.76s\n",
      "Epoch: 40, Batch: 480/896, Loss: 1.4484, Time: 3.76s\n",
      "Epoch: 40, Batch: 490/896, Loss: 0.2762, Time: 3.76s\n",
      "Epoch: 40, Batch: 500/896, Loss: 1.5591, Time: 3.77s\n",
      "Epoch: 40, Batch: 510/896, Loss: 0.6466, Time: 3.77s\n",
      "Epoch: 40, Batch: 520/896, Loss: 1.0740, Time: 3.77s\n",
      "Epoch: 40, Batch: 530/896, Loss: 0.4234, Time: 3.76s\n",
      "Epoch: 40, Batch: 540/896, Loss: 0.5629, Time: 3.77s\n",
      "Epoch: 40, Batch: 550/896, Loss: 1.7262, Time: 3.77s\n",
      "Epoch: 40, Batch: 560/896, Loss: 1.9209, Time: 3.78s\n",
      "Epoch: 40, Batch: 570/896, Loss: 0.6659, Time: 3.76s\n",
      "Epoch: 40, Batch: 580/896, Loss: 0.4079, Time: 3.78s\n",
      "Epoch: 40, Batch: 590/896, Loss: 0.4680, Time: 3.77s\n",
      "Epoch: 40, Batch: 600/896, Loss: 0.3223, Time: 3.77s\n",
      "Epoch: 40, Batch: 610/896, Loss: 0.6877, Time: 3.77s\n",
      "Epoch: 40, Batch: 620/896, Loss: 0.6614, Time: 3.76s\n",
      "Epoch: 40, Batch: 630/896, Loss: 1.0955, Time: 3.78s\n",
      "Epoch: 40, Batch: 640/896, Loss: 0.8877, Time: 3.77s\n",
      "Epoch: 40, Batch: 650/896, Loss: 0.7389, Time: 3.77s\n",
      "Epoch: 40, Batch: 660/896, Loss: 0.7909, Time: 3.77s\n",
      "Epoch: 40, Batch: 670/896, Loss: 0.8475, Time: 3.77s\n",
      "Epoch: 40, Batch: 680/896, Loss: 1.3496, Time: 3.77s\n",
      "Epoch: 40, Batch: 690/896, Loss: 0.4123, Time: 3.77s\n",
      "Epoch: 40, Batch: 700/896, Loss: 1.3441, Time: 3.77s\n",
      "Epoch: 40, Batch: 710/896, Loss: 0.7166, Time: 3.77s\n",
      "Epoch: 40, Batch: 720/896, Loss: 0.4343, Time: 3.77s\n",
      "Epoch: 40, Batch: 730/896, Loss: 1.3214, Time: 3.78s\n",
      "Epoch: 40, Batch: 740/896, Loss: 0.3576, Time: 3.77s\n",
      "Epoch: 40, Batch: 750/896, Loss: 0.4935, Time: 3.77s\n",
      "Epoch: 40, Batch: 760/896, Loss: 0.8167, Time: 3.78s\n",
      "Epoch: 40, Batch: 770/896, Loss: 0.9995, Time: 3.77s\n",
      "Epoch: 40, Batch: 780/896, Loss: 0.5182, Time: 3.77s\n",
      "Epoch: 40, Batch: 790/896, Loss: 0.6625, Time: 3.79s\n",
      "Epoch: 40, Batch: 800/896, Loss: 0.7022, Time: 3.77s\n",
      "Epoch: 40, Batch: 810/896, Loss: 1.0670, Time: 3.79s\n",
      "Epoch: 40, Batch: 820/896, Loss: 1.1213, Time: 3.77s\n",
      "Epoch: 40, Batch: 830/896, Loss: 0.8728, Time: 3.78s\n",
      "Epoch: 40, Batch: 840/896, Loss: 0.6376, Time: 3.77s\n",
      "Epoch: 40, Batch: 850/896, Loss: 0.6092, Time: 3.77s\n",
      "Epoch: 40, Batch: 860/896, Loss: 0.7608, Time: 3.77s\n",
      "Epoch: 40, Batch: 870/896, Loss: 0.7322, Time: 3.76s\n",
      "Epoch: 40, Batch: 880/896, Loss: 1.5141, Time: 3.77s\n",
      "Epoch: 40, Batch: 890/896, Loss: 0.9954, Time: 3.77s\n",
      "Epoch 41/50: Train Loss: 0.7766, Val Loss: 0.8200, Val IoU: 0.3726, Val Dice: 0.3964\n",
      "Epoch: 41, Batch: 0/896, Loss: 0.6237, Time: 29.14s\n",
      "Epoch: 41, Batch: 10/896, Loss: 0.8130, Time: 3.77s\n",
      "Epoch: 41, Batch: 20/896, Loss: 0.4492, Time: 3.75s\n",
      "Epoch: 41, Batch: 30/896, Loss: 0.8659, Time: 3.75s\n",
      "Epoch: 41, Batch: 40/896, Loss: 1.5061, Time: 3.77s\n",
      "Epoch: 41, Batch: 50/896, Loss: 0.3588, Time: 3.78s\n",
      "Epoch: 41, Batch: 60/896, Loss: 1.1365, Time: 3.77s\n",
      "Epoch: 41, Batch: 70/896, Loss: 1.0917, Time: 3.79s\n",
      "Epoch: 41, Batch: 80/896, Loss: 0.7520, Time: 3.78s\n",
      "Epoch: 41, Batch: 90/896, Loss: 0.8305, Time: 3.78s\n",
      "Epoch: 41, Batch: 100/896, Loss: 1.1079, Time: 3.78s\n",
      "Epoch: 41, Batch: 110/896, Loss: 0.9243, Time: 3.78s\n",
      "Epoch: 41, Batch: 120/896, Loss: 1.0251, Time: 3.81s\n",
      "Epoch: 41, Batch: 130/896, Loss: 0.6561, Time: 3.79s\n",
      "Epoch: 41, Batch: 140/896, Loss: 1.2770, Time: 3.80s\n",
      "Epoch: 41, Batch: 150/896, Loss: 0.7672, Time: 3.80s\n",
      "Epoch: 41, Batch: 160/896, Loss: 1.0383, Time: 3.80s\n",
      "Epoch: 41, Batch: 170/896, Loss: 0.8037, Time: 3.81s\n",
      "Epoch: 41, Batch: 180/896, Loss: 0.8019, Time: 3.79s\n",
      "Epoch: 41, Batch: 190/896, Loss: 1.5010, Time: 3.79s\n",
      "Epoch: 41, Batch: 200/896, Loss: 0.5569, Time: 3.80s\n",
      "Epoch: 41, Batch: 210/896, Loss: 0.6055, Time: 3.80s\n",
      "Epoch: 41, Batch: 220/896, Loss: 0.7881, Time: 3.80s\n",
      "Epoch: 41, Batch: 230/896, Loss: 0.8378, Time: 3.81s\n",
      "Epoch: 41, Batch: 240/896, Loss: 0.5670, Time: 3.81s\n",
      "Epoch: 41, Batch: 250/896, Loss: 0.9120, Time: 3.80s\n",
      "Epoch: 41, Batch: 260/896, Loss: 0.9709, Time: 3.81s\n",
      "Epoch: 41, Batch: 270/896, Loss: 0.8647, Time: 3.82s\n",
      "Epoch: 41, Batch: 280/896, Loss: 0.4049, Time: 3.82s\n",
      "Epoch: 41, Batch: 290/896, Loss: 0.8955, Time: 3.80s\n",
      "Epoch: 41, Batch: 300/896, Loss: 0.9747, Time: 3.80s\n",
      "Epoch: 41, Batch: 310/896, Loss: 0.6930, Time: 3.82s\n",
      "Epoch: 41, Batch: 320/896, Loss: 1.1525, Time: 3.80s\n",
      "Epoch: 41, Batch: 330/896, Loss: 0.9306, Time: 3.81s\n",
      "Epoch: 41, Batch: 340/896, Loss: 0.8615, Time: 3.83s\n",
      "Epoch: 41, Batch: 350/896, Loss: 0.5179, Time: 3.82s\n",
      "Epoch: 41, Batch: 360/896, Loss: 1.2267, Time: 3.80s\n",
      "Epoch: 41, Batch: 370/896, Loss: 1.3471, Time: 3.83s\n",
      "Epoch: 41, Batch: 380/896, Loss: 1.4558, Time: 3.82s\n",
      "Epoch: 41, Batch: 390/896, Loss: 0.7539, Time: 3.82s\n",
      "Epoch: 41, Batch: 400/896, Loss: 0.9314, Time: 3.82s\n",
      "Epoch: 41, Batch: 410/896, Loss: 0.9198, Time: 3.81s\n",
      "Epoch: 41, Batch: 420/896, Loss: 0.9988, Time: 3.82s\n",
      "Epoch: 41, Batch: 430/896, Loss: 0.7137, Time: 3.82s\n",
      "Epoch: 41, Batch: 440/896, Loss: 1.0039, Time: 3.82s\n",
      "Epoch: 41, Batch: 450/896, Loss: 0.4737, Time: 3.82s\n",
      "Epoch: 41, Batch: 460/896, Loss: 0.4214, Time: 3.82s\n",
      "Epoch: 41, Batch: 470/896, Loss: 0.8555, Time: 3.81s\n",
      "Epoch: 41, Batch: 480/896, Loss: 0.7309, Time: 3.82s\n",
      "Epoch: 41, Batch: 490/896, Loss: 1.2352, Time: 3.82s\n",
      "Epoch: 41, Batch: 500/896, Loss: 0.8266, Time: 3.83s\n",
      "Epoch: 41, Batch: 510/896, Loss: 1.2008, Time: 3.81s\n",
      "Epoch: 41, Batch: 520/896, Loss: 0.6240, Time: 3.83s\n",
      "Epoch: 41, Batch: 530/896, Loss: 0.6607, Time: 3.82s\n",
      "Epoch: 41, Batch: 540/896, Loss: 0.5250, Time: 3.82s\n",
      "Epoch: 41, Batch: 550/896, Loss: 0.9601, Time: 3.82s\n",
      "Epoch: 41, Batch: 560/896, Loss: 0.9359, Time: 3.81s\n",
      "Epoch: 41, Batch: 570/896, Loss: 1.3276, Time: 3.82s\n",
      "Epoch: 41, Batch: 580/896, Loss: 0.4615, Time: 3.82s\n",
      "Epoch: 41, Batch: 590/896, Loss: 0.4657, Time: 3.81s\n",
      "Epoch: 41, Batch: 600/896, Loss: 1.0030, Time: 3.83s\n",
      "Epoch: 41, Batch: 610/896, Loss: 0.4165, Time: 3.82s\n",
      "Epoch: 41, Batch: 620/896, Loss: 1.2301, Time: 3.82s\n",
      "Epoch: 41, Batch: 630/896, Loss: 0.7644, Time: 3.82s\n",
      "Epoch: 41, Batch: 640/896, Loss: 1.3104, Time: 3.82s\n",
      "Epoch: 41, Batch: 650/896, Loss: 0.5796, Time: 3.82s\n",
      "Epoch: 41, Batch: 660/896, Loss: 0.5719, Time: 3.82s\n",
      "Epoch: 41, Batch: 670/896, Loss: 0.4975, Time: 3.83s\n",
      "Epoch: 41, Batch: 680/896, Loss: 0.2850, Time: 3.82s\n",
      "Epoch: 41, Batch: 690/896, Loss: 0.4050, Time: 3.83s\n",
      "Epoch: 41, Batch: 700/896, Loss: 0.7970, Time: 3.82s\n",
      "Epoch: 41, Batch: 710/896, Loss: 1.0051, Time: 3.83s\n",
      "Epoch: 41, Batch: 720/896, Loss: 0.7170, Time: 3.82s\n",
      "Epoch: 41, Batch: 730/896, Loss: 0.4410, Time: 3.83s\n",
      "Epoch: 41, Batch: 740/896, Loss: 0.3903, Time: 3.82s\n",
      "Epoch: 41, Batch: 750/896, Loss: 1.1824, Time: 3.81s\n",
      "Epoch: 41, Batch: 760/896, Loss: 1.3153, Time: 3.85s\n",
      "Epoch: 41, Batch: 770/896, Loss: 0.8125, Time: 3.84s\n",
      "Epoch: 41, Batch: 780/896, Loss: 0.7659, Time: 3.82s\n",
      "Epoch: 41, Batch: 790/896, Loss: 0.7012, Time: 3.83s\n",
      "Epoch: 41, Batch: 800/896, Loss: 0.4149, Time: 3.83s\n",
      "Epoch: 41, Batch: 810/896, Loss: 0.3875, Time: 3.82s\n",
      "Epoch: 41, Batch: 820/896, Loss: 0.6098, Time: 3.82s\n",
      "Epoch: 41, Batch: 830/896, Loss: 0.6798, Time: 3.82s\n",
      "Epoch: 41, Batch: 840/896, Loss: 0.4683, Time: 3.83s\n",
      "Epoch: 41, Batch: 850/896, Loss: 1.1528, Time: 3.81s\n",
      "Epoch: 41, Batch: 860/896, Loss: 0.5171, Time: 3.82s\n",
      "Epoch: 41, Batch: 870/896, Loss: 0.3915, Time: 3.83s\n",
      "Epoch: 41, Batch: 880/896, Loss: 0.4056, Time: 3.83s\n",
      "Epoch: 41, Batch: 890/896, Loss: 0.5063, Time: 3.82s\n",
      "Epoch 42/50: Train Loss: 0.7735, Val Loss: 0.8439, Val IoU: 0.3740, Val Dice: 0.3977\n",
      "Epoch: 42, Batch: 0/896, Loss: 0.6426, Time: 29.00s\n",
      "Epoch: 42, Batch: 10/896, Loss: 0.6484, Time: 3.76s\n",
      "Epoch: 42, Batch: 20/896, Loss: 0.2965, Time: 3.76s\n",
      "Epoch: 42, Batch: 30/896, Loss: 0.7320, Time: 3.76s\n",
      "Epoch: 42, Batch: 40/896, Loss: 1.1619, Time: 3.79s\n",
      "Epoch: 42, Batch: 50/896, Loss: 0.7499, Time: 3.76s\n",
      "Epoch: 42, Batch: 60/896, Loss: 0.7548, Time: 3.77s\n",
      "Epoch: 42, Batch: 70/896, Loss: 0.6123, Time: 3.77s\n",
      "Epoch: 42, Batch: 80/896, Loss: 0.2886, Time: 3.77s\n",
      "Epoch: 42, Batch: 90/896, Loss: 1.2283, Time: 3.78s\n",
      "Epoch: 42, Batch: 100/896, Loss: 0.3616, Time: 3.79s\n",
      "Epoch: 42, Batch: 110/896, Loss: 0.5931, Time: 3.73s\n",
      "Epoch: 42, Batch: 120/896, Loss: 1.2666, Time: 3.73s\n",
      "Epoch: 42, Batch: 130/896, Loss: 0.9373, Time: 3.73s\n",
      "Epoch: 42, Batch: 140/896, Loss: 0.3722, Time: 3.74s\n",
      "Epoch: 42, Batch: 150/896, Loss: 1.5813, Time: 3.74s\n",
      "Epoch: 42, Batch: 160/896, Loss: 0.5759, Time: 3.74s\n",
      "Epoch: 42, Batch: 170/896, Loss: 0.8822, Time: 3.74s\n",
      "Epoch: 42, Batch: 180/896, Loss: 0.7185, Time: 3.74s\n",
      "Epoch: 42, Batch: 190/896, Loss: 0.9030, Time: 3.75s\n",
      "Epoch: 42, Batch: 200/896, Loss: 1.1077, Time: 3.75s\n",
      "Epoch: 42, Batch: 210/896, Loss: 0.4757, Time: 3.75s\n",
      "Epoch: 42, Batch: 220/896, Loss: 0.7422, Time: 3.77s\n",
      "Epoch: 42, Batch: 230/896, Loss: 0.8785, Time: 3.75s\n",
      "Epoch: 42, Batch: 240/896, Loss: 1.1047, Time: 3.75s\n",
      "Epoch: 42, Batch: 250/896, Loss: 0.8266, Time: 3.75s\n",
      "Epoch: 42, Batch: 260/896, Loss: 0.3644, Time: 3.76s\n",
      "Epoch: 42, Batch: 270/896, Loss: 0.7564, Time: 3.76s\n",
      "Epoch: 42, Batch: 280/896, Loss: 0.4359, Time: 3.77s\n",
      "Epoch: 42, Batch: 290/896, Loss: 0.8258, Time: 3.76s\n",
      "Epoch: 42, Batch: 300/896, Loss: 0.4529, Time: 3.77s\n",
      "Epoch: 42, Batch: 310/896, Loss: 0.6522, Time: 3.77s\n",
      "Epoch: 42, Batch: 320/896, Loss: 1.1679, Time: 3.76s\n",
      "Epoch: 42, Batch: 330/896, Loss: 0.5716, Time: 3.76s\n",
      "Epoch: 42, Batch: 340/896, Loss: 1.0671, Time: 3.77s\n",
      "Epoch: 42, Batch: 350/896, Loss: 0.8736, Time: 3.77s\n",
      "Epoch: 42, Batch: 360/896, Loss: 0.7939, Time: 3.76s\n",
      "Epoch: 42, Batch: 370/896, Loss: 1.2073, Time: 3.78s\n",
      "Epoch: 42, Batch: 380/896, Loss: 0.5023, Time: 3.76s\n",
      "Epoch: 42, Batch: 390/896, Loss: 0.6557, Time: 3.76s\n",
      "Epoch: 42, Batch: 400/896, Loss: 1.0614, Time: 3.77s\n",
      "Epoch: 42, Batch: 410/896, Loss: 0.4472, Time: 3.77s\n",
      "Epoch: 42, Batch: 420/896, Loss: 1.1220, Time: 3.77s\n",
      "Epoch: 42, Batch: 430/896, Loss: 0.9819, Time: 3.76s\n",
      "Epoch: 42, Batch: 440/896, Loss: 0.6173, Time: 3.77s\n",
      "Epoch: 42, Batch: 450/896, Loss: 0.9161, Time: 3.77s\n",
      "Epoch: 42, Batch: 460/896, Loss: 0.8221, Time: 3.77s\n",
      "Epoch: 42, Batch: 470/896, Loss: 0.4716, Time: 3.77s\n",
      "Epoch: 42, Batch: 480/896, Loss: 1.0629, Time: 3.77s\n",
      "Epoch: 42, Batch: 490/896, Loss: 0.7316, Time: 3.77s\n",
      "Epoch: 42, Batch: 500/896, Loss: 0.9308, Time: 3.79s\n",
      "Epoch: 42, Batch: 510/896, Loss: 0.7202, Time: 3.77s\n",
      "Epoch: 42, Batch: 520/896, Loss: 0.5087, Time: 3.78s\n",
      "Epoch: 42, Batch: 530/896, Loss: 0.5970, Time: 3.77s\n",
      "Epoch: 42, Batch: 540/896, Loss: 1.0094, Time: 3.77s\n",
      "Epoch: 42, Batch: 550/896, Loss: 0.5210, Time: 3.82s\n",
      "Epoch: 42, Batch: 560/896, Loss: 0.6846, Time: 3.82s\n",
      "Epoch: 42, Batch: 570/896, Loss: 0.6581, Time: 3.82s\n",
      "Epoch: 42, Batch: 580/896, Loss: 1.3657, Time: 3.83s\n",
      "Epoch: 42, Batch: 590/896, Loss: 0.7811, Time: 3.82s\n",
      "Epoch: 42, Batch: 600/896, Loss: 2.4547, Time: 3.82s\n",
      "Epoch: 42, Batch: 610/896, Loss: 0.6255, Time: 3.83s\n",
      "Epoch: 42, Batch: 620/896, Loss: 1.1067, Time: 3.83s\n",
      "Epoch: 42, Batch: 630/896, Loss: 0.4815, Time: 3.81s\n",
      "Epoch: 42, Batch: 640/896, Loss: 0.4943, Time: 3.83s\n",
      "Epoch: 42, Batch: 650/896, Loss: 0.5143, Time: 3.82s\n",
      "Epoch: 42, Batch: 660/896, Loss: 0.8371, Time: 3.82s\n",
      "Epoch: 42, Batch: 670/896, Loss: 0.7487, Time: 3.86s\n",
      "Epoch: 42, Batch: 680/896, Loss: 1.5495, Time: 3.84s\n",
      "Epoch: 42, Batch: 690/896, Loss: 0.4415, Time: 3.84s\n",
      "Epoch: 42, Batch: 700/896, Loss: 0.5426, Time: 3.84s\n",
      "Epoch: 42, Batch: 710/896, Loss: 0.8354, Time: 3.83s\n",
      "Epoch: 42, Batch: 720/896, Loss: 0.5130, Time: 3.82s\n",
      "Epoch: 42, Batch: 730/896, Loss: 0.8686, Time: 3.82s\n",
      "Epoch: 42, Batch: 740/896, Loss: 0.4786, Time: 3.82s\n",
      "Epoch: 42, Batch: 750/896, Loss: 0.4290, Time: 3.83s\n",
      "Epoch: 42, Batch: 760/896, Loss: 1.3332, Time: 3.81s\n",
      "Epoch: 42, Batch: 770/896, Loss: 0.5126, Time: 3.83s\n",
      "Epoch: 42, Batch: 780/896, Loss: 1.1597, Time: 3.81s\n",
      "Epoch: 42, Batch: 790/896, Loss: 0.9651, Time: 3.82s\n",
      "Epoch: 42, Batch: 800/896, Loss: 1.2015, Time: 3.83s\n",
      "Epoch: 42, Batch: 810/896, Loss: 0.6445, Time: 3.81s\n",
      "Epoch: 42, Batch: 820/896, Loss: 0.5622, Time: 3.81s\n",
      "Epoch: 42, Batch: 830/896, Loss: 0.8438, Time: 3.83s\n",
      "Epoch: 42, Batch: 840/896, Loss: 0.6450, Time: 3.82s\n",
      "Epoch: 42, Batch: 850/896, Loss: 0.8294, Time: 3.81s\n",
      "Epoch: 42, Batch: 860/896, Loss: 0.9248, Time: 3.81s\n",
      "Epoch: 42, Batch: 870/896, Loss: 0.9038, Time: 3.82s\n",
      "Epoch: 42, Batch: 880/896, Loss: 0.9824, Time: 3.81s\n",
      "Epoch: 42, Batch: 890/896, Loss: 0.2957, Time: 3.83s\n",
      "Epoch 43/50: Train Loss: 0.7705, Val Loss: 0.8322, Val IoU: 0.3775, Val Dice: 0.4007\n",
      "Epoch: 43, Batch: 0/896, Loss: 0.8005, Time: 29.04s\n",
      "Epoch: 43, Batch: 10/896, Loss: 1.2193, Time: 3.76s\n",
      "Epoch: 43, Batch: 20/896, Loss: 0.5449, Time: 3.76s\n",
      "Epoch: 43, Batch: 30/896, Loss: 0.7252, Time: 3.70s\n",
      "Epoch: 43, Batch: 40/896, Loss: 0.4734, Time: 3.70s\n",
      "Epoch: 43, Batch: 50/896, Loss: 0.8195, Time: 3.72s\n",
      "Epoch: 43, Batch: 60/896, Loss: 0.4657, Time: 3.73s\n",
      "Epoch: 43, Batch: 70/896, Loss: 1.2799, Time: 3.72s\n",
      "Epoch: 43, Batch: 80/896, Loss: 1.2873, Time: 3.72s\n",
      "Epoch: 43, Batch: 90/896, Loss: 0.9152, Time: 3.72s\n",
      "Epoch: 43, Batch: 100/896, Loss: 0.8632, Time: 3.72s\n",
      "Epoch: 43, Batch: 110/896, Loss: 1.2647, Time: 3.73s\n",
      "Epoch: 43, Batch: 120/896, Loss: 0.5367, Time: 3.73s\n",
      "Epoch: 43, Batch: 130/896, Loss: 0.8394, Time: 3.74s\n",
      "Epoch: 43, Batch: 140/896, Loss: 0.6483, Time: 3.78s\n",
      "Epoch: 43, Batch: 150/896, Loss: 0.7275, Time: 3.82s\n",
      "Epoch: 43, Batch: 160/896, Loss: 0.3744, Time: 3.80s\n",
      "Epoch: 43, Batch: 170/896, Loss: 0.5053, Time: 3.80s\n",
      "Epoch: 43, Batch: 180/896, Loss: 1.3800, Time: 3.80s\n",
      "Epoch: 43, Batch: 190/896, Loss: 0.5357, Time: 3.82s\n",
      "Epoch: 43, Batch: 200/896, Loss: 0.6381, Time: 3.78s\n",
      "Epoch: 43, Batch: 210/896, Loss: 0.7294, Time: 3.82s\n",
      "Epoch: 43, Batch: 220/896, Loss: 0.5425, Time: 3.81s\n",
      "Epoch: 43, Batch: 230/896, Loss: 0.6714, Time: 3.80s\n",
      "Epoch: 43, Batch: 240/896, Loss: 0.6608, Time: 3.83s\n",
      "Epoch: 43, Batch: 250/896, Loss: 1.1957, Time: 3.80s\n",
      "Epoch: 43, Batch: 260/896, Loss: 0.4166, Time: 3.74s\n",
      "Epoch: 43, Batch: 270/896, Loss: 0.7313, Time: 3.73s\n",
      "Epoch: 43, Batch: 280/896, Loss: 1.0750, Time: 3.75s\n",
      "Epoch: 43, Batch: 290/896, Loss: 0.7334, Time: 3.73s\n",
      "Epoch: 43, Batch: 300/896, Loss: 0.6462, Time: 3.74s\n",
      "Epoch: 43, Batch: 310/896, Loss: 1.1937, Time: 3.74s\n",
      "Epoch: 43, Batch: 320/896, Loss: 0.7657, Time: 3.74s\n",
      "Epoch: 43, Batch: 330/896, Loss: 0.6451, Time: 3.73s\n",
      "Epoch: 43, Batch: 340/896, Loss: 0.7586, Time: 3.74s\n",
      "Epoch: 43, Batch: 350/896, Loss: 1.1808, Time: 3.73s\n",
      "Epoch: 43, Batch: 360/896, Loss: 0.4813, Time: 3.73s\n",
      "Epoch: 43, Batch: 370/896, Loss: 1.1691, Time: 3.73s\n",
      "Epoch: 43, Batch: 380/896, Loss: 2.4975, Time: 3.74s\n",
      "Epoch: 43, Batch: 390/896, Loss: 0.9733, Time: 3.74s\n",
      "Epoch: 43, Batch: 400/896, Loss: 1.0299, Time: 3.74s\n",
      "Epoch: 43, Batch: 410/896, Loss: 0.7660, Time: 3.73s\n",
      "Epoch: 43, Batch: 420/896, Loss: 0.6909, Time: 3.75s\n",
      "Epoch: 43, Batch: 430/896, Loss: 1.2163, Time: 3.74s\n",
      "Epoch: 43, Batch: 440/896, Loss: 1.2439, Time: 3.73s\n",
      "Epoch: 43, Batch: 450/896, Loss: 0.5343, Time: 3.74s\n",
      "Epoch: 43, Batch: 460/896, Loss: 0.8863, Time: 3.75s\n",
      "Epoch: 43, Batch: 470/896, Loss: 0.4358, Time: 3.73s\n",
      "Epoch: 43, Batch: 480/896, Loss: 0.4796, Time: 3.75s\n",
      "Epoch: 43, Batch: 490/896, Loss: 0.6864, Time: 3.75s\n",
      "Epoch: 43, Batch: 500/896, Loss: 0.6834, Time: 3.75s\n",
      "Epoch: 43, Batch: 510/896, Loss: 0.7825, Time: 3.74s\n",
      "Epoch: 43, Batch: 520/896, Loss: 1.5759, Time: 3.74s\n",
      "Epoch: 43, Batch: 530/896, Loss: 0.4642, Time: 3.75s\n",
      "Epoch: 43, Batch: 540/896, Loss: 0.6844, Time: 3.74s\n",
      "Epoch: 43, Batch: 550/896, Loss: 0.3854, Time: 3.75s\n",
      "Epoch: 43, Batch: 560/896, Loss: 0.5743, Time: 3.75s\n",
      "Epoch: 43, Batch: 570/896, Loss: 1.3867, Time: 3.75s\n",
      "Epoch: 43, Batch: 580/896, Loss: 0.4975, Time: 3.76s\n",
      "Epoch: 43, Batch: 590/896, Loss: 0.7184, Time: 3.75s\n",
      "Epoch: 43, Batch: 600/896, Loss: 0.6598, Time: 3.82s\n",
      "Epoch: 43, Batch: 610/896, Loss: 0.6410, Time: 3.82s\n",
      "Epoch: 43, Batch: 620/896, Loss: 0.8716, Time: 3.82s\n",
      "Epoch: 43, Batch: 630/896, Loss: 0.4983, Time: 3.81s\n",
      "Epoch: 43, Batch: 640/896, Loss: 0.6722, Time: 3.82s\n",
      "Epoch: 43, Batch: 650/896, Loss: 1.2313, Time: 3.81s\n",
      "Epoch: 43, Batch: 660/896, Loss: 1.0693, Time: 3.80s\n",
      "Epoch: 43, Batch: 670/896, Loss: 1.0442, Time: 3.82s\n",
      "Epoch: 43, Batch: 680/896, Loss: 1.3027, Time: 3.81s\n",
      "Epoch: 43, Batch: 690/896, Loss: 0.7086, Time: 3.81s\n",
      "Epoch: 43, Batch: 700/896, Loss: 0.7667, Time: 3.80s\n",
      "Epoch: 43, Batch: 710/896, Loss: 0.8082, Time: 3.82s\n",
      "Epoch: 43, Batch: 720/896, Loss: 0.5466, Time: 3.81s\n",
      "Epoch: 43, Batch: 730/896, Loss: 0.5053, Time: 3.80s\n",
      "Epoch: 43, Batch: 740/896, Loss: 0.3210, Time: 3.82s\n",
      "Epoch: 43, Batch: 750/896, Loss: 1.2138, Time: 3.82s\n",
      "Epoch: 43, Batch: 760/896, Loss: 0.3921, Time: 3.82s\n",
      "Epoch: 43, Batch: 770/896, Loss: 0.6793, Time: 3.81s\n",
      "Epoch: 43, Batch: 780/896, Loss: 0.5246, Time: 3.82s\n",
      "Epoch: 43, Batch: 790/896, Loss: 0.5620, Time: 3.81s\n",
      "Epoch: 43, Batch: 800/896, Loss: 1.3998, Time: 3.77s\n",
      "Epoch: 43, Batch: 810/896, Loss: 0.3529, Time: 3.77s\n",
      "Epoch: 43, Batch: 820/896, Loss: 0.3286, Time: 3.77s\n",
      "Epoch: 43, Batch: 830/896, Loss: 1.4901, Time: 3.77s\n",
      "Epoch: 43, Batch: 840/896, Loss: 0.3324, Time: 3.77s\n",
      "Epoch: 43, Batch: 850/896, Loss: 0.4432, Time: 3.77s\n",
      "Epoch: 43, Batch: 860/896, Loss: 0.5604, Time: 3.77s\n",
      "Epoch: 43, Batch: 870/896, Loss: 0.7498, Time: 3.76s\n",
      "Epoch: 43, Batch: 880/896, Loss: 0.6105, Time: 3.77s\n",
      "Epoch: 43, Batch: 890/896, Loss: 0.3224, Time: 3.77s\n",
      "Epoch 44/50: Train Loss: 0.7664, Val Loss: 0.8221, Val IoU: 0.3766, Val Dice: 0.4000\n",
      "Epoch: 44, Batch: 0/896, Loss: 0.5471, Time: 29.10s\n",
      "Epoch: 44, Batch: 10/896, Loss: 0.8991, Time: 3.76s\n",
      "Epoch: 44, Batch: 20/896, Loss: 0.3963, Time: 3.76s\n",
      "Epoch: 44, Batch: 30/896, Loss: 1.1408, Time: 3.76s\n",
      "Epoch: 44, Batch: 40/896, Loss: 0.9326, Time: 3.77s\n",
      "Epoch: 44, Batch: 50/896, Loss: 0.7431, Time: 3.77s\n",
      "Epoch: 44, Batch: 60/896, Loss: 0.8076, Time: 3.78s\n",
      "Epoch: 44, Batch: 70/896, Loss: 0.6682, Time: 3.76s\n",
      "Epoch: 44, Batch: 80/896, Loss: 0.5784, Time: 3.78s\n",
      "Epoch: 44, Batch: 90/896, Loss: 0.7911, Time: 3.79s\n",
      "Epoch: 44, Batch: 100/896, Loss: 1.5037, Time: 3.79s\n",
      "Epoch: 44, Batch: 110/896, Loss: 0.8996, Time: 3.78s\n",
      "Epoch: 44, Batch: 120/896, Loss: 0.4262, Time: 3.78s\n",
      "Epoch: 44, Batch: 130/896, Loss: 0.6804, Time: 3.79s\n",
      "Epoch: 44, Batch: 140/896, Loss: 0.3816, Time: 3.79s\n",
      "Epoch: 44, Batch: 150/896, Loss: 0.3991, Time: 3.79s\n",
      "Epoch: 44, Batch: 160/896, Loss: 0.6535, Time: 3.79s\n",
      "Epoch: 44, Batch: 170/896, Loss: 0.8195, Time: 3.79s\n",
      "Epoch: 44, Batch: 180/896, Loss: 0.6958, Time: 3.80s\n",
      "Epoch: 44, Batch: 190/896, Loss: 0.9516, Time: 3.79s\n",
      "Epoch: 44, Batch: 200/896, Loss: 0.7348, Time: 3.80s\n",
      "Epoch: 44, Batch: 210/896, Loss: 0.4328, Time: 3.79s\n",
      "Epoch: 44, Batch: 220/896, Loss: 0.9977, Time: 3.80s\n",
      "Epoch: 44, Batch: 230/896, Loss: 0.9508, Time: 3.79s\n",
      "Epoch: 44, Batch: 240/896, Loss: 0.5030, Time: 3.79s\n",
      "Epoch: 44, Batch: 250/896, Loss: 0.8600, Time: 3.81s\n",
      "Epoch: 44, Batch: 260/896, Loss: 0.5180, Time: 3.81s\n",
      "Epoch: 44, Batch: 270/896, Loss: 0.7596, Time: 3.80s\n",
      "Epoch: 44, Batch: 280/896, Loss: 1.1435, Time: 3.81s\n",
      "Epoch: 44, Batch: 290/896, Loss: 0.8467, Time: 3.81s\n",
      "Epoch: 44, Batch: 300/896, Loss: 0.5972, Time: 3.81s\n",
      "Epoch: 44, Batch: 310/896, Loss: 0.6100, Time: 3.80s\n",
      "Epoch: 44, Batch: 320/896, Loss: 1.2584, Time: 3.82s\n",
      "Epoch: 44, Batch: 330/896, Loss: 0.5868, Time: 3.81s\n",
      "Epoch: 44, Batch: 340/896, Loss: 0.6658, Time: 3.81s\n",
      "Epoch: 44, Batch: 350/896, Loss: 0.6772, Time: 3.81s\n",
      "Epoch: 44, Batch: 360/896, Loss: 0.6497, Time: 3.80s\n",
      "Epoch: 44, Batch: 370/896, Loss: 0.7298, Time: 3.83s\n",
      "Epoch: 44, Batch: 380/896, Loss: 0.6718, Time: 3.81s\n",
      "Epoch: 44, Batch: 390/896, Loss: 0.7193, Time: 3.82s\n",
      "Epoch: 44, Batch: 400/896, Loss: 1.6487, Time: 3.82s\n",
      "Epoch: 44, Batch: 410/896, Loss: 1.0859, Time: 3.81s\n",
      "Epoch: 44, Batch: 420/896, Loss: 1.0491, Time: 3.81s\n",
      "Epoch: 44, Batch: 430/896, Loss: 1.2998, Time: 3.81s\n",
      "Epoch: 44, Batch: 440/896, Loss: 0.8256, Time: 3.81s\n",
      "Epoch: 44, Batch: 450/896, Loss: 0.4701, Time: 3.81s\n",
      "Epoch: 44, Batch: 460/896, Loss: 0.5770, Time: 3.80s\n",
      "Epoch: 44, Batch: 470/896, Loss: 0.6048, Time: 3.83s\n",
      "Epoch: 44, Batch: 480/896, Loss: 0.6699, Time: 3.82s\n",
      "Epoch: 44, Batch: 490/896, Loss: 0.3027, Time: 3.82s\n",
      "Epoch: 44, Batch: 500/896, Loss: 0.3598, Time: 3.82s\n",
      "Epoch: 44, Batch: 510/896, Loss: 0.2921, Time: 3.81s\n",
      "Epoch: 44, Batch: 520/896, Loss: 0.3440, Time: 3.82s\n",
      "Epoch: 44, Batch: 530/896, Loss: 0.7188, Time: 3.82s\n",
      "Epoch: 44, Batch: 540/896, Loss: 1.0271, Time: 3.82s\n",
      "Epoch: 44, Batch: 550/896, Loss: 0.3400, Time: 3.83s\n",
      "Epoch: 44, Batch: 560/896, Loss: 0.5342, Time: 3.82s\n",
      "Epoch: 44, Batch: 570/896, Loss: 0.2807, Time: 3.80s\n",
      "Epoch: 44, Batch: 580/896, Loss: 0.8677, Time: 3.83s\n",
      "Epoch: 44, Batch: 590/896, Loss: 0.4611, Time: 3.81s\n",
      "Epoch: 44, Batch: 600/896, Loss: 0.4898, Time: 3.82s\n",
      "Epoch: 44, Batch: 610/896, Loss: 1.0164, Time: 3.82s\n",
      "Epoch: 44, Batch: 620/896, Loss: 0.5665, Time: 3.82s\n",
      "Epoch: 44, Batch: 630/896, Loss: 1.2479, Time: 3.82s\n",
      "Epoch: 44, Batch: 640/896, Loss: 0.2381, Time: 3.82s\n",
      "Epoch: 44, Batch: 650/896, Loss: 1.2486, Time: 3.82s\n",
      "Epoch: 44, Batch: 660/896, Loss: 0.4491, Time: 3.80s\n",
      "Epoch: 44, Batch: 670/896, Loss: 0.4230, Time: 3.83s\n",
      "Epoch: 44, Batch: 680/896, Loss: 0.3692, Time: 3.82s\n",
      "Epoch: 44, Batch: 690/896, Loss: 0.3095, Time: 3.80s\n",
      "Epoch: 44, Batch: 700/896, Loss: 1.5349, Time: 3.83s\n",
      "Epoch: 44, Batch: 710/896, Loss: 0.4303, Time: 3.81s\n",
      "Epoch: 44, Batch: 720/896, Loss: 0.4013, Time: 3.82s\n",
      "Epoch: 44, Batch: 730/896, Loss: 0.9125, Time: 3.80s\n",
      "Epoch: 44, Batch: 740/896, Loss: 1.0696, Time: 3.83s\n",
      "Epoch: 44, Batch: 750/896, Loss: 1.4294, Time: 3.81s\n",
      "Epoch: 44, Batch: 760/896, Loss: 1.4433, Time: 3.83s\n",
      "Epoch: 44, Batch: 770/896, Loss: 0.9658, Time: 3.81s\n",
      "Epoch: 44, Batch: 780/896, Loss: 0.4812, Time: 3.83s\n",
      "Epoch: 44, Batch: 790/896, Loss: 0.4843, Time: 3.81s\n",
      "Epoch: 44, Batch: 800/896, Loss: 0.7893, Time: 3.82s\n",
      "Epoch: 44, Batch: 810/896, Loss: 0.8408, Time: 3.81s\n",
      "Epoch: 44, Batch: 820/896, Loss: 0.5811, Time: 3.82s\n",
      "Epoch: 44, Batch: 830/896, Loss: 1.0724, Time: 3.81s\n",
      "Epoch: 44, Batch: 840/896, Loss: 0.8296, Time: 3.83s\n",
      "Epoch: 44, Batch: 850/896, Loss: 0.6535, Time: 3.83s\n",
      "Epoch: 44, Batch: 860/896, Loss: 0.6677, Time: 3.81s\n",
      "Epoch: 44, Batch: 870/896, Loss: 1.4952, Time: 3.83s\n",
      "Epoch: 44, Batch: 880/896, Loss: 1.0096, Time: 3.81s\n",
      "Epoch: 44, Batch: 890/896, Loss: 0.4991, Time: 3.82s\n",
      "Epoch 45/50: Train Loss: 0.7638, Val Loss: 0.8101, Val IoU: 0.3748, Val Dice: 0.3986\n",
      "Epoch: 45, Batch: 0/896, Loss: 0.8520, Time: 29.22s\n",
      "Epoch: 45, Batch: 10/896, Loss: 0.9868, Time: 3.77s\n",
      "Epoch: 45, Batch: 20/896, Loss: 0.6304, Time: 3.76s\n",
      "Epoch: 45, Batch: 30/896, Loss: 1.5071, Time: 3.76s\n",
      "Epoch: 45, Batch: 40/896, Loss: 1.0893, Time: 3.76s\n",
      "Epoch: 45, Batch: 50/896, Loss: 1.1085, Time: 3.77s\n",
      "Epoch: 45, Batch: 60/896, Loss: 1.1367, Time: 3.77s\n",
      "Epoch: 45, Batch: 70/896, Loss: 1.8779, Time: 3.77s\n",
      "Epoch: 45, Batch: 80/896, Loss: 0.9285, Time: 3.78s\n",
      "Epoch: 45, Batch: 90/896, Loss: 0.5072, Time: 3.78s\n",
      "Epoch: 45, Batch: 100/896, Loss: 0.5130, Time: 3.79s\n",
      "Epoch: 45, Batch: 110/896, Loss: 1.2375, Time: 3.78s\n",
      "Epoch: 45, Batch: 120/896, Loss: 0.9335, Time: 3.78s\n",
      "Epoch: 45, Batch: 130/896, Loss: 1.2693, Time: 3.79s\n",
      "Epoch: 45, Batch: 140/896, Loss: 0.9406, Time: 3.79s\n",
      "Epoch: 45, Batch: 150/896, Loss: 0.4665, Time: 3.79s\n",
      "Epoch: 45, Batch: 160/896, Loss: 0.6933, Time: 3.79s\n",
      "Epoch: 45, Batch: 170/896, Loss: 0.4187, Time: 3.80s\n",
      "Epoch: 45, Batch: 180/896, Loss: 0.3984, Time: 3.80s\n",
      "Epoch: 45, Batch: 190/896, Loss: 0.8820, Time: 3.79s\n",
      "Epoch: 45, Batch: 200/896, Loss: 0.5928, Time: 3.80s\n",
      "Epoch: 45, Batch: 210/896, Loss: 1.1648, Time: 3.79s\n",
      "Epoch: 45, Batch: 220/896, Loss: 1.0947, Time: 3.80s\n",
      "Epoch: 45, Batch: 230/896, Loss: 0.5151, Time: 3.78s\n",
      "Epoch: 45, Batch: 240/896, Loss: 0.8172, Time: 3.80s\n",
      "Epoch: 45, Batch: 250/896, Loss: 0.4058, Time: 3.80s\n",
      "Epoch: 45, Batch: 260/896, Loss: 1.0269, Time: 3.81s\n",
      "Epoch: 45, Batch: 270/896, Loss: 0.7256, Time: 3.80s\n",
      "Epoch: 45, Batch: 280/896, Loss: 0.5560, Time: 3.80s\n",
      "Epoch: 45, Batch: 290/896, Loss: 0.3322, Time: 3.80s\n",
      "Epoch: 45, Batch: 300/896, Loss: 1.1622, Time: 3.81s\n",
      "Epoch: 45, Batch: 310/896, Loss: 0.7079, Time: 3.81s\n",
      "Epoch: 45, Batch: 320/896, Loss: 0.3544, Time: 3.81s\n",
      "Epoch: 45, Batch: 330/896, Loss: 0.6901, Time: 3.80s\n",
      "Epoch: 45, Batch: 340/896, Loss: 0.7070, Time: 3.82s\n",
      "Epoch: 45, Batch: 350/896, Loss: 1.0052, Time: 3.83s\n",
      "Epoch: 45, Batch: 360/896, Loss: 1.0703, Time: 3.77s\n",
      "Epoch: 45, Batch: 370/896, Loss: 0.5104, Time: 3.77s\n",
      "Epoch: 45, Batch: 380/896, Loss: 0.5637, Time: 3.77s\n",
      "Epoch: 45, Batch: 390/896, Loss: 0.5352, Time: 3.77s\n",
      "Epoch: 45, Batch: 400/896, Loss: 0.4355, Time: 3.75s\n",
      "Epoch: 45, Batch: 410/896, Loss: 1.4440, Time: 3.76s\n",
      "Epoch: 45, Batch: 420/896, Loss: 0.6875, Time: 3.76s\n",
      "Epoch: 45, Batch: 430/896, Loss: 0.5006, Time: 3.77s\n",
      "Epoch: 45, Batch: 440/896, Loss: 0.5276, Time: 3.77s\n",
      "Epoch: 45, Batch: 450/896, Loss: 1.1753, Time: 3.76s\n",
      "Epoch: 45, Batch: 460/896, Loss: 1.0421, Time: 3.77s\n",
      "Epoch: 45, Batch: 470/896, Loss: 0.6544, Time: 3.76s\n",
      "Epoch: 45, Batch: 480/896, Loss: 0.5856, Time: 3.77s\n",
      "Epoch: 45, Batch: 490/896, Loss: 0.7827, Time: 3.77s\n",
      "Epoch: 45, Batch: 500/896, Loss: 0.6357, Time: 3.76s\n",
      "Epoch: 45, Batch: 510/896, Loss: 0.6555, Time: 3.76s\n",
      "Epoch: 45, Batch: 520/896, Loss: 0.9710, Time: 3.77s\n",
      "Epoch: 45, Batch: 530/896, Loss: 0.9805, Time: 3.77s\n",
      "Epoch: 45, Batch: 540/896, Loss: 0.6863, Time: 3.77s\n",
      "Epoch: 45, Batch: 550/896, Loss: 0.4551, Time: 3.78s\n",
      "Epoch: 45, Batch: 560/896, Loss: 0.4650, Time: 3.77s\n",
      "Epoch: 45, Batch: 570/896, Loss: 0.7086, Time: 3.77s\n",
      "Epoch: 45, Batch: 580/896, Loss: 1.6184, Time: 3.76s\n",
      "Epoch: 45, Batch: 590/896, Loss: 0.5744, Time: 3.77s\n",
      "Epoch: 45, Batch: 600/896, Loss: 0.7982, Time: 3.77s\n",
      "Epoch: 45, Batch: 610/896, Loss: 1.3020, Time: 3.77s\n",
      "Epoch: 45, Batch: 620/896, Loss: 0.4795, Time: 3.76s\n",
      "Epoch: 45, Batch: 630/896, Loss: 0.5485, Time: 3.75s\n",
      "Epoch: 45, Batch: 640/896, Loss: 0.5681, Time: 3.77s\n",
      "Epoch: 45, Batch: 650/896, Loss: 0.7964, Time: 3.81s\n",
      "Epoch: 45, Batch: 660/896, Loss: 1.3343, Time: 3.83s\n",
      "Epoch: 45, Batch: 670/896, Loss: 0.7719, Time: 3.82s\n",
      "Epoch: 45, Batch: 680/896, Loss: 0.8702, Time: 3.82s\n",
      "Epoch: 45, Batch: 690/896, Loss: 0.5689, Time: 3.76s\n",
      "Epoch: 45, Batch: 700/896, Loss: 0.3423, Time: 3.76s\n",
      "Epoch: 45, Batch: 710/896, Loss: 0.5264, Time: 3.77s\n",
      "Epoch: 45, Batch: 720/896, Loss: 0.8850, Time: 3.79s\n",
      "Epoch: 45, Batch: 730/896, Loss: 0.8584, Time: 3.77s\n",
      "Epoch: 45, Batch: 740/896, Loss: 0.5354, Time: 3.78s\n",
      "Epoch: 45, Batch: 750/896, Loss: 0.5266, Time: 3.77s\n",
      "Epoch: 45, Batch: 760/896, Loss: 0.3176, Time: 3.78s\n",
      "Epoch: 45, Batch: 770/896, Loss: 1.0449, Time: 3.78s\n",
      "Epoch: 45, Batch: 780/896, Loss: 1.0832, Time: 3.78s\n",
      "Epoch: 45, Batch: 790/896, Loss: 0.8410, Time: 3.76s\n",
      "Epoch: 45, Batch: 800/896, Loss: 0.2979, Time: 3.77s\n",
      "Epoch: 45, Batch: 810/896, Loss: 0.3846, Time: 3.76s\n",
      "Epoch: 45, Batch: 820/896, Loss: 0.2936, Time: 3.77s\n",
      "Epoch: 45, Batch: 830/896, Loss: 0.4457, Time: 3.78s\n",
      "Epoch: 45, Batch: 840/896, Loss: 0.8082, Time: 3.77s\n",
      "Epoch: 45, Batch: 850/896, Loss: 1.4099, Time: 3.78s\n",
      "Epoch: 45, Batch: 860/896, Loss: 1.0147, Time: 3.78s\n",
      "Epoch: 45, Batch: 870/896, Loss: 0.3178, Time: 3.78s\n",
      "Epoch: 45, Batch: 880/896, Loss: 0.6805, Time: 3.77s\n",
      "Epoch: 45, Batch: 890/896, Loss: 0.5143, Time: 3.77s\n",
      "Epoch 46/50: Train Loss: 0.7639, Val Loss: 0.8232, Val IoU: 0.3750, Val Dice: 0.3989\n",
      "Epoch: 46, Batch: 0/896, Loss: 0.6732, Time: 28.84s\n",
      "Epoch: 46, Batch: 10/896, Loss: 1.0465, Time: 3.71s\n",
      "Epoch: 46, Batch: 20/896, Loss: 0.3566, Time: 3.69s\n",
      "Epoch: 46, Batch: 30/896, Loss: 1.4999, Time: 3.72s\n",
      "Epoch: 46, Batch: 40/896, Loss: 0.5559, Time: 3.70s\n",
      "Epoch: 46, Batch: 50/896, Loss: 1.3047, Time: 3.72s\n",
      "Epoch: 46, Batch: 60/896, Loss: 0.3885, Time: 3.72s\n",
      "Epoch: 46, Batch: 70/896, Loss: 1.5105, Time: 3.73s\n",
      "Epoch: 46, Batch: 80/896, Loss: 0.5554, Time: 3.72s\n",
      "Epoch: 46, Batch: 90/896, Loss: 0.9495, Time: 3.73s\n",
      "Epoch: 46, Batch: 100/896, Loss: 0.7949, Time: 3.73s\n",
      "Epoch: 46, Batch: 110/896, Loss: 0.2668, Time: 3.73s\n",
      "Epoch: 46, Batch: 120/896, Loss: 0.5726, Time: 3.73s\n",
      "Epoch: 46, Batch: 130/896, Loss: 0.2763, Time: 3.73s\n",
      "Epoch: 46, Batch: 140/896, Loss: 1.5608, Time: 3.74s\n",
      "Epoch: 46, Batch: 150/896, Loss: 0.5878, Time: 3.73s\n",
      "Epoch: 46, Batch: 160/896, Loss: 1.0642, Time: 3.74s\n",
      "Epoch: 46, Batch: 170/896, Loss: 0.7861, Time: 3.73s\n",
      "Epoch: 46, Batch: 180/896, Loss: 1.3250, Time: 3.75s\n",
      "Epoch: 46, Batch: 190/896, Loss: 0.4001, Time: 3.75s\n",
      "Epoch: 46, Batch: 200/896, Loss: 0.8132, Time: 3.75s\n",
      "Epoch: 46, Batch: 210/896, Loss: 0.4138, Time: 3.76s\n",
      "Epoch: 46, Batch: 220/896, Loss: 0.6758, Time: 3.75s\n",
      "Epoch: 46, Batch: 230/896, Loss: 0.3375, Time: 3.76s\n",
      "Epoch: 46, Batch: 240/896, Loss: 0.9147, Time: 3.75s\n",
      "Epoch: 46, Batch: 250/896, Loss: 0.8378, Time: 3.75s\n",
      "Epoch: 46, Batch: 260/896, Loss: 0.8748, Time: 3.76s\n",
      "Epoch: 46, Batch: 270/896, Loss: 0.7027, Time: 3.76s\n",
      "Epoch: 46, Batch: 280/896, Loss: 0.4968, Time: 3.76s\n",
      "Epoch: 46, Batch: 290/896, Loss: 0.5557, Time: 3.77s\n",
      "Epoch: 46, Batch: 300/896, Loss: 0.8285, Time: 3.76s\n",
      "Epoch: 46, Batch: 310/896, Loss: 0.4537, Time: 3.76s\n",
      "Epoch: 46, Batch: 320/896, Loss: 1.5153, Time: 3.77s\n",
      "Epoch: 46, Batch: 330/896, Loss: 0.8373, Time: 3.77s\n",
      "Epoch: 46, Batch: 340/896, Loss: 0.4078, Time: 3.77s\n",
      "Epoch: 46, Batch: 350/896, Loss: 0.4218, Time: 3.77s\n",
      "Epoch: 46, Batch: 360/896, Loss: 1.7007, Time: 3.77s\n",
      "Epoch: 46, Batch: 370/896, Loss: 1.1138, Time: 3.78s\n",
      "Epoch: 46, Batch: 380/896, Loss: 0.4444, Time: 3.76s\n",
      "Epoch: 46, Batch: 390/896, Loss: 0.8228, Time: 3.76s\n",
      "Epoch: 46, Batch: 400/896, Loss: 0.6940, Time: 3.77s\n",
      "Epoch: 46, Batch: 410/896, Loss: 1.1927, Time: 3.76s\n",
      "Epoch: 46, Batch: 420/896, Loss: 0.4014, Time: 3.76s\n",
      "Epoch: 46, Batch: 430/896, Loss: 0.6250, Time: 3.75s\n",
      "Epoch: 46, Batch: 440/896, Loss: 0.4621, Time: 3.77s\n",
      "Epoch: 46, Batch: 450/896, Loss: 0.8720, Time: 3.76s\n",
      "Epoch: 46, Batch: 460/896, Loss: 0.5735, Time: 3.76s\n",
      "Epoch: 46, Batch: 470/896, Loss: 0.9219, Time: 3.77s\n",
      "Epoch: 46, Batch: 480/896, Loss: 1.0377, Time: 3.76s\n",
      "Epoch: 46, Batch: 490/896, Loss: 0.6203, Time: 3.77s\n",
      "Epoch: 46, Batch: 500/896, Loss: 1.0350, Time: 3.77s\n",
      "Epoch: 46, Batch: 510/896, Loss: 0.4432, Time: 3.76s\n",
      "Epoch: 46, Batch: 520/896, Loss: 1.0617, Time: 3.77s\n",
      "Epoch: 46, Batch: 530/896, Loss: 0.4992, Time: 3.77s\n",
      "Epoch: 46, Batch: 540/896, Loss: 0.2876, Time: 3.77s\n",
      "Epoch: 46, Batch: 550/896, Loss: 0.3645, Time: 3.78s\n",
      "Epoch: 46, Batch: 560/896, Loss: 0.7645, Time: 3.76s\n",
      "Epoch: 46, Batch: 570/896, Loss: 1.0633, Time: 3.78s\n",
      "Epoch: 46, Batch: 580/896, Loss: 0.8896, Time: 3.76s\n",
      "Epoch: 46, Batch: 590/896, Loss: 0.9375, Time: 3.79s\n",
      "Epoch: 46, Batch: 600/896, Loss: 0.7640, Time: 3.76s\n",
      "Epoch: 46, Batch: 610/896, Loss: 1.2229, Time: 3.78s\n",
      "Epoch: 46, Batch: 620/896, Loss: 0.9433, Time: 3.76s\n",
      "Epoch: 46, Batch: 630/896, Loss: 0.6429, Time: 3.77s\n",
      "Epoch: 46, Batch: 640/896, Loss: 0.9736, Time: 3.76s\n",
      "Epoch: 46, Batch: 650/896, Loss: 0.9007, Time: 3.77s\n",
      "Epoch: 46, Batch: 660/896, Loss: 0.7177, Time: 3.78s\n",
      "Epoch: 46, Batch: 670/896, Loss: 1.4377, Time: 3.77s\n",
      "Epoch: 46, Batch: 680/896, Loss: 0.5857, Time: 3.77s\n",
      "Epoch: 46, Batch: 690/896, Loss: 0.4542, Time: 3.77s\n",
      "Epoch: 46, Batch: 700/896, Loss: 0.3539, Time: 3.79s\n",
      "Epoch: 46, Batch: 710/896, Loss: 0.9387, Time: 3.78s\n",
      "Epoch: 46, Batch: 720/896, Loss: 0.9406, Time: 3.77s\n",
      "Epoch: 46, Batch: 730/896, Loss: 0.4504, Time: 3.77s\n",
      "Epoch: 46, Batch: 740/896, Loss: 0.6649, Time: 3.77s\n",
      "Epoch: 46, Batch: 750/896, Loss: 1.3144, Time: 3.76s\n",
      "Epoch: 46, Batch: 760/896, Loss: 0.3436, Time: 3.77s\n",
      "Epoch: 46, Batch: 770/896, Loss: 0.6076, Time: 3.77s\n",
      "Epoch: 46, Batch: 780/896, Loss: 1.4537, Time: 3.78s\n",
      "Epoch: 46, Batch: 790/896, Loss: 0.4816, Time: 3.77s\n",
      "Epoch: 46, Batch: 800/896, Loss: 1.6886, Time: 3.78s\n",
      "Epoch: 46, Batch: 810/896, Loss: 0.8057, Time: 3.77s\n",
      "Epoch: 46, Batch: 820/896, Loss: 0.7063, Time: 3.77s\n",
      "Epoch: 46, Batch: 830/896, Loss: 0.6742, Time: 3.76s\n",
      "Epoch: 46, Batch: 840/896, Loss: 0.3441, Time: 3.77s\n",
      "Epoch: 46, Batch: 850/896, Loss: 0.7068, Time: 3.77s\n",
      "Epoch: 46, Batch: 860/896, Loss: 1.3005, Time: 3.77s\n",
      "Epoch: 46, Batch: 870/896, Loss: 0.4492, Time: 3.77s\n",
      "Epoch: 46, Batch: 880/896, Loss: 0.4500, Time: 3.76s\n",
      "Epoch: 46, Batch: 890/896, Loss: 0.8091, Time: 3.78s\n",
      "Epoch 47/50: Train Loss: 0.7617, Val Loss: 0.8293, Val IoU: 0.3785, Val Dice: 0.4018\n",
      "Epoch: 47, Batch: 0/896, Loss: 1.1834, Time: 28.82s\n",
      "Epoch: 47, Batch: 10/896, Loss: 0.7787, Time: 3.72s\n",
      "Epoch: 47, Batch: 20/896, Loss: 0.6398, Time: 3.70s\n",
      "Epoch: 47, Batch: 30/896, Loss: 0.7180, Time: 3.69s\n",
      "Epoch: 47, Batch: 40/896, Loss: 0.4875, Time: 3.72s\n",
      "Epoch: 47, Batch: 50/896, Loss: 0.5874, Time: 3.72s\n",
      "Epoch: 47, Batch: 60/896, Loss: 0.3999, Time: 3.72s\n",
      "Epoch: 47, Batch: 70/896, Loss: 0.6630, Time: 3.71s\n",
      "Epoch: 47, Batch: 80/896, Loss: 0.3019, Time: 3.71s\n",
      "Epoch: 47, Batch: 90/896, Loss: 0.7504, Time: 3.73s\n",
      "Epoch: 47, Batch: 100/896, Loss: 0.8945, Time: 3.73s\n",
      "Epoch: 47, Batch: 110/896, Loss: 0.6902, Time: 3.72s\n",
      "Epoch: 47, Batch: 120/896, Loss: 0.4655, Time: 3.74s\n",
      "Epoch: 47, Batch: 130/896, Loss: 0.4889, Time: 3.75s\n",
      "Epoch: 47, Batch: 140/896, Loss: 1.3759, Time: 3.74s\n",
      "Epoch: 47, Batch: 150/896, Loss: 1.5899, Time: 3.74s\n",
      "Epoch: 47, Batch: 160/896, Loss: 0.8184, Time: 3.74s\n",
      "Epoch: 47, Batch: 170/896, Loss: 1.1452, Time: 3.75s\n",
      "Epoch: 47, Batch: 180/896, Loss: 1.0126, Time: 3.73s\n",
      "Epoch: 47, Batch: 190/896, Loss: 1.2657, Time: 3.74s\n",
      "Epoch: 47, Batch: 200/896, Loss: 0.4352, Time: 3.75s\n",
      "Epoch: 47, Batch: 210/896, Loss: 1.3688, Time: 3.75s\n",
      "Epoch: 47, Batch: 220/896, Loss: 0.7365, Time: 3.74s\n",
      "Epoch: 47, Batch: 230/896, Loss: 0.5021, Time: 3.75s\n",
      "Epoch: 47, Batch: 240/896, Loss: 0.8563, Time: 3.74s\n",
      "Epoch: 47, Batch: 250/896, Loss: 0.9327, Time: 3.75s\n",
      "Epoch: 47, Batch: 260/896, Loss: 0.3440, Time: 3.74s\n",
      "Epoch: 47, Batch: 270/896, Loss: 0.5799, Time: 3.75s\n",
      "Epoch: 47, Batch: 280/896, Loss: 0.6313, Time: 3.78s\n",
      "Epoch: 47, Batch: 290/896, Loss: 0.4410, Time: 3.76s\n",
      "Epoch: 47, Batch: 300/896, Loss: 0.7341, Time: 3.75s\n",
      "Epoch: 47, Batch: 310/896, Loss: 0.9419, Time: 3.77s\n",
      "Epoch: 47, Batch: 320/896, Loss: 0.5915, Time: 3.74s\n",
      "Epoch: 47, Batch: 330/896, Loss: 0.9481, Time: 3.76s\n",
      "Epoch: 47, Batch: 340/896, Loss: 0.8528, Time: 3.76s\n",
      "Epoch: 47, Batch: 350/896, Loss: 0.4695, Time: 3.76s\n",
      "Epoch: 47, Batch: 360/896, Loss: 0.3776, Time: 3.77s\n",
      "Epoch: 47, Batch: 370/896, Loss: 1.3606, Time: 3.76s\n",
      "Epoch: 47, Batch: 380/896, Loss: 1.1403, Time: 3.76s\n",
      "Epoch: 47, Batch: 390/896, Loss: 0.3147, Time: 3.77s\n",
      "Epoch: 47, Batch: 400/896, Loss: 0.4815, Time: 3.77s\n",
      "Epoch: 47, Batch: 410/896, Loss: 0.8054, Time: 3.76s\n",
      "Epoch: 47, Batch: 420/896, Loss: 0.9712, Time: 3.76s\n",
      "Epoch: 47, Batch: 430/896, Loss: 0.6155, Time: 3.77s\n",
      "Epoch: 47, Batch: 440/896, Loss: 0.7217, Time: 3.77s\n",
      "Epoch: 47, Batch: 450/896, Loss: 0.9606, Time: 3.77s\n",
      "Epoch: 47, Batch: 460/896, Loss: 0.7953, Time: 3.77s\n",
      "Epoch: 47, Batch: 470/896, Loss: 0.5120, Time: 3.77s\n",
      "Epoch: 47, Batch: 480/896, Loss: 0.6687, Time: 3.77s\n",
      "Epoch: 47, Batch: 490/896, Loss: 0.8379, Time: 3.76s\n",
      "Epoch: 47, Batch: 500/896, Loss: 1.1683, Time: 3.76s\n",
      "Epoch: 47, Batch: 510/896, Loss: 0.4256, Time: 3.77s\n",
      "Epoch: 47, Batch: 520/896, Loss: 0.4477, Time: 3.77s\n",
      "Epoch: 47, Batch: 530/896, Loss: 0.8487, Time: 3.79s\n",
      "Epoch: 47, Batch: 540/896, Loss: 0.4345, Time: 3.77s\n",
      "Epoch: 47, Batch: 550/896, Loss: 1.1609, Time: 3.77s\n",
      "Epoch: 47, Batch: 560/896, Loss: 0.7866, Time: 3.77s\n",
      "Epoch: 47, Batch: 570/896, Loss: 0.8574, Time: 3.76s\n",
      "Epoch: 47, Batch: 580/896, Loss: 1.0962, Time: 3.76s\n",
      "Epoch: 47, Batch: 590/896, Loss: 0.5077, Time: 3.78s\n",
      "Epoch: 47, Batch: 600/896, Loss: 1.1463, Time: 3.77s\n",
      "Epoch: 47, Batch: 610/896, Loss: 1.1248, Time: 3.76s\n",
      "Epoch: 47, Batch: 620/896, Loss: 0.6475, Time: 3.77s\n",
      "Epoch: 47, Batch: 630/896, Loss: 1.5198, Time: 3.76s\n",
      "Epoch: 47, Batch: 640/896, Loss: 0.5298, Time: 3.77s\n",
      "Epoch: 47, Batch: 650/896, Loss: 0.5264, Time: 3.77s\n",
      "Epoch: 47, Batch: 660/896, Loss: 0.5657, Time: 3.77s\n",
      "Epoch: 47, Batch: 670/896, Loss: 0.7369, Time: 3.77s\n",
      "Epoch: 47, Batch: 680/896, Loss: 0.4409, Time: 3.78s\n",
      "Epoch: 47, Batch: 690/896, Loss: 0.7641, Time: 3.77s\n",
      "Epoch: 47, Batch: 700/896, Loss: 0.5926, Time: 3.75s\n",
      "Epoch: 47, Batch: 710/896, Loss: 1.0498, Time: 3.77s\n",
      "Epoch: 47, Batch: 720/896, Loss: 1.1624, Time: 3.83s\n",
      "Epoch: 47, Batch: 730/896, Loss: 1.1723, Time: 3.82s\n",
      "Epoch: 47, Batch: 740/896, Loss: 0.6278, Time: 3.81s\n",
      "Epoch: 47, Batch: 750/896, Loss: 0.3213, Time: 3.82s\n",
      "Epoch: 47, Batch: 760/896, Loss: 0.6531, Time: 3.81s\n",
      "Epoch: 47, Batch: 770/896, Loss: 0.7108, Time: 3.83s\n",
      "Epoch: 47, Batch: 780/896, Loss: 0.7908, Time: 3.81s\n",
      "Epoch: 47, Batch: 790/896, Loss: 0.4444, Time: 3.81s\n",
      "Epoch: 47, Batch: 800/896, Loss: 0.7415, Time: 3.83s\n",
      "Epoch: 47, Batch: 810/896, Loss: 1.1101, Time: 3.82s\n",
      "Epoch: 47, Batch: 820/896, Loss: 0.9816, Time: 3.82s\n",
      "Epoch: 47, Batch: 830/896, Loss: 0.3830, Time: 3.81s\n",
      "Epoch: 47, Batch: 840/896, Loss: 0.6194, Time: 3.82s\n",
      "Epoch: 47, Batch: 850/896, Loss: 1.7033, Time: 3.82s\n",
      "Epoch: 47, Batch: 860/896, Loss: 0.6008, Time: 3.82s\n",
      "Epoch: 47, Batch: 870/896, Loss: 0.9140, Time: 3.83s\n",
      "Epoch: 47, Batch: 880/896, Loss: 0.8203, Time: 3.82s\n",
      "Epoch: 47, Batch: 890/896, Loss: 0.4269, Time: 3.82s\n",
      "Epoch 48/50: Train Loss: 0.7589, Val Loss: 0.8194, Val IoU: 0.3765, Val Dice: 0.4003\n",
      "Epoch: 48, Batch: 0/896, Loss: 0.4309, Time: 28.93s\n",
      "Epoch: 48, Batch: 10/896, Loss: 0.5123, Time: 3.77s\n",
      "Epoch: 48, Batch: 20/896, Loss: 0.8826, Time: 3.75s\n",
      "Epoch: 48, Batch: 30/896, Loss: 0.4043, Time: 3.77s\n",
      "Epoch: 48, Batch: 40/896, Loss: 1.4046, Time: 3.76s\n",
      "Epoch: 48, Batch: 50/896, Loss: 1.3228, Time: 3.76s\n",
      "Epoch: 48, Batch: 60/896, Loss: 0.7150, Time: 3.77s\n",
      "Epoch: 48, Batch: 70/896, Loss: 0.9317, Time: 3.76s\n",
      "Epoch: 48, Batch: 80/896, Loss: 0.7282, Time: 3.79s\n",
      "Epoch: 48, Batch: 90/896, Loss: 0.3390, Time: 3.78s\n",
      "Epoch: 48, Batch: 100/896, Loss: 0.7071, Time: 3.78s\n",
      "Epoch: 48, Batch: 110/896, Loss: 0.4245, Time: 3.77s\n",
      "Epoch: 48, Batch: 120/896, Loss: 0.8189, Time: 3.78s\n",
      "Epoch: 48, Batch: 130/896, Loss: 0.3437, Time: 3.79s\n",
      "Epoch: 48, Batch: 140/896, Loss: 0.4348, Time: 3.78s\n",
      "Epoch: 48, Batch: 150/896, Loss: 0.7034, Time: 3.80s\n",
      "Epoch: 48, Batch: 160/896, Loss: 0.5100, Time: 3.79s\n",
      "Epoch: 48, Batch: 170/896, Loss: 0.7690, Time: 3.79s\n",
      "Epoch: 48, Batch: 180/896, Loss: 0.8919, Time: 3.79s\n",
      "Epoch: 48, Batch: 190/896, Loss: 0.4208, Time: 3.80s\n",
      "Epoch: 48, Batch: 200/896, Loss: 0.5876, Time: 3.79s\n",
      "Epoch: 48, Batch: 210/896, Loss: 0.7020, Time: 3.80s\n",
      "Epoch: 48, Batch: 220/896, Loss: 0.5478, Time: 3.81s\n",
      "Epoch: 48, Batch: 230/896, Loss: 1.4560, Time: 3.81s\n",
      "Epoch: 48, Batch: 240/896, Loss: 0.9056, Time: 3.79s\n",
      "Epoch: 48, Batch: 250/896, Loss: 0.7943, Time: 3.82s\n",
      "Epoch: 48, Batch: 260/896, Loss: 1.4083, Time: 3.80s\n",
      "Epoch: 48, Batch: 270/896, Loss: 0.3549, Time: 3.81s\n",
      "Epoch: 48, Batch: 280/896, Loss: 1.0546, Time: 3.81s\n",
      "Epoch: 48, Batch: 290/896, Loss: 0.8608, Time: 3.81s\n",
      "Epoch: 48, Batch: 300/896, Loss: 0.4096, Time: 3.80s\n",
      "Epoch: 48, Batch: 310/896, Loss: 0.8652, Time: 3.81s\n",
      "Epoch: 48, Batch: 320/896, Loss: 0.8537, Time: 3.81s\n",
      "Epoch: 48, Batch: 330/896, Loss: 0.6760, Time: 3.81s\n",
      "Epoch: 48, Batch: 340/896, Loss: 1.3491, Time: 3.80s\n",
      "Epoch: 48, Batch: 350/896, Loss: 0.6483, Time: 3.82s\n",
      "Epoch: 48, Batch: 360/896, Loss: 0.3347, Time: 3.81s\n",
      "Epoch: 48, Batch: 370/896, Loss: 1.1709, Time: 3.81s\n",
      "Epoch: 48, Batch: 380/896, Loss: 0.5266, Time: 3.83s\n",
      "Epoch: 48, Batch: 390/896, Loss: 0.9461, Time: 3.82s\n",
      "Epoch: 48, Batch: 400/896, Loss: 0.7657, Time: 3.82s\n",
      "Epoch: 48, Batch: 410/896, Loss: 0.9549, Time: 3.81s\n",
      "Epoch: 48, Batch: 420/896, Loss: 0.3403, Time: 3.83s\n",
      "Epoch: 48, Batch: 430/896, Loss: 1.0673, Time: 3.82s\n",
      "Epoch: 48, Batch: 440/896, Loss: 1.4215, Time: 3.82s\n",
      "Epoch: 48, Batch: 450/896, Loss: 0.9904, Time: 3.80s\n",
      "Epoch: 48, Batch: 460/896, Loss: 0.4897, Time: 3.82s\n",
      "Epoch: 48, Batch: 470/896, Loss: 0.6810, Time: 3.82s\n",
      "Epoch: 48, Batch: 480/896, Loss: 0.4381, Time: 3.81s\n",
      "Epoch: 48, Batch: 490/896, Loss: 0.2879, Time: 3.81s\n",
      "Epoch: 48, Batch: 500/896, Loss: 0.7937, Time: 3.82s\n",
      "Epoch: 48, Batch: 510/896, Loss: 0.7455, Time: 3.82s\n",
      "Epoch: 48, Batch: 520/896, Loss: 1.3932, Time: 3.83s\n",
      "Epoch: 48, Batch: 530/896, Loss: 1.2496, Time: 3.83s\n",
      "Epoch: 48, Batch: 540/896, Loss: 0.3254, Time: 3.83s\n",
      "Epoch: 48, Batch: 550/896, Loss: 0.5209, Time: 3.82s\n",
      "Epoch: 48, Batch: 560/896, Loss: 0.7411, Time: 3.83s\n",
      "Epoch: 48, Batch: 570/896, Loss: 1.1755, Time: 3.81s\n",
      "Epoch: 48, Batch: 580/896, Loss: 0.4940, Time: 3.82s\n",
      "Epoch: 48, Batch: 590/896, Loss: 0.6371, Time: 3.82s\n",
      "Epoch: 48, Batch: 600/896, Loss: 1.0813, Time: 3.82s\n",
      "Epoch: 48, Batch: 610/896, Loss: 0.5273, Time: 3.82s\n",
      "Epoch: 48, Batch: 620/896, Loss: 0.6654, Time: 3.82s\n",
      "Epoch: 48, Batch: 630/896, Loss: 0.5129, Time: 3.80s\n",
      "Epoch: 48, Batch: 640/896, Loss: 1.6205, Time: 3.82s\n",
      "Epoch: 48, Batch: 650/896, Loss: 0.7018, Time: 3.82s\n",
      "Epoch: 48, Batch: 660/896, Loss: 0.9049, Time: 3.82s\n",
      "Epoch: 48, Batch: 670/896, Loss: 0.3784, Time: 3.82s\n",
      "Epoch: 48, Batch: 680/896, Loss: 0.5646, Time: 3.81s\n",
      "Epoch: 48, Batch: 690/896, Loss: 0.9300, Time: 3.82s\n",
      "Epoch: 48, Batch: 700/896, Loss: 1.2806, Time: 3.82s\n",
      "Epoch: 48, Batch: 710/896, Loss: 0.8728, Time: 3.82s\n",
      "Epoch: 48, Batch: 720/896, Loss: 0.5766, Time: 3.83s\n",
      "Epoch: 48, Batch: 730/896, Loss: 0.5380, Time: 3.83s\n",
      "Epoch: 48, Batch: 740/896, Loss: 0.6171, Time: 3.81s\n",
      "Epoch: 48, Batch: 750/896, Loss: 0.6128, Time: 3.83s\n",
      "Epoch: 48, Batch: 760/896, Loss: 0.3764, Time: 3.81s\n",
      "Epoch: 48, Batch: 770/896, Loss: 0.7277, Time: 3.83s\n",
      "Epoch: 48, Batch: 780/896, Loss: 0.9180, Time: 3.82s\n",
      "Epoch: 48, Batch: 790/896, Loss: 0.8233, Time: 3.82s\n",
      "Epoch: 48, Batch: 800/896, Loss: 0.7801, Time: 3.82s\n",
      "Epoch: 48, Batch: 810/896, Loss: 0.5540, Time: 3.82s\n",
      "Epoch: 48, Batch: 820/896, Loss: 0.3811, Time: 3.81s\n",
      "Epoch: 48, Batch: 830/896, Loss: 0.4984, Time: 3.83s\n",
      "Epoch: 48, Batch: 840/896, Loss: 1.5047, Time: 3.82s\n",
      "Epoch: 48, Batch: 850/896, Loss: 1.3868, Time: 3.82s\n",
      "Epoch: 48, Batch: 860/896, Loss: 0.8794, Time: 3.83s\n",
      "Epoch: 48, Batch: 870/896, Loss: 0.8422, Time: 3.82s\n",
      "Epoch: 48, Batch: 880/896, Loss: 1.0053, Time: 3.83s\n",
      "Epoch: 48, Batch: 890/896, Loss: 0.6629, Time: 3.83s\n",
      "Epoch 49/50: Train Loss: 0.7557, Val Loss: 0.8182, Val IoU: 0.3772, Val Dice: 0.4005\n",
      "Epoch: 49, Batch: 0/896, Loss: 0.4609, Time: 29.11s\n",
      "Epoch: 49, Batch: 10/896, Loss: 0.8075, Time: 3.76s\n",
      "Epoch: 49, Batch: 20/896, Loss: 1.0080, Time: 3.76s\n",
      "Epoch: 49, Batch: 30/896, Loss: 0.8290, Time: 3.77s\n",
      "Epoch: 49, Batch: 40/896, Loss: 0.6778, Time: 3.77s\n",
      "Epoch: 49, Batch: 50/896, Loss: 1.3166, Time: 3.78s\n",
      "Epoch: 49, Batch: 60/896, Loss: 0.9764, Time: 3.78s\n",
      "Epoch: 49, Batch: 70/896, Loss: 0.5130, Time: 3.77s\n",
      "Epoch: 49, Batch: 80/896, Loss: 0.6140, Time: 3.78s\n",
      "Epoch: 49, Batch: 90/896, Loss: 0.7699, Time: 3.77s\n",
      "Epoch: 49, Batch: 100/896, Loss: 0.8224, Time: 3.78s\n",
      "Epoch: 49, Batch: 110/896, Loss: 0.4250, Time: 3.78s\n",
      "Epoch: 49, Batch: 120/896, Loss: 0.8211, Time: 3.79s\n",
      "Epoch: 49, Batch: 130/896, Loss: 1.2624, Time: 3.78s\n",
      "Epoch: 49, Batch: 140/896, Loss: 0.7224, Time: 3.80s\n",
      "Epoch: 49, Batch: 150/896, Loss: 0.5679, Time: 3.79s\n",
      "Epoch: 49, Batch: 160/896, Loss: 0.9083, Time: 3.80s\n",
      "Epoch: 49, Batch: 170/896, Loss: 0.5673, Time: 3.80s\n",
      "Epoch: 49, Batch: 180/896, Loss: 0.5929, Time: 3.80s\n",
      "Epoch: 49, Batch: 190/896, Loss: 0.6501, Time: 3.80s\n",
      "Epoch: 49, Batch: 200/896, Loss: 0.4528, Time: 3.80s\n",
      "Epoch: 49, Batch: 210/896, Loss: 0.4355, Time: 3.79s\n",
      "Epoch: 49, Batch: 220/896, Loss: 0.6157, Time: 3.79s\n",
      "Epoch: 49, Batch: 230/896, Loss: 0.3454, Time: 3.80s\n",
      "Epoch: 49, Batch: 240/896, Loss: 0.6630, Time: 3.80s\n",
      "Epoch: 49, Batch: 250/896, Loss: 0.3802, Time: 3.80s\n",
      "Epoch: 49, Batch: 260/896, Loss: 0.3497, Time: 3.82s\n",
      "Epoch: 49, Batch: 270/896, Loss: 0.9041, Time: 3.81s\n",
      "Epoch: 49, Batch: 280/896, Loss: 0.5884, Time: 3.82s\n",
      "Epoch: 49, Batch: 290/896, Loss: 0.8090, Time: 3.81s\n",
      "Epoch: 49, Batch: 300/896, Loss: 0.9393, Time: 3.82s\n",
      "Epoch: 49, Batch: 310/896, Loss: 0.7252, Time: 3.81s\n",
      "Epoch: 49, Batch: 320/896, Loss: 0.6957, Time: 3.82s\n",
      "Epoch: 49, Batch: 330/896, Loss: 0.9234, Time: 3.81s\n",
      "Epoch: 49, Batch: 340/896, Loss: 1.1355, Time: 3.81s\n",
      "Epoch: 49, Batch: 350/896, Loss: 1.6008, Time: 3.82s\n",
      "Epoch: 49, Batch: 360/896, Loss: 0.4866, Time: 3.82s\n",
      "Epoch: 49, Batch: 370/896, Loss: 0.7105, Time: 3.80s\n",
      "Epoch: 49, Batch: 380/896, Loss: 0.5316, Time: 3.81s\n",
      "Epoch: 49, Batch: 390/896, Loss: 0.4666, Time: 3.83s\n",
      "Epoch: 49, Batch: 400/896, Loss: 0.5551, Time: 3.82s\n",
      "Epoch: 49, Batch: 410/896, Loss: 1.1264, Time: 3.81s\n",
      "Epoch: 49, Batch: 420/896, Loss: 0.7638, Time: 3.83s\n",
      "Epoch: 49, Batch: 430/896, Loss: 0.4278, Time: 3.83s\n",
      "Epoch: 49, Batch: 440/896, Loss: 0.5024, Time: 3.82s\n",
      "Epoch: 49, Batch: 450/896, Loss: 0.7138, Time: 3.81s\n",
      "Epoch: 49, Batch: 460/896, Loss: 0.6545, Time: 3.82s\n",
      "Epoch: 49, Batch: 470/896, Loss: 0.6459, Time: 3.82s\n",
      "Epoch: 49, Batch: 480/896, Loss: 0.4801, Time: 3.81s\n",
      "Epoch: 49, Batch: 490/896, Loss: 0.8222, Time: 3.82s\n",
      "Epoch: 49, Batch: 500/896, Loss: 0.4591, Time: 3.82s\n",
      "Epoch: 49, Batch: 510/896, Loss: 0.7665, Time: 3.82s\n",
      "Epoch: 49, Batch: 520/896, Loss: 0.3690, Time: 3.81s\n",
      "Epoch: 49, Batch: 530/896, Loss: 0.8594, Time: 3.82s\n",
      "Epoch: 49, Batch: 540/896, Loss: 1.0770, Time: 3.81s\n",
      "Epoch: 49, Batch: 550/896, Loss: 1.1722, Time: 3.81s\n",
      "Epoch: 49, Batch: 560/896, Loss: 0.8884, Time: 3.82s\n",
      "Epoch: 49, Batch: 570/896, Loss: 0.5311, Time: 3.82s\n",
      "Epoch: 49, Batch: 580/896, Loss: 0.4157, Time: 3.81s\n",
      "Epoch: 49, Batch: 590/896, Loss: 0.9586, Time: 3.82s\n",
      "Epoch: 49, Batch: 600/896, Loss: 0.6544, Time: 3.81s\n",
      "Epoch: 49, Batch: 610/896, Loss: 0.7717, Time: 3.83s\n",
      "Epoch: 49, Batch: 620/896, Loss: 0.6663, Time: 3.82s\n",
      "Epoch: 49, Batch: 630/896, Loss: 0.2583, Time: 3.82s\n",
      "Epoch: 49, Batch: 640/896, Loss: 0.2465, Time: 3.84s\n",
      "Epoch: 49, Batch: 650/896, Loss: 0.3821, Time: 3.82s\n",
      "Epoch: 49, Batch: 660/896, Loss: 0.8200, Time: 3.82s\n",
      "Epoch: 49, Batch: 670/896, Loss: 1.4949, Time: 3.82s\n",
      "Epoch: 49, Batch: 680/896, Loss: 1.7561, Time: 3.83s\n",
      "Epoch: 49, Batch: 690/896, Loss: 0.8342, Time: 3.82s\n",
      "Epoch: 49, Batch: 700/896, Loss: 0.5987, Time: 3.81s\n",
      "Epoch: 49, Batch: 710/896, Loss: 0.4345, Time: 3.82s\n",
      "Epoch: 49, Batch: 720/896, Loss: 0.8524, Time: 3.83s\n",
      "Epoch: 49, Batch: 730/896, Loss: 0.9794, Time: 3.81s\n",
      "Epoch: 49, Batch: 740/896, Loss: 0.9090, Time: 3.81s\n",
      "Epoch: 49, Batch: 750/896, Loss: 0.9619, Time: 3.85s\n",
      "Epoch: 49, Batch: 760/896, Loss: 1.1517, Time: 3.82s\n",
      "Epoch: 49, Batch: 770/896, Loss: 0.4378, Time: 3.83s\n",
      "Epoch: 49, Batch: 780/896, Loss: 1.4702, Time: 3.83s\n",
      "Epoch: 49, Batch: 790/896, Loss: 0.4435, Time: 3.81s\n",
      "Epoch: 49, Batch: 800/896, Loss: 0.6424, Time: 3.83s\n",
      "Epoch: 49, Batch: 810/896, Loss: 0.5462, Time: 3.82s\n",
      "Epoch: 49, Batch: 820/896, Loss: 0.4967, Time: 3.82s\n",
      "Epoch: 49, Batch: 830/896, Loss: 0.4670, Time: 3.82s\n",
      "Epoch: 49, Batch: 840/896, Loss: 0.5407, Time: 3.83s\n",
      "Epoch: 49, Batch: 850/896, Loss: 1.3064, Time: 3.82s\n",
      "Epoch: 49, Batch: 860/896, Loss: 0.3927, Time: 3.82s\n",
      "Epoch: 49, Batch: 870/896, Loss: 0.8212, Time: 3.82s\n",
      "Epoch: 49, Batch: 880/896, Loss: 1.5945, Time: 3.82s\n",
      "Epoch: 49, Batch: 890/896, Loss: 0.8374, Time: 3.82s\n",
      "Epoch 50/50: Train Loss: 0.7545, Val Loss: 0.8377, Val IoU: 0.3697, Val Dice: 0.3937\n",
      "Training complete! Best IoU: 0.3797\n",
      "Models saved to landcover_pabbi_satellite/unet_models\n",
      "Training curves saved to landcover_pabbi_satellite/unet_models\\training_curves.png\n"
     ]
    }
   ],
   "source": [
    "# Train U-Net model\n",
    "geoai.train_segmentation_model(\n",
    "    images_dir=f\"{out_folder}/images\",\n",
    "    labels_dir=f\"{out_folder}/labels\",\n",
    "    output_dir=f\"{out_folder}/unet_models\",\n",
    "    architecture=\"unet\",\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    num_channels=4,\n",
    "    num_classes=13,\n",
    "    batch_size=8,\n",
    "    num_epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    val_split=0.2,\n",
    "    verbose=True,\n",
    "    plot_curves=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "masks_path = \"naip_test_semantic_prediction.tif\"\n",
    "model_path = f\"{out_folder}/unet_models/best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run semantic segmentation inference\n",
    "geoai.semantic_segmentation(\n",
    "    input_path=test_raster_path,\n",
    "    output_path=masks_path,\n",
    "    model_path=model_path,\n",
    "    architecture=\"unet\",\n",
    "    encoder_name=\"resnet34\",\n",
    "    num_channels=4,\n",
    "    num_classes=13,\n",
    "    window_size=512,\n",
    "    overlap=256,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36029dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masks_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m geoai.write_colormap(\u001b[43mmasks_path\u001b[49m, train_landcover_path, output=masks_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'masks_path' is not defined"
     ]
    }
   ],
   "source": [
    "geoai.write_colormap(masks_path, train_landcover_path, output=masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f97930",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.view_raster(masks_path, basemap=test_raster_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
