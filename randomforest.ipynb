{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34818cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "export_harmonics_rf.py - Google Earth Engine NDVI Analysis with Random Forest\n",
    "\"\"\"\n",
    "import ee\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print(\"Earth Engine initialized successfully\")\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n",
    "class Config:\n",
    "    # Time Parameters\n",
    "    START_DATE = '2022-10-01'\n",
    "    END_DATE = '2023-06-02'\n",
    "    \n",
    "    # Cloud Masking Parameters\n",
    "    CLOUD_FILTER = 60\n",
    "    CLD_PRB_THRESH = 50\n",
    "    NIR_DRK_THRESH = 0.15\n",
    "    CLD_PRJ_DIST = 1\n",
    "    BUFFER = 50\n",
    "    \n",
    "    # RF Parameters\n",
    "    NUM_TREES = 100\n",
    "    RF_VARIABLES = ['B2', 'B3', 'B4', 'B8', 'NDVI', 't']\n",
    "    \n",
    "    # Area Parameters\n",
    "    AOI_COUNTRY_CODE = 256\n",
    "    CRS = 'EPSG:27700'\n",
    "    \n",
    "    # Export Parameters\n",
    "    EXPORT_FOLDER = 'GEE_Exports'\n",
    "    EXPORT_PREFIX = 'rf_ndvi_analysis_'\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Helper Functions\n",
    "def print_info(collection, name):\n",
    "    size = collection.size().getInfo()\n",
    "    date_range = ee.Image(collection.first()).date().format('YYYY-MM-dd').getInfo()\n",
    "    print(f\"{name}: {size} images from {date_range}\")\n",
    "\n",
    "# Core Processing Functions \n",
    "def get_s2_collection(aoi, start_date, end_date):\n",
    "    s2_sr = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cfg.CLOUD_FILTER)))\n",
    "    \n",
    "    s2_cloudless = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "    \n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(\n",
    "        primary=s2_sr,\n",
    "        secondary=s2_cloudless,\n",
    "        condition=ee.Filter.equals(\n",
    "            leftField='system:index',\n",
    "            rightField='system:index'\n",
    "        )\n",
    "    ))\n",
    "\n",
    "def add_time_variables(img):\n",
    "    date = ee.Date(img.get('system:time_start'))\n",
    "    years = date.difference(ee.Date('1970-01-01'), 'year')\n",
    "    return img.addBands(ee.Image(years).rename('t'))\n",
    "\n",
    "def add_ndvi(img):\n",
    "    return img.addBands(\n",
    "        img.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    )\n",
    "\n",
    "def prepare_training_data(collection):\n",
    "    \"\"\"Converts ImageCollection to FeatureCollection for ML\"\"\"\n",
    "    return collection.map(lambda img: \n",
    "        img.select(cfg.RF_VARIABLES)\n",
    "        .sample(region=aoi, scale=10, numPixels=500)\n",
    "    ).flatten()\n",
    "\n",
    "# Main Processing Chain\n",
    "def main():\n",
    "    # 1. Set up Area of Interest\n",
    "    aoi = ee.FeatureCollection('FAO/GAUL/2015/level0') \\\n",
    "            .filterMetadata('ADM0_CODE', 'equals', cfg.AOI_COUNTRY_CODE)\n",
    "    print(f\"AOI: {aoi.first().get('ADM0_NAME').getInfo()}\")\n",
    "\n",
    "    # 2. Get and preprocess Sentinel-2 data\n",
    "    s2_col = get_s2_collection(aoi, cfg.START_DATE, cfg.END_DATE)\n",
    "    processed_col = s2_col.map(add_time_variables).map(add_ndvi)\n",
    "    print_info(processed_col, \"Processed Collection\")\n",
    "\n",
    "    # 3. Prepare training data\n",
    "    training_data = prepare_training_data(processed_col)\n",
    "    print(f\"Training samples: {training_data.size().getInfo()}\")\n",
    "\n",
    "    # 4. Train Random Forest model\n",
    "    classifier = ee.Classifier.smileRandomForest(cfg.NUM_TREES) \\\n",
    "        .train(\n",
    "            features=training_data,\n",
    "            classProperty='NDVI',  # Regression mode\n",
    "            inputProperties=cfg.RF_VARIABLES\n",
    "        )\n",
    "\n",
    "    # 5. Apply model to entire collection\n",
    "    classified_col = processed_col.map(lambda img: \n",
    "        img.addBands(\n",
    "            img.classify(classifier, 'rf_prediction')\n",
    "    )\n",
    "\n",
    "    # 6. Create time series predictions\n",
    "    rf_median = classified_col.select('rf_prediction').median()\n",
    "\n",
    "    # 7. Export results\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=rf_median.clip(aoi),\n",
    "        description='RF_NDVI_Prediction',\n",
    "        folder=cfg.EXPORT_FOLDER,\n",
    "        fileNamePrefix=f\"{cfg.EXPORT_PREFIX}{timestamp}\",\n",
    "        region=aoi.geometry(),\n",
    "        scale=10,\n",
    "        crs=cfg.CRS,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Export started with Task ID: {task.id}\")\n",
    "    print(f\"Monitor at: https://code.earthengine.google.com/tasks\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
