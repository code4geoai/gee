{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd4d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import geoai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f1f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_imagery = './pabbi_satellite_image_COG.tif'\n",
    "vector_file = './pabb_crop_V3.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3744485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parcels 7012\n",
      "Number of Parcels with values (other than null): 6515\n",
      "Details of Crop are : Landuse_Ma\n",
      "Agriculture     5759\n",
      "Stream           302\n",
      "Other            229\n",
      "Road/Streets     172\n",
      "Graveyard         29\n",
      "Built up          24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gdf = gpd.read_file(vector_file)\n",
    "\n",
    "print(f\"Total Number of Parcels {len(gdf)}\")\n",
    "\n",
    "print(f\"Number of Parcels with values (other than null): {gdf['Landuse_Ma'].notna().sum()}\")\n",
    "\n",
    "print(f\"Details of Crop are : {gdf['Landuse_Ma'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c6c46",
   "metadata": {},
   "source": [
    "# Setting Class Ids for Land use Before generating Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d007496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    'Agriculture': 1,\n",
    "    'Stream': 2,\n",
    "    'Other': 3,\n",
    "    'Road/Streets': 4,\n",
    "    'Graveyard': 5,\n",
    "    'Built up': 6\n",
    "}\n",
    "\n",
    "gdf['class_id'] = gdf['Landuse_Ma'].map(label_map)\n",
    "\n",
    "gdf = gdf[gdf['class_id'].notna()]\n",
    "gdf['class_id'] = gdf['class_id'].astype('uint8')\n",
    "gdf=gdf.to_crs('EPSG:4326')\n",
    "print(gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5a4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 2 4 5 3]\n",
      "0\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(gdf['class_id'].unique())\n",
    "print(gdf['class_id'].isnull().sum())\n",
    "print(gdf['class_id'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c3d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to temporary file\n",
    "gdf.to_file('temp_cleaned_vector.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e0a59",
   "metadata": {},
   "source": [
    "This code didnot work so i have to use the above code for manual vector to raster conversion.\n",
    "geoai.vector_to_raster(\n",
    "    vector_path=vector_file,\n",
    "    reference_raster=satellite_imagery,\n",
    "    attribute_field='class_id',\n",
    "    output_path='Labelraster_For_Unet_v4.tif',\n",
    "    dtype='uint8',\n",
    "    plot_result=True,\n",
    "    nodata=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b0114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_e47590984ed90a755185e459306da7d5 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet.fullscreen@3.0.0/Control.FullScreen.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet.fullscreen@3.0.0/Control.FullScreen.css&quot;/&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.draw/1.0.2/leaflet.draw.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.draw/1.0.2/leaflet.draw.css&quot;/&gt;\n",
       "    &lt;script src=&quot;https://unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/leaflet-control-geocoder/dist/Control.Geocoder.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_e47590984ed90a755185e459306da7d5&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_e47590984ed90a755185e459306da7d5 = L.map(\n",
       "                &quot;map_e47590984ed90a755185e459306da7d5&quot;,\n",
       "                {\n",
       "                    center: [20.0, 0.0],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 2,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "  &quot;drawExport&quot;: false,\n",
       "  &quot;layersControl&quot;: true,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "            L.control.scale().addTo(map_e47590984ed90a755185e459306da7d5);\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_e98997100ac746a038663b09800fd39c = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 24,\n",
       "  &quot;maxNativeZoom&quot;: 24,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_e98997100ac746a038663b09800fd39c.addTo(map_e47590984ed90a755185e459306da7d5);\n",
       "        \n",
       "    \n",
       "            L.control.fullscreen(\n",
       "                {\n",
       "  &quot;position&quot;: &quot;topleft&quot;,\n",
       "  &quot;title&quot;: &quot;Full Screen&quot;,\n",
       "  &quot;titleCancel&quot;: &quot;Exit Full Screen&quot;,\n",
       "  &quot;forceSeparateButton&quot;: false,\n",
       "}\n",
       "            ).addTo(map_e47590984ed90a755185e459306da7d5);\n",
       "        \n",
       "    \n",
       "            var options = {\n",
       "              position: &quot;topleft&quot;,\n",
       "              draw: {},\n",
       "              edit: {},\n",
       "            }\n",
       "                // FeatureGroup is to store editable layers.\n",
       "                var drawnItems_draw_control_236f0532fcff1a7490fceacc78786b24 =\n",
       "                    new L.featureGroup().addTo(\n",
       "                        map_e47590984ed90a755185e459306da7d5\n",
       "                    );\n",
       "\n",
       "            options.edit.featureGroup = drawnItems_draw_control_236f0532fcff1a7490fceacc78786b24;\n",
       "            var draw_control_236f0532fcff1a7490fceacc78786b24 = new L.Control.Draw(\n",
       "                options\n",
       "            ).addTo( map_e47590984ed90a755185e459306da7d5 );\n",
       "            map_e47590984ed90a755185e459306da7d5.on(L.Draw.Event.CREATED, function(e) {\n",
       "                var layer = e.layer,\n",
       "                    type = e.layerType;\n",
       "                var coords = JSON.stringify(layer.toGeoJSON());\n",
       "                layer.on(&#x27;click&#x27;, function() {\n",
       "                    alert(coords);\n",
       "                    console.log(coords);\n",
       "                });\n",
       "                drawnItems_draw_control_236f0532fcff1a7490fceacc78786b24.addLayer(layer);\n",
       "            });\n",
       "            map_e47590984ed90a755185e459306da7d5.on(&#x27;draw:created&#x27;, function(e) {\n",
       "                drawnItems_draw_control_236f0532fcff1a7490fceacc78786b24.addLayer(e.layer);\n",
       "            });\n",
       "\n",
       "            \n",
       "        \n",
       "    \n",
       "\n",
       "            var geocoderOpts_geocoder_d3a09c0d435f43b535d0dbd7584e3833 = {\n",
       "  &quot;collapsed&quot;: true,\n",
       "  &quot;position&quot;: &quot;topleft&quot;,\n",
       "  &quot;defaultMarkGeocode&quot;: true,\n",
       "  &quot;zoom&quot;: 11,\n",
       "  &quot;provider&quot;: &quot;nominatim&quot;,\n",
       "  &quot;providerOptions&quot;: {\n",
       "},\n",
       "};\n",
       "\n",
       "            // note: geocoder name should start with lowercase\n",
       "            var geocoderName_geocoder_d3a09c0d435f43b535d0dbd7584e3833 = geocoderOpts_geocoder_d3a09c0d435f43b535d0dbd7584e3833[&quot;provider&quot;];\n",
       "\n",
       "            var customGeocoder_geocoder_d3a09c0d435f43b535d0dbd7584e3833 = L.Control.Geocoder[ geocoderName_geocoder_d3a09c0d435f43b535d0dbd7584e3833 ](\n",
       "                geocoderOpts_geocoder_d3a09c0d435f43b535d0dbd7584e3833[&#x27;providerOptions&#x27;]\n",
       "            );\n",
       "            geocoderOpts_geocoder_d3a09c0d435f43b535d0dbd7584e3833[&quot;geocoder&quot;] = customGeocoder_geocoder_d3a09c0d435f43b535d0dbd7584e3833;\n",
       "\n",
       "            L.Control.geocoder(\n",
       "                geocoderOpts_geocoder_d3a09c0d435f43b535d0dbd7584e3833\n",
       "            ).on(&#x27;markgeocode&#x27;, function(e) {\n",
       "                var zoom = geocoderOpts_geocoder_d3a09c0d435f43b535d0dbd7584e3833[&#x27;zoom&#x27;] || map_e47590984ed90a755185e459306da7d5.getZoom();\n",
       "                map_e47590984ed90a755185e459306da7d5.setView(e.geocode.center, zoom);\n",
       "            }).addTo(map_e47590984ed90a755185e459306da7d5);\n",
       "\n",
       "        \n",
       "    \n",
       "            map_e47590984ed90a755185e459306da7d5.fitBounds(\n",
       "                [[20, 0], [20, 0]],\n",
       "                {&quot;maxZoom&quot;: 2}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var tile_layer_6cbfcae3b3c2400906354a2050727317 = L.tileLayer(\n",
       "                &quot;http://localhost:57355/api/tiles/{z}/{x}/{y}.png?\\u0026filename=d%3A%5CTrainings%5Cgee%5CLabelraster_Manual.tif\\u0026colormap=tab20&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 30,\n",
       "  &quot;maxNativeZoom&quot;: 30,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;Raster file served by \\u003ca href=\\u0027https://github.com/banesullivan/localtileserver\\u0027 target=\\u0027_blank\\u0027\\u003elocaltileserver\\u003c/a\\u003e.&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1.0,\n",
       "  &quot;bounds&quot;: [[33.986465, 71.73165], [34.04837, 71.815998]],\n",
       "  &quot;zoomToLayer&quot;: true,\n",
       "  &quot;visible&quot;: true,\n",
       "  &quot;corsAll&quot;: false,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_6cbfcae3b3c2400906354a2050727317.addTo(map_e47590984ed90a755185e459306da7d5);\n",
       "        \n",
       "    \n",
       "            map_e47590984ed90a755185e459306da7d5.fitBounds(\n",
       "                [[33.986465, 71.73165], [34.04837, 71.815998]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var layer_control_79845be439f4b525250790291a8e8994_layers = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_e98997100ac746a038663b09800fd39c,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Raster&quot; : tile_layer_6cbfcae3b3c2400906354a2050727317,\n",
       "                },\n",
       "            };\n",
       "            let layer_control_79845be439f4b525250790291a8e8994 = L.control.layers(\n",
       "                layer_control_79845be439f4b525250790291a8e8994_layers.base_layers,\n",
       "                layer_control_79845be439f4b525250790291a8e8994_layers.overlays,\n",
       "                {\n",
       "  &quot;position&quot;: &quot;topright&quot;,\n",
       "  &quot;collapsed&quot;: true,\n",
       "  &quot;autoZIndex&quot;: true,\n",
       "}\n",
       "            ).addTo(map_e47590984ed90a755185e459306da7d5);\n",
       "\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" width=\"100%\" height=\"600\"style=\"border:none !important;\" \"allowfullscreen\" \"webkitallowfullscreen\" \"mozallowfullscreen\"></iframe>"
      ],
      "text/plain": [
       "<leafmap.foliumap.Map at 0x1fccad72de0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoai.view_raster('Labelraster_Manual.tif', cmap='tab20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52ef2d",
   "metadata": {},
   "source": [
    "# Unet Part to create image tiles / patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b048255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_path = 'temp_cleaned_vector.geojson'\n",
    "labeled_raster_path = 'labelraster_Manual.tif'\n",
    "out_folder = 'landcover_pabbi_satellite2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18575b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected in_class_data as raster: labelraster_Manual.tif\n",
      "Raster CRS: EPSG:4326\n",
      "Raster dimensions: 31447 x 23080\n",
      "\n",
      "Raster info for ./pabbi_satellite_image_COG.tif:\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 31447 x 23080\n",
      "  Resolution: (2.6822089999998085e-06, 2.682208999999812e-06)\n",
      "  Bands: 3\n",
      "  Bounds: BoundingBox(left=71.731650084257, bottom=33.986464888201006, right=71.81599751067999, top=34.048370271921)\n",
      "Found 6 unique classes in raster: [1 2 3 4 5 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated: 16753, With features: 16753: 100%|██████████| 44100/44100 [07:00<00:00, 104.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Export Summary -------\n",
      "Total tiles exported: 16753\n",
      "Tiles with features: 16753 (100.0%)\n",
      "Average feature pixels per tile: 117714.2\n",
      "Output saved to: landcover_pabbi_satellite2\n",
      "\n",
      "------- Georeference Verification -------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tiles = geoai.export_geotiff_tiles(\n",
    "    in_raster = satellite_imagery,\n",
    "    out_folder= out_folder,\n",
    "    in_class_data= labeled_raster_path,\n",
    "    #class_value_field= 'labels',\n",
    "    tile_size=256,\n",
    "    stride=128,\n",
    "    buffer_radius=0,\n",
    "    skip_empty_tiles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 16753 image files and 16753 label files\n",
      "Training on 13402 images, validating on 3351 images\n",
      "Starting training with unet + resnet34\n",
      "Model parameters: 24,441,245\n",
      "Epoch: 0, Batch: 0/1676, Loss: 2.6744, Time: 37.38s\n",
      "Epoch: 0, Batch: 10/1676, Loss: 1.6480, Time: 2.06s\n",
      "Epoch: 0, Batch: 20/1676, Loss: 1.2370, Time: 2.04s\n",
      "Epoch: 0, Batch: 30/1676, Loss: 0.8287, Time: 2.06s\n",
      "Epoch: 0, Batch: 40/1676, Loss: 0.5270, Time: 2.05s\n",
      "Epoch: 0, Batch: 50/1676, Loss: 0.4519, Time: 2.05s\n",
      "Epoch: 0, Batch: 60/1676, Loss: 1.6450, Time: 2.05s\n",
      "Epoch: 0, Batch: 70/1676, Loss: 0.7865, Time: 2.05s\n",
      "Epoch: 0, Batch: 80/1676, Loss: 1.1752, Time: 2.06s\n",
      "Epoch: 0, Batch: 90/1676, Loss: 1.3902, Time: 2.06s\n",
      "Epoch: 0, Batch: 100/1676, Loss: 0.9501, Time: 2.06s\n",
      "Epoch: 0, Batch: 110/1676, Loss: 0.8420, Time: 2.05s\n",
      "Epoch: 0, Batch: 120/1676, Loss: 0.5599, Time: 2.06s\n",
      "Epoch: 0, Batch: 130/1676, Loss: 1.1044, Time: 2.06s\n",
      "Epoch: 0, Batch: 140/1676, Loss: 1.2360, Time: 2.06s\n",
      "Epoch: 0, Batch: 150/1676, Loss: 0.7091, Time: 2.02s\n",
      "Epoch: 0, Batch: 160/1676, Loss: 0.4708, Time: 2.03s\n",
      "Epoch: 0, Batch: 170/1676, Loss: 1.5725, Time: 2.04s\n",
      "Epoch: 0, Batch: 180/1676, Loss: 1.0322, Time: 2.03s\n",
      "Epoch: 0, Batch: 190/1676, Loss: 0.6296, Time: 2.04s\n",
      "Epoch: 0, Batch: 200/1676, Loss: 1.0505, Time: 2.05s\n",
      "Epoch: 0, Batch: 210/1676, Loss: 0.4732, Time: 2.04s\n",
      "Epoch: 0, Batch: 220/1676, Loss: 1.3982, Time: 2.04s\n",
      "Epoch: 0, Batch: 230/1676, Loss: 1.2124, Time: 2.04s\n",
      "Epoch: 0, Batch: 240/1676, Loss: 0.7022, Time: 2.04s\n",
      "Epoch: 0, Batch: 250/1676, Loss: 0.9625, Time: 2.04s\n",
      "Epoch: 0, Batch: 260/1676, Loss: 1.2420, Time: 2.03s\n",
      "Epoch: 0, Batch: 270/1676, Loss: 0.7470, Time: 2.04s\n",
      "Epoch: 0, Batch: 280/1676, Loss: 0.8071, Time: 2.04s\n",
      "Epoch: 0, Batch: 290/1676, Loss: 0.6649, Time: 2.05s\n",
      "Epoch: 0, Batch: 300/1676, Loss: 0.7104, Time: 2.05s\n",
      "Epoch: 0, Batch: 310/1676, Loss: 0.6013, Time: 2.05s\n",
      "Epoch: 0, Batch: 320/1676, Loss: 0.3432, Time: 2.05s\n",
      "Epoch: 0, Batch: 330/1676, Loss: 1.1838, Time: 2.05s\n",
      "Epoch: 0, Batch: 340/1676, Loss: 0.5909, Time: 2.05s\n",
      "Epoch: 0, Batch: 350/1676, Loss: 0.4654, Time: 2.05s\n",
      "Epoch: 0, Batch: 360/1676, Loss: 1.2081, Time: 2.05s\n",
      "Epoch: 0, Batch: 370/1676, Loss: 0.8280, Time: 2.05s\n",
      "Epoch: 0, Batch: 380/1676, Loss: 1.0892, Time: 2.06s\n",
      "Epoch: 0, Batch: 390/1676, Loss: 0.7994, Time: 2.06s\n",
      "Epoch: 0, Batch: 400/1676, Loss: 0.8273, Time: 2.06s\n",
      "Epoch: 0, Batch: 410/1676, Loss: 0.6216, Time: 2.06s\n",
      "Epoch: 0, Batch: 420/1676, Loss: 0.7487, Time: 2.06s\n",
      "Epoch: 0, Batch: 430/1676, Loss: 0.4841, Time: 2.05s\n",
      "Epoch: 0, Batch: 440/1676, Loss: 0.6362, Time: 2.06s\n",
      "Epoch: 0, Batch: 450/1676, Loss: 0.7735, Time: 2.05s\n",
      "Epoch: 0, Batch: 460/1676, Loss: 0.6167, Time: 2.04s\n",
      "Epoch: 0, Batch: 470/1676, Loss: 0.8226, Time: 2.05s\n",
      "Epoch: 0, Batch: 480/1676, Loss: 0.6144, Time: 2.06s\n",
      "Epoch: 0, Batch: 490/1676, Loss: 0.2565, Time: 2.06s\n",
      "Epoch: 0, Batch: 500/1676, Loss: 0.6240, Time: 2.05s\n",
      "Epoch: 0, Batch: 510/1676, Loss: 0.4245, Time: 2.05s\n",
      "Epoch: 0, Batch: 520/1676, Loss: 0.7978, Time: 2.06s\n",
      "Epoch: 0, Batch: 530/1676, Loss: 0.6224, Time: 2.06s\n",
      "Epoch: 0, Batch: 540/1676, Loss: 0.4195, Time: 2.05s\n",
      "Epoch: 0, Batch: 550/1676, Loss: 0.7406, Time: 2.06s\n",
      "Epoch: 0, Batch: 560/1676, Loss: 0.5694, Time: 2.05s\n",
      "Epoch: 0, Batch: 570/1676, Loss: 1.0707, Time: 2.06s\n",
      "Epoch: 0, Batch: 580/1676, Loss: 1.1263, Time: 2.05s\n",
      "Epoch: 0, Batch: 590/1676, Loss: 0.8781, Time: 2.06s\n",
      "Epoch: 0, Batch: 600/1676, Loss: 0.7834, Time: 2.05s\n",
      "Epoch: 0, Batch: 610/1676, Loss: 0.8846, Time: 2.05s\n",
      "Epoch: 0, Batch: 620/1676, Loss: 1.1518, Time: 2.05s\n",
      "Epoch: 0, Batch: 630/1676, Loss: 0.5499, Time: 2.06s\n",
      "Epoch: 0, Batch: 640/1676, Loss: 1.0566, Time: 2.05s\n",
      "Epoch: 0, Batch: 650/1676, Loss: 1.5895, Time: 2.06s\n",
      "Epoch: 0, Batch: 660/1676, Loss: 0.8018, Time: 2.05s\n",
      "Epoch: 0, Batch: 670/1676, Loss: 0.4483, Time: 2.05s\n",
      "Epoch: 0, Batch: 680/1676, Loss: 0.8397, Time: 2.06s\n",
      "Epoch: 0, Batch: 690/1676, Loss: 1.0949, Time: 2.06s\n",
      "Epoch: 0, Batch: 700/1676, Loss: 0.5611, Time: 2.06s\n",
      "Epoch: 0, Batch: 710/1676, Loss: 1.0794, Time: 2.05s\n",
      "Epoch: 0, Batch: 720/1676, Loss: 0.5319, Time: 2.06s\n",
      "Epoch: 0, Batch: 730/1676, Loss: 0.6627, Time: 2.07s\n",
      "Epoch: 0, Batch: 740/1676, Loss: 0.9605, Time: 2.06s\n",
      "Epoch: 0, Batch: 750/1676, Loss: 1.4845, Time: 2.05s\n",
      "Epoch: 0, Batch: 760/1676, Loss: 1.0101, Time: 2.06s\n",
      "Epoch: 0, Batch: 770/1676, Loss: 0.8189, Time: 2.05s\n",
      "Epoch: 0, Batch: 780/1676, Loss: 0.4164, Time: 2.06s\n",
      "Epoch: 0, Batch: 790/1676, Loss: 1.4322, Time: 2.06s\n",
      "Epoch: 0, Batch: 800/1676, Loss: 0.7207, Time: 2.06s\n",
      "Epoch: 0, Batch: 810/1676, Loss: 0.5289, Time: 2.05s\n",
      "Epoch: 0, Batch: 820/1676, Loss: 1.2287, Time: 2.06s\n",
      "Epoch: 0, Batch: 830/1676, Loss: 0.9400, Time: 2.05s\n",
      "Epoch: 0, Batch: 840/1676, Loss: 1.2332, Time: 2.06s\n",
      "Epoch: 0, Batch: 850/1676, Loss: 0.8477, Time: 2.06s\n",
      "Epoch: 0, Batch: 860/1676, Loss: 1.2287, Time: 2.06s\n",
      "Epoch: 0, Batch: 870/1676, Loss: 0.5623, Time: 2.06s\n",
      "Epoch: 0, Batch: 880/1676, Loss: 0.3689, Time: 2.07s\n",
      "Epoch: 0, Batch: 890/1676, Loss: 0.7537, Time: 2.06s\n",
      "Epoch: 0, Batch: 900/1676, Loss: 1.1455, Time: 2.06s\n",
      "Epoch: 0, Batch: 910/1676, Loss: 0.7955, Time: 2.07s\n",
      "Epoch: 0, Batch: 920/1676, Loss: 1.0240, Time: 2.06s\n",
      "Epoch: 0, Batch: 930/1676, Loss: 0.5335, Time: 2.06s\n",
      "Epoch: 0, Batch: 940/1676, Loss: 0.8213, Time: 2.07s\n",
      "Epoch: 0, Batch: 950/1676, Loss: 0.5908, Time: 2.07s\n",
      "Epoch: 0, Batch: 960/1676, Loss: 0.4735, Time: 2.08s\n",
      "Epoch: 0, Batch: 970/1676, Loss: 0.3853, Time: 2.06s\n",
      "Epoch: 0, Batch: 980/1676, Loss: 0.8162, Time: 2.06s\n",
      "Epoch: 0, Batch: 990/1676, Loss: 0.4354, Time: 2.07s\n",
      "Epoch: 0, Batch: 1000/1676, Loss: 0.5086, Time: 2.06s\n",
      "Epoch: 0, Batch: 1010/1676, Loss: 0.5332, Time: 2.06s\n",
      "Epoch: 0, Batch: 1020/1676, Loss: 1.4543, Time: 2.07s\n",
      "Epoch: 0, Batch: 1030/1676, Loss: 1.0582, Time: 2.06s\n",
      "Epoch: 0, Batch: 1040/1676, Loss: 1.1477, Time: 2.06s\n",
      "Epoch: 0, Batch: 1050/1676, Loss: 0.4942, Time: 2.07s\n",
      "Epoch: 0, Batch: 1060/1676, Loss: 0.5608, Time: 2.06s\n",
      "Epoch: 0, Batch: 1070/1676, Loss: 0.7109, Time: 2.07s\n",
      "Epoch: 0, Batch: 1080/1676, Loss: 0.5974, Time: 2.07s\n",
      "Epoch: 0, Batch: 1090/1676, Loss: 0.9379, Time: 2.06s\n",
      "Epoch: 0, Batch: 1100/1676, Loss: 0.8923, Time: 2.07s\n",
      "Epoch: 0, Batch: 1110/1676, Loss: 0.8619, Time: 2.07s\n",
      "Epoch: 0, Batch: 1120/1676, Loss: 1.0557, Time: 2.06s\n",
      "Epoch: 0, Batch: 1130/1676, Loss: 0.7632, Time: 2.07s\n",
      "Epoch: 0, Batch: 1140/1676, Loss: 1.0845, Time: 2.07s\n",
      "Epoch: 0, Batch: 1150/1676, Loss: 0.4457, Time: 2.08s\n",
      "Epoch: 0, Batch: 1160/1676, Loss: 0.8630, Time: 2.07s\n",
      "Epoch: 0, Batch: 1170/1676, Loss: 0.4381, Time: 2.07s\n",
      "Epoch: 0, Batch: 1180/1676, Loss: 0.9663, Time: 2.07s\n",
      "Epoch: 0, Batch: 1190/1676, Loss: 0.3532, Time: 2.07s\n",
      "Epoch: 0, Batch: 1200/1676, Loss: 0.8780, Time: 2.07s\n",
      "Epoch: 0, Batch: 1210/1676, Loss: 0.5614, Time: 2.06s\n",
      "Epoch: 0, Batch: 1220/1676, Loss: 1.1197, Time: 2.08s\n",
      "Epoch: 0, Batch: 1230/1676, Loss: 1.0487, Time: 2.06s\n",
      "Epoch: 0, Batch: 1240/1676, Loss: 0.8963, Time: 2.08s\n",
      "Epoch: 0, Batch: 1250/1676, Loss: 1.0933, Time: 2.07s\n",
      "Epoch: 0, Batch: 1260/1676, Loss: 0.8157, Time: 2.07s\n",
      "Epoch: 0, Batch: 1270/1676, Loss: 0.3063, Time: 2.07s\n",
      "Epoch: 0, Batch: 1280/1676, Loss: 0.5518, Time: 2.07s\n",
      "Epoch: 0, Batch: 1290/1676, Loss: 0.5565, Time: 2.07s\n",
      "Epoch: 0, Batch: 1300/1676, Loss: 1.3791, Time: 2.07s\n",
      "Epoch: 0, Batch: 1310/1676, Loss: 0.4440, Time: 2.07s\n",
      "Epoch: 0, Batch: 1320/1676, Loss: 0.3827, Time: 2.06s\n",
      "Epoch: 0, Batch: 1330/1676, Loss: 0.4690, Time: 2.08s\n",
      "Epoch: 0, Batch: 1340/1676, Loss: 0.3990, Time: 2.07s\n",
      "Epoch: 0, Batch: 1350/1676, Loss: 0.8066, Time: 2.06s\n",
      "Epoch: 0, Batch: 1360/1676, Loss: 0.9521, Time: 2.06s\n",
      "Epoch: 0, Batch: 1370/1676, Loss: 1.0920, Time: 2.08s\n",
      "Epoch: 0, Batch: 1380/1676, Loss: 0.7451, Time: 2.07s\n",
      "Epoch: 0, Batch: 1390/1676, Loss: 0.4645, Time: 2.07s\n",
      "Epoch: 0, Batch: 1400/1676, Loss: 0.4767, Time: 2.08s\n",
      "Epoch: 0, Batch: 1410/1676, Loss: 1.7031, Time: 2.08s\n",
      "Epoch: 0, Batch: 1420/1676, Loss: 1.2111, Time: 2.08s\n",
      "Epoch: 0, Batch: 1430/1676, Loss: 1.0565, Time: 2.07s\n",
      "Epoch: 0, Batch: 1440/1676, Loss: 0.8667, Time: 2.08s\n",
      "Epoch: 0, Batch: 1450/1676, Loss: 0.6681, Time: 2.07s\n",
      "Epoch: 0, Batch: 1460/1676, Loss: 0.5198, Time: 2.07s\n",
      "Epoch: 0, Batch: 1470/1676, Loss: 0.8102, Time: 2.07s\n",
      "Epoch: 0, Batch: 1480/1676, Loss: 0.7572, Time: 2.07s\n",
      "Epoch: 0, Batch: 1490/1676, Loss: 1.4783, Time: 2.06s\n",
      "Epoch: 0, Batch: 1500/1676, Loss: 0.5959, Time: 2.07s\n",
      "Epoch: 0, Batch: 1510/1676, Loss: 1.0213, Time: 2.08s\n",
      "Epoch: 0, Batch: 1520/1676, Loss: 0.2687, Time: 2.07s\n",
      "Epoch: 0, Batch: 1530/1676, Loss: 0.5997, Time: 2.07s\n",
      "Epoch: 0, Batch: 1540/1676, Loss: 1.5881, Time: 2.07s\n",
      "Epoch: 0, Batch: 1550/1676, Loss: 0.6595, Time: 2.06s\n",
      "Epoch: 0, Batch: 1560/1676, Loss: 0.5201, Time: 2.06s\n",
      "Epoch: 0, Batch: 1570/1676, Loss: 0.5603, Time: 2.07s\n",
      "Epoch: 0, Batch: 1580/1676, Loss: 0.3808, Time: 2.06s\n",
      "Epoch: 0, Batch: 1590/1676, Loss: 1.8943, Time: 2.06s\n",
      "Epoch: 0, Batch: 1600/1676, Loss: 1.1666, Time: 2.07s\n",
      "Epoch: 0, Batch: 1610/1676, Loss: 0.4969, Time: 2.07s\n",
      "Epoch: 0, Batch: 1620/1676, Loss: 1.2169, Time: 2.07s\n",
      "Epoch: 0, Batch: 1630/1676, Loss: 0.4468, Time: 2.07s\n",
      "Epoch: 0, Batch: 1640/1676, Loss: 1.4498, Time: 2.06s\n",
      "Epoch: 0, Batch: 1650/1676, Loss: 0.6768, Time: 2.06s\n",
      "Epoch: 0, Batch: 1660/1676, Loss: 0.8217, Time: 2.06s\n",
      "Epoch: 0, Batch: 1670/1676, Loss: 0.8441, Time: 2.06s\n",
      "Epoch 1/50: Train Loss: 0.8165, Val Loss: 0.7884, Val IoU: 0.5501, Val Dice: 0.5688\n",
      "Saving best model with IoU: 0.5501\n",
      "Epoch: 1, Batch: 0/1676, Loss: 0.8945, Time: 35.90s\n",
      "Epoch: 1, Batch: 10/1676, Loss: 0.5709, Time: 2.05s\n",
      "Epoch: 1, Batch: 20/1676, Loss: 1.0639, Time: 2.01s\n",
      "Epoch: 1, Batch: 30/1676, Loss: 0.8862, Time: 2.04s\n",
      "Epoch: 1, Batch: 40/1676, Loss: 1.0450, Time: 2.02s\n",
      "Epoch: 1, Batch: 50/1676, Loss: 0.8536, Time: 2.04s\n",
      "Epoch: 1, Batch: 60/1676, Loss: 0.6508, Time: 2.04s\n",
      "Epoch: 1, Batch: 70/1676, Loss: 0.5600, Time: 2.04s\n",
      "Epoch: 1, Batch: 80/1676, Loss: 1.3184, Time: 2.02s\n",
      "Epoch: 1, Batch: 90/1676, Loss: 0.5438, Time: 2.03s\n",
      "Epoch: 1, Batch: 100/1676, Loss: 0.3078, Time: 2.04s\n",
      "Epoch: 1, Batch: 110/1676, Loss: 1.1701, Time: 2.04s\n",
      "Epoch: 1, Batch: 120/1676, Loss: 0.8369, Time: 2.04s\n",
      "Epoch: 1, Batch: 130/1676, Loss: 1.1618, Time: 2.05s\n",
      "Epoch: 1, Batch: 140/1676, Loss: 0.4506, Time: 2.04s\n",
      "Epoch: 1, Batch: 150/1676, Loss: 1.2674, Time: 2.05s\n",
      "Epoch: 1, Batch: 160/1676, Loss: 0.4104, Time: 2.05s\n",
      "Epoch: 1, Batch: 170/1676, Loss: 0.7161, Time: 2.05s\n",
      "Epoch: 1, Batch: 180/1676, Loss: 1.2634, Time: 2.03s\n",
      "Epoch: 1, Batch: 190/1676, Loss: 0.6238, Time: 2.05s\n",
      "Epoch: 1, Batch: 200/1676, Loss: 0.7737, Time: 2.04s\n",
      "Epoch: 1, Batch: 210/1676, Loss: 0.5049, Time: 2.05s\n",
      "Epoch: 1, Batch: 220/1676, Loss: 1.3627, Time: 2.04s\n",
      "Epoch: 1, Batch: 230/1676, Loss: 0.6264, Time: 2.05s\n",
      "Epoch: 1, Batch: 240/1676, Loss: 1.6796, Time: 2.04s\n",
      "Epoch: 1, Batch: 250/1676, Loss: 0.6715, Time: 2.05s\n",
      "Epoch: 1, Batch: 260/1676, Loss: 0.5724, Time: 2.06s\n",
      "Epoch: 1, Batch: 270/1676, Loss: 0.5912, Time: 2.05s\n",
      "Epoch: 1, Batch: 280/1676, Loss: 0.7459, Time: 2.06s\n",
      "Epoch: 1, Batch: 290/1676, Loss: 1.2356, Time: 2.06s\n",
      "Epoch: 1, Batch: 300/1676, Loss: 0.3453, Time: 2.06s\n",
      "Epoch: 1, Batch: 310/1676, Loss: 0.9306, Time: 2.05s\n",
      "Epoch: 1, Batch: 320/1676, Loss: 0.9139, Time: 2.06s\n",
      "Epoch: 1, Batch: 330/1676, Loss: 0.5729, Time: 2.06s\n",
      "Epoch: 1, Batch: 340/1676, Loss: 0.5375, Time: 2.06s\n",
      "Epoch: 1, Batch: 350/1676, Loss: 0.3904, Time: 2.06s\n",
      "Epoch: 1, Batch: 360/1676, Loss: 0.3537, Time: 2.05s\n",
      "Epoch: 1, Batch: 370/1676, Loss: 0.9123, Time: 2.06s\n",
      "Epoch: 1, Batch: 380/1676, Loss: 0.8359, Time: 2.07s\n",
      "Epoch: 1, Batch: 390/1676, Loss: 0.9293, Time: 2.06s\n",
      "Epoch: 1, Batch: 400/1676, Loss: 0.9364, Time: 2.06s\n",
      "Epoch: 1, Batch: 410/1676, Loss: 0.7917, Time: 2.06s\n",
      "Epoch: 1, Batch: 420/1676, Loss: 0.6577, Time: 2.05s\n",
      "Epoch: 1, Batch: 430/1676, Loss: 1.0580, Time: 2.06s\n",
      "Epoch: 1, Batch: 440/1676, Loss: 0.8711, Time: 2.06s\n",
      "Epoch: 1, Batch: 450/1676, Loss: 0.9406, Time: 2.07s\n",
      "Epoch: 1, Batch: 460/1676, Loss: 1.0320, Time: 2.06s\n",
      "Epoch: 1, Batch: 470/1676, Loss: 0.8644, Time: 2.06s\n",
      "Epoch: 1, Batch: 480/1676, Loss: 0.6604, Time: 2.07s\n",
      "Epoch: 1, Batch: 490/1676, Loss: 0.8948, Time: 2.06s\n",
      "Epoch: 1, Batch: 500/1676, Loss: 0.8726, Time: 2.06s\n",
      "Epoch: 1, Batch: 510/1676, Loss: 0.5174, Time: 2.07s\n",
      "Epoch: 1, Batch: 520/1676, Loss: 0.3684, Time: 2.06s\n",
      "Epoch: 1, Batch: 530/1676, Loss: 0.7124, Time: 2.07s\n",
      "Epoch: 1, Batch: 540/1676, Loss: 0.6504, Time: 2.06s\n",
      "Epoch: 1, Batch: 550/1676, Loss: 0.4008, Time: 2.06s\n",
      "Epoch: 1, Batch: 560/1676, Loss: 0.8418, Time: 2.07s\n",
      "Epoch: 1, Batch: 570/1676, Loss: 0.7235, Time: 2.06s\n",
      "Epoch: 1, Batch: 580/1676, Loss: 1.6233, Time: 2.06s\n",
      "Epoch: 1, Batch: 590/1676, Loss: 0.6428, Time: 2.07s\n",
      "Epoch: 1, Batch: 600/1676, Loss: 0.8111, Time: 2.07s\n",
      "Epoch: 1, Batch: 610/1676, Loss: 0.3253, Time: 2.07s\n",
      "Epoch: 1, Batch: 620/1676, Loss: 1.2529, Time: 2.06s\n",
      "Epoch: 1, Batch: 630/1676, Loss: 0.6285, Time: 2.06s\n",
      "Epoch: 1, Batch: 640/1676, Loss: 1.2318, Time: 2.05s\n",
      "Epoch: 1, Batch: 650/1676, Loss: 0.5740, Time: 2.07s\n",
      "Epoch: 1, Batch: 660/1676, Loss: 0.9182, Time: 2.07s\n",
      "Epoch: 1, Batch: 670/1676, Loss: 1.0652, Time: 2.07s\n",
      "Epoch: 1, Batch: 680/1676, Loss: 0.9171, Time: 2.07s\n",
      "Epoch: 1, Batch: 690/1676, Loss: 0.5764, Time: 2.07s\n",
      "Epoch: 1, Batch: 700/1676, Loss: 0.5340, Time: 2.07s\n",
      "Epoch: 1, Batch: 710/1676, Loss: 1.0356, Time: 2.06s\n",
      "Epoch: 1, Batch: 720/1676, Loss: 0.7733, Time: 2.07s\n",
      "Epoch: 1, Batch: 730/1676, Loss: 0.4362, Time: 2.06s\n",
      "Epoch: 1, Batch: 740/1676, Loss: 0.2922, Time: 2.06s\n",
      "Epoch: 1, Batch: 750/1676, Loss: 1.0924, Time: 2.07s\n",
      "Epoch: 1, Batch: 760/1676, Loss: 1.1446, Time: 2.07s\n",
      "Epoch: 1, Batch: 770/1676, Loss: 1.3399, Time: 2.06s\n",
      "Epoch: 1, Batch: 780/1676, Loss: 1.1197, Time: 2.05s\n",
      "Epoch: 1, Batch: 790/1676, Loss: 1.0150, Time: 2.07s\n",
      "Epoch: 1, Batch: 800/1676, Loss: 0.7594, Time: 2.06s\n",
      "Epoch: 1, Batch: 810/1676, Loss: 0.7958, Time: 2.06s\n",
      "Epoch: 1, Batch: 820/1676, Loss: 1.0526, Time: 2.07s\n",
      "Epoch: 1, Batch: 830/1676, Loss: 0.8210, Time: 2.06s\n",
      "Epoch: 1, Batch: 840/1676, Loss: 0.9105, Time: 2.06s\n",
      "Epoch: 1, Batch: 850/1676, Loss: 0.5192, Time: 2.07s\n",
      "Epoch: 1, Batch: 860/1676, Loss: 0.4979, Time: 2.07s\n",
      "Epoch: 1, Batch: 870/1676, Loss: 1.1693, Time: 2.07s\n",
      "Epoch: 1, Batch: 880/1676, Loss: 0.9218, Time: 2.07s\n",
      "Epoch: 1, Batch: 890/1676, Loss: 0.6758, Time: 2.07s\n",
      "Epoch: 1, Batch: 900/1676, Loss: 0.5777, Time: 2.07s\n",
      "Epoch: 1, Batch: 910/1676, Loss: 0.8853, Time: 2.06s\n",
      "Epoch: 1, Batch: 920/1676, Loss: 0.9224, Time: 2.07s\n",
      "Epoch: 1, Batch: 930/1676, Loss: 0.8564, Time: 2.07s\n",
      "Epoch: 1, Batch: 940/1676, Loss: 1.0358, Time: 2.05s\n",
      "Epoch: 1, Batch: 950/1676, Loss: 0.8303, Time: 2.08s\n",
      "Epoch: 1, Batch: 960/1676, Loss: 1.0819, Time: 2.06s\n",
      "Epoch: 1, Batch: 970/1676, Loss: 0.9625, Time: 2.06s\n",
      "Epoch: 1, Batch: 980/1676, Loss: 0.7011, Time: 2.07s\n",
      "Epoch: 1, Batch: 990/1676, Loss: 0.9633, Time: 2.06s\n",
      "Epoch: 1, Batch: 1000/1676, Loss: 0.4124, Time: 2.06s\n",
      "Epoch: 1, Batch: 1010/1676, Loss: 1.0736, Time: 2.07s\n",
      "Epoch: 1, Batch: 1020/1676, Loss: 0.5528, Time: 2.06s\n",
      "Epoch: 1, Batch: 1030/1676, Loss: 0.6454, Time: 2.06s\n",
      "Epoch: 1, Batch: 1040/1676, Loss: 1.0455, Time: 2.06s\n",
      "Epoch: 1, Batch: 1050/1676, Loss: 0.7062, Time: 2.07s\n",
      "Epoch: 1, Batch: 1060/1676, Loss: 0.8681, Time: 2.06s\n",
      "Epoch: 1, Batch: 1070/1676, Loss: 0.5554, Time: 2.08s\n",
      "Epoch: 1, Batch: 1080/1676, Loss: 0.9840, Time: 2.11s\n",
      "Epoch: 1, Batch: 1090/1676, Loss: 0.4911, Time: 2.13s\n",
      "Epoch: 1, Batch: 1100/1676, Loss: 0.7410, Time: 2.10s\n",
      "Epoch: 1, Batch: 1110/1676, Loss: 1.1692, Time: 2.11s\n",
      "Epoch: 1, Batch: 1120/1676, Loss: 0.7773, Time: 2.10s\n",
      "Epoch: 1, Batch: 1130/1676, Loss: 0.8100, Time: 2.11s\n",
      "Epoch: 1, Batch: 1140/1676, Loss: 0.5416, Time: 2.09s\n",
      "Epoch: 1, Batch: 1150/1676, Loss: 0.6606, Time: 2.09s\n",
      "Epoch: 1, Batch: 1160/1676, Loss: 0.8805, Time: 2.09s\n",
      "Epoch: 1, Batch: 1170/1676, Loss: 1.0286, Time: 2.10s\n",
      "Epoch: 1, Batch: 1180/1676, Loss: 0.5412, Time: 2.08s\n",
      "Epoch: 1, Batch: 1190/1676, Loss: 1.1651, Time: 2.10s\n",
      "Epoch: 1, Batch: 1200/1676, Loss: 0.5438, Time: 2.08s\n",
      "Epoch: 1, Batch: 1210/1676, Loss: 0.7278, Time: 2.09s\n",
      "Epoch: 1, Batch: 1220/1676, Loss: 0.4897, Time: 2.09s\n",
      "Epoch: 1, Batch: 1230/1676, Loss: 0.6291, Time: 2.09s\n",
      "Epoch: 1, Batch: 1240/1676, Loss: 0.6385, Time: 2.10s\n",
      "Epoch: 1, Batch: 1250/1676, Loss: 0.3929, Time: 2.10s\n",
      "Epoch: 1, Batch: 1260/1676, Loss: 0.6516, Time: 2.08s\n",
      "Epoch: 1, Batch: 1270/1676, Loss: 0.9986, Time: 2.09s\n",
      "Epoch: 1, Batch: 1280/1676, Loss: 1.2437, Time: 2.10s\n",
      "Epoch: 1, Batch: 1290/1676, Loss: 0.6985, Time: 2.09s\n",
      "Epoch: 1, Batch: 1300/1676, Loss: 0.6213, Time: 2.09s\n",
      "Epoch: 1, Batch: 1310/1676, Loss: 0.5252, Time: 2.09s\n",
      "Epoch: 1, Batch: 1320/1676, Loss: 1.5502, Time: 2.10s\n",
      "Epoch: 1, Batch: 1330/1676, Loss: 0.4944, Time: 2.10s\n",
      "Epoch: 1, Batch: 1340/1676, Loss: 0.9418, Time: 2.09s\n",
      "Epoch: 1, Batch: 1350/1676, Loss: 0.8719, Time: 2.09s\n",
      "Epoch: 1, Batch: 1360/1676, Loss: 0.9278, Time: 2.09s\n",
      "Epoch: 1, Batch: 1370/1676, Loss: 0.3792, Time: 2.08s\n",
      "Epoch: 1, Batch: 1380/1676, Loss: 0.6245, Time: 2.09s\n",
      "Epoch: 1, Batch: 1390/1676, Loss: 1.0517, Time: 2.10s\n",
      "Epoch: 1, Batch: 1400/1676, Loss: 0.8036, Time: 2.09s\n",
      "Epoch: 1, Batch: 1410/1676, Loss: 0.9600, Time: 2.09s\n",
      "Epoch: 1, Batch: 1420/1676, Loss: 0.8881, Time: 2.08s\n",
      "Epoch: 1, Batch: 1430/1676, Loss: 0.6644, Time: 2.09s\n",
      "Epoch: 1, Batch: 1440/1676, Loss: 0.9107, Time: 2.09s\n",
      "Epoch: 1, Batch: 1450/1676, Loss: 0.6728, Time: 2.08s\n",
      "Epoch: 1, Batch: 1460/1676, Loss: 0.7749, Time: 2.09s\n",
      "Epoch: 1, Batch: 1470/1676, Loss: 0.8700, Time: 2.09s\n",
      "Epoch: 1, Batch: 1480/1676, Loss: 0.8956, Time: 2.09s\n",
      "Epoch: 1, Batch: 1490/1676, Loss: 0.5357, Time: 2.08s\n",
      "Epoch: 1, Batch: 1500/1676, Loss: 1.0479, Time: 2.08s\n",
      "Epoch: 1, Batch: 1510/1676, Loss: 0.5607, Time: 2.09s\n",
      "Epoch: 1, Batch: 1520/1676, Loss: 1.0527, Time: 2.06s\n",
      "Epoch: 1, Batch: 1530/1676, Loss: 1.6882, Time: 2.09s\n",
      "Epoch: 1, Batch: 1540/1676, Loss: 0.6143, Time: 2.09s\n",
      "Epoch: 1, Batch: 1550/1676, Loss: 0.6163, Time: 2.08s\n",
      "Epoch: 1, Batch: 1560/1676, Loss: 1.3471, Time: 2.08s\n",
      "Epoch: 1, Batch: 1570/1676, Loss: 0.4810, Time: 2.09s\n",
      "Epoch: 1, Batch: 1580/1676, Loss: 0.6365, Time: 2.08s\n",
      "Epoch: 1, Batch: 1590/1676, Loss: 0.2640, Time: 2.08s\n",
      "Epoch: 1, Batch: 1600/1676, Loss: 0.4830, Time: 2.09s\n",
      "Epoch: 1, Batch: 1610/1676, Loss: 1.2262, Time: 2.09s\n",
      "Epoch: 1, Batch: 1620/1676, Loss: 0.9276, Time: 2.09s\n",
      "Epoch: 1, Batch: 1630/1676, Loss: 0.6993, Time: 2.07s\n",
      "Epoch: 1, Batch: 1640/1676, Loss: 0.5513, Time: 2.09s\n",
      "Epoch: 1, Batch: 1650/1676, Loss: 0.3735, Time: 2.08s\n",
      "Epoch: 1, Batch: 1660/1676, Loss: 0.4981, Time: 2.08s\n",
      "Epoch: 1, Batch: 1670/1676, Loss: 0.3957, Time: 2.09s\n",
      "Epoch 2/50: Train Loss: 0.7836, Val Loss: 0.8185, Val IoU: 0.5158, Val Dice: 0.5414\n",
      "Epoch: 2, Batch: 0/1676, Loss: 0.5098, Time: 35.11s\n",
      "Epoch: 2, Batch: 10/1676, Loss: 0.6368, Time: 2.05s\n",
      "Epoch: 2, Batch: 20/1676, Loss: 0.9090, Time: 2.01s\n",
      "Epoch: 2, Batch: 30/1676, Loss: 0.7460, Time: 2.01s\n",
      "Epoch: 2, Batch: 40/1676, Loss: 0.9761, Time: 2.01s\n",
      "Epoch: 2, Batch: 50/1676, Loss: 0.5529, Time: 2.01s\n",
      "Epoch: 2, Batch: 60/1676, Loss: 1.2618, Time: 2.01s\n",
      "Epoch: 2, Batch: 70/1676, Loss: 0.4458, Time: 2.01s\n",
      "Epoch: 2, Batch: 80/1676, Loss: 0.6109, Time: 2.01s\n",
      "Epoch: 2, Batch: 90/1676, Loss: 0.9101, Time: 2.02s\n",
      "Epoch: 2, Batch: 100/1676, Loss: 0.7103, Time: 2.03s\n",
      "Epoch: 2, Batch: 110/1676, Loss: 0.5576, Time: 2.02s\n",
      "Epoch: 2, Batch: 120/1676, Loss: 0.9989, Time: 2.02s\n",
      "Epoch: 2, Batch: 130/1676, Loss: 0.7447, Time: 2.03s\n",
      "Epoch: 2, Batch: 140/1676, Loss: 0.6929, Time: 2.02s\n",
      "Epoch: 2, Batch: 150/1676, Loss: 0.7472, Time: 2.04s\n",
      "Epoch: 2, Batch: 160/1676, Loss: 0.2565, Time: 2.02s\n",
      "Epoch: 2, Batch: 170/1676, Loss: 0.5940, Time: 2.02s\n",
      "Epoch: 2, Batch: 180/1676, Loss: 1.0674, Time: 2.04s\n",
      "Epoch: 2, Batch: 190/1676, Loss: 0.5705, Time: 2.03s\n",
      "Epoch: 2, Batch: 200/1676, Loss: 0.3884, Time: 2.04s\n",
      "Epoch: 2, Batch: 210/1676, Loss: 1.2107, Time: 2.03s\n",
      "Epoch: 2, Batch: 220/1676, Loss: 0.5610, Time: 2.04s\n",
      "Epoch: 2, Batch: 230/1676, Loss: 0.9741, Time: 2.04s\n",
      "Epoch: 2, Batch: 240/1676, Loss: 0.8647, Time: 2.02s\n",
      "Epoch: 2, Batch: 250/1676, Loss: 1.0796, Time: 2.04s\n",
      "Epoch: 2, Batch: 260/1676, Loss: 0.7031, Time: 2.03s\n",
      "Epoch: 2, Batch: 270/1676, Loss: 0.8955, Time: 2.04s\n",
      "Epoch: 2, Batch: 280/1676, Loss: 0.7715, Time: 2.03s\n",
      "Epoch: 2, Batch: 290/1676, Loss: 0.9780, Time: 2.04s\n",
      "Epoch: 2, Batch: 300/1676, Loss: 0.9380, Time: 2.04s\n",
      "Epoch: 2, Batch: 310/1676, Loss: 1.1448, Time: 2.04s\n",
      "Epoch: 2, Batch: 320/1676, Loss: 0.8762, Time: 2.04s\n",
      "Epoch: 2, Batch: 330/1676, Loss: 0.9942, Time: 2.05s\n",
      "Epoch: 2, Batch: 340/1676, Loss: 0.9935, Time: 2.04s\n",
      "Epoch: 2, Batch: 350/1676, Loss: 0.8756, Time: 2.05s\n",
      "Epoch: 2, Batch: 360/1676, Loss: 1.1256, Time: 2.04s\n",
      "Epoch: 2, Batch: 370/1676, Loss: 0.5768, Time: 2.05s\n",
      "Epoch: 2, Batch: 380/1676, Loss: 0.6475, Time: 2.04s\n",
      "Epoch: 2, Batch: 390/1676, Loss: 1.0539, Time: 2.04s\n",
      "Epoch: 2, Batch: 400/1676, Loss: 1.0522, Time: 2.05s\n",
      "Epoch: 2, Batch: 410/1676, Loss: 1.1247, Time: 2.04s\n",
      "Epoch: 2, Batch: 420/1676, Loss: 0.5434, Time: 2.04s\n",
      "Epoch: 2, Batch: 430/1676, Loss: 0.2931, Time: 2.04s\n",
      "Epoch: 2, Batch: 440/1676, Loss: 0.5704, Time: 2.03s\n",
      "Epoch: 2, Batch: 450/1676, Loss: 0.5127, Time: 2.04s\n",
      "Epoch: 2, Batch: 460/1676, Loss: 0.8511, Time: 2.05s\n",
      "Epoch: 2, Batch: 470/1676, Loss: 0.6598, Time: 2.06s\n",
      "Epoch: 2, Batch: 480/1676, Loss: 0.6847, Time: 2.05s\n",
      "Epoch: 2, Batch: 490/1676, Loss: 0.5927, Time: 2.05s\n",
      "Epoch: 2, Batch: 500/1676, Loss: 1.2457, Time: 2.05s\n",
      "Epoch: 2, Batch: 510/1676, Loss: 0.5756, Time: 2.05s\n",
      "Epoch: 2, Batch: 520/1676, Loss: 1.0547, Time: 2.05s\n",
      "Epoch: 2, Batch: 530/1676, Loss: 1.3034, Time: 2.05s\n",
      "Epoch: 2, Batch: 540/1676, Loss: 0.4906, Time: 2.05s\n",
      "Epoch: 2, Batch: 550/1676, Loss: 0.4836, Time: 2.05s\n",
      "Epoch: 2, Batch: 560/1676, Loss: 0.6008, Time: 2.05s\n",
      "Epoch: 2, Batch: 570/1676, Loss: 0.8838, Time: 2.05s\n",
      "Epoch: 2, Batch: 580/1676, Loss: 0.6595, Time: 2.05s\n",
      "Epoch: 2, Batch: 590/1676, Loss: 0.5670, Time: 2.04s\n",
      "Epoch: 2, Batch: 600/1676, Loss: 0.7965, Time: 2.04s\n",
      "Epoch: 2, Batch: 610/1676, Loss: 0.3974, Time: 2.05s\n",
      "Epoch: 2, Batch: 620/1676, Loss: 0.6523, Time: 2.05s\n",
      "Epoch: 2, Batch: 630/1676, Loss: 1.0810, Time: 2.06s\n",
      "Epoch: 2, Batch: 640/1676, Loss: 0.9581, Time: 2.05s\n",
      "Epoch: 2, Batch: 650/1676, Loss: 0.6903, Time: 2.05s\n",
      "Epoch: 2, Batch: 660/1676, Loss: 0.4262, Time: 2.04s\n",
      "Epoch: 2, Batch: 670/1676, Loss: 0.6709, Time: 2.05s\n",
      "Epoch: 2, Batch: 680/1676, Loss: 0.8153, Time: 2.05s\n",
      "Epoch: 2, Batch: 690/1676, Loss: 1.0274, Time: 2.04s\n",
      "Epoch: 2, Batch: 700/1676, Loss: 0.7120, Time: 2.03s\n",
      "Epoch: 2, Batch: 710/1676, Loss: 0.7416, Time: 2.04s\n",
      "Epoch: 2, Batch: 720/1676, Loss: 0.4675, Time: 2.04s\n",
      "Epoch: 2, Batch: 730/1676, Loss: 0.4665, Time: 2.04s\n",
      "Epoch: 2, Batch: 740/1676, Loss: 0.9311, Time: 2.04s\n",
      "Epoch: 2, Batch: 750/1676, Loss: 0.4284, Time: 2.05s\n",
      "Epoch: 2, Batch: 760/1676, Loss: 0.4748, Time: 2.05s\n",
      "Epoch: 2, Batch: 770/1676, Loss: 0.5528, Time: 2.05s\n",
      "Epoch: 2, Batch: 780/1676, Loss: 0.3855, Time: 2.05s\n",
      "Epoch: 2, Batch: 790/1676, Loss: 1.2313, Time: 2.04s\n",
      "Epoch: 2, Batch: 800/1676, Loss: 1.1997, Time: 2.04s\n",
      "Epoch: 2, Batch: 810/1676, Loss: 0.8421, Time: 2.05s\n",
      "Epoch: 2, Batch: 820/1676, Loss: 1.2040, Time: 2.04s\n",
      "Epoch: 2, Batch: 830/1676, Loss: 1.4881, Time: 2.05s\n",
      "Epoch: 2, Batch: 840/1676, Loss: 0.9369, Time: 2.04s\n",
      "Epoch: 2, Batch: 850/1676, Loss: 1.1206, Time: 2.04s\n",
      "Epoch: 2, Batch: 860/1676, Loss: 1.1658, Time: 2.05s\n",
      "Epoch: 2, Batch: 870/1676, Loss: 0.3498, Time: 2.05s\n",
      "Epoch: 2, Batch: 880/1676, Loss: 1.0367, Time: 2.05s\n",
      "Epoch: 2, Batch: 890/1676, Loss: 0.9674, Time: 2.05s\n",
      "Epoch: 2, Batch: 900/1676, Loss: 0.6338, Time: 2.04s\n",
      "Epoch: 2, Batch: 910/1676, Loss: 0.7056, Time: 2.04s\n",
      "Epoch: 2, Batch: 920/1676, Loss: 0.6189, Time: 2.04s\n",
      "Epoch: 2, Batch: 930/1676, Loss: 0.6999, Time: 2.05s\n",
      "Epoch: 2, Batch: 940/1676, Loss: 0.3463, Time: 2.05s\n",
      "Epoch: 2, Batch: 950/1676, Loss: 0.7158, Time: 2.04s\n",
      "Epoch: 2, Batch: 960/1676, Loss: 0.3345, Time: 2.04s\n",
      "Epoch: 2, Batch: 970/1676, Loss: 1.0504, Time: 2.05s\n",
      "Epoch: 2, Batch: 980/1676, Loss: 1.0126, Time: 2.05s\n",
      "Epoch: 2, Batch: 990/1676, Loss: 0.9893, Time: 2.04s\n",
      "Epoch: 2, Batch: 1000/1676, Loss: 0.5615, Time: 2.04s\n",
      "Epoch: 2, Batch: 1010/1676, Loss: 0.7483, Time: 2.05s\n",
      "Epoch: 2, Batch: 1020/1676, Loss: 1.1066, Time: 2.04s\n",
      "Epoch: 2, Batch: 1030/1676, Loss: 1.2013, Time: 2.04s\n",
      "Epoch: 2, Batch: 1040/1676, Loss: 1.0981, Time: 2.04s\n",
      "Epoch: 2, Batch: 1050/1676, Loss: 0.9323, Time: 2.04s\n",
      "Epoch: 2, Batch: 1060/1676, Loss: 0.3417, Time: 2.05s\n",
      "Epoch: 2, Batch: 1070/1676, Loss: 0.3521, Time: 2.03s\n",
      "Epoch: 2, Batch: 1080/1676, Loss: 0.7414, Time: 2.04s\n",
      "Epoch: 2, Batch: 1090/1676, Loss: 0.8437, Time: 2.04s\n",
      "Epoch: 2, Batch: 1100/1676, Loss: 0.8830, Time: 2.03s\n",
      "Epoch: 2, Batch: 1110/1676, Loss: 0.3661, Time: 2.04s\n",
      "Epoch: 2, Batch: 1120/1676, Loss: 0.3134, Time: 2.04s\n",
      "Epoch: 2, Batch: 1130/1676, Loss: 0.5895, Time: 2.03s\n",
      "Epoch: 2, Batch: 1140/1676, Loss: 1.0901, Time: 2.05s\n",
      "Epoch: 2, Batch: 1150/1676, Loss: 0.7228, Time: 2.04s\n",
      "Epoch: 2, Batch: 1160/1676, Loss: 0.3228, Time: 2.04s\n",
      "Epoch: 2, Batch: 1170/1676, Loss: 0.2581, Time: 2.03s\n",
      "Epoch: 2, Batch: 1180/1676, Loss: 0.3411, Time: 2.04s\n",
      "Epoch: 2, Batch: 1190/1676, Loss: 0.7605, Time: 2.04s\n",
      "Epoch: 2, Batch: 1200/1676, Loss: 1.2552, Time: 2.04s\n",
      "Epoch: 2, Batch: 1210/1676, Loss: 0.5747, Time: 2.02s\n",
      "Epoch: 2, Batch: 1220/1676, Loss: 0.7423, Time: 2.04s\n",
      "Epoch: 2, Batch: 1230/1676, Loss: 0.3411, Time: 2.02s\n",
      "Epoch: 2, Batch: 1240/1676, Loss: 0.6248, Time: 2.03s\n",
      "Epoch: 2, Batch: 1250/1676, Loss: 1.3750, Time: 2.04s\n",
      "Epoch: 2, Batch: 1260/1676, Loss: 0.3980, Time: 2.04s\n",
      "Epoch: 2, Batch: 1270/1676, Loss: 0.9751, Time: 2.02s\n",
      "Epoch: 2, Batch: 1280/1676, Loss: 0.5097, Time: 2.03s\n",
      "Epoch: 2, Batch: 1290/1676, Loss: 1.0593, Time: 2.03s\n",
      "Epoch: 2, Batch: 1300/1676, Loss: 0.3860, Time: 2.03s\n",
      "Epoch: 2, Batch: 1310/1676, Loss: 1.1100, Time: 2.03s\n",
      "Epoch: 2, Batch: 1320/1676, Loss: 0.9946, Time: 2.02s\n",
      "Epoch: 2, Batch: 1330/1676, Loss: 0.7816, Time: 2.04s\n",
      "Epoch: 2, Batch: 1340/1676, Loss: 0.9608, Time: 2.02s\n",
      "Epoch: 2, Batch: 1350/1676, Loss: 0.7459, Time: 2.03s\n",
      "Epoch: 2, Batch: 1360/1676, Loss: 1.0690, Time: 2.02s\n",
      "Epoch: 2, Batch: 1370/1676, Loss: 0.2496, Time: 2.04s\n",
      "Epoch: 2, Batch: 1380/1676, Loss: 0.7351, Time: 2.04s\n",
      "Epoch: 2, Batch: 1390/1676, Loss: 0.4569, Time: 2.03s\n",
      "Epoch: 2, Batch: 1400/1676, Loss: 0.6719, Time: 2.03s\n",
      "Epoch: 2, Batch: 1410/1676, Loss: 1.2681, Time: 2.03s\n",
      "Epoch: 2, Batch: 1420/1676, Loss: 1.3687, Time: 2.02s\n",
      "Epoch: 2, Batch: 1430/1676, Loss: 0.6975, Time: 2.03s\n",
      "Epoch: 2, Batch: 1440/1676, Loss: 0.5531, Time: 2.03s\n",
      "Epoch: 2, Batch: 1450/1676, Loss: 0.9238, Time: 2.03s\n",
      "Epoch: 2, Batch: 1460/1676, Loss: 0.7255, Time: 2.03s\n",
      "Epoch: 2, Batch: 1470/1676, Loss: 0.6454, Time: 2.03s\n",
      "Epoch: 2, Batch: 1480/1676, Loss: 0.7071, Time: 2.03s\n",
      "Epoch: 2, Batch: 1490/1676, Loss: 0.9047, Time: 2.03s\n",
      "Epoch: 2, Batch: 1500/1676, Loss: 0.8778, Time: 2.02s\n",
      "Epoch: 2, Batch: 1510/1676, Loss: 0.9183, Time: 2.02s\n",
      "Epoch: 2, Batch: 1520/1676, Loss: 1.1594, Time: 2.04s\n",
      "Epoch: 2, Batch: 1530/1676, Loss: 1.0650, Time: 2.02s\n",
      "Epoch: 2, Batch: 1540/1676, Loss: 1.0609, Time: 2.03s\n",
      "Epoch: 2, Batch: 1550/1676, Loss: 0.8899, Time: 2.03s\n",
      "Epoch: 2, Batch: 1560/1676, Loss: 0.9186, Time: 2.02s\n",
      "Epoch: 2, Batch: 1570/1676, Loss: 1.1312, Time: 2.01s\n",
      "Epoch: 2, Batch: 1580/1676, Loss: 0.8914, Time: 2.02s\n",
      "Epoch: 2, Batch: 1590/1676, Loss: 0.5603, Time: 2.02s\n",
      "Epoch: 2, Batch: 1600/1676, Loss: 0.3594, Time: 2.03s\n",
      "Epoch: 2, Batch: 1610/1676, Loss: 0.9142, Time: 2.03s\n",
      "Epoch: 2, Batch: 1620/1676, Loss: 0.6868, Time: 2.01s\n",
      "Epoch: 2, Batch: 1630/1676, Loss: 0.9811, Time: 2.03s\n",
      "Epoch: 2, Batch: 1640/1676, Loss: 0.5180, Time: 2.03s\n",
      "Epoch: 2, Batch: 1650/1676, Loss: 1.1672, Time: 2.02s\n",
      "Epoch: 2, Batch: 1660/1676, Loss: 1.4443, Time: 2.01s\n",
      "Epoch: 2, Batch: 1670/1676, Loss: 0.7275, Time: 2.01s\n",
      "Epoch 3/50: Train Loss: 0.7741, Val Loss: 0.7613, Val IoU: 0.5449, Val Dice: 0.5656\n",
      "Epoch: 3, Batch: 0/1676, Loss: 0.4362, Time: 35.08s\n",
      "Epoch: 3, Batch: 10/1676, Loss: 0.5001, Time: 2.03s\n",
      "Epoch: 3, Batch: 20/1676, Loss: 0.6786, Time: 1.99s\n",
      "Epoch: 3, Batch: 30/1676, Loss: 1.4115, Time: 2.00s\n",
      "Epoch: 3, Batch: 40/1676, Loss: 1.3355, Time: 2.00s\n",
      "Epoch: 3, Batch: 50/1676, Loss: 0.5861, Time: 2.00s\n",
      "Epoch: 3, Batch: 60/1676, Loss: 1.0190, Time: 1.98s\n",
      "Epoch: 3, Batch: 70/1676, Loss: 0.9331, Time: 2.01s\n",
      "Epoch: 3, Batch: 80/1676, Loss: 0.6128, Time: 2.01s\n",
      "Epoch: 3, Batch: 90/1676, Loss: 0.7177, Time: 2.01s\n",
      "Epoch: 3, Batch: 100/1676, Loss: 0.5921, Time: 2.00s\n",
      "Epoch: 3, Batch: 110/1676, Loss: 0.4081, Time: 2.00s\n",
      "Epoch: 3, Batch: 120/1676, Loss: 0.5117, Time: 1.99s\n",
      "Epoch: 3, Batch: 130/1676, Loss: 0.7377, Time: 2.01s\n",
      "Epoch: 3, Batch: 140/1676, Loss: 1.3083, Time: 2.01s\n",
      "Epoch: 3, Batch: 150/1676, Loss: 1.1072, Time: 2.00s\n",
      "Epoch: 3, Batch: 160/1676, Loss: 0.7108, Time: 2.01s\n",
      "Epoch: 3, Batch: 170/1676, Loss: 0.4772, Time: 2.01s\n",
      "Epoch: 3, Batch: 180/1676, Loss: 1.0518, Time: 2.01s\n",
      "Epoch: 3, Batch: 190/1676, Loss: 1.4940, Time: 2.01s\n",
      "Epoch: 3, Batch: 200/1676, Loss: 0.6850, Time: 2.01s\n",
      "Epoch: 3, Batch: 210/1676, Loss: 0.7717, Time: 2.01s\n",
      "Epoch: 3, Batch: 220/1676, Loss: 0.6021, Time: 2.01s\n",
      "Epoch: 3, Batch: 230/1676, Loss: 0.3573, Time: 2.01s\n",
      "Epoch: 3, Batch: 240/1676, Loss: 0.8242, Time: 2.01s\n",
      "Epoch: 3, Batch: 250/1676, Loss: 0.3352, Time: 2.01s\n",
      "Epoch: 3, Batch: 260/1676, Loss: 0.9277, Time: 2.01s\n",
      "Epoch: 3, Batch: 270/1676, Loss: 0.6319, Time: 2.01s\n",
      "Epoch: 3, Batch: 280/1676, Loss: 1.2214, Time: 2.01s\n",
      "Epoch: 3, Batch: 290/1676, Loss: 1.6933, Time: 2.01s\n",
      "Epoch: 3, Batch: 300/1676, Loss: 0.6410, Time: 2.01s\n",
      "Epoch: 3, Batch: 310/1676, Loss: 0.6536, Time: 2.01s\n",
      "Epoch: 3, Batch: 320/1676, Loss: 1.0888, Time: 2.01s\n",
      "Epoch: 3, Batch: 330/1676, Loss: 1.5664, Time: 2.01s\n",
      "Epoch: 3, Batch: 340/1676, Loss: 0.4021, Time: 2.01s\n",
      "Epoch: 3, Batch: 350/1676, Loss: 0.9248, Time: 2.01s\n",
      "Epoch: 3, Batch: 360/1676, Loss: 0.5999, Time: 2.00s\n",
      "Epoch: 3, Batch: 370/1676, Loss: 0.4374, Time: 2.01s\n",
      "Epoch: 3, Batch: 380/1676, Loss: 0.7098, Time: 2.01s\n",
      "Epoch: 3, Batch: 390/1676, Loss: 0.7560, Time: 2.01s\n",
      "Epoch: 3, Batch: 400/1676, Loss: 0.8029, Time: 2.01s\n",
      "Epoch: 3, Batch: 410/1676, Loss: 0.6555, Time: 2.01s\n",
      "Epoch: 3, Batch: 420/1676, Loss: 0.9029, Time: 2.01s\n",
      "Epoch: 3, Batch: 430/1676, Loss: 1.0655, Time: 2.01s\n",
      "Epoch: 3, Batch: 440/1676, Loss: 0.7105, Time: 2.01s\n",
      "Epoch: 3, Batch: 450/1676, Loss: 0.6761, Time: 2.01s\n",
      "Epoch: 3, Batch: 460/1676, Loss: 0.7149, Time: 2.01s\n",
      "Epoch: 3, Batch: 470/1676, Loss: 1.3343, Time: 2.01s\n",
      "Epoch: 3, Batch: 480/1676, Loss: 0.7236, Time: 2.01s\n",
      "Epoch: 3, Batch: 490/1676, Loss: 0.5442, Time: 2.01s\n",
      "Epoch: 3, Batch: 500/1676, Loss: 0.9147, Time: 2.01s\n",
      "Epoch: 3, Batch: 510/1676, Loss: 0.9344, Time: 2.01s\n",
      "Epoch: 3, Batch: 520/1676, Loss: 0.9153, Time: 2.01s\n",
      "Epoch: 3, Batch: 530/1676, Loss: 0.8489, Time: 2.01s\n",
      "Epoch: 3, Batch: 540/1676, Loss: 0.9357, Time: 2.01s\n",
      "Epoch: 3, Batch: 550/1676, Loss: 0.3688, Time: 2.01s\n",
      "Epoch: 3, Batch: 560/1676, Loss: 0.6661, Time: 2.01s\n",
      "Epoch: 3, Batch: 570/1676, Loss: 0.3450, Time: 2.00s\n",
      "Epoch: 3, Batch: 580/1676, Loss: 0.7257, Time: 2.01s\n",
      "Epoch: 3, Batch: 590/1676, Loss: 0.7791, Time: 2.01s\n",
      "Epoch: 3, Batch: 600/1676, Loss: 1.1776, Time: 2.01s\n",
      "Epoch: 3, Batch: 610/1676, Loss: 0.5628, Time: 2.01s\n",
      "Epoch: 3, Batch: 620/1676, Loss: 0.5271, Time: 2.01s\n",
      "Epoch: 3, Batch: 630/1676, Loss: 0.9970, Time: 2.01s\n",
      "Epoch: 3, Batch: 640/1676, Loss: 1.0620, Time: 2.01s\n",
      "Epoch: 3, Batch: 650/1676, Loss: 1.2909, Time: 2.01s\n",
      "Epoch: 3, Batch: 660/1676, Loss: 0.3543, Time: 2.01s\n",
      "Epoch: 3, Batch: 670/1676, Loss: 0.6941, Time: 2.01s\n",
      "Epoch: 3, Batch: 680/1676, Loss: 0.8154, Time: 2.01s\n",
      "Epoch: 3, Batch: 690/1676, Loss: 0.5456, Time: 2.01s\n",
      "Epoch: 3, Batch: 700/1676, Loss: 0.3978, Time: 2.01s\n",
      "Epoch: 3, Batch: 710/1676, Loss: 1.1435, Time: 2.01s\n",
      "Epoch: 3, Batch: 720/1676, Loss: 1.0398, Time: 2.01s\n",
      "Epoch: 3, Batch: 730/1676, Loss: 0.8765, Time: 2.01s\n",
      "Epoch: 3, Batch: 740/1676, Loss: 0.4746, Time: 2.01s\n",
      "Epoch: 3, Batch: 750/1676, Loss: 1.2979, Time: 2.01s\n",
      "Epoch: 3, Batch: 760/1676, Loss: 0.8695, Time: 2.01s\n",
      "Epoch: 3, Batch: 770/1676, Loss: 0.6685, Time: 2.01s\n",
      "Epoch: 3, Batch: 780/1676, Loss: 0.4389, Time: 2.01s\n",
      "Epoch: 3, Batch: 790/1676, Loss: 0.6849, Time: 2.01s\n",
      "Epoch: 3, Batch: 800/1676, Loss: 0.9471, Time: 2.01s\n",
      "Epoch: 3, Batch: 810/1676, Loss: 0.4291, Time: 2.01s\n",
      "Epoch: 3, Batch: 820/1676, Loss: 0.4231, Time: 2.01s\n",
      "Epoch: 3, Batch: 830/1676, Loss: 0.5430, Time: 2.01s\n",
      "Epoch: 3, Batch: 840/1676, Loss: 0.4842, Time: 2.00s\n",
      "Epoch: 3, Batch: 850/1676, Loss: 0.8286, Time: 2.01s\n",
      "Epoch: 3, Batch: 860/1676, Loss: 0.3290, Time: 2.01s\n",
      "Epoch: 3, Batch: 870/1676, Loss: 1.1397, Time: 2.01s\n",
      "Epoch: 3, Batch: 880/1676, Loss: 0.4132, Time: 2.01s\n",
      "Epoch: 3, Batch: 890/1676, Loss: 0.2999, Time: 2.01s\n",
      "Epoch: 3, Batch: 900/1676, Loss: 0.4865, Time: 2.01s\n",
      "Epoch: 3, Batch: 910/1676, Loss: 1.0581, Time: 2.01s\n",
      "Epoch: 3, Batch: 920/1676, Loss: 0.8205, Time: 2.01s\n",
      "Epoch: 3, Batch: 930/1676, Loss: 1.1350, Time: 2.01s\n",
      "Epoch: 3, Batch: 940/1676, Loss: 0.6892, Time: 2.01s\n",
      "Epoch: 3, Batch: 950/1676, Loss: 0.3064, Time: 2.01s\n",
      "Epoch: 3, Batch: 960/1676, Loss: 0.9347, Time: 2.01s\n",
      "Epoch: 3, Batch: 970/1676, Loss: 0.6208, Time: 2.01s\n",
      "Epoch: 3, Batch: 980/1676, Loss: 0.8707, Time: 2.01s\n",
      "Epoch: 3, Batch: 990/1676, Loss: 0.8514, Time: 2.01s\n",
      "Epoch: 3, Batch: 1000/1676, Loss: 0.4073, Time: 2.01s\n",
      "Epoch: 3, Batch: 1010/1676, Loss: 0.7765, Time: 2.01s\n",
      "Epoch: 3, Batch: 1020/1676, Loss: 0.8659, Time: 2.01s\n",
      "Epoch: 3, Batch: 1030/1676, Loss: 0.7519, Time: 2.01s\n",
      "Epoch: 3, Batch: 1040/1676, Loss: 0.6185, Time: 2.01s\n",
      "Epoch: 3, Batch: 1050/1676, Loss: 0.7217, Time: 2.01s\n",
      "Epoch: 3, Batch: 1060/1676, Loss: 0.8951, Time: 2.01s\n",
      "Epoch: 3, Batch: 1070/1676, Loss: 0.7082, Time: 2.01s\n",
      "Epoch: 3, Batch: 1080/1676, Loss: 0.4507, Time: 2.01s\n",
      "Epoch: 3, Batch: 1090/1676, Loss: 0.5722, Time: 2.01s\n",
      "Epoch: 3, Batch: 1100/1676, Loss: 0.6970, Time: 2.01s\n",
      "Epoch: 3, Batch: 1110/1676, Loss: 0.9418, Time: 2.01s\n",
      "Epoch: 3, Batch: 1120/1676, Loss: 0.7341, Time: 2.01s\n",
      "Epoch: 3, Batch: 1130/1676, Loss: 0.4847, Time: 2.01s\n",
      "Epoch: 3, Batch: 1140/1676, Loss: 0.5981, Time: 2.01s\n",
      "Epoch: 3, Batch: 1150/1676, Loss: 0.7093, Time: 2.01s\n",
      "Epoch: 3, Batch: 1160/1676, Loss: 0.6698, Time: 2.01s\n",
      "Epoch: 3, Batch: 1170/1676, Loss: 0.2484, Time: 2.01s\n",
      "Epoch: 3, Batch: 1180/1676, Loss: 0.8238, Time: 2.01s\n",
      "Epoch: 3, Batch: 1190/1676, Loss: 0.7104, Time: 2.01s\n",
      "Epoch: 3, Batch: 1200/1676, Loss: 1.2871, Time: 2.00s\n",
      "Epoch: 3, Batch: 1210/1676, Loss: 0.4986, Time: 2.01s\n",
      "Epoch: 3, Batch: 1220/1676, Loss: 0.8253, Time: 2.01s\n",
      "Epoch: 3, Batch: 1230/1676, Loss: 1.0250, Time: 2.01s\n",
      "Epoch: 3, Batch: 1240/1676, Loss: 0.7902, Time: 2.01s\n",
      "Epoch: 3, Batch: 1250/1676, Loss: 0.3621, Time: 2.02s\n",
      "Epoch: 3, Batch: 1260/1676, Loss: 0.4409, Time: 2.01s\n",
      "Epoch: 3, Batch: 1270/1676, Loss: 1.0233, Time: 2.01s\n",
      "Epoch: 3, Batch: 1280/1676, Loss: 0.4859, Time: 2.01s\n",
      "Epoch: 3, Batch: 1290/1676, Loss: 1.3092, Time: 2.01s\n",
      "Epoch: 3, Batch: 1300/1676, Loss: 0.5364, Time: 2.01s\n",
      "Epoch: 3, Batch: 1310/1676, Loss: 1.0151, Time: 2.01s\n",
      "Epoch: 3, Batch: 1320/1676, Loss: 1.1073, Time: 2.01s\n",
      "Epoch: 3, Batch: 1330/1676, Loss: 1.4767, Time: 2.01s\n",
      "Epoch: 3, Batch: 1340/1676, Loss: 0.4155, Time: 2.01s\n",
      "Epoch: 3, Batch: 1350/1676, Loss: 0.4438, Time: 2.01s\n",
      "Epoch: 3, Batch: 1360/1676, Loss: 0.9526, Time: 2.01s\n",
      "Epoch: 3, Batch: 1370/1676, Loss: 0.5766, Time: 2.01s\n",
      "Epoch: 3, Batch: 1380/1676, Loss: 0.3966, Time: 2.01s\n",
      "Epoch: 3, Batch: 1390/1676, Loss: 0.6952, Time: 2.01s\n",
      "Epoch: 3, Batch: 1400/1676, Loss: 0.4865, Time: 2.01s\n",
      "Epoch: 3, Batch: 1410/1676, Loss: 0.9298, Time: 2.01s\n",
      "Epoch: 3, Batch: 1420/1676, Loss: 0.7683, Time: 2.01s\n",
      "Epoch: 3, Batch: 1430/1676, Loss: 0.6773, Time: 2.01s\n",
      "Epoch: 3, Batch: 1440/1676, Loss: 1.2491, Time: 2.01s\n",
      "Epoch: 3, Batch: 1450/1676, Loss: 0.8770, Time: 2.01s\n",
      "Epoch: 3, Batch: 1460/1676, Loss: 0.7648, Time: 2.01s\n",
      "Epoch: 3, Batch: 1470/1676, Loss: 0.5052, Time: 2.01s\n",
      "Epoch: 3, Batch: 1480/1676, Loss: 0.8193, Time: 2.01s\n",
      "Epoch: 3, Batch: 1490/1676, Loss: 1.3154, Time: 2.01s\n",
      "Epoch: 3, Batch: 1500/1676, Loss: 0.9059, Time: 2.01s\n",
      "Epoch: 3, Batch: 1510/1676, Loss: 1.2666, Time: 2.01s\n",
      "Epoch: 3, Batch: 1520/1676, Loss: 0.5984, Time: 2.01s\n",
      "Epoch: 3, Batch: 1530/1676, Loss: 0.5348, Time: 2.01s\n",
      "Epoch: 3, Batch: 1540/1676, Loss: 0.3113, Time: 2.01s\n",
      "Epoch: 3, Batch: 1550/1676, Loss: 1.0858, Time: 2.01s\n",
      "Epoch: 3, Batch: 1560/1676, Loss: 0.5303, Time: 2.01s\n",
      "Epoch: 3, Batch: 1570/1676, Loss: 0.4787, Time: 2.01s\n",
      "Epoch: 3, Batch: 1580/1676, Loss: 0.5320, Time: 2.01s\n",
      "Epoch: 3, Batch: 1590/1676, Loss: 0.7804, Time: 2.01s\n",
      "Epoch: 3, Batch: 1600/1676, Loss: 0.6975, Time: 2.01s\n",
      "Epoch: 3, Batch: 1610/1676, Loss: 0.5406, Time: 2.01s\n",
      "Epoch: 3, Batch: 1620/1676, Loss: 0.5475, Time: 2.01s\n",
      "Epoch: 3, Batch: 1630/1676, Loss: 0.8630, Time: 2.01s\n",
      "Epoch: 3, Batch: 1640/1676, Loss: 0.3148, Time: 2.01s\n",
      "Epoch: 3, Batch: 1650/1676, Loss: 0.6771, Time: 2.01s\n",
      "Epoch: 3, Batch: 1660/1676, Loss: 0.8269, Time: 2.01s\n",
      "Epoch: 3, Batch: 1670/1676, Loss: 0.9449, Time: 2.01s\n",
      "Epoch 4/50: Train Loss: 0.7664, Val Loss: 0.7836, Val IoU: 0.5501, Val Dice: 0.5688\n",
      "Epoch: 4, Batch: 0/1676, Loss: 0.6397, Time: 35.86s\n",
      "Epoch: 4, Batch: 10/1676, Loss: 1.3365, Time: 2.00s\n",
      "Epoch: 4, Batch: 20/1676, Loss: 0.5538, Time: 1.98s\n",
      "Epoch: 4, Batch: 30/1676, Loss: 0.6509, Time: 1.98s\n",
      "Epoch: 4, Batch: 40/1676, Loss: 0.9160, Time: 1.97s\n",
      "Epoch: 4, Batch: 50/1676, Loss: 0.6241, Time: 1.98s\n",
      "Epoch: 4, Batch: 60/1676, Loss: 0.6794, Time: 1.97s\n",
      "Epoch: 4, Batch: 70/1676, Loss: 0.3575, Time: 1.99s\n",
      "Epoch: 4, Batch: 80/1676, Loss: 0.2892, Time: 1.97s\n",
      "Epoch: 4, Batch: 90/1676, Loss: 0.4658, Time: 1.98s\n",
      "Epoch: 4, Batch: 100/1676, Loss: 0.3519, Time: 1.97s\n",
      "Epoch: 4, Batch: 110/1676, Loss: 1.0926, Time: 1.98s\n",
      "Epoch: 4, Batch: 120/1676, Loss: 0.6774, Time: 1.98s\n",
      "Epoch: 4, Batch: 130/1676, Loss: 1.1829, Time: 1.98s\n",
      "Epoch: 4, Batch: 140/1676, Loss: 1.2317, Time: 1.98s\n",
      "Epoch: 4, Batch: 150/1676, Loss: 1.2357, Time: 1.98s\n",
      "Epoch: 4, Batch: 160/1676, Loss: 0.4313, Time: 1.98s\n",
      "Epoch: 4, Batch: 170/1676, Loss: 1.5638, Time: 1.98s\n",
      "Epoch: 4, Batch: 180/1676, Loss: 0.8232, Time: 2.00s\n",
      "Epoch: 4, Batch: 190/1676, Loss: 0.7778, Time: 1.99s\n",
      "Epoch: 4, Batch: 200/1676, Loss: 1.2047, Time: 1.99s\n",
      "Epoch: 4, Batch: 210/1676, Loss: 1.0448, Time: 1.99s\n",
      "Epoch: 4, Batch: 220/1676, Loss: 0.3495, Time: 1.98s\n",
      "Epoch: 4, Batch: 230/1676, Loss: 0.4035, Time: 2.00s\n",
      "Epoch: 4, Batch: 240/1676, Loss: 0.9710, Time: 1.99s\n",
      "Epoch: 4, Batch: 250/1676, Loss: 0.3435, Time: 1.99s\n",
      "Epoch: 4, Batch: 260/1676, Loss: 0.5015, Time: 1.99s\n",
      "Epoch: 4, Batch: 270/1676, Loss: 0.6630, Time: 1.99s\n",
      "Epoch: 4, Batch: 280/1676, Loss: 0.8729, Time: 2.00s\n",
      "Epoch: 4, Batch: 290/1676, Loss: 0.4858, Time: 2.01s\n",
      "Epoch: 4, Batch: 300/1676, Loss: 0.6827, Time: 2.00s\n",
      "Epoch: 4, Batch: 310/1676, Loss: 0.3630, Time: 1.99s\n",
      "Epoch: 4, Batch: 320/1676, Loss: 0.7798, Time: 1.99s\n",
      "Epoch: 4, Batch: 330/1676, Loss: 0.3263, Time: 1.99s\n",
      "Epoch: 4, Batch: 340/1676, Loss: 0.7974, Time: 1.99s\n",
      "Epoch: 4, Batch: 350/1676, Loss: 1.2096, Time: 2.01s\n",
      "Epoch: 4, Batch: 360/1676, Loss: 0.7510, Time: 2.01s\n",
      "Epoch: 4, Batch: 370/1676, Loss: 0.6622, Time: 1.99s\n",
      "Epoch: 4, Batch: 380/1676, Loss: 0.6040, Time: 2.01s\n",
      "Epoch: 4, Batch: 390/1676, Loss: 1.1165, Time: 2.01s\n",
      "Epoch: 4, Batch: 400/1676, Loss: 0.5436, Time: 2.01s\n",
      "Epoch: 4, Batch: 410/1676, Loss: 1.3796, Time: 2.00s\n",
      "Epoch: 4, Batch: 420/1676, Loss: 0.6184, Time: 2.00s\n",
      "Epoch: 4, Batch: 430/1676, Loss: 0.8573, Time: 2.01s\n",
      "Epoch: 4, Batch: 440/1676, Loss: 0.5276, Time: 2.00s\n",
      "Epoch: 4, Batch: 450/1676, Loss: 1.2732, Time: 2.00s\n",
      "Epoch: 4, Batch: 460/1676, Loss: 0.5346, Time: 2.02s\n",
      "Epoch: 4, Batch: 470/1676, Loss: 0.5848, Time: 2.00s\n",
      "Epoch: 4, Batch: 480/1676, Loss: 0.8291, Time: 2.00s\n",
      "Epoch: 4, Batch: 490/1676, Loss: 1.0084, Time: 2.01s\n",
      "Epoch: 4, Batch: 500/1676, Loss: 1.0228, Time: 2.00s\n",
      "Epoch: 4, Batch: 510/1676, Loss: 0.5525, Time: 2.00s\n",
      "Epoch: 4, Batch: 520/1676, Loss: 0.5085, Time: 2.02s\n",
      "Epoch: 4, Batch: 530/1676, Loss: 0.7095, Time: 2.01s\n",
      "Epoch: 4, Batch: 540/1676, Loss: 0.6429, Time: 2.01s\n",
      "Epoch: 4, Batch: 550/1676, Loss: 0.7141, Time: 1.99s\n",
      "Epoch: 4, Batch: 560/1676, Loss: 0.7500, Time: 2.01s\n",
      "Epoch: 4, Batch: 570/1676, Loss: 1.0591, Time: 2.01s\n",
      "Epoch: 4, Batch: 580/1676, Loss: 0.8955, Time: 2.00s\n",
      "Epoch: 4, Batch: 590/1676, Loss: 1.4073, Time: 2.00s\n",
      "Epoch: 4, Batch: 600/1676, Loss: 0.7222, Time: 1.99s\n",
      "Epoch: 4, Batch: 610/1676, Loss: 1.0265, Time: 2.00s\n",
      "Epoch: 4, Batch: 620/1676, Loss: 0.4372, Time: 2.01s\n",
      "Epoch: 4, Batch: 630/1676, Loss: 0.6621, Time: 2.00s\n",
      "Epoch: 4, Batch: 640/1676, Loss: 0.6057, Time: 2.00s\n",
      "Epoch: 4, Batch: 650/1676, Loss: 0.8707, Time: 1.99s\n",
      "Epoch: 4, Batch: 660/1676, Loss: 0.7008, Time: 2.00s\n",
      "Epoch: 4, Batch: 670/1676, Loss: 1.7407, Time: 2.01s\n",
      "Epoch: 4, Batch: 680/1676, Loss: 0.8022, Time: 2.01s\n",
      "Epoch: 4, Batch: 690/1676, Loss: 0.5489, Time: 2.00s\n",
      "Epoch: 4, Batch: 700/1676, Loss: 0.7449, Time: 1.99s\n",
      "Epoch: 4, Batch: 710/1676, Loss: 0.7571, Time: 2.01s\n",
      "Epoch: 4, Batch: 720/1676, Loss: 0.5080, Time: 2.01s\n",
      "Epoch: 4, Batch: 730/1676, Loss: 0.3571, Time: 2.00s\n",
      "Epoch: 4, Batch: 740/1676, Loss: 0.7760, Time: 2.00s\n",
      "Epoch: 4, Batch: 750/1676, Loss: 0.4417, Time: 2.01s\n",
      "Epoch: 4, Batch: 760/1676, Loss: 0.5661, Time: 2.01s\n",
      "Epoch: 4, Batch: 770/1676, Loss: 0.4356, Time: 2.01s\n",
      "Epoch: 4, Batch: 780/1676, Loss: 0.8119, Time: 2.01s\n",
      "Epoch: 4, Batch: 790/1676, Loss: 1.0015, Time: 1.99s\n",
      "Epoch: 4, Batch: 800/1676, Loss: 0.6235, Time: 2.01s\n",
      "Epoch: 4, Batch: 810/1676, Loss: 0.8800, Time: 2.01s\n",
      "Epoch: 4, Batch: 820/1676, Loss: 0.5185, Time: 2.01s\n",
      "Epoch: 4, Batch: 830/1676, Loss: 0.4486, Time: 2.01s\n",
      "Epoch: 4, Batch: 840/1676, Loss: 0.9097, Time: 2.00s\n",
      "Epoch: 4, Batch: 850/1676, Loss: 0.5971, Time: 2.00s\n",
      "Epoch: 4, Batch: 860/1676, Loss: 1.3038, Time: 2.00s\n",
      "Epoch: 4, Batch: 870/1676, Loss: 0.7555, Time: 2.01s\n",
      "Epoch: 4, Batch: 880/1676, Loss: 0.3371, Time: 1.99s\n",
      "Epoch: 4, Batch: 890/1676, Loss: 0.9367, Time: 2.01s\n",
      "Epoch: 4, Batch: 900/1676, Loss: 0.5969, Time: 2.01s\n",
      "Epoch: 4, Batch: 910/1676, Loss: 1.4074, Time: 2.01s\n",
      "Epoch: 4, Batch: 920/1676, Loss: 1.1732, Time: 2.01s\n",
      "Epoch: 4, Batch: 930/1676, Loss: 1.0534, Time: 2.00s\n",
      "Epoch: 4, Batch: 940/1676, Loss: 0.3821, Time: 2.00s\n",
      "Epoch: 4, Batch: 950/1676, Loss: 1.0882, Time: 2.00s\n",
      "Epoch: 4, Batch: 960/1676, Loss: 0.4878, Time: 1.99s\n",
      "Epoch: 4, Batch: 970/1676, Loss: 0.5223, Time: 2.01s\n",
      "Epoch: 4, Batch: 980/1676, Loss: 1.6704, Time: 2.01s\n",
      "Epoch: 4, Batch: 990/1676, Loss: 0.9237, Time: 2.00s\n",
      "Epoch: 4, Batch: 1000/1676, Loss: 1.0119, Time: 2.01s\n",
      "Epoch: 4, Batch: 1010/1676, Loss: 0.5523, Time: 1.99s\n",
      "Epoch: 4, Batch: 1020/1676, Loss: 0.4019, Time: 2.01s\n",
      "Epoch: 4, Batch: 1030/1676, Loss: 0.7215, Time: 2.00s\n",
      "Epoch: 4, Batch: 1040/1676, Loss: 0.5043, Time: 2.00s\n",
      "Epoch: 4, Batch: 1050/1676, Loss: 0.3622, Time: 2.00s\n",
      "Epoch: 4, Batch: 1060/1676, Loss: 1.0005, Time: 2.02s\n",
      "Epoch: 4, Batch: 1070/1676, Loss: 0.7634, Time: 2.01s\n",
      "Epoch: 4, Batch: 1080/1676, Loss: 1.2067, Time: 2.01s\n",
      "Epoch: 4, Batch: 1090/1676, Loss: 0.4860, Time: 2.01s\n",
      "Epoch: 4, Batch: 1100/1676, Loss: 0.7267, Time: 2.00s\n",
      "Epoch: 4, Batch: 1110/1676, Loss: 1.0665, Time: 2.00s\n",
      "Epoch: 4, Batch: 1120/1676, Loss: 0.8674, Time: 2.00s\n",
      "Epoch: 4, Batch: 1130/1676, Loss: 0.5400, Time: 2.00s\n",
      "Epoch: 4, Batch: 1140/1676, Loss: 0.7518, Time: 2.01s\n",
      "Epoch: 4, Batch: 1150/1676, Loss: 0.9990, Time: 2.01s\n",
      "Epoch: 4, Batch: 1160/1676, Loss: 0.7542, Time: 2.01s\n",
      "Epoch: 4, Batch: 1170/1676, Loss: 0.3186, Time: 2.01s\n",
      "Epoch: 4, Batch: 1180/1676, Loss: 0.3166, Time: 2.00s\n",
      "Epoch: 4, Batch: 1190/1676, Loss: 0.6475, Time: 2.00s\n",
      "Epoch: 4, Batch: 1200/1676, Loss: 0.3688, Time: 2.01s\n",
      "Epoch: 4, Batch: 1210/1676, Loss: 0.6249, Time: 2.01s\n",
      "Epoch: 4, Batch: 1220/1676, Loss: 0.5682, Time: 2.00s\n",
      "Epoch: 4, Batch: 1230/1676, Loss: 0.2752, Time: 2.00s\n",
      "Epoch: 4, Batch: 1240/1676, Loss: 0.7883, Time: 2.01s\n",
      "Epoch: 4, Batch: 1250/1676, Loss: 0.5635, Time: 1.99s\n",
      "Epoch: 4, Batch: 1260/1676, Loss: 0.9203, Time: 2.01s\n",
      "Epoch: 4, Batch: 1270/1676, Loss: 0.6314, Time: 2.01s\n",
      "Epoch: 4, Batch: 1280/1676, Loss: 1.0073, Time: 2.01s\n",
      "Epoch: 4, Batch: 1290/1676, Loss: 0.5714, Time: 2.01s\n",
      "Epoch: 4, Batch: 1300/1676, Loss: 0.7091, Time: 2.01s\n",
      "Epoch: 4, Batch: 1310/1676, Loss: 0.8508, Time: 1.99s\n",
      "Epoch: 4, Batch: 1320/1676, Loss: 0.6917, Time: 2.01s\n",
      "Epoch: 4, Batch: 1330/1676, Loss: 0.8904, Time: 2.01s\n",
      "Epoch: 4, Batch: 1340/1676, Loss: 0.7686, Time: 2.00s\n",
      "Epoch: 4, Batch: 1350/1676, Loss: 1.3981, Time: 2.01s\n",
      "Epoch: 4, Batch: 1360/1676, Loss: 0.7600, Time: 2.01s\n",
      "Epoch: 4, Batch: 1370/1676, Loss: 0.4445, Time: 2.01s\n",
      "Epoch: 4, Batch: 1380/1676, Loss: 1.1766, Time: 2.01s\n",
      "Epoch: 4, Batch: 1390/1676, Loss: 0.6932, Time: 2.01s\n",
      "Epoch: 4, Batch: 1400/1676, Loss: 0.8781, Time: 1.99s\n",
      "Epoch: 4, Batch: 1410/1676, Loss: 0.9031, Time: 2.01s\n",
      "Epoch: 4, Batch: 1420/1676, Loss: 1.0284, Time: 2.00s\n",
      "Epoch: 4, Batch: 1430/1676, Loss: 0.7072, Time: 2.01s\n",
      "Epoch: 4, Batch: 1440/1676, Loss: 0.4872, Time: 2.00s\n",
      "Epoch: 4, Batch: 1450/1676, Loss: 0.7314, Time: 2.00s\n",
      "Epoch: 4, Batch: 1460/1676, Loss: 1.4905, Time: 2.00s\n",
      "Epoch: 4, Batch: 1470/1676, Loss: 0.6969, Time: 1.99s\n",
      "Epoch: 4, Batch: 1480/1676, Loss: 0.5127, Time: 2.01s\n",
      "Epoch: 4, Batch: 1490/1676, Loss: 0.6810, Time: 1.99s\n",
      "Epoch: 4, Batch: 1500/1676, Loss: 0.7081, Time: 2.01s\n",
      "Epoch: 4, Batch: 1510/1676, Loss: 1.0924, Time: 2.00s\n",
      "Epoch: 4, Batch: 1520/1676, Loss: 1.0400, Time: 2.01s\n",
      "Epoch: 4, Batch: 1530/1676, Loss: 0.6263, Time: 2.00s\n",
      "Epoch: 4, Batch: 1540/1676, Loss: 1.1650, Time: 2.01s\n",
      "Epoch: 4, Batch: 1550/1676, Loss: 0.8222, Time: 1.99s\n",
      "Epoch: 4, Batch: 1560/1676, Loss: 0.9997, Time: 2.01s\n",
      "Epoch: 4, Batch: 1570/1676, Loss: 0.9069, Time: 2.01s\n",
      "Epoch: 4, Batch: 1580/1676, Loss: 1.3336, Time: 2.01s\n",
      "Epoch: 4, Batch: 1590/1676, Loss: 1.2299, Time: 1.99s\n",
      "Epoch: 4, Batch: 1600/1676, Loss: 0.5627, Time: 2.01s\n",
      "Epoch: 4, Batch: 1610/1676, Loss: 0.2532, Time: 2.00s\n",
      "Epoch: 4, Batch: 1620/1676, Loss: 0.6954, Time: 2.00s\n",
      "Epoch: 4, Batch: 1630/1676, Loss: 0.7212, Time: 2.00s\n",
      "Epoch: 4, Batch: 1640/1676, Loss: 0.4468, Time: 2.00s\n",
      "Epoch: 4, Batch: 1650/1676, Loss: 0.8892, Time: 2.01s\n",
      "Epoch: 4, Batch: 1660/1676, Loss: 0.6828, Time: 2.01s\n",
      "Epoch: 4, Batch: 1670/1676, Loss: 0.8162, Time: 2.00s\n",
      "Epoch 5/50: Train Loss: 0.7585, Val Loss: 0.7578, Val IoU: 0.5520, Val Dice: 0.5712\n",
      "Saving best model with IoU: 0.5520\n",
      "Epoch: 5, Batch: 0/1676, Loss: 0.5648, Time: 35.96s\n",
      "Epoch: 5, Batch: 10/1676, Loss: 0.3156, Time: 2.00s\n",
      "Epoch: 5, Batch: 20/1676, Loss: 0.3173, Time: 1.95s\n",
      "Epoch: 5, Batch: 30/1676, Loss: 0.7542, Time: 1.95s\n",
      "Epoch: 5, Batch: 40/1676, Loss: 0.8286, Time: 1.95s\n",
      "Epoch: 5, Batch: 50/1676, Loss: 0.4545, Time: 1.96s\n",
      "Epoch: 5, Batch: 60/1676, Loss: 0.8514, Time: 1.96s\n",
      "Epoch: 5, Batch: 70/1676, Loss: 0.7856, Time: 1.96s\n",
      "Epoch: 5, Batch: 80/1676, Loss: 0.9885, Time: 1.96s\n",
      "Epoch: 5, Batch: 90/1676, Loss: 1.3696, Time: 1.96s\n",
      "Epoch: 5, Batch: 100/1676, Loss: 0.4817, Time: 1.96s\n",
      "Epoch: 5, Batch: 110/1676, Loss: 0.4062, Time: 1.97s\n",
      "Epoch: 5, Batch: 120/1676, Loss: 0.9550, Time: 1.96s\n",
      "Epoch: 5, Batch: 130/1676, Loss: 0.5153, Time: 1.97s\n",
      "Epoch: 5, Batch: 140/1676, Loss: 1.1806, Time: 1.97s\n",
      "Epoch: 5, Batch: 150/1676, Loss: 0.6506, Time: 1.96s\n",
      "Epoch: 5, Batch: 160/1676, Loss: 0.5876, Time: 1.97s\n",
      "Epoch: 5, Batch: 170/1676, Loss: 1.0454, Time: 1.98s\n",
      "Epoch: 5, Batch: 180/1676, Loss: 0.8525, Time: 1.97s\n",
      "Epoch: 5, Batch: 190/1676, Loss: 0.4712, Time: 1.97s\n",
      "Epoch: 5, Batch: 200/1676, Loss: 0.4028, Time: 1.97s\n",
      "Epoch: 5, Batch: 210/1676, Loss: 0.7922, Time: 1.97s\n",
      "Epoch: 5, Batch: 220/1676, Loss: 0.5949, Time: 1.97s\n",
      "Epoch: 5, Batch: 230/1676, Loss: 0.5853, Time: 1.97s\n",
      "Epoch: 5, Batch: 240/1676, Loss: 0.5477, Time: 1.97s\n",
      "Epoch: 5, Batch: 250/1676, Loss: 0.3761, Time: 1.97s\n",
      "Epoch: 5, Batch: 260/1676, Loss: 1.1799, Time: 1.97s\n",
      "Epoch: 5, Batch: 270/1676, Loss: 1.0988, Time: 1.98s\n",
      "Epoch: 5, Batch: 280/1676, Loss: 0.4314, Time: 1.98s\n",
      "Epoch: 5, Batch: 290/1676, Loss: 0.6568, Time: 1.97s\n",
      "Epoch: 5, Batch: 300/1676, Loss: 1.1975, Time: 1.98s\n",
      "Epoch: 5, Batch: 310/1676, Loss: 0.5088, Time: 1.97s\n",
      "Epoch: 5, Batch: 320/1676, Loss: 0.3824, Time: 1.98s\n",
      "Epoch: 5, Batch: 330/1676, Loss: 0.5452, Time: 1.98s\n",
      "Epoch: 5, Batch: 340/1676, Loss: 0.4572, Time: 1.97s\n",
      "Epoch: 5, Batch: 350/1676, Loss: 0.6867, Time: 1.98s\n",
      "Epoch: 5, Batch: 360/1676, Loss: 0.5121, Time: 1.99s\n",
      "Epoch: 5, Batch: 370/1676, Loss: 0.3120, Time: 1.98s\n",
      "Epoch: 5, Batch: 380/1676, Loss: 0.4026, Time: 1.99s\n",
      "Epoch: 5, Batch: 390/1676, Loss: 0.4396, Time: 1.97s\n",
      "Epoch: 5, Batch: 400/1676, Loss: 0.9060, Time: 1.98s\n",
      "Epoch: 5, Batch: 410/1676, Loss: 0.5339, Time: 1.97s\n",
      "Epoch: 5, Batch: 420/1676, Loss: 0.6455, Time: 1.98s\n",
      "Epoch: 5, Batch: 430/1676, Loss: 0.3457, Time: 1.99s\n",
      "Epoch: 5, Batch: 440/1676, Loss: 0.8460, Time: 1.98s\n",
      "Epoch: 5, Batch: 450/1676, Loss: 0.7142, Time: 1.99s\n",
      "Epoch: 5, Batch: 460/1676, Loss: 0.3956, Time: 1.98s\n",
      "Epoch: 5, Batch: 470/1676, Loss: 0.8769, Time: 1.98s\n",
      "Epoch: 5, Batch: 480/1676, Loss: 1.0192, Time: 1.99s\n",
      "Epoch: 5, Batch: 490/1676, Loss: 0.8020, Time: 1.98s\n",
      "Epoch: 5, Batch: 500/1676, Loss: 0.3401, Time: 1.99s\n",
      "Epoch: 5, Batch: 510/1676, Loss: 1.4530, Time: 1.99s\n",
      "Epoch: 5, Batch: 520/1676, Loss: 1.1018, Time: 1.98s\n",
      "Epoch: 5, Batch: 530/1676, Loss: 0.4846, Time: 1.98s\n",
      "Epoch: 5, Batch: 540/1676, Loss: 1.2723, Time: 1.98s\n",
      "Epoch: 5, Batch: 550/1676, Loss: 1.1587, Time: 1.99s\n",
      "Epoch: 5, Batch: 560/1676, Loss: 0.7571, Time: 1.99s\n",
      "Epoch: 5, Batch: 570/1676, Loss: 0.5463, Time: 1.98s\n",
      "Epoch: 5, Batch: 580/1676, Loss: 0.9691, Time: 1.99s\n",
      "Epoch: 5, Batch: 590/1676, Loss: 0.4162, Time: 1.99s\n",
      "Epoch: 5, Batch: 600/1676, Loss: 0.4761, Time: 1.98s\n",
      "Epoch: 5, Batch: 610/1676, Loss: 0.3989, Time: 1.99s\n",
      "Epoch: 5, Batch: 620/1676, Loss: 0.6376, Time: 1.99s\n",
      "Epoch: 5, Batch: 630/1676, Loss: 0.7034, Time: 1.98s\n",
      "Epoch: 5, Batch: 640/1676, Loss: 0.7092, Time: 1.98s\n",
      "Epoch: 5, Batch: 650/1676, Loss: 0.7976, Time: 1.99s\n",
      "Epoch: 5, Batch: 660/1676, Loss: 0.4973, Time: 1.98s\n",
      "Epoch: 5, Batch: 670/1676, Loss: 0.3956, Time: 1.98s\n",
      "Epoch: 5, Batch: 680/1676, Loss: 1.0198, Time: 1.99s\n",
      "Epoch: 5, Batch: 690/1676, Loss: 0.7572, Time: 1.99s\n",
      "Epoch: 5, Batch: 700/1676, Loss: 0.7136, Time: 1.98s\n",
      "Epoch: 5, Batch: 710/1676, Loss: 1.2886, Time: 1.99s\n",
      "Epoch: 5, Batch: 720/1676, Loss: 0.8513, Time: 1.98s\n",
      "Epoch: 5, Batch: 730/1676, Loss: 0.4773, Time: 1.99s\n",
      "Epoch: 5, Batch: 740/1676, Loss: 0.4467, Time: 1.99s\n",
      "Epoch: 5, Batch: 750/1676, Loss: 0.8267, Time: 1.98s\n",
      "Epoch: 5, Batch: 760/1676, Loss: 0.8179, Time: 1.99s\n",
      "Epoch: 5, Batch: 770/1676, Loss: 0.4621, Time: 2.00s\n",
      "Epoch: 5, Batch: 780/1676, Loss: 0.9573, Time: 1.99s\n",
      "Epoch: 5, Batch: 790/1676, Loss: 0.6036, Time: 1.98s\n",
      "Epoch: 5, Batch: 800/1676, Loss: 0.3491, Time: 1.99s\n",
      "Epoch: 5, Batch: 810/1676, Loss: 0.3894, Time: 1.99s\n",
      "Epoch: 5, Batch: 820/1676, Loss: 0.5888, Time: 1.98s\n",
      "Epoch: 5, Batch: 830/1676, Loss: 2.0237, Time: 1.98s\n",
      "Epoch: 5, Batch: 840/1676, Loss: 1.5775, Time: 1.98s\n",
      "Epoch: 5, Batch: 850/1676, Loss: 0.3675, Time: 1.99s\n",
      "Epoch: 5, Batch: 860/1676, Loss: 0.3539, Time: 1.99s\n",
      "Epoch: 5, Batch: 870/1676, Loss: 0.8555, Time: 1.99s\n",
      "Epoch: 5, Batch: 880/1676, Loss: 0.3952, Time: 1.99s\n",
      "Epoch: 5, Batch: 890/1676, Loss: 0.8881, Time: 1.99s\n",
      "Epoch: 5, Batch: 900/1676, Loss: 0.5420, Time: 1.99s\n",
      "Epoch: 5, Batch: 910/1676, Loss: 0.7232, Time: 2.00s\n",
      "Epoch: 5, Batch: 920/1676, Loss: 0.8187, Time: 1.99s\n",
      "Epoch: 5, Batch: 930/1676, Loss: 0.8073, Time: 1.99s\n",
      "Epoch: 5, Batch: 940/1676, Loss: 0.5492, Time: 1.99s\n",
      "Epoch: 5, Batch: 950/1676, Loss: 0.4768, Time: 1.99s\n",
      "Epoch: 5, Batch: 960/1676, Loss: 0.7276, Time: 1.98s\n",
      "Epoch: 5, Batch: 970/1676, Loss: 0.4929, Time: 1.99s\n",
      "Epoch: 5, Batch: 980/1676, Loss: 0.8256, Time: 2.00s\n",
      "Epoch: 5, Batch: 990/1676, Loss: 0.9871, Time: 1.99s\n",
      "Epoch: 5, Batch: 1000/1676, Loss: 1.1061, Time: 1.99s\n",
      "Epoch: 5, Batch: 1010/1676, Loss: 0.3305, Time: 1.99s\n",
      "Epoch: 5, Batch: 1020/1676, Loss: 0.9826, Time: 1.99s\n",
      "Epoch: 5, Batch: 1030/1676, Loss: 0.2594, Time: 2.00s\n",
      "Epoch: 5, Batch: 1040/1676, Loss: 0.4665, Time: 1.99s\n",
      "Epoch: 5, Batch: 1050/1676, Loss: 0.5918, Time: 1.99s\n",
      "Epoch: 5, Batch: 1060/1676, Loss: 0.6738, Time: 1.99s\n",
      "Epoch: 5, Batch: 1070/1676, Loss: 1.0477, Time: 1.99s\n",
      "Epoch: 5, Batch: 1080/1676, Loss: 0.4885, Time: 1.98s\n",
      "Epoch: 5, Batch: 1090/1676, Loss: 1.0136, Time: 1.99s\n",
      "Epoch: 5, Batch: 1100/1676, Loss: 0.5974, Time: 1.99s\n",
      "Epoch: 5, Batch: 1110/1676, Loss: 0.3351, Time: 1.99s\n",
      "Epoch: 5, Batch: 1120/1676, Loss: 0.3756, Time: 1.99s\n",
      "Epoch: 5, Batch: 1130/1676, Loss: 0.4751, Time: 1.99s\n",
      "Epoch: 5, Batch: 1140/1676, Loss: 1.1372, Time: 1.99s\n",
      "Epoch: 5, Batch: 1150/1676, Loss: 0.6695, Time: 1.99s\n",
      "Epoch: 5, Batch: 1160/1676, Loss: 0.4857, Time: 1.99s\n",
      "Epoch: 5, Batch: 1170/1676, Loss: 1.0606, Time: 1.99s\n",
      "Epoch: 5, Batch: 1180/1676, Loss: 0.7702, Time: 1.99s\n",
      "Epoch: 5, Batch: 1190/1676, Loss: 0.4859, Time: 1.99s\n",
      "Epoch: 5, Batch: 1200/1676, Loss: 1.1710, Time: 1.99s\n",
      "Epoch: 5, Batch: 1210/1676, Loss: 1.0615, Time: 1.99s\n",
      "Epoch: 5, Batch: 1220/1676, Loss: 0.7553, Time: 1.98s\n",
      "Epoch: 5, Batch: 1230/1676, Loss: 0.5301, Time: 1.99s\n",
      "Epoch: 5, Batch: 1240/1676, Loss: 0.6324, Time: 1.99s\n",
      "Epoch: 5, Batch: 1250/1676, Loss: 1.0385, Time: 1.99s\n",
      "Epoch: 5, Batch: 1260/1676, Loss: 0.7083, Time: 1.99s\n",
      "Epoch: 5, Batch: 1270/1676, Loss: 0.6575, Time: 1.99s\n",
      "Epoch: 5, Batch: 1280/1676, Loss: 0.4192, Time: 1.99s\n",
      "Epoch: 5, Batch: 1290/1676, Loss: 0.6961, Time: 1.99s\n",
      "Epoch: 5, Batch: 1300/1676, Loss: 0.5842, Time: 1.98s\n",
      "Epoch: 5, Batch: 1310/1676, Loss: 0.6372, Time: 2.01s\n",
      "Epoch: 5, Batch: 1320/1676, Loss: 0.3410, Time: 2.00s\n",
      "Epoch: 5, Batch: 1330/1676, Loss: 0.2548, Time: 1.99s\n",
      "Epoch: 5, Batch: 1340/1676, Loss: 0.5599, Time: 1.99s\n",
      "Epoch: 5, Batch: 1350/1676, Loss: 0.9165, Time: 1.99s\n",
      "Epoch: 5, Batch: 1360/1676, Loss: 0.8104, Time: 1.99s\n",
      "Epoch: 5, Batch: 1370/1676, Loss: 0.7728, Time: 1.98s\n",
      "Epoch: 5, Batch: 1380/1676, Loss: 0.7114, Time: 2.00s\n",
      "Epoch: 5, Batch: 1390/1676, Loss: 0.6532, Time: 1.99s\n",
      "Epoch: 5, Batch: 1400/1676, Loss: 0.8155, Time: 1.99s\n",
      "Epoch: 5, Batch: 1410/1676, Loss: 0.6888, Time: 1.99s\n",
      "Epoch: 5, Batch: 1420/1676, Loss: 0.8222, Time: 2.00s\n",
      "Epoch: 5, Batch: 1430/1676, Loss: 0.5330, Time: 1.99s\n",
      "Epoch: 5, Batch: 1440/1676, Loss: 0.4480, Time: 1.99s\n",
      "Epoch: 5, Batch: 1450/1676, Loss: 0.7222, Time: 1.99s\n",
      "Epoch: 5, Batch: 1460/1676, Loss: 0.7503, Time: 1.99s\n",
      "Epoch: 5, Batch: 1470/1676, Loss: 0.5836, Time: 1.98s\n",
      "Epoch: 5, Batch: 1480/1676, Loss: 0.5030, Time: 1.99s\n",
      "Epoch: 5, Batch: 1490/1676, Loss: 0.8944, Time: 1.99s\n",
      "Epoch: 5, Batch: 1500/1676, Loss: 0.3697, Time: 1.99s\n",
      "Epoch: 5, Batch: 1510/1676, Loss: 1.1375, Time: 1.99s\n",
      "Epoch: 5, Batch: 1520/1676, Loss: 1.0548, Time: 2.00s\n",
      "Epoch: 5, Batch: 1530/1676, Loss: 0.5784, Time: 1.99s\n",
      "Epoch: 5, Batch: 1540/1676, Loss: 0.9276, Time: 1.98s\n",
      "Epoch: 5, Batch: 1550/1676, Loss: 0.4424, Time: 2.00s\n",
      "Epoch: 5, Batch: 1560/1676, Loss: 0.7791, Time: 1.99s\n",
      "Epoch: 5, Batch: 1570/1676, Loss: 0.6910, Time: 1.99s\n",
      "Epoch: 5, Batch: 1580/1676, Loss: 0.2561, Time: 1.99s\n",
      "Epoch: 5, Batch: 1590/1676, Loss: 0.9434, Time: 1.99s\n",
      "Epoch: 5, Batch: 1600/1676, Loss: 0.6569, Time: 1.98s\n",
      "Epoch: 5, Batch: 1610/1676, Loss: 0.8345, Time: 1.99s\n",
      "Epoch: 5, Batch: 1620/1676, Loss: 1.0280, Time: 1.98s\n",
      "Epoch: 5, Batch: 1630/1676, Loss: 0.8502, Time: 1.99s\n",
      "Epoch: 5, Batch: 1640/1676, Loss: 0.7037, Time: 1.99s\n",
      "Epoch: 5, Batch: 1650/1676, Loss: 0.5946, Time: 1.99s\n",
      "Epoch: 5, Batch: 1660/1676, Loss: 1.2352, Time: 1.99s\n",
      "Epoch: 5, Batch: 1670/1676, Loss: 0.6534, Time: 1.99s\n",
      "Epoch 6/50: Train Loss: 0.7486, Val Loss: 0.7480, Val IoU: 0.5578, Val Dice: 0.5774\n",
      "Saving best model with IoU: 0.5578\n",
      "Epoch: 6, Batch: 0/1676, Loss: 0.7935, Time: 36.03s\n",
      "Epoch: 6, Batch: 10/1676, Loss: 1.5304, Time: 1.99s\n",
      "Epoch: 6, Batch: 20/1676, Loss: 0.7309, Time: 1.94s\n",
      "Epoch: 6, Batch: 30/1676, Loss: 0.2806, Time: 1.94s\n",
      "Epoch: 6, Batch: 40/1676, Loss: 0.5286, Time: 1.95s\n",
      "Epoch: 6, Batch: 50/1676, Loss: 0.7184, Time: 1.95s\n",
      "Epoch: 6, Batch: 60/1676, Loss: 0.4635, Time: 1.96s\n",
      "Epoch: 6, Batch: 70/1676, Loss: 0.6565, Time: 1.95s\n",
      "Epoch: 6, Batch: 80/1676, Loss: 0.7629, Time: 1.95s\n",
      "Epoch: 6, Batch: 90/1676, Loss: 0.7262, Time: 1.96s\n",
      "Epoch: 6, Batch: 100/1676, Loss: 0.8959, Time: 1.95s\n",
      "Epoch: 6, Batch: 110/1676, Loss: 0.8788, Time: 1.95s\n",
      "Epoch: 6, Batch: 120/1676, Loss: 1.0159, Time: 1.96s\n",
      "Epoch: 6, Batch: 130/1676, Loss: 1.2044, Time: 1.95s\n",
      "Epoch: 6, Batch: 140/1676, Loss: 0.7032, Time: 1.96s\n",
      "Epoch: 6, Batch: 150/1676, Loss: 0.7847, Time: 1.96s\n",
      "Epoch: 6, Batch: 160/1676, Loss: 0.8583, Time: 1.97s\n",
      "Epoch: 6, Batch: 170/1676, Loss: 0.7252, Time: 1.96s\n",
      "Epoch: 6, Batch: 180/1676, Loss: 0.4799, Time: 1.97s\n",
      "Epoch: 6, Batch: 190/1676, Loss: 0.3209, Time: 1.96s\n",
      "Epoch: 6, Batch: 200/1676, Loss: 0.5243, Time: 1.96s\n",
      "Epoch: 6, Batch: 210/1676, Loss: 0.8998, Time: 1.96s\n",
      "Epoch: 6, Batch: 220/1676, Loss: 1.0113, Time: 1.97s\n",
      "Epoch: 6, Batch: 230/1676, Loss: 0.4810, Time: 1.96s\n",
      "Epoch: 6, Batch: 240/1676, Loss: 1.5701, Time: 1.98s\n",
      "Epoch: 6, Batch: 250/1676, Loss: 0.4237, Time: 1.99s\n",
      "Epoch: 6, Batch: 260/1676, Loss: 0.3581, Time: 2.01s\n",
      "Epoch: 6, Batch: 270/1676, Loss: 1.2913, Time: 2.00s\n",
      "Epoch: 6, Batch: 280/1676, Loss: 0.2815, Time: 2.00s\n",
      "Epoch: 6, Batch: 290/1676, Loss: 0.7975, Time: 2.00s\n",
      "Epoch: 6, Batch: 300/1676, Loss: 0.6629, Time: 1.98s\n",
      "Epoch: 6, Batch: 310/1676, Loss: 0.8308, Time: 1.97s\n",
      "Epoch: 6, Batch: 320/1676, Loss: 0.9392, Time: 1.97s\n",
      "Epoch: 6, Batch: 330/1676, Loss: 0.2983, Time: 1.97s\n",
      "Epoch: 6, Batch: 340/1676, Loss: 1.4428, Time: 1.97s\n",
      "Epoch: 6, Batch: 350/1676, Loss: 0.3504, Time: 1.97s\n",
      "Epoch: 6, Batch: 360/1676, Loss: 0.3717, Time: 1.97s\n",
      "Epoch: 6, Batch: 370/1676, Loss: 0.7674, Time: 1.97s\n",
      "Epoch: 6, Batch: 380/1676, Loss: 0.7675, Time: 1.97s\n",
      "Epoch: 6, Batch: 390/1676, Loss: 0.7846, Time: 1.98s\n",
      "Epoch: 6, Batch: 400/1676, Loss: 1.3807, Time: 1.97s\n",
      "Epoch: 6, Batch: 410/1676, Loss: 0.9522, Time: 1.97s\n",
      "Epoch: 6, Batch: 420/1676, Loss: 1.1386, Time: 1.97s\n",
      "Epoch: 6, Batch: 430/1676, Loss: 0.7187, Time: 1.98s\n",
      "Epoch: 6, Batch: 440/1676, Loss: 0.9337, Time: 1.98s\n",
      "Epoch: 6, Batch: 450/1676, Loss: 0.8845, Time: 1.97s\n",
      "Epoch: 6, Batch: 460/1676, Loss: 1.1194, Time: 1.98s\n",
      "Epoch: 6, Batch: 470/1676, Loss: 0.6731, Time: 1.98s\n",
      "Epoch: 6, Batch: 480/1676, Loss: 0.4976, Time: 1.98s\n",
      "Epoch: 6, Batch: 490/1676, Loss: 0.6220, Time: 1.97s\n",
      "Epoch: 6, Batch: 500/1676, Loss: 1.1517, Time: 1.98s\n",
      "Epoch: 6, Batch: 510/1676, Loss: 0.6750, Time: 1.97s\n",
      "Epoch: 6, Batch: 520/1676, Loss: 0.8118, Time: 1.98s\n",
      "Epoch: 6, Batch: 530/1676, Loss: 0.4888, Time: 1.97s\n",
      "Epoch: 6, Batch: 540/1676, Loss: 0.5184, Time: 1.97s\n",
      "Epoch: 6, Batch: 550/1676, Loss: 0.7989, Time: 1.97s\n",
      "Epoch: 6, Batch: 560/1676, Loss: 0.7017, Time: 1.98s\n",
      "Epoch: 6, Batch: 570/1676, Loss: 1.3524, Time: 1.98s\n",
      "Epoch: 6, Batch: 580/1676, Loss: 0.3307, Time: 1.97s\n",
      "Epoch: 6, Batch: 590/1676, Loss: 0.4846, Time: 1.99s\n",
      "Epoch: 6, Batch: 600/1676, Loss: 0.4131, Time: 1.98s\n",
      "Epoch: 6, Batch: 610/1676, Loss: 0.6713, Time: 1.98s\n",
      "Epoch: 6, Batch: 620/1676, Loss: 0.3356, Time: 1.98s\n",
      "Epoch: 6, Batch: 630/1676, Loss: 1.5388, Time: 1.97s\n",
      "Epoch: 6, Batch: 640/1676, Loss: 0.6822, Time: 1.98s\n",
      "Epoch: 6, Batch: 650/1676, Loss: 0.8606, Time: 1.98s\n",
      "Epoch: 6, Batch: 660/1676, Loss: 0.5119, Time: 1.98s\n",
      "Epoch: 6, Batch: 670/1676, Loss: 0.3622, Time: 1.98s\n",
      "Epoch: 6, Batch: 680/1676, Loss: 0.4589, Time: 1.98s\n",
      "Epoch: 6, Batch: 690/1676, Loss: 1.5911, Time: 1.98s\n",
      "Epoch: 6, Batch: 700/1676, Loss: 1.5149, Time: 1.99s\n",
      "Epoch: 6, Batch: 710/1676, Loss: 0.6502, Time: 1.98s\n",
      "Epoch: 6, Batch: 720/1676, Loss: 0.8766, Time: 1.98s\n",
      "Epoch: 6, Batch: 730/1676, Loss: 0.6113, Time: 1.98s\n",
      "Epoch: 6, Batch: 740/1676, Loss: 0.3966, Time: 1.98s\n",
      "Epoch: 6, Batch: 750/1676, Loss: 0.5013, Time: 1.99s\n",
      "Epoch: 6, Batch: 760/1676, Loss: 0.7094, Time: 1.98s\n",
      "Epoch: 6, Batch: 770/1676, Loss: 1.0280, Time: 1.98s\n",
      "Epoch: 6, Batch: 780/1676, Loss: 0.4103, Time: 1.98s\n",
      "Epoch: 6, Batch: 790/1676, Loss: 0.8569, Time: 1.98s\n",
      "Epoch: 6, Batch: 800/1676, Loss: 0.6361, Time: 1.98s\n",
      "Epoch: 6, Batch: 810/1676, Loss: 0.5484, Time: 1.98s\n",
      "Epoch: 6, Batch: 820/1676, Loss: 1.1388, Time: 1.99s\n",
      "Epoch: 6, Batch: 830/1676, Loss: 0.7682, Time: 1.98s\n",
      "Epoch: 6, Batch: 840/1676, Loss: 0.5887, Time: 1.98s\n",
      "Epoch: 6, Batch: 850/1676, Loss: 0.7680, Time: 1.98s\n",
      "Epoch: 6, Batch: 860/1676, Loss: 0.4808, Time: 1.98s\n",
      "Epoch: 6, Batch: 870/1676, Loss: 1.0718, Time: 1.98s\n",
      "Epoch: 6, Batch: 880/1676, Loss: 0.6704, Time: 1.99s\n",
      "Epoch: 6, Batch: 890/1676, Loss: 0.2696, Time: 1.98s\n",
      "Epoch: 6, Batch: 900/1676, Loss: 0.6767, Time: 1.98s\n",
      "Epoch: 6, Batch: 910/1676, Loss: 0.3165, Time: 1.99s\n",
      "Epoch: 6, Batch: 920/1676, Loss: 1.1087, Time: 1.98s\n",
      "Epoch: 6, Batch: 930/1676, Loss: 0.4407, Time: 1.98s\n",
      "Epoch: 6, Batch: 940/1676, Loss: 1.5879, Time: 1.98s\n",
      "Epoch: 6, Batch: 950/1676, Loss: 0.4205, Time: 1.98s\n",
      "Epoch: 6, Batch: 960/1676, Loss: 0.6683, Time: 1.99s\n",
      "Epoch: 6, Batch: 970/1676, Loss: 0.6828, Time: 1.98s\n",
      "Epoch: 6, Batch: 980/1676, Loss: 0.7384, Time: 1.99s\n",
      "Epoch: 6, Batch: 990/1676, Loss: 0.8616, Time: 1.98s\n",
      "Epoch: 6, Batch: 1000/1676, Loss: 1.0073, Time: 1.99s\n",
      "Epoch: 6, Batch: 1010/1676, Loss: 0.4605, Time: 1.98s\n",
      "Epoch: 6, Batch: 1020/1676, Loss: 0.6299, Time: 1.99s\n",
      "Epoch: 6, Batch: 1030/1676, Loss: 0.5120, Time: 1.98s\n",
      "Epoch: 6, Batch: 1040/1676, Loss: 0.3529, Time: 1.99s\n",
      "Epoch: 6, Batch: 1050/1676, Loss: 0.5635, Time: 1.98s\n",
      "Epoch: 6, Batch: 1060/1676, Loss: 1.0937, Time: 1.98s\n",
      "Epoch: 6, Batch: 1070/1676, Loss: 0.6191, Time: 1.99s\n",
      "Epoch: 6, Batch: 1080/1676, Loss: 0.4574, Time: 1.98s\n",
      "Epoch: 6, Batch: 1090/1676, Loss: 0.3233, Time: 1.99s\n",
      "Epoch: 6, Batch: 1100/1676, Loss: 0.9177, Time: 1.98s\n",
      "Epoch: 6, Batch: 1110/1676, Loss: 0.5307, Time: 1.99s\n",
      "Epoch: 6, Batch: 1120/1676, Loss: 0.5345, Time: 1.99s\n",
      "Epoch: 6, Batch: 1130/1676, Loss: 0.3902, Time: 1.99s\n",
      "Epoch: 6, Batch: 1140/1676, Loss: 0.4032, Time: 1.98s\n",
      "Epoch: 6, Batch: 1150/1676, Loss: 0.3069, Time: 1.99s\n",
      "Epoch: 6, Batch: 1160/1676, Loss: 0.9119, Time: 1.98s\n",
      "Epoch: 6, Batch: 1170/1676, Loss: 0.7398, Time: 1.98s\n",
      "Epoch: 6, Batch: 1180/1676, Loss: 0.6245, Time: 1.99s\n",
      "Epoch: 6, Batch: 1190/1676, Loss: 0.6583, Time: 1.98s\n",
      "Epoch: 6, Batch: 1200/1676, Loss: 1.2332, Time: 1.99s\n",
      "Epoch: 6, Batch: 1210/1676, Loss: 0.7345, Time: 1.98s\n",
      "Epoch: 6, Batch: 1220/1676, Loss: 0.6515, Time: 1.99s\n",
      "Epoch: 6, Batch: 1230/1676, Loss: 1.1786, Time: 1.98s\n",
      "Epoch: 6, Batch: 1240/1676, Loss: 0.3324, Time: 1.98s\n",
      "Epoch: 6, Batch: 1250/1676, Loss: 0.5838, Time: 1.98s\n",
      "Epoch: 6, Batch: 1260/1676, Loss: 0.7719, Time: 1.99s\n",
      "Epoch: 6, Batch: 1270/1676, Loss: 1.3573, Time: 1.99s\n",
      "Epoch: 6, Batch: 1280/1676, Loss: 1.3332, Time: 1.98s\n",
      "Epoch: 6, Batch: 1290/1676, Loss: 0.7989, Time: 1.99s\n",
      "Epoch: 6, Batch: 1300/1676, Loss: 0.7539, Time: 1.99s\n",
      "Epoch: 6, Batch: 1310/1676, Loss: 0.9371, Time: 1.99s\n",
      "Epoch: 6, Batch: 1320/1676, Loss: 0.5850, Time: 1.98s\n",
      "Epoch: 6, Batch: 1330/1676, Loss: 1.1913, Time: 1.99s\n",
      "Epoch: 6, Batch: 1340/1676, Loss: 0.9067, Time: 1.99s\n",
      "Epoch: 6, Batch: 1350/1676, Loss: 0.5912, Time: 1.99s\n",
      "Epoch: 6, Batch: 1360/1676, Loss: 0.3668, Time: 1.98s\n",
      "Epoch: 6, Batch: 1370/1676, Loss: 1.1890, Time: 1.99s\n",
      "Epoch: 6, Batch: 1380/1676, Loss: 0.7126, Time: 1.99s\n",
      "Epoch: 6, Batch: 1390/1676, Loss: 0.5946, Time: 1.99s\n",
      "Epoch: 6, Batch: 1400/1676, Loss: 0.5107, Time: 1.99s\n",
      "Epoch: 6, Batch: 1410/1676, Loss: 0.5843, Time: 1.98s\n",
      "Epoch: 6, Batch: 1420/1676, Loss: 1.2302, Time: 1.99s\n",
      "Epoch: 6, Batch: 1430/1676, Loss: 0.9980, Time: 1.98s\n",
      "Epoch: 6, Batch: 1440/1676, Loss: 0.7908, Time: 1.98s\n",
      "Epoch: 6, Batch: 1450/1676, Loss: 0.6991, Time: 1.98s\n",
      "Epoch: 6, Batch: 1460/1676, Loss: 0.6473, Time: 1.99s\n",
      "Epoch: 6, Batch: 1470/1676, Loss: 0.4871, Time: 1.99s\n",
      "Epoch: 6, Batch: 1480/1676, Loss: 0.9508, Time: 1.99s\n",
      "Epoch: 6, Batch: 1490/1676, Loss: 0.4794, Time: 1.99s\n",
      "Epoch: 6, Batch: 1500/1676, Loss: 0.6057, Time: 1.99s\n",
      "Epoch: 6, Batch: 1510/1676, Loss: 1.0848, Time: 1.99s\n",
      "Epoch: 6, Batch: 1520/1676, Loss: 0.5717, Time: 1.99s\n",
      "Epoch: 6, Batch: 1530/1676, Loss: 0.3284, Time: 1.99s\n",
      "Epoch: 6, Batch: 1540/1676, Loss: 0.7566, Time: 1.98s\n",
      "Epoch: 6, Batch: 1550/1676, Loss: 0.3813, Time: 1.98s\n",
      "Epoch: 6, Batch: 1560/1676, Loss: 0.6096, Time: 1.99s\n",
      "Epoch: 6, Batch: 1570/1676, Loss: 0.8082, Time: 1.99s\n",
      "Epoch: 6, Batch: 1580/1676, Loss: 0.8069, Time: 1.99s\n",
      "Epoch: 6, Batch: 1590/1676, Loss: 0.9896, Time: 1.99s\n",
      "Epoch: 6, Batch: 1600/1676, Loss: 0.5432, Time: 1.99s\n",
      "Epoch: 6, Batch: 1610/1676, Loss: 0.3147, Time: 1.99s\n",
      "Epoch: 6, Batch: 1620/1676, Loss: 1.4148, Time: 1.99s\n",
      "Epoch: 6, Batch: 1630/1676, Loss: 0.8413, Time: 1.99s\n",
      "Epoch: 6, Batch: 1640/1676, Loss: 0.9947, Time: 1.98s\n",
      "Epoch: 6, Batch: 1650/1676, Loss: 0.6091, Time: 1.99s\n",
      "Epoch: 6, Batch: 1660/1676, Loss: 0.8239, Time: 1.99s\n",
      "Epoch: 6, Batch: 1670/1676, Loss: 0.6494, Time: 1.99s\n",
      "Epoch 7/50: Train Loss: 0.7420, Val Loss: 0.7694, Val IoU: 0.5525, Val Dice: 0.5718\n",
      "Epoch: 7, Batch: 0/1676, Loss: 0.5859, Time: 35.90s\n",
      "Epoch: 7, Batch: 10/1676, Loss: 0.6360, Time: 1.99s\n",
      "Epoch: 7, Batch: 20/1676, Loss: 0.5136, Time: 1.94s\n",
      "Epoch: 7, Batch: 30/1676, Loss: 0.3362, Time: 1.95s\n",
      "Epoch: 7, Batch: 40/1676, Loss: 0.7614, Time: 1.94s\n",
      "Epoch: 7, Batch: 50/1676, Loss: 0.9677, Time: 1.95s\n",
      "Epoch: 7, Batch: 60/1676, Loss: 0.7245, Time: 1.95s\n",
      "Epoch: 7, Batch: 70/1676, Loss: 0.6536, Time: 1.95s\n",
      "Epoch: 7, Batch: 80/1676, Loss: 0.4389, Time: 1.96s\n",
      "Epoch: 7, Batch: 90/1676, Loss: 0.4891, Time: 1.95s\n",
      "Epoch: 7, Batch: 100/1676, Loss: 0.7265, Time: 1.95s\n",
      "Epoch: 7, Batch: 110/1676, Loss: 0.5651, Time: 1.96s\n",
      "Epoch: 7, Batch: 120/1676, Loss: 0.6470, Time: 1.95s\n",
      "Epoch: 7, Batch: 130/1676, Loss: 1.2720, Time: 1.96s\n",
      "Epoch: 7, Batch: 140/1676, Loss: 0.8787, Time: 1.96s\n",
      "Epoch: 7, Batch: 150/1676, Loss: 0.6447, Time: 1.96s\n",
      "Epoch: 7, Batch: 160/1676, Loss: 0.9125, Time: 1.96s\n",
      "Epoch: 7, Batch: 170/1676, Loss: 0.4806, Time: 1.96s\n",
      "Epoch: 7, Batch: 180/1676, Loss: 0.8551, Time: 1.96s\n",
      "Epoch: 7, Batch: 190/1676, Loss: 0.4365, Time: 1.96s\n",
      "Epoch: 7, Batch: 200/1676, Loss: 0.2483, Time: 1.96s\n",
      "Epoch: 7, Batch: 210/1676, Loss: 0.9858, Time: 1.97s\n",
      "Epoch: 7, Batch: 220/1676, Loss: 0.7238, Time: 1.96s\n",
      "Epoch: 7, Batch: 230/1676, Loss: 0.5803, Time: 1.97s\n",
      "Epoch: 7, Batch: 240/1676, Loss: 1.0277, Time: 1.97s\n",
      "Epoch: 7, Batch: 250/1676, Loss: 0.3927, Time: 1.97s\n",
      "Epoch: 7, Batch: 260/1676, Loss: 0.5476, Time: 1.97s\n",
      "Epoch: 7, Batch: 270/1676, Loss: 0.4911, Time: 1.96s\n",
      "Epoch: 7, Batch: 280/1676, Loss: 0.7776, Time: 1.97s\n",
      "Epoch: 7, Batch: 290/1676, Loss: 0.7328, Time: 1.96s\n",
      "Epoch: 7, Batch: 300/1676, Loss: 1.0168, Time: 1.97s\n",
      "Epoch: 7, Batch: 310/1676, Loss: 0.5886, Time: 1.97s\n",
      "Epoch: 7, Batch: 320/1676, Loss: 0.5349, Time: 1.97s\n",
      "Epoch: 7, Batch: 330/1676, Loss: 1.2033, Time: 1.96s\n",
      "Epoch: 7, Batch: 340/1676, Loss: 0.3740, Time: 1.97s\n",
      "Epoch: 7, Batch: 350/1676, Loss: 1.1866, Time: 1.98s\n",
      "Epoch: 7, Batch: 360/1676, Loss: 0.6515, Time: 1.97s\n",
      "Epoch: 7, Batch: 370/1676, Loss: 0.4942, Time: 1.97s\n",
      "Epoch: 7, Batch: 380/1676, Loss: 0.6509, Time: 1.96s\n",
      "Epoch: 7, Batch: 390/1676, Loss: 0.5208, Time: 1.98s\n",
      "Epoch: 7, Batch: 400/1676, Loss: 0.8364, Time: 1.97s\n",
      "Epoch: 7, Batch: 410/1676, Loss: 1.1429, Time: 1.98s\n",
      "Epoch: 7, Batch: 420/1676, Loss: 0.9924, Time: 1.97s\n",
      "Epoch: 7, Batch: 430/1676, Loss: 0.8229, Time: 1.97s\n",
      "Epoch: 7, Batch: 440/1676, Loss: 0.6727, Time: 1.97s\n",
      "Epoch: 7, Batch: 450/1676, Loss: 0.6249, Time: 1.98s\n",
      "Epoch: 7, Batch: 460/1676, Loss: 1.0924, Time: 1.97s\n",
      "Epoch: 7, Batch: 470/1676, Loss: 0.6898, Time: 1.97s\n",
      "Epoch: 7, Batch: 480/1676, Loss: 1.5921, Time: 1.97s\n",
      "Epoch: 7, Batch: 490/1676, Loss: 1.3663, Time: 1.98s\n",
      "Epoch: 7, Batch: 500/1676, Loss: 0.5426, Time: 1.97s\n",
      "Epoch: 7, Batch: 510/1676, Loss: 0.7189, Time: 1.97s\n",
      "Epoch: 7, Batch: 520/1676, Loss: 0.4994, Time: 1.98s\n",
      "Epoch: 7, Batch: 530/1676, Loss: 0.3290, Time: 1.97s\n",
      "Epoch: 7, Batch: 540/1676, Loss: 0.8506, Time: 1.98s\n",
      "Epoch: 7, Batch: 550/1676, Loss: 0.6266, Time: 1.97s\n",
      "Epoch: 7, Batch: 560/1676, Loss: 0.5704, Time: 1.98s\n",
      "Epoch: 7, Batch: 570/1676, Loss: 0.4776, Time: 1.97s\n",
      "Epoch: 7, Batch: 580/1676, Loss: 0.5385, Time: 1.97s\n",
      "Epoch: 7, Batch: 590/1676, Loss: 1.0127, Time: 1.98s\n",
      "Epoch: 7, Batch: 600/1676, Loss: 0.7462, Time: 1.98s\n",
      "Epoch: 7, Batch: 610/1676, Loss: 0.9660, Time: 1.98s\n",
      "Epoch: 7, Batch: 620/1676, Loss: 1.3286, Time: 1.98s\n",
      "Epoch: 7, Batch: 630/1676, Loss: 1.3036, Time: 1.97s\n",
      "Epoch: 7, Batch: 640/1676, Loss: 0.9682, Time: 1.98s\n",
      "Epoch: 7, Batch: 650/1676, Loss: 0.5063, Time: 1.98s\n",
      "Epoch: 7, Batch: 660/1676, Loss: 0.6288, Time: 1.98s\n",
      "Epoch: 7, Batch: 670/1676, Loss: 0.9261, Time: 1.98s\n",
      "Epoch: 7, Batch: 680/1676, Loss: 0.4968, Time: 1.97s\n",
      "Epoch: 7, Batch: 690/1676, Loss: 0.6675, Time: 1.98s\n",
      "Epoch: 7, Batch: 700/1676, Loss: 0.8441, Time: 1.98s\n",
      "Epoch: 7, Batch: 710/1676, Loss: 1.0247, Time: 1.98s\n",
      "Epoch: 7, Batch: 720/1676, Loss: 1.1456, Time: 1.98s\n",
      "Epoch: 7, Batch: 730/1676, Loss: 0.3661, Time: 1.97s\n",
      "Epoch: 7, Batch: 740/1676, Loss: 0.5369, Time: 1.98s\n",
      "Epoch: 7, Batch: 750/1676, Loss: 0.5628, Time: 1.98s\n",
      "Epoch: 7, Batch: 760/1676, Loss: 0.3474, Time: 1.99s\n",
      "Epoch: 7, Batch: 770/1676, Loss: 0.5484, Time: 1.99s\n",
      "Epoch: 7, Batch: 780/1676, Loss: 1.0631, Time: 1.98s\n",
      "Epoch: 7, Batch: 790/1676, Loss: 0.2093, Time: 1.99s\n",
      "Epoch: 7, Batch: 800/1676, Loss: 0.6622, Time: 1.98s\n",
      "Epoch: 7, Batch: 810/1676, Loss: 1.1773, Time: 1.98s\n",
      "Epoch: 7, Batch: 820/1676, Loss: 0.5275, Time: 1.99s\n",
      "Epoch: 7, Batch: 830/1676, Loss: 0.8102, Time: 1.98s\n",
      "Epoch: 7, Batch: 840/1676, Loss: 0.4939, Time: 1.98s\n",
      "Epoch: 7, Batch: 850/1676, Loss: 0.9473, Time: 1.99s\n",
      "Epoch: 7, Batch: 860/1676, Loss: 0.5243, Time: 1.98s\n",
      "Epoch: 7, Batch: 870/1676, Loss: 1.0870, Time: 1.99s\n",
      "Epoch: 7, Batch: 880/1676, Loss: 0.5049, Time: 1.98s\n",
      "Epoch: 7, Batch: 890/1676, Loss: 0.6864, Time: 1.98s\n",
      "Epoch: 7, Batch: 900/1676, Loss: 0.5782, Time: 1.98s\n",
      "Epoch: 7, Batch: 910/1676, Loss: 0.8692, Time: 1.98s\n",
      "Epoch: 7, Batch: 920/1676, Loss: 0.7719, Time: 1.98s\n",
      "Epoch: 7, Batch: 930/1676, Loss: 0.9699, Time: 1.99s\n",
      "Epoch: 7, Batch: 940/1676, Loss: 1.0479, Time: 1.99s\n",
      "Epoch: 7, Batch: 950/1676, Loss: 0.8926, Time: 1.98s\n",
      "Epoch: 7, Batch: 960/1676, Loss: 1.3525, Time: 1.99s\n",
      "Epoch: 7, Batch: 970/1676, Loss: 0.5899, Time: 1.98s\n",
      "Epoch: 7, Batch: 980/1676, Loss: 0.8995, Time: 1.99s\n",
      "Epoch: 7, Batch: 990/1676, Loss: 0.5967, Time: 1.98s\n",
      "Epoch: 7, Batch: 1000/1676, Loss: 0.3901, Time: 1.99s\n",
      "Epoch: 7, Batch: 1010/1676, Loss: 0.7158, Time: 1.98s\n",
      "Epoch: 7, Batch: 1020/1676, Loss: 0.6765, Time: 1.99s\n",
      "Epoch: 7, Batch: 1030/1676, Loss: 1.2564, Time: 1.98s\n",
      "Epoch: 7, Batch: 1040/1676, Loss: 1.1082, Time: 1.98s\n",
      "Epoch: 7, Batch: 1050/1676, Loss: 0.8493, Time: 1.98s\n",
      "Epoch: 7, Batch: 1060/1676, Loss: 0.4390, Time: 1.99s\n",
      "Epoch: 7, Batch: 1070/1676, Loss: 0.2804, Time: 1.99s\n",
      "Epoch: 7, Batch: 1080/1676, Loss: 0.6356, Time: 1.98s\n",
      "Epoch: 7, Batch: 1090/1676, Loss: 0.7327, Time: 1.99s\n",
      "Epoch: 7, Batch: 1100/1676, Loss: 0.6454, Time: 1.98s\n",
      "Epoch: 7, Batch: 1110/1676, Loss: 0.8262, Time: 1.98s\n",
      "Epoch: 7, Batch: 1120/1676, Loss: 1.0363, Time: 1.98s\n",
      "Epoch: 7, Batch: 1130/1676, Loss: 0.7917, Time: 1.99s\n",
      "Epoch: 7, Batch: 1140/1676, Loss: 0.4287, Time: 1.98s\n",
      "Epoch: 7, Batch: 1150/1676, Loss: 0.7501, Time: 1.99s\n",
      "Epoch: 7, Batch: 1160/1676, Loss: 0.5925, Time: 1.99s\n",
      "Epoch: 7, Batch: 1170/1676, Loss: 0.5114, Time: 1.98s\n",
      "Epoch: 7, Batch: 1180/1676, Loss: 0.7782, Time: 1.98s\n",
      "Epoch: 7, Batch: 1190/1676, Loss: 0.8192, Time: 1.98s\n",
      "Epoch: 7, Batch: 1200/1676, Loss: 1.3258, Time: 1.99s\n",
      "Epoch: 7, Batch: 1210/1676, Loss: 1.0205, Time: 1.99s\n",
      "Epoch: 7, Batch: 1220/1676, Loss: 1.0480, Time: 1.98s\n",
      "Epoch: 7, Batch: 1230/1676, Loss: 0.4024, Time: 2.00s\n",
      "Epoch: 7, Batch: 1240/1676, Loss: 0.3684, Time: 1.99s\n",
      "Epoch: 7, Batch: 1250/1676, Loss: 0.6236, Time: 1.98s\n",
      "Epoch: 7, Batch: 1260/1676, Loss: 0.9923, Time: 1.99s\n",
      "Epoch: 7, Batch: 1270/1676, Loss: 0.8189, Time: 1.99s\n",
      "Epoch: 7, Batch: 1280/1676, Loss: 1.2045, Time: 1.99s\n",
      "Epoch: 7, Batch: 1290/1676, Loss: 0.8881, Time: 1.98s\n",
      "Epoch: 7, Batch: 1300/1676, Loss: 0.8365, Time: 1.99s\n",
      "Epoch: 7, Batch: 1310/1676, Loss: 0.3730, Time: 1.98s\n",
      "Epoch: 7, Batch: 1320/1676, Loss: 1.1717, Time: 1.98s\n",
      "Epoch: 7, Batch: 1330/1676, Loss: 0.7118, Time: 1.98s\n",
      "Epoch: 7, Batch: 1340/1676, Loss: 0.6198, Time: 1.98s\n",
      "Epoch: 7, Batch: 1350/1676, Loss: 0.9543, Time: 1.98s\n",
      "Epoch: 7, Batch: 1360/1676, Loss: 1.3029, Time: 1.99s\n",
      "Epoch: 7, Batch: 1370/1676, Loss: 0.4118, Time: 2.00s\n",
      "Epoch: 7, Batch: 1380/1676, Loss: 0.7551, Time: 1.98s\n",
      "Epoch: 7, Batch: 1390/1676, Loss: 0.4480, Time: 1.99s\n",
      "Epoch: 7, Batch: 1400/1676, Loss: 0.8809, Time: 1.98s\n",
      "Epoch: 7, Batch: 1410/1676, Loss: 0.5879, Time: 1.98s\n",
      "Epoch: 7, Batch: 1420/1676, Loss: 0.4677, Time: 1.99s\n",
      "Epoch: 7, Batch: 1430/1676, Loss: 1.1612, Time: 1.98s\n",
      "Epoch: 7, Batch: 1440/1676, Loss: 0.8710, Time: 1.99s\n",
      "Epoch: 7, Batch: 1450/1676, Loss: 1.4255, Time: 1.98s\n",
      "Epoch: 7, Batch: 1460/1676, Loss: 0.8436, Time: 1.98s\n",
      "Epoch: 7, Batch: 1470/1676, Loss: 0.6015, Time: 1.99s\n",
      "Epoch: 7, Batch: 1480/1676, Loss: 0.2844, Time: 1.98s\n",
      "Epoch: 7, Batch: 1490/1676, Loss: 0.4603, Time: 1.99s\n",
      "Epoch: 7, Batch: 1500/1676, Loss: 0.6820, Time: 1.99s\n",
      "Epoch: 7, Batch: 1510/1676, Loss: 0.2911, Time: 1.98s\n",
      "Epoch: 7, Batch: 1520/1676, Loss: 0.7849, Time: 1.98s\n",
      "Epoch: 7, Batch: 1530/1676, Loss: 0.6090, Time: 1.99s\n",
      "Epoch: 7, Batch: 1540/1676, Loss: 0.5755, Time: 1.98s\n",
      "Epoch: 7, Batch: 1550/1676, Loss: 1.3752, Time: 1.99s\n",
      "Epoch: 7, Batch: 1560/1676, Loss: 0.6236, Time: 1.98s\n",
      "Epoch: 7, Batch: 1570/1676, Loss: 0.6046, Time: 1.99s\n",
      "Epoch: 7, Batch: 1580/1676, Loss: 0.9017, Time: 1.99s\n",
      "Epoch: 7, Batch: 1590/1676, Loss: 0.5135, Time: 1.99s\n",
      "Epoch: 7, Batch: 1600/1676, Loss: 0.5110, Time: 1.99s\n",
      "Epoch: 7, Batch: 1610/1676, Loss: 1.2133, Time: 1.98s\n",
      "Epoch: 7, Batch: 1620/1676, Loss: 1.5587, Time: 1.98s\n",
      "Epoch: 7, Batch: 1630/1676, Loss: 0.3762, Time: 1.99s\n",
      "Epoch: 7, Batch: 1640/1676, Loss: 0.5244, Time: 1.99s\n",
      "Epoch: 7, Batch: 1650/1676, Loss: 0.4229, Time: 1.99s\n",
      "Epoch: 7, Batch: 1660/1676, Loss: 0.3502, Time: 1.98s\n",
      "Epoch: 7, Batch: 1670/1676, Loss: 0.5781, Time: 1.98s\n",
      "Epoch 8/50: Train Loss: 0.7378, Val Loss: 0.7348, Val IoU: 0.5576, Val Dice: 0.5771\n",
      "Epoch: 8, Batch: 0/1676, Loss: 0.7053, Time: 36.12s\n",
      "Epoch: 8, Batch: 10/1676, Loss: 0.4703, Time: 1.98s\n",
      "Epoch: 8, Batch: 20/1676, Loss: 0.6696, Time: 1.94s\n",
      "Epoch: 8, Batch: 30/1676, Loss: 0.7300, Time: 1.95s\n",
      "Epoch: 8, Batch: 40/1676, Loss: 0.9247, Time: 1.95s\n",
      "Epoch: 8, Batch: 50/1676, Loss: 0.4594, Time: 1.94s\n",
      "Epoch: 8, Batch: 60/1676, Loss: 0.8502, Time: 1.95s\n",
      "Epoch: 8, Batch: 70/1676, Loss: 1.0753, Time: 1.95s\n",
      "Epoch: 8, Batch: 80/1676, Loss: 0.2825, Time: 1.95s\n",
      "Epoch: 8, Batch: 90/1676, Loss: 0.8404, Time: 1.95s\n",
      "Epoch: 8, Batch: 100/1676, Loss: 0.7552, Time: 1.95s\n",
      "Epoch: 8, Batch: 110/1676, Loss: 0.8047, Time: 1.95s\n",
      "Epoch: 8, Batch: 120/1676, Loss: 1.1641, Time: 1.96s\n",
      "Epoch: 8, Batch: 130/1676, Loss: 0.7647, Time: 1.95s\n",
      "Epoch: 8, Batch: 140/1676, Loss: 0.4816, Time: 1.96s\n",
      "Epoch: 8, Batch: 150/1676, Loss: 0.2327, Time: 1.96s\n",
      "Epoch: 8, Batch: 160/1676, Loss: 0.6625, Time: 1.96s\n",
      "Epoch: 8, Batch: 170/1676, Loss: 0.6601, Time: 1.96s\n",
      "Epoch: 8, Batch: 180/1676, Loss: 0.6672, Time: 1.97s\n",
      "Epoch: 8, Batch: 190/1676, Loss: 1.4279, Time: 1.96s\n",
      "Epoch: 8, Batch: 200/1676, Loss: 1.0989, Time: 1.96s\n",
      "Epoch: 8, Batch: 210/1676, Loss: 0.4917, Time: 1.96s\n",
      "Epoch: 8, Batch: 220/1676, Loss: 0.5681, Time: 1.97s\n",
      "Epoch: 8, Batch: 230/1676, Loss: 0.9069, Time: 1.96s\n",
      "Epoch: 8, Batch: 240/1676, Loss: 0.5728, Time: 1.96s\n",
      "Epoch: 8, Batch: 250/1676, Loss: 0.9653, Time: 1.97s\n",
      "Epoch: 8, Batch: 260/1676, Loss: 0.7915, Time: 1.97s\n",
      "Epoch: 8, Batch: 270/1676, Loss: 0.7061, Time: 1.96s\n",
      "Epoch: 8, Batch: 280/1676, Loss: 1.2066, Time: 1.97s\n",
      "Epoch: 8, Batch: 290/1676, Loss: 0.2726, Time: 1.97s\n",
      "Epoch: 8, Batch: 300/1676, Loss: 0.6303, Time: 1.97s\n",
      "Epoch: 8, Batch: 310/1676, Loss: 0.8083, Time: 1.97s\n",
      "Epoch: 8, Batch: 320/1676, Loss: 0.6851, Time: 1.97s\n",
      "Epoch: 8, Batch: 330/1676, Loss: 1.0153, Time: 1.97s\n",
      "Epoch: 8, Batch: 340/1676, Loss: 0.4936, Time: 1.97s\n",
      "Epoch: 8, Batch: 350/1676, Loss: 0.6136, Time: 1.97s\n",
      "Epoch: 8, Batch: 360/1676, Loss: 1.0199, Time: 1.97s\n",
      "Epoch: 8, Batch: 370/1676, Loss: 0.4975, Time: 1.97s\n",
      "Epoch: 8, Batch: 380/1676, Loss: 0.7642, Time: 1.97s\n",
      "Epoch: 8, Batch: 390/1676, Loss: 0.7205, Time: 1.97s\n",
      "Epoch: 8, Batch: 400/1676, Loss: 0.8479, Time: 1.97s\n",
      "Epoch: 8, Batch: 410/1676, Loss: 0.5854, Time: 1.97s\n",
      "Epoch: 8, Batch: 420/1676, Loss: 0.4238, Time: 1.97s\n",
      "Epoch: 8, Batch: 430/1676, Loss: 0.6403, Time: 1.97s\n",
      "Epoch: 8, Batch: 440/1676, Loss: 0.6532, Time: 1.98s\n",
      "Epoch: 8, Batch: 450/1676, Loss: 0.5642, Time: 1.98s\n",
      "Epoch: 8, Batch: 460/1676, Loss: 1.1376, Time: 1.98s\n",
      "Epoch: 8, Batch: 470/1676, Loss: 0.6286, Time: 1.97s\n",
      "Epoch: 8, Batch: 480/1676, Loss: 1.0560, Time: 1.98s\n",
      "Epoch: 8, Batch: 490/1676, Loss: 0.7389, Time: 1.98s\n",
      "Epoch: 8, Batch: 500/1676, Loss: 0.8307, Time: 1.97s\n",
      "Epoch: 8, Batch: 510/1676, Loss: 1.1689, Time: 1.98s\n",
      "Epoch: 8, Batch: 520/1676, Loss: 0.4722, Time: 1.98s\n",
      "Epoch: 8, Batch: 530/1676, Loss: 0.8022, Time: 1.97s\n",
      "Epoch: 8, Batch: 540/1676, Loss: 1.0283, Time: 1.98s\n",
      "Epoch: 8, Batch: 550/1676, Loss: 0.6307, Time: 1.97s\n",
      "Epoch: 8, Batch: 560/1676, Loss: 0.9016, Time: 1.97s\n",
      "Epoch: 8, Batch: 570/1676, Loss: 0.8126, Time: 1.98s\n",
      "Epoch: 8, Batch: 580/1676, Loss: 0.4828, Time: 1.97s\n",
      "Epoch: 8, Batch: 590/1676, Loss: 0.5633, Time: 1.98s\n",
      "Epoch: 8, Batch: 600/1676, Loss: 1.3763, Time: 1.98s\n",
      "Epoch: 8, Batch: 610/1676, Loss: 0.7891, Time: 1.97s\n",
      "Epoch: 8, Batch: 620/1676, Loss: 0.7349, Time: 1.98s\n",
      "Epoch: 8, Batch: 630/1676, Loss: 0.4186, Time: 1.98s\n",
      "Epoch: 8, Batch: 640/1676, Loss: 0.6200, Time: 1.98s\n",
      "Epoch: 8, Batch: 650/1676, Loss: 0.5712, Time: 1.98s\n",
      "Epoch: 8, Batch: 660/1676, Loss: 0.5932, Time: 1.98s\n",
      "Epoch: 8, Batch: 670/1676, Loss: 0.3925, Time: 1.98s\n",
      "Epoch: 8, Batch: 680/1676, Loss: 0.7448, Time: 1.98s\n",
      "Epoch: 8, Batch: 690/1676, Loss: 0.5209, Time: 1.98s\n",
      "Epoch: 8, Batch: 700/1676, Loss: 0.4285, Time: 1.97s\n",
      "Epoch: 8, Batch: 710/1676, Loss: 0.8824, Time: 1.97s\n",
      "Epoch: 8, Batch: 720/1676, Loss: 0.6117, Time: 1.97s\n",
      "Epoch: 8, Batch: 730/1676, Loss: 0.5691, Time: 1.97s\n",
      "Epoch: 8, Batch: 740/1676, Loss: 0.5991, Time: 1.98s\n",
      "Epoch: 8, Batch: 750/1676, Loss: 0.4493, Time: 1.98s\n",
      "Epoch: 8, Batch: 760/1676, Loss: 0.7074, Time: 1.98s\n",
      "Epoch: 8, Batch: 770/1676, Loss: 0.8675, Time: 1.98s\n",
      "Epoch: 8, Batch: 780/1676, Loss: 0.9404, Time: 1.98s\n",
      "Epoch: 8, Batch: 790/1676, Loss: 1.0753, Time: 1.97s\n",
      "Epoch: 8, Batch: 800/1676, Loss: 0.5992, Time: 1.98s\n",
      "Epoch: 8, Batch: 810/1676, Loss: 1.0957, Time: 1.98s\n",
      "Epoch: 8, Batch: 820/1676, Loss: 0.3052, Time: 1.98s\n",
      "Epoch: 8, Batch: 830/1676, Loss: 0.5401, Time: 1.97s\n",
      "Epoch: 8, Batch: 840/1676, Loss: 1.0831, Time: 1.98s\n",
      "Epoch: 8, Batch: 850/1676, Loss: 0.7067, Time: 1.98s\n",
      "Epoch: 8, Batch: 860/1676, Loss: 0.3199, Time: 1.98s\n",
      "Epoch: 8, Batch: 870/1676, Loss: 0.8270, Time: 1.98s\n",
      "Epoch: 8, Batch: 880/1676, Loss: 1.2208, Time: 1.98s\n",
      "Epoch: 8, Batch: 890/1676, Loss: 0.7586, Time: 1.98s\n",
      "Epoch: 8, Batch: 900/1676, Loss: 0.6584, Time: 1.98s\n",
      "Epoch: 8, Batch: 910/1676, Loss: 0.3994, Time: 1.98s\n",
      "Epoch: 8, Batch: 920/1676, Loss: 0.7511, Time: 1.98s\n",
      "Epoch: 8, Batch: 930/1676, Loss: 0.3732, Time: 1.98s\n",
      "Epoch: 8, Batch: 940/1676, Loss: 0.7909, Time: 1.98s\n",
      "Epoch: 8, Batch: 950/1676, Loss: 1.0117, Time: 1.98s\n",
      "Epoch: 8, Batch: 960/1676, Loss: 0.8378, Time: 1.99s\n",
      "Epoch: 8, Batch: 970/1676, Loss: 0.5388, Time: 1.99s\n",
      "Epoch: 8, Batch: 980/1676, Loss: 0.7818, Time: 1.98s\n",
      "Epoch: 8, Batch: 990/1676, Loss: 0.5352, Time: 1.99s\n",
      "Epoch: 8, Batch: 1000/1676, Loss: 0.8067, Time: 1.99s\n",
      "Epoch: 8, Batch: 1010/1676, Loss: 0.6842, Time: 1.97s\n",
      "Epoch: 8, Batch: 1020/1676, Loss: 0.2849, Time: 1.98s\n",
      "Epoch: 8, Batch: 1030/1676, Loss: 0.8621, Time: 1.98s\n",
      "Epoch: 8, Batch: 1040/1676, Loss: 0.6514, Time: 1.98s\n",
      "Epoch: 8, Batch: 1050/1676, Loss: 0.8119, Time: 1.98s\n",
      "Epoch: 8, Batch: 1060/1676, Loss: 0.7603, Time: 1.99s\n",
      "Epoch: 8, Batch: 1070/1676, Loss: 1.0716, Time: 1.98s\n",
      "Epoch: 8, Batch: 1080/1676, Loss: 1.1661, Time: 1.99s\n",
      "Epoch: 8, Batch: 1090/1676, Loss: 1.1478, Time: 1.98s\n",
      "Epoch: 8, Batch: 1100/1676, Loss: 0.7459, Time: 1.98s\n",
      "Epoch: 8, Batch: 1110/1676, Loss: 0.5677, Time: 1.98s\n",
      "Epoch: 8, Batch: 1120/1676, Loss: 0.8174, Time: 1.98s\n",
      "Epoch: 8, Batch: 1130/1676, Loss: 0.5636, Time: 1.99s\n",
      "Epoch: 8, Batch: 1140/1676, Loss: 0.4343, Time: 1.98s\n",
      "Epoch: 8, Batch: 1150/1676, Loss: 0.8313, Time: 1.98s\n",
      "Epoch: 8, Batch: 1160/1676, Loss: 0.4300, Time: 1.98s\n",
      "Epoch: 8, Batch: 1170/1676, Loss: 0.3373, Time: 1.98s\n",
      "Epoch: 8, Batch: 1180/1676, Loss: 0.9005, Time: 1.98s\n",
      "Epoch: 8, Batch: 1190/1676, Loss: 0.7123, Time: 1.98s\n",
      "Epoch: 8, Batch: 1200/1676, Loss: 0.9249, Time: 1.98s\n",
      "Epoch: 8, Batch: 1210/1676, Loss: 0.6925, Time: 1.98s\n",
      "Epoch: 8, Batch: 1220/1676, Loss: 0.5959, Time: 1.98s\n",
      "Epoch: 8, Batch: 1230/1676, Loss: 0.8091, Time: 1.98s\n",
      "Epoch: 8, Batch: 1240/1676, Loss: 0.7587, Time: 1.97s\n",
      "Epoch: 8, Batch: 1250/1676, Loss: 1.1681, Time: 1.98s\n",
      "Epoch: 8, Batch: 1260/1676, Loss: 0.5861, Time: 1.98s\n",
      "Epoch: 8, Batch: 1270/1676, Loss: 0.6682, Time: 1.98s\n",
      "Epoch: 8, Batch: 1280/1676, Loss: 1.3667, Time: 1.98s\n",
      "Epoch: 8, Batch: 1290/1676, Loss: 1.1038, Time: 1.98s\n",
      "Epoch: 8, Batch: 1300/1676, Loss: 0.5014, Time: 1.98s\n",
      "Epoch: 8, Batch: 1310/1676, Loss: 0.9344, Time: 1.99s\n",
      "Epoch: 8, Batch: 1320/1676, Loss: 0.7050, Time: 1.98s\n",
      "Epoch: 8, Batch: 1330/1676, Loss: 1.5429, Time: 1.98s\n",
      "Epoch: 8, Batch: 1340/1676, Loss: 0.8450, Time: 1.98s\n",
      "Epoch: 8, Batch: 1350/1676, Loss: 0.4091, Time: 1.98s\n",
      "Epoch: 8, Batch: 1360/1676, Loss: 1.0789, Time: 1.99s\n",
      "Epoch: 8, Batch: 1370/1676, Loss: 0.5884, Time: 1.98s\n",
      "Epoch: 8, Batch: 1380/1676, Loss: 0.5950, Time: 1.98s\n",
      "Epoch: 8, Batch: 1390/1676, Loss: 0.9480, Time: 1.98s\n",
      "Epoch: 8, Batch: 1400/1676, Loss: 0.3425, Time: 1.98s\n",
      "Epoch: 8, Batch: 1410/1676, Loss: 0.6292, Time: 1.98s\n",
      "Epoch: 8, Batch: 1420/1676, Loss: 1.2055, Time: 1.98s\n",
      "Epoch: 8, Batch: 1430/1676, Loss: 0.4489, Time: 1.98s\n",
      "Epoch: 8, Batch: 1440/1676, Loss: 0.5460, Time: 1.98s\n",
      "Epoch: 8, Batch: 1450/1676, Loss: 0.8886, Time: 1.98s\n",
      "Epoch: 8, Batch: 1460/1676, Loss: 1.4716, Time: 1.99s\n",
      "Epoch: 8, Batch: 1470/1676, Loss: 0.6511, Time: 1.98s\n",
      "Epoch: 8, Batch: 1480/1676, Loss: 0.8308, Time: 1.98s\n",
      "Epoch: 8, Batch: 1490/1676, Loss: 0.2615, Time: 1.98s\n",
      "Epoch: 8, Batch: 1500/1676, Loss: 0.4069, Time: 1.98s\n",
      "Epoch: 8, Batch: 1510/1676, Loss: 1.0303, Time: 1.98s\n",
      "Epoch: 8, Batch: 1520/1676, Loss: 1.1930, Time: 1.99s\n",
      "Epoch: 8, Batch: 1530/1676, Loss: 0.7131, Time: 1.99s\n",
      "Epoch: 8, Batch: 1540/1676, Loss: 0.4372, Time: 1.98s\n",
      "Epoch: 8, Batch: 1550/1676, Loss: 0.6313, Time: 1.98s\n",
      "Epoch: 8, Batch: 1560/1676, Loss: 0.6763, Time: 1.99s\n",
      "Epoch: 8, Batch: 1570/1676, Loss: 0.5972, Time: 1.98s\n",
      "Epoch: 8, Batch: 1580/1676, Loss: 0.7708, Time: 1.99s\n",
      "Epoch: 8, Batch: 1590/1676, Loss: 1.1994, Time: 1.98s\n",
      "Epoch: 8, Batch: 1600/1676, Loss: 0.4234, Time: 1.99s\n",
      "Epoch: 8, Batch: 1610/1676, Loss: 0.9097, Time: 1.98s\n",
      "Epoch: 8, Batch: 1620/1676, Loss: 0.8189, Time: 1.99s\n",
      "Epoch: 8, Batch: 1630/1676, Loss: 0.4613, Time: 1.99s\n",
      "Epoch: 8, Batch: 1640/1676, Loss: 0.8601, Time: 1.99s\n",
      "Epoch: 8, Batch: 1650/1676, Loss: 1.1336, Time: 2.00s\n",
      "Epoch: 8, Batch: 1660/1676, Loss: 0.7620, Time: 1.98s\n",
      "Epoch: 8, Batch: 1670/1676, Loss: 0.5688, Time: 1.97s\n",
      "Epoch 9/50: Train Loss: 0.7336, Val Loss: 0.7565, Val IoU: 0.5519, Val Dice: 0.5712\n",
      "Epoch: 9, Batch: 0/1676, Loss: 1.1164, Time: 35.98s\n",
      "Epoch: 9, Batch: 10/1676, Loss: 0.8210, Time: 1.98s\n",
      "Epoch: 9, Batch: 20/1676, Loss: 1.2495, Time: 1.94s\n",
      "Epoch: 9, Batch: 30/1676, Loss: 0.3535, Time: 1.94s\n",
      "Epoch: 9, Batch: 40/1676, Loss: 0.9248, Time: 1.94s\n",
      "Epoch: 9, Batch: 50/1676, Loss: 0.5733, Time: 1.94s\n",
      "Epoch: 9, Batch: 60/1676, Loss: 0.5705, Time: 1.95s\n",
      "Epoch: 9, Batch: 70/1676, Loss: 0.8509, Time: 1.94s\n",
      "Epoch: 9, Batch: 80/1676, Loss: 0.6758, Time: 1.95s\n",
      "Epoch: 9, Batch: 90/1676, Loss: 0.5833, Time: 1.95s\n",
      "Epoch: 9, Batch: 100/1676, Loss: 0.3754, Time: 1.95s\n",
      "Epoch: 9, Batch: 110/1676, Loss: 0.5403, Time: 1.96s\n",
      "Epoch: 9, Batch: 120/1676, Loss: 1.0391, Time: 1.95s\n",
      "Epoch: 9, Batch: 130/1676, Loss: 0.7167, Time: 1.95s\n",
      "Epoch: 9, Batch: 140/1676, Loss: 0.5510, Time: 1.95s\n",
      "Epoch: 9, Batch: 150/1676, Loss: 0.9815, Time: 1.96s\n",
      "Epoch: 9, Batch: 160/1676, Loss: 0.5053, Time: 1.96s\n",
      "Epoch: 9, Batch: 170/1676, Loss: 0.2951, Time: 1.96s\n",
      "Epoch: 9, Batch: 180/1676, Loss: 1.2398, Time: 1.96s\n",
      "Epoch: 9, Batch: 190/1676, Loss: 0.7125, Time: 1.96s\n",
      "Epoch: 9, Batch: 200/1676, Loss: 0.2823, Time: 1.96s\n",
      "Epoch: 9, Batch: 210/1676, Loss: 0.5561, Time: 1.97s\n",
      "Epoch: 9, Batch: 220/1676, Loss: 0.4008, Time: 1.96s\n",
      "Epoch: 9, Batch: 230/1676, Loss: 0.9291, Time: 1.96s\n",
      "Epoch: 9, Batch: 240/1676, Loss: 1.0154, Time: 1.97s\n",
      "Epoch: 9, Batch: 250/1676, Loss: 1.0281, Time: 1.96s\n",
      "Epoch: 9, Batch: 260/1676, Loss: 0.9460, Time: 1.96s\n",
      "Epoch: 9, Batch: 270/1676, Loss: 0.6824, Time: 1.96s\n",
      "Epoch: 9, Batch: 280/1676, Loss: 1.1661, Time: 1.97s\n",
      "Epoch: 9, Batch: 290/1676, Loss: 1.2824, Time: 1.96s\n",
      "Epoch: 9, Batch: 300/1676, Loss: 0.9072, Time: 1.96s\n",
      "Epoch: 9, Batch: 310/1676, Loss: 0.9183, Time: 1.97s\n",
      "Epoch: 9, Batch: 320/1676, Loss: 1.1685, Time: 1.96s\n",
      "Epoch: 9, Batch: 330/1676, Loss: 0.8507, Time: 1.97s\n",
      "Epoch: 9, Batch: 340/1676, Loss: 0.3925, Time: 1.97s\n",
      "Epoch: 9, Batch: 350/1676, Loss: 0.5338, Time: 1.97s\n",
      "Epoch: 9, Batch: 360/1676, Loss: 0.4177, Time: 1.97s\n",
      "Epoch: 9, Batch: 370/1676, Loss: 0.7354, Time: 1.96s\n",
      "Epoch: 9, Batch: 380/1676, Loss: 0.5337, Time: 1.97s\n",
      "Epoch: 9, Batch: 390/1676, Loss: 0.8011, Time: 1.97s\n",
      "Epoch: 9, Batch: 400/1676, Loss: 0.9265, Time: 1.97s\n",
      "Epoch: 9, Batch: 410/1676, Loss: 0.6385, Time: 1.97s\n",
      "Epoch: 9, Batch: 420/1676, Loss: 0.8791, Time: 1.98s\n",
      "Epoch: 9, Batch: 430/1676, Loss: 0.6281, Time: 1.97s\n",
      "Epoch: 9, Batch: 440/1676, Loss: 0.5880, Time: 1.97s\n",
      "Epoch: 9, Batch: 450/1676, Loss: 0.7847, Time: 1.97s\n",
      "Epoch: 9, Batch: 460/1676, Loss: 0.7518, Time: 1.98s\n",
      "Epoch: 9, Batch: 470/1676, Loss: 0.9994, Time: 1.97s\n",
      "Epoch: 9, Batch: 480/1676, Loss: 0.9298, Time: 1.97s\n",
      "Epoch: 9, Batch: 490/1676, Loss: 0.8510, Time: 1.97s\n",
      "Epoch: 9, Batch: 500/1676, Loss: 0.7415, Time: 1.97s\n",
      "Epoch: 9, Batch: 510/1676, Loss: 0.9013, Time: 1.98s\n",
      "Epoch: 9, Batch: 520/1676, Loss: 0.6965, Time: 1.97s\n",
      "Epoch: 9, Batch: 530/1676, Loss: 0.4528, Time: 1.97s\n",
      "Epoch: 9, Batch: 540/1676, Loss: 1.1807, Time: 1.97s\n",
      "Epoch: 9, Batch: 550/1676, Loss: 1.1280, Time: 1.98s\n",
      "Epoch: 9, Batch: 560/1676, Loss: 0.7369, Time: 1.98s\n",
      "Epoch: 9, Batch: 570/1676, Loss: 0.6483, Time: 1.97s\n",
      "Epoch: 9, Batch: 580/1676, Loss: 0.3860, Time: 1.97s\n",
      "Epoch: 9, Batch: 590/1676, Loss: 0.5978, Time: 1.98s\n",
      "Epoch: 9, Batch: 600/1676, Loss: 1.0344, Time: 1.97s\n",
      "Epoch: 9, Batch: 610/1676, Loss: 0.8109, Time: 1.98s\n",
      "Epoch: 9, Batch: 620/1676, Loss: 0.5592, Time: 1.97s\n",
      "Epoch: 9, Batch: 630/1676, Loss: 1.1070, Time: 1.98s\n",
      "Epoch: 9, Batch: 640/1676, Loss: 0.8660, Time: 1.98s\n",
      "Epoch: 9, Batch: 650/1676, Loss: 0.7216, Time: 1.97s\n",
      "Epoch: 9, Batch: 660/1676, Loss: 0.5462, Time: 1.98s\n",
      "Epoch: 9, Batch: 670/1676, Loss: 0.5806, Time: 1.97s\n",
      "Epoch: 9, Batch: 680/1676, Loss: 1.3090, Time: 1.98s\n",
      "Epoch: 9, Batch: 690/1676, Loss: 0.6788, Time: 1.97s\n",
      "Epoch: 9, Batch: 700/1676, Loss: 0.9449, Time: 1.98s\n",
      "Epoch: 9, Batch: 710/1676, Loss: 0.4715, Time: 1.97s\n",
      "Epoch: 9, Batch: 720/1676, Loss: 0.6069, Time: 1.97s\n",
      "Epoch: 9, Batch: 730/1676, Loss: 0.3508, Time: 1.98s\n",
      "Epoch: 9, Batch: 740/1676, Loss: 0.9719, Time: 1.97s\n",
      "Epoch: 9, Batch: 750/1676, Loss: 0.6630, Time: 1.97s\n",
      "Epoch: 9, Batch: 760/1676, Loss: 0.3876, Time: 1.98s\n",
      "Epoch: 9, Batch: 770/1676, Loss: 0.8901, Time: 1.97s\n",
      "Epoch: 9, Batch: 780/1676, Loss: 0.2675, Time: 1.98s\n",
      "Epoch: 9, Batch: 790/1676, Loss: 0.4371, Time: 1.98s\n",
      "Epoch: 9, Batch: 800/1676, Loss: 0.6358, Time: 1.98s\n",
      "Epoch: 9, Batch: 810/1676, Loss: 0.7358, Time: 1.98s\n",
      "Epoch: 9, Batch: 820/1676, Loss: 0.3298, Time: 1.97s\n",
      "Epoch: 9, Batch: 830/1676, Loss: 0.6580, Time: 1.98s\n",
      "Epoch: 9, Batch: 840/1676, Loss: 0.8012, Time: 1.97s\n",
      "Epoch: 9, Batch: 850/1676, Loss: 0.3727, Time: 1.97s\n",
      "Epoch: 9, Batch: 860/1676, Loss: 0.5124, Time: 1.97s\n",
      "Epoch: 9, Batch: 870/1676, Loss: 1.1275, Time: 1.97s\n",
      "Epoch: 9, Batch: 880/1676, Loss: 0.4101, Time: 1.98s\n",
      "Epoch: 9, Batch: 890/1676, Loss: 0.4475, Time: 1.98s\n",
      "Epoch: 9, Batch: 900/1676, Loss: 0.4987, Time: 1.98s\n",
      "Epoch: 9, Batch: 910/1676, Loss: 0.4998, Time: 1.98s\n",
      "Epoch: 9, Batch: 920/1676, Loss: 0.5862, Time: 1.99s\n",
      "Epoch: 9, Batch: 930/1676, Loss: 0.9324, Time: 1.98s\n",
      "Epoch: 9, Batch: 940/1676, Loss: 0.6631, Time: 1.98s\n",
      "Epoch: 9, Batch: 950/1676, Loss: 0.7429, Time: 1.98s\n",
      "Epoch: 9, Batch: 960/1676, Loss: 0.4431, Time: 1.97s\n",
      "Epoch: 9, Batch: 970/1676, Loss: 1.0768, Time: 1.98s\n",
      "Epoch: 9, Batch: 980/1676, Loss: 0.5816, Time: 1.98s\n",
      "Epoch: 9, Batch: 990/1676, Loss: 1.2342, Time: 1.98s\n",
      "Epoch: 9, Batch: 1000/1676, Loss: 0.6139, Time: 1.98s\n",
      "Epoch: 9, Batch: 1010/1676, Loss: 0.5894, Time: 1.98s\n",
      "Epoch: 9, Batch: 1020/1676, Loss: 0.3070, Time: 1.98s\n",
      "Epoch: 9, Batch: 1030/1676, Loss: 1.2855, Time: 1.98s\n",
      "Epoch: 9, Batch: 1040/1676, Loss: 0.6563, Time: 1.98s\n",
      "Epoch: 9, Batch: 1050/1676, Loss: 0.4237, Time: 1.98s\n",
      "Epoch: 9, Batch: 1060/1676, Loss: 1.1100, Time: 1.98s\n",
      "Epoch: 9, Batch: 1070/1676, Loss: 0.5468, Time: 1.99s\n",
      "Epoch: 9, Batch: 1080/1676, Loss: 0.2498, Time: 1.98s\n",
      "Epoch: 9, Batch: 1090/1676, Loss: 0.7704, Time: 1.97s\n",
      "Epoch: 9, Batch: 1100/1676, Loss: 0.3029, Time: 1.98s\n",
      "Epoch: 9, Batch: 1110/1676, Loss: 0.9495, Time: 1.98s\n",
      "Epoch: 9, Batch: 1120/1676, Loss: 0.4910, Time: 1.98s\n",
      "Epoch: 9, Batch: 1130/1676, Loss: 0.5988, Time: 1.99s\n",
      "Epoch: 9, Batch: 1140/1676, Loss: 0.4094, Time: 1.98s\n",
      "Epoch: 9, Batch: 1150/1676, Loss: 0.8280, Time: 1.97s\n",
      "Epoch: 9, Batch: 1160/1676, Loss: 0.6292, Time: 1.98s\n",
      "Epoch: 9, Batch: 1170/1676, Loss: 1.1503, Time: 1.98s\n",
      "Epoch: 9, Batch: 1180/1676, Loss: 0.9896, Time: 1.98s\n",
      "Epoch: 9, Batch: 1190/1676, Loss: 0.9825, Time: 1.98s\n",
      "Epoch: 9, Batch: 1200/1676, Loss: 0.5268, Time: 1.98s\n",
      "Epoch: 9, Batch: 1210/1676, Loss: 0.5432, Time: 1.98s\n",
      "Epoch: 9, Batch: 1220/1676, Loss: 0.8243, Time: 1.98s\n",
      "Epoch: 9, Batch: 1230/1676, Loss: 0.5222, Time: 1.98s\n",
      "Epoch: 9, Batch: 1240/1676, Loss: 1.0235, Time: 1.98s\n",
      "Epoch: 9, Batch: 1250/1676, Loss: 0.2897, Time: 1.98s\n",
      "Epoch: 9, Batch: 1260/1676, Loss: 0.9755, Time: 1.97s\n",
      "Epoch: 9, Batch: 1270/1676, Loss: 0.6433, Time: 1.98s\n",
      "Epoch: 9, Batch: 1280/1676, Loss: 0.6651, Time: 1.99s\n",
      "Epoch: 9, Batch: 1290/1676, Loss: 0.3947, Time: 1.98s\n",
      "Epoch: 9, Batch: 1300/1676, Loss: 0.6418, Time: 1.99s\n",
      "Epoch: 9, Batch: 1310/1676, Loss: 0.2858, Time: 1.98s\n",
      "Epoch: 9, Batch: 1320/1676, Loss: 0.7131, Time: 1.99s\n",
      "Epoch: 9, Batch: 1330/1676, Loss: 0.5962, Time: 1.98s\n",
      "Epoch: 9, Batch: 1340/1676, Loss: 0.9616, Time: 1.98s\n",
      "Epoch: 9, Batch: 1350/1676, Loss: 0.7492, Time: 1.98s\n",
      "Epoch: 9, Batch: 1360/1676, Loss: 0.4191, Time: 1.98s\n",
      "Epoch: 9, Batch: 1370/1676, Loss: 0.6251, Time: 1.99s\n",
      "Epoch: 9, Batch: 1380/1676, Loss: 0.4587, Time: 1.98s\n",
      "Epoch: 9, Batch: 1390/1676, Loss: 0.7924, Time: 1.98s\n",
      "Epoch: 9, Batch: 1400/1676, Loss: 1.0181, Time: 1.98s\n",
      "Epoch: 9, Batch: 1410/1676, Loss: 0.9387, Time: 1.98s\n",
      "Epoch: 9, Batch: 1420/1676, Loss: 0.3753, Time: 1.99s\n",
      "Epoch: 9, Batch: 1430/1676, Loss: 0.6653, Time: 1.98s\n",
      "Epoch: 9, Batch: 1440/1676, Loss: 0.7451, Time: 1.98s\n",
      "Epoch: 9, Batch: 1450/1676, Loss: 0.5937, Time: 1.98s\n",
      "Epoch: 9, Batch: 1460/1676, Loss: 0.5252, Time: 1.98s\n",
      "Epoch: 9, Batch: 1470/1676, Loss: 0.4239, Time: 1.99s\n",
      "Epoch: 9, Batch: 1480/1676, Loss: 0.8698, Time: 1.99s\n",
      "Epoch: 9, Batch: 1490/1676, Loss: 0.9044, Time: 1.98s\n",
      "Epoch: 9, Batch: 1500/1676, Loss: 0.5294, Time: 1.99s\n",
      "Epoch: 9, Batch: 1510/1676, Loss: 0.7667, Time: 1.98s\n",
      "Epoch: 9, Batch: 1520/1676, Loss: 0.5274, Time: 1.98s\n",
      "Epoch: 9, Batch: 1530/1676, Loss: 0.9576, Time: 1.98s\n",
      "Epoch: 9, Batch: 1540/1676, Loss: 0.5550, Time: 1.99s\n",
      "Epoch: 9, Batch: 1550/1676, Loss: 0.8739, Time: 1.98s\n",
      "Epoch: 9, Batch: 1560/1676, Loss: 0.4052, Time: 1.98s\n",
      "Epoch: 9, Batch: 1570/1676, Loss: 0.8058, Time: 1.98s\n",
      "Epoch: 9, Batch: 1580/1676, Loss: 0.9724, Time: 1.98s\n",
      "Epoch: 9, Batch: 1590/1676, Loss: 0.6748, Time: 1.98s\n",
      "Epoch: 9, Batch: 1600/1676, Loss: 0.5542, Time: 1.97s\n",
      "Epoch: 9, Batch: 1610/1676, Loss: 0.8319, Time: 1.99s\n",
      "Epoch: 9, Batch: 1620/1676, Loss: 1.1353, Time: 1.98s\n",
      "Epoch: 9, Batch: 1630/1676, Loss: 0.4330, Time: 1.98s\n",
      "Epoch: 9, Batch: 1640/1676, Loss: 0.4794, Time: 1.98s\n",
      "Epoch: 9, Batch: 1650/1676, Loss: 0.2637, Time: 1.98s\n",
      "Epoch: 9, Batch: 1660/1676, Loss: 0.5195, Time: 1.98s\n",
      "Epoch: 9, Batch: 1670/1676, Loss: 0.9409, Time: 1.98s\n",
      "Epoch 10/50: Train Loss: 0.7304, Val Loss: 0.7393, Val IoU: 0.5579, Val Dice: 0.5774\n",
      "Saving best model with IoU: 0.5579\n",
      "Epoch: 10, Batch: 0/1676, Loss: 1.3230, Time: 35.84s\n",
      "Epoch: 10, Batch: 10/1676, Loss: 0.5312, Time: 1.99s\n",
      "Epoch: 10, Batch: 20/1676, Loss: 0.3717, Time: 1.94s\n",
      "Epoch: 10, Batch: 30/1676, Loss: 0.4695, Time: 1.94s\n",
      "Epoch: 10, Batch: 40/1676, Loss: 0.3729, Time: 1.94s\n",
      "Epoch: 10, Batch: 50/1676, Loss: 0.7170, Time: 1.94s\n",
      "Epoch: 10, Batch: 60/1676, Loss: 0.4778, Time: 1.95s\n",
      "Epoch: 10, Batch: 70/1676, Loss: 0.8687, Time: 1.95s\n",
      "Epoch: 10, Batch: 80/1676, Loss: 0.7558, Time: 1.95s\n",
      "Epoch: 10, Batch: 90/1676, Loss: 0.9835, Time: 1.95s\n",
      "Epoch: 10, Batch: 100/1676, Loss: 0.4937, Time: 1.94s\n",
      "Epoch: 10, Batch: 110/1676, Loss: 0.7240, Time: 1.96s\n",
      "Epoch: 10, Batch: 120/1676, Loss: 0.8952, Time: 1.95s\n",
      "Epoch: 10, Batch: 130/1676, Loss: 0.6357, Time: 1.95s\n",
      "Epoch: 10, Batch: 140/1676, Loss: 0.3950, Time: 1.96s\n",
      "Epoch: 10, Batch: 150/1676, Loss: 0.5737, Time: 1.95s\n",
      "Epoch: 10, Batch: 160/1676, Loss: 0.7273, Time: 1.96s\n",
      "Epoch: 10, Batch: 170/1676, Loss: 0.7745, Time: 1.96s\n",
      "Epoch: 10, Batch: 180/1676, Loss: 1.1133, Time: 1.96s\n",
      "Epoch: 10, Batch: 190/1676, Loss: 0.8027, Time: 1.96s\n",
      "Epoch: 10, Batch: 200/1676, Loss: 0.4433, Time: 1.96s\n",
      "Epoch: 10, Batch: 210/1676, Loss: 0.6318, Time: 1.96s\n",
      "Epoch: 10, Batch: 220/1676, Loss: 0.5983, Time: 1.96s\n",
      "Epoch: 10, Batch: 230/1676, Loss: 1.4435, Time: 1.96s\n",
      "Epoch: 10, Batch: 240/1676, Loss: 1.2116, Time: 1.97s\n",
      "Epoch: 10, Batch: 250/1676, Loss: 0.9683, Time: 1.97s\n",
      "Epoch: 10, Batch: 260/1676, Loss: 0.9381, Time: 1.96s\n",
      "Epoch: 10, Batch: 270/1676, Loss: 0.4058, Time: 1.97s\n",
      "Epoch: 10, Batch: 280/1676, Loss: 0.9831, Time: 1.96s\n",
      "Epoch: 10, Batch: 290/1676, Loss: 0.6400, Time: 1.96s\n",
      "Epoch: 10, Batch: 300/1676, Loss: 0.5549, Time: 1.97s\n",
      "Epoch: 10, Batch: 310/1676, Loss: 1.1019, Time: 1.96s\n",
      "Epoch: 10, Batch: 320/1676, Loss: 0.4929, Time: 1.96s\n",
      "Epoch: 10, Batch: 330/1676, Loss: 0.4870, Time: 1.96s\n",
      "Epoch: 10, Batch: 340/1676, Loss: 0.4532, Time: 1.97s\n",
      "Epoch: 10, Batch: 350/1676, Loss: 0.4425, Time: 1.96s\n",
      "Epoch: 10, Batch: 360/1676, Loss: 0.4967, Time: 1.97s\n",
      "Epoch: 10, Batch: 370/1676, Loss: 0.8462, Time: 1.97s\n",
      "Epoch: 10, Batch: 380/1676, Loss: 0.5606, Time: 1.97s\n",
      "Epoch: 10, Batch: 390/1676, Loss: 0.9865, Time: 1.97s\n",
      "Epoch: 10, Batch: 400/1676, Loss: 0.7970, Time: 1.96s\n",
      "Epoch: 10, Batch: 410/1676, Loss: 0.8869, Time: 1.97s\n",
      "Epoch: 10, Batch: 420/1676, Loss: 0.6645, Time: 1.97s\n",
      "Epoch: 10, Batch: 430/1676, Loss: 0.2921, Time: 1.97s\n",
      "Epoch: 10, Batch: 440/1676, Loss: 0.6101, Time: 1.97s\n",
      "Epoch: 10, Batch: 450/1676, Loss: 0.5656, Time: 1.97s\n",
      "Epoch: 10, Batch: 460/1676, Loss: 0.5780, Time: 1.97s\n",
      "Epoch: 10, Batch: 470/1676, Loss: 0.9278, Time: 1.98s\n",
      "Epoch: 10, Batch: 480/1676, Loss: 0.7702, Time: 1.97s\n",
      "Epoch: 10, Batch: 490/1676, Loss: 0.3747, Time: 1.97s\n",
      "Epoch: 10, Batch: 500/1676, Loss: 0.5421, Time: 1.98s\n",
      "Epoch: 10, Batch: 510/1676, Loss: 0.7528, Time: 1.97s\n",
      "Epoch: 10, Batch: 520/1676, Loss: 0.7994, Time: 1.97s\n",
      "Epoch: 10, Batch: 530/1676, Loss: 0.4635, Time: 1.98s\n",
      "Epoch: 10, Batch: 540/1676, Loss: 0.8062, Time: 1.97s\n",
      "Epoch: 10, Batch: 550/1676, Loss: 0.3243, Time: 1.97s\n",
      "Epoch: 10, Batch: 560/1676, Loss: 0.9544, Time: 1.97s\n",
      "Epoch: 10, Batch: 570/1676, Loss: 0.6286, Time: 1.98s\n",
      "Epoch: 10, Batch: 580/1676, Loss: 0.4271, Time: 1.97s\n",
      "Epoch: 10, Batch: 590/1676, Loss: 0.4079, Time: 1.97s\n",
      "Epoch: 10, Batch: 600/1676, Loss: 0.9542, Time: 1.97s\n",
      "Epoch: 10, Batch: 610/1676, Loss: 0.4340, Time: 1.98s\n",
      "Epoch: 10, Batch: 620/1676, Loss: 1.2589, Time: 1.97s\n",
      "Epoch: 10, Batch: 630/1676, Loss: 0.8677, Time: 1.97s\n",
      "Epoch: 10, Batch: 640/1676, Loss: 1.0052, Time: 1.97s\n",
      "Epoch: 10, Batch: 650/1676, Loss: 0.9684, Time: 1.97s\n",
      "Epoch: 10, Batch: 660/1676, Loss: 0.5405, Time: 1.97s\n",
      "Epoch: 10, Batch: 670/1676, Loss: 0.4648, Time: 1.97s\n",
      "Epoch: 10, Batch: 680/1676, Loss: 0.7140, Time: 1.98s\n",
      "Epoch: 10, Batch: 690/1676, Loss: 0.7331, Time: 1.97s\n",
      "Epoch: 10, Batch: 700/1676, Loss: 0.5472, Time: 1.98s\n",
      "Epoch: 10, Batch: 710/1676, Loss: 0.7090, Time: 1.98s\n",
      "Epoch: 10, Batch: 720/1676, Loss: 0.6082, Time: 1.97s\n",
      "Epoch: 10, Batch: 730/1676, Loss: 1.1284, Time: 1.97s\n",
      "Epoch: 10, Batch: 740/1676, Loss: 0.5109, Time: 1.96s\n",
      "Epoch: 10, Batch: 750/1676, Loss: 0.3971, Time: 1.98s\n",
      "Epoch: 10, Batch: 760/1676, Loss: 0.4355, Time: 1.97s\n",
      "Epoch: 10, Batch: 770/1676, Loss: 0.8938, Time: 1.98s\n",
      "Epoch: 10, Batch: 780/1676, Loss: 1.0954, Time: 1.97s\n",
      "Epoch: 10, Batch: 790/1676, Loss: 0.6559, Time: 1.98s\n",
      "Epoch: 10, Batch: 800/1676, Loss: 1.2494, Time: 1.97s\n",
      "Epoch: 10, Batch: 810/1676, Loss: 0.3108, Time: 1.98s\n",
      "Epoch: 10, Batch: 820/1676, Loss: 0.5496, Time: 1.98s\n",
      "Epoch: 10, Batch: 830/1676, Loss: 0.8406, Time: 1.98s\n",
      "Epoch: 10, Batch: 840/1676, Loss: 0.5287, Time: 1.97s\n",
      "Epoch: 10, Batch: 850/1676, Loss: 0.6635, Time: 1.98s\n",
      "Epoch: 10, Batch: 860/1676, Loss: 0.6729, Time: 1.98s\n",
      "Epoch: 10, Batch: 870/1676, Loss: 0.5255, Time: 1.98s\n",
      "Epoch: 10, Batch: 880/1676, Loss: 0.3555, Time: 1.97s\n",
      "Epoch: 10, Batch: 890/1676, Loss: 0.5334, Time: 1.97s\n",
      "Epoch: 10, Batch: 900/1676, Loss: 0.9077, Time: 1.98s\n",
      "Epoch: 10, Batch: 910/1676, Loss: 0.6180, Time: 1.98s\n",
      "Epoch: 10, Batch: 920/1676, Loss: 1.1290, Time: 1.98s\n",
      "Epoch: 10, Batch: 930/1676, Loss: 0.6849, Time: 1.98s\n",
      "Epoch: 10, Batch: 940/1676, Loss: 0.4994, Time: 1.97s\n",
      "Epoch: 10, Batch: 950/1676, Loss: 0.7007, Time: 1.98s\n",
      "Epoch: 10, Batch: 960/1676, Loss: 0.8182, Time: 1.98s\n",
      "Epoch: 10, Batch: 970/1676, Loss: 1.0437, Time: 1.98s\n",
      "Epoch: 10, Batch: 980/1676, Loss: 0.7582, Time: 1.98s\n",
      "Epoch: 10, Batch: 990/1676, Loss: 0.7224, Time: 1.98s\n",
      "Epoch: 10, Batch: 1000/1676, Loss: 1.0019, Time: 1.98s\n",
      "Epoch: 10, Batch: 1010/1676, Loss: 0.2732, Time: 1.98s\n",
      "Epoch: 10, Batch: 1020/1676, Loss: 0.4494, Time: 1.98s\n",
      "Epoch: 10, Batch: 1030/1676, Loss: 1.2561, Time: 1.98s\n",
      "Epoch: 10, Batch: 1040/1676, Loss: 0.7761, Time: 1.97s\n",
      "Epoch: 10, Batch: 1050/1676, Loss: 1.0243, Time: 1.98s\n",
      "Epoch: 10, Batch: 1060/1676, Loss: 0.5864, Time: 1.98s\n",
      "Epoch: 10, Batch: 1070/1676, Loss: 0.5015, Time: 1.98s\n",
      "Epoch: 10, Batch: 1080/1676, Loss: 0.6210, Time: 1.98s\n",
      "Epoch: 10, Batch: 1090/1676, Loss: 0.6066, Time: 1.98s\n",
      "Epoch: 10, Batch: 1100/1676, Loss: 0.9172, Time: 1.98s\n",
      "Epoch: 10, Batch: 1110/1676, Loss: 0.4462, Time: 1.97s\n",
      "Epoch: 10, Batch: 1120/1676, Loss: 0.7716, Time: 1.98s\n",
      "Epoch: 10, Batch: 1130/1676, Loss: 0.6157, Time: 1.98s\n",
      "Epoch: 10, Batch: 1140/1676, Loss: 0.6932, Time: 1.98s\n",
      "Epoch: 10, Batch: 1150/1676, Loss: 1.3410, Time: 1.98s\n",
      "Epoch: 10, Batch: 1160/1676, Loss: 0.5979, Time: 1.98s\n",
      "Epoch: 10, Batch: 1170/1676, Loss: 0.5412, Time: 1.97s\n",
      "Epoch: 10, Batch: 1180/1676, Loss: 0.8764, Time: 1.98s\n",
      "Epoch: 10, Batch: 1190/1676, Loss: 1.1586, Time: 1.98s\n",
      "Epoch: 10, Batch: 1200/1676, Loss: 0.4249, Time: 1.98s\n",
      "Epoch: 10, Batch: 1210/1676, Loss: 0.6780, Time: 1.98s\n",
      "Epoch: 10, Batch: 1220/1676, Loss: 1.2314, Time: 1.98s\n",
      "Epoch: 10, Batch: 1230/1676, Loss: 0.6157, Time: 1.98s\n",
      "Epoch: 10, Batch: 1240/1676, Loss: 0.7824, Time: 1.98s\n",
      "Epoch: 10, Batch: 1250/1676, Loss: 0.5665, Time: 1.97s\n",
      "Epoch: 10, Batch: 1260/1676, Loss: 0.7260, Time: 1.98s\n",
      "Epoch: 10, Batch: 1270/1676, Loss: 1.0119, Time: 1.98s\n",
      "Epoch: 10, Batch: 1280/1676, Loss: 0.9808, Time: 1.99s\n",
      "Epoch: 10, Batch: 1290/1676, Loss: 0.4707, Time: 1.98s\n",
      "Epoch: 10, Batch: 1300/1676, Loss: 0.4235, Time: 1.98s\n",
      "Epoch: 10, Batch: 1310/1676, Loss: 0.3303, Time: 1.98s\n",
      "Epoch: 10, Batch: 1320/1676, Loss: 0.5351, Time: 1.99s\n",
      "Epoch: 10, Batch: 1330/1676, Loss: 0.2969, Time: 1.98s\n",
      "Epoch: 10, Batch: 1340/1676, Loss: 0.3529, Time: 1.98s\n",
      "Epoch: 10, Batch: 1350/1676, Loss: 0.6156, Time: 1.99s\n",
      "Epoch: 10, Batch: 1360/1676, Loss: 1.1179, Time: 1.98s\n",
      "Epoch: 10, Batch: 1370/1676, Loss: 1.2678, Time: 1.97s\n",
      "Epoch: 10, Batch: 1380/1676, Loss: 1.1726, Time: 1.99s\n",
      "Epoch: 10, Batch: 1390/1676, Loss: 0.9242, Time: 1.98s\n",
      "Epoch: 10, Batch: 1400/1676, Loss: 0.7963, Time: 1.98s\n",
      "Epoch: 10, Batch: 1410/1676, Loss: 0.8218, Time: 1.98s\n",
      "Epoch: 10, Batch: 1420/1676, Loss: 0.6066, Time: 1.98s\n",
      "Epoch: 10, Batch: 1430/1676, Loss: 0.6739, Time: 1.98s\n",
      "Epoch: 10, Batch: 1440/1676, Loss: 0.9065, Time: 1.98s\n",
      "Epoch: 10, Batch: 1450/1676, Loss: 0.9419, Time: 1.99s\n",
      "Epoch: 10, Batch: 1460/1676, Loss: 1.1941, Time: 1.97s\n",
      "Epoch: 10, Batch: 1470/1676, Loss: 0.4193, Time: 1.98s\n",
      "Epoch: 10, Batch: 1480/1676, Loss: 0.7716, Time: 1.99s\n",
      "Epoch: 10, Batch: 1490/1676, Loss: 0.3666, Time: 1.98s\n",
      "Epoch: 10, Batch: 1500/1676, Loss: 1.1687, Time: 1.99s\n",
      "Epoch: 10, Batch: 1510/1676, Loss: 0.9287, Time: 1.98s\n",
      "Epoch: 10, Batch: 1520/1676, Loss: 0.8497, Time: 1.98s\n",
      "Epoch: 10, Batch: 1530/1676, Loss: 1.0289, Time: 1.98s\n",
      "Epoch: 10, Batch: 1540/1676, Loss: 1.1425, Time: 1.98s\n",
      "Epoch: 10, Batch: 1550/1676, Loss: 0.6557, Time: 1.98s\n",
      "Epoch: 10, Batch: 1560/1676, Loss: 0.7215, Time: 1.98s\n",
      "Epoch: 10, Batch: 1570/1676, Loss: 0.8886, Time: 1.98s\n",
      "Epoch: 10, Batch: 1580/1676, Loss: 0.5720, Time: 1.99s\n",
      "Epoch: 10, Batch: 1590/1676, Loss: 0.4663, Time: 1.98s\n",
      "Epoch: 10, Batch: 1600/1676, Loss: 0.5404, Time: 1.98s\n",
      "Epoch: 10, Batch: 1610/1676, Loss: 1.0916, Time: 1.98s\n",
      "Epoch: 10, Batch: 1620/1676, Loss: 1.3576, Time: 1.98s\n",
      "Epoch: 10, Batch: 1630/1676, Loss: 0.7542, Time: 1.98s\n",
      "Epoch: 10, Batch: 1640/1676, Loss: 0.5623, Time: 1.98s\n",
      "Epoch: 10, Batch: 1650/1676, Loss: 0.5535, Time: 1.97s\n",
      "Epoch: 10, Batch: 1660/1676, Loss: 1.1164, Time: 1.98s\n",
      "Epoch: 10, Batch: 1670/1676, Loss: 0.6729, Time: 1.98s\n",
      "Epoch 11/50: Train Loss: 0.7301, Val Loss: 0.7379, Val IoU: 0.5611, Val Dice: 0.5804\n",
      "Saving best model with IoU: 0.5611\n",
      "Epoch: 11, Batch: 0/1676, Loss: 0.8397, Time: 35.89s\n",
      "Epoch: 11, Batch: 10/1676, Loss: 0.9991, Time: 1.98s\n",
      "Epoch: 11, Batch: 20/1676, Loss: 0.3132, Time: 1.94s\n",
      "Epoch: 11, Batch: 30/1676, Loss: 0.9004, Time: 1.94s\n",
      "Epoch: 11, Batch: 40/1676, Loss: 0.8297, Time: 1.94s\n",
      "Epoch: 11, Batch: 50/1676, Loss: 0.7661, Time: 1.94s\n",
      "Epoch: 11, Batch: 60/1676, Loss: 0.8628, Time: 1.95s\n",
      "Epoch: 11, Batch: 70/1676, Loss: 0.4385, Time: 1.94s\n",
      "Epoch: 11, Batch: 80/1676, Loss: 0.4359, Time: 1.95s\n",
      "Epoch: 11, Batch: 90/1676, Loss: 0.8299, Time: 1.95s\n",
      "Epoch: 11, Batch: 100/1676, Loss: 0.9265, Time: 1.95s\n",
      "Epoch: 11, Batch: 110/1676, Loss: 0.4947, Time: 1.95s\n",
      "Epoch: 11, Batch: 120/1676, Loss: 0.8138, Time: 1.95s\n",
      "Epoch: 11, Batch: 130/1676, Loss: 0.3950, Time: 1.95s\n",
      "Epoch: 11, Batch: 140/1676, Loss: 0.3473, Time: 1.95s\n",
      "Epoch: 11, Batch: 150/1676, Loss: 0.8414, Time: 1.95s\n",
      "Epoch: 11, Batch: 160/1676, Loss: 0.9326, Time: 1.96s\n",
      "Epoch: 11, Batch: 170/1676, Loss: 1.0073, Time: 1.96s\n",
      "Epoch: 11, Batch: 180/1676, Loss: 1.3140, Time: 1.95s\n",
      "Epoch: 11, Batch: 190/1676, Loss: 0.8732, Time: 1.96s\n",
      "Epoch: 11, Batch: 200/1676, Loss: 0.6758, Time: 1.96s\n",
      "Epoch: 11, Batch: 210/1676, Loss: 0.4514, Time: 1.95s\n",
      "Epoch: 11, Batch: 220/1676, Loss: 0.6814, Time: 1.96s\n",
      "Epoch: 11, Batch: 230/1676, Loss: 0.6881, Time: 1.96s\n",
      "Epoch: 11, Batch: 240/1676, Loss: 0.8396, Time: 1.95s\n",
      "Epoch: 11, Batch: 250/1676, Loss: 0.5836, Time: 1.96s\n",
      "Epoch: 11, Batch: 260/1676, Loss: 0.4509, Time: 1.96s\n",
      "Epoch: 11, Batch: 270/1676, Loss: 0.8008, Time: 1.96s\n",
      "Epoch: 11, Batch: 280/1676, Loss: 0.8275, Time: 1.96s\n",
      "Epoch: 11, Batch: 290/1676, Loss: 0.8295, Time: 1.97s\n",
      "Epoch: 11, Batch: 300/1676, Loss: 0.4345, Time: 1.96s\n",
      "Epoch: 11, Batch: 310/1676, Loss: 0.9602, Time: 1.96s\n",
      "Epoch: 11, Batch: 320/1676, Loss: 0.7313, Time: 1.96s\n",
      "Epoch: 11, Batch: 330/1676, Loss: 0.8809, Time: 1.97s\n",
      "Epoch: 11, Batch: 340/1676, Loss: 0.6931, Time: 1.97s\n",
      "Epoch: 11, Batch: 350/1676, Loss: 0.7727, Time: 1.96s\n",
      "Epoch: 11, Batch: 360/1676, Loss: 0.3823, Time: 1.97s\n",
      "Epoch: 11, Batch: 370/1676, Loss: 0.6536, Time: 1.97s\n",
      "Epoch: 11, Batch: 380/1676, Loss: 0.5951, Time: 1.97s\n",
      "Epoch: 11, Batch: 390/1676, Loss: 0.5776, Time: 1.97s\n",
      "Epoch: 11, Batch: 400/1676, Loss: 0.4509, Time: 1.97s\n",
      "Epoch: 11, Batch: 410/1676, Loss: 1.4602, Time: 1.96s\n",
      "Epoch: 11, Batch: 420/1676, Loss: 0.5983, Time: 1.97s\n",
      "Epoch: 11, Batch: 430/1676, Loss: 0.9298, Time: 1.98s\n",
      "Epoch: 11, Batch: 440/1676, Loss: 0.4651, Time: 1.98s\n",
      "Epoch: 11, Batch: 450/1676, Loss: 0.4868, Time: 1.97s\n",
      "Epoch: 11, Batch: 460/1676, Loss: 0.4238, Time: 1.97s\n",
      "Epoch: 11, Batch: 470/1676, Loss: 1.0576, Time: 1.97s\n",
      "Epoch: 11, Batch: 480/1676, Loss: 0.5235, Time: 1.97s\n",
      "Epoch: 11, Batch: 490/1676, Loss: 0.3041, Time: 1.97s\n",
      "Epoch: 11, Batch: 500/1676, Loss: 0.6896, Time: 1.97s\n",
      "Epoch: 11, Batch: 510/1676, Loss: 0.6518, Time: 1.98s\n",
      "Epoch: 11, Batch: 520/1676, Loss: 0.5464, Time: 1.97s\n",
      "Epoch: 11, Batch: 530/1676, Loss: 0.6761, Time: 1.97s\n",
      "Epoch: 11, Batch: 540/1676, Loss: 0.4476, Time: 1.97s\n",
      "Epoch: 11, Batch: 550/1676, Loss: 0.4081, Time: 1.97s\n",
      "Epoch: 11, Batch: 560/1676, Loss: 0.6167, Time: 1.97s\n",
      "Epoch: 11, Batch: 570/1676, Loss: 0.5053, Time: 1.97s\n",
      "Epoch: 11, Batch: 580/1676, Loss: 0.3768, Time: 1.98s\n",
      "Epoch: 11, Batch: 590/1676, Loss: 1.0707, Time: 1.97s\n",
      "Epoch: 11, Batch: 600/1676, Loss: 0.5440, Time: 1.98s\n",
      "Epoch: 11, Batch: 610/1676, Loss: 0.4656, Time: 1.97s\n",
      "Epoch: 11, Batch: 620/1676, Loss: 0.6590, Time: 1.98s\n",
      "Epoch: 11, Batch: 630/1676, Loss: 0.8293, Time: 1.97s\n",
      "Epoch: 11, Batch: 640/1676, Loss: 0.8260, Time: 1.98s\n",
      "Epoch: 11, Batch: 650/1676, Loss: 0.3478, Time: 1.97s\n",
      "Epoch: 11, Batch: 660/1676, Loss: 0.9849, Time: 1.97s\n",
      "Epoch: 11, Batch: 670/1676, Loss: 0.3491, Time: 1.97s\n",
      "Epoch: 11, Batch: 680/1676, Loss: 0.7814, Time: 1.97s\n",
      "Epoch: 11, Batch: 690/1676, Loss: 0.4495, Time: 1.97s\n",
      "Epoch: 11, Batch: 700/1676, Loss: 0.6140, Time: 1.97s\n",
      "Epoch: 11, Batch: 710/1676, Loss: 0.6279, Time: 1.97s\n",
      "Epoch: 11, Batch: 720/1676, Loss: 0.6987, Time: 1.98s\n",
      "Epoch: 11, Batch: 730/1676, Loss: 0.9039, Time: 1.98s\n",
      "Epoch: 11, Batch: 740/1676, Loss: 0.4119, Time: 1.98s\n",
      "Epoch: 11, Batch: 750/1676, Loss: 0.3616, Time: 1.98s\n",
      "Epoch: 11, Batch: 760/1676, Loss: 0.4435, Time: 1.97s\n",
      "Epoch: 11, Batch: 770/1676, Loss: 0.6928, Time: 1.98s\n",
      "Epoch: 11, Batch: 780/1676, Loss: 0.7286, Time: 1.98s\n",
      "Epoch: 11, Batch: 790/1676, Loss: 0.6174, Time: 1.98s\n",
      "Epoch: 11, Batch: 800/1676, Loss: 0.7419, Time: 1.97s\n",
      "Epoch: 11, Batch: 810/1676, Loss: 0.6634, Time: 1.98s\n",
      "Epoch: 11, Batch: 820/1676, Loss: 1.2836, Time: 1.97s\n",
      "Epoch: 11, Batch: 830/1676, Loss: 0.7600, Time: 1.97s\n",
      "Epoch: 11, Batch: 840/1676, Loss: 0.6796, Time: 1.98s\n",
      "Epoch: 11, Batch: 850/1676, Loss: 1.1040, Time: 1.97s\n",
      "Epoch: 11, Batch: 860/1676, Loss: 0.5429, Time: 1.98s\n",
      "Epoch: 11, Batch: 870/1676, Loss: 0.5072, Time: 1.97s\n",
      "Epoch: 11, Batch: 880/1676, Loss: 0.4691, Time: 1.97s\n",
      "Epoch: 11, Batch: 890/1676, Loss: 1.1688, Time: 1.98s\n",
      "Epoch: 11, Batch: 900/1676, Loss: 0.5230, Time: 1.97s\n",
      "Epoch: 11, Batch: 910/1676, Loss: 1.0848, Time: 1.97s\n",
      "Epoch: 11, Batch: 920/1676, Loss: 0.4870, Time: 1.97s\n",
      "Epoch: 11, Batch: 930/1676, Loss: 1.2590, Time: 1.98s\n",
      "Epoch: 11, Batch: 940/1676, Loss: 0.4114, Time: 1.98s\n",
      "Epoch: 11, Batch: 950/1676, Loss: 0.6551, Time: 1.98s\n",
      "Epoch: 11, Batch: 960/1676, Loss: 0.9474, Time: 1.97s\n",
      "Epoch: 11, Batch: 970/1676, Loss: 0.4828, Time: 1.97s\n",
      "Epoch: 11, Batch: 980/1676, Loss: 0.5050, Time: 1.97s\n",
      "Epoch: 11, Batch: 990/1676, Loss: 0.5776, Time: 1.98s\n",
      "Epoch: 11, Batch: 1000/1676, Loss: 0.6996, Time: 1.98s\n",
      "Epoch: 11, Batch: 1010/1676, Loss: 0.8828, Time: 1.98s\n",
      "Epoch: 11, Batch: 1020/1676, Loss: 0.5976, Time: 1.98s\n",
      "Epoch: 11, Batch: 1030/1676, Loss: 1.4403, Time: 1.97s\n",
      "Epoch: 11, Batch: 1040/1676, Loss: 0.5668, Time: 1.97s\n",
      "Epoch: 11, Batch: 1050/1676, Loss: 0.5753, Time: 1.97s\n",
      "Epoch: 11, Batch: 1060/1676, Loss: 0.6654, Time: 1.97s\n",
      "Epoch: 11, Batch: 1070/1676, Loss: 0.4227, Time: 1.97s\n",
      "Epoch: 11, Batch: 1080/1676, Loss: 0.8189, Time: 1.97s\n",
      "Epoch: 11, Batch: 1090/1676, Loss: 0.7668, Time: 1.97s\n",
      "Epoch: 11, Batch: 1100/1676, Loss: 0.4399, Time: 1.98s\n",
      "Epoch: 11, Batch: 1110/1676, Loss: 0.5821, Time: 1.98s\n",
      "Epoch: 11, Batch: 1120/1676, Loss: 0.8860, Time: 1.99s\n",
      "Epoch: 11, Batch: 1130/1676, Loss: 0.1813, Time: 1.98s\n",
      "Epoch: 11, Batch: 1140/1676, Loss: 0.4985, Time: 1.98s\n",
      "Epoch: 11, Batch: 1150/1676, Loss: 1.0356, Time: 1.97s\n",
      "Epoch: 11, Batch: 1160/1676, Loss: 1.1536, Time: 1.98s\n",
      "Epoch: 11, Batch: 1170/1676, Loss: 0.5843, Time: 1.98s\n",
      "Epoch: 11, Batch: 1180/1676, Loss: 0.6206, Time: 1.98s\n",
      "Epoch: 11, Batch: 1190/1676, Loss: 0.4775, Time: 1.98s\n",
      "Epoch: 11, Batch: 1200/1676, Loss: 1.3377, Time: 1.97s\n",
      "Epoch: 11, Batch: 1210/1676, Loss: 0.8504, Time: 1.98s\n",
      "Epoch: 11, Batch: 1220/1676, Loss: 0.4620, Time: 1.98s\n",
      "Epoch: 11, Batch: 1230/1676, Loss: 0.7317, Time: 1.98s\n",
      "Epoch: 11, Batch: 1240/1676, Loss: 0.3144, Time: 1.97s\n",
      "Epoch: 11, Batch: 1250/1676, Loss: 0.9166, Time: 1.97s\n",
      "Epoch: 11, Batch: 1260/1676, Loss: 0.8206, Time: 1.97s\n",
      "Epoch: 11, Batch: 1270/1676, Loss: 0.5536, Time: 1.99s\n",
      "Epoch: 11, Batch: 1280/1676, Loss: 1.0645, Time: 1.97s\n",
      "Epoch: 11, Batch: 1290/1676, Loss: 0.4931, Time: 1.97s\n",
      "Epoch: 11, Batch: 1300/1676, Loss: 1.0465, Time: 1.98s\n",
      "Epoch: 11, Batch: 1310/1676, Loss: 1.3472, Time: 1.98s\n",
      "Epoch: 11, Batch: 1320/1676, Loss: 0.3354, Time: 1.99s\n",
      "Epoch: 11, Batch: 1330/1676, Loss: 0.3954, Time: 1.98s\n",
      "Epoch: 11, Batch: 1340/1676, Loss: 0.4441, Time: 1.97s\n",
      "Epoch: 11, Batch: 1350/1676, Loss: 0.5755, Time: 1.97s\n",
      "Epoch: 11, Batch: 1360/1676, Loss: 0.9520, Time: 1.98s\n",
      "Epoch: 11, Batch: 1370/1676, Loss: 1.0099, Time: 1.98s\n",
      "Epoch: 11, Batch: 1380/1676, Loss: 1.0488, Time: 1.98s\n",
      "Epoch: 11, Batch: 1390/1676, Loss: 0.9551, Time: 1.97s\n",
      "Epoch: 11, Batch: 1400/1676, Loss: 0.8817, Time: 1.98s\n",
      "Epoch: 11, Batch: 1410/1676, Loss: 0.4859, Time: 1.97s\n",
      "Epoch: 11, Batch: 1420/1676, Loss: 0.7713, Time: 1.98s\n",
      "Epoch: 11, Batch: 1430/1676, Loss: 0.8647, Time: 1.98s\n",
      "Epoch: 11, Batch: 1440/1676, Loss: 0.6849, Time: 1.98s\n",
      "Epoch: 11, Batch: 1450/1676, Loss: 0.8823, Time: 1.98s\n",
      "Epoch: 11, Batch: 1460/1676, Loss: 0.6168, Time: 1.98s\n",
      "Epoch: 11, Batch: 1470/1676, Loss: 0.4361, Time: 1.98s\n",
      "Epoch: 11, Batch: 1480/1676, Loss: 1.0244, Time: 1.98s\n",
      "Epoch: 11, Batch: 1490/1676, Loss: 0.3065, Time: 1.98s\n",
      "Epoch: 11, Batch: 1500/1676, Loss: 1.1982, Time: 1.97s\n",
      "Epoch: 11, Batch: 1510/1676, Loss: 0.7726, Time: 1.98s\n",
      "Epoch: 11, Batch: 1520/1676, Loss: 0.5684, Time: 1.98s\n",
      "Epoch: 11, Batch: 1530/1676, Loss: 0.7081, Time: 1.98s\n",
      "Epoch: 11, Batch: 1540/1676, Loss: 0.7554, Time: 1.97s\n",
      "Epoch: 11, Batch: 1550/1676, Loss: 0.6313, Time: 1.98s\n",
      "Epoch: 11, Batch: 1560/1676, Loss: 0.3040, Time: 1.98s\n",
      "Epoch: 11, Batch: 1570/1676, Loss: 0.4770, Time: 1.97s\n",
      "Epoch: 11, Batch: 1580/1676, Loss: 0.4205, Time: 1.98s\n",
      "Epoch: 11, Batch: 1590/1676, Loss: 0.5276, Time: 1.98s\n",
      "Epoch: 11, Batch: 1600/1676, Loss: 0.6351, Time: 1.98s\n",
      "Epoch: 11, Batch: 1610/1676, Loss: 0.9512, Time: 1.97s\n",
      "Epoch: 11, Batch: 1620/1676, Loss: 0.4252, Time: 1.97s\n",
      "Epoch: 11, Batch: 1630/1676, Loss: 0.5425, Time: 1.97s\n",
      "Epoch: 11, Batch: 1640/1676, Loss: 0.3212, Time: 1.98s\n",
      "Epoch: 11, Batch: 1650/1676, Loss: 0.7444, Time: 1.99s\n",
      "Epoch: 11, Batch: 1660/1676, Loss: 0.7757, Time: 1.98s\n",
      "Epoch: 11, Batch: 1670/1676, Loss: 0.6446, Time: 1.97s\n",
      "Epoch 12/50: Train Loss: 0.7273, Val Loss: 0.7349, Val IoU: 0.5591, Val Dice: 0.5785\n",
      "Epoch: 12, Batch: 0/1676, Loss: 1.0096, Time: 35.60s\n",
      "Epoch: 12, Batch: 10/1676, Loss: 0.7340, Time: 2.00s\n",
      "Epoch: 12, Batch: 20/1676, Loss: 0.7169, Time: 1.97s\n",
      "Epoch: 12, Batch: 30/1676, Loss: 0.8344, Time: 1.97s\n",
      "Epoch: 12, Batch: 40/1676, Loss: 0.7534, Time: 1.97s\n",
      "Epoch: 12, Batch: 50/1676, Loss: 0.9261, Time: 1.98s\n",
      "Epoch: 12, Batch: 60/1676, Loss: 0.6922, Time: 1.97s\n",
      "Epoch: 12, Batch: 70/1676, Loss: 0.4842, Time: 1.97s\n",
      "Epoch: 12, Batch: 80/1676, Loss: 0.3237, Time: 1.97s\n",
      "Epoch: 12, Batch: 90/1676, Loss: 0.8866, Time: 1.98s\n",
      "Epoch: 12, Batch: 100/1676, Loss: 0.4405, Time: 1.99s\n",
      "Epoch: 12, Batch: 110/1676, Loss: 0.6215, Time: 1.98s\n",
      "Epoch: 12, Batch: 120/1676, Loss: 0.3301, Time: 1.99s\n",
      "Epoch: 12, Batch: 130/1676, Loss: 0.3608, Time: 1.98s\n",
      "Epoch: 12, Batch: 140/1676, Loss: 0.3801, Time: 1.98s\n",
      "Epoch: 12, Batch: 150/1676, Loss: 0.8715, Time: 1.98s\n",
      "Epoch: 12, Batch: 160/1676, Loss: 1.6360, Time: 1.99s\n",
      "Epoch: 12, Batch: 170/1676, Loss: 0.6036, Time: 1.98s\n",
      "Epoch: 12, Batch: 180/1676, Loss: 0.6277, Time: 2.00s\n",
      "Epoch: 12, Batch: 190/1676, Loss: 0.8737, Time: 1.98s\n",
      "Epoch: 12, Batch: 200/1676, Loss: 0.8545, Time: 1.98s\n",
      "Epoch: 12, Batch: 210/1676, Loss: 0.5501, Time: 1.99s\n",
      "Epoch: 12, Batch: 220/1676, Loss: 0.2066, Time: 1.99s\n",
      "Epoch: 12, Batch: 230/1676, Loss: 1.0853, Time: 1.99s\n",
      "Epoch: 12, Batch: 240/1676, Loss: 0.4527, Time: 1.98s\n",
      "Epoch: 12, Batch: 250/1676, Loss: 0.4444, Time: 1.99s\n",
      "Epoch: 12, Batch: 260/1676, Loss: 0.6827, Time: 1.98s\n",
      "Epoch: 12, Batch: 270/1676, Loss: 0.6807, Time: 1.99s\n",
      "Epoch: 12, Batch: 280/1676, Loss: 0.2974, Time: 1.99s\n",
      "Epoch: 12, Batch: 290/1676, Loss: 0.6799, Time: 1.99s\n",
      "Epoch: 12, Batch: 300/1676, Loss: 0.4154, Time: 1.99s\n",
      "Epoch: 12, Batch: 310/1676, Loss: 1.1630, Time: 1.98s\n",
      "Epoch: 12, Batch: 320/1676, Loss: 0.6589, Time: 1.99s\n",
      "Epoch: 12, Batch: 330/1676, Loss: 0.9573, Time: 1.99s\n",
      "Epoch: 12, Batch: 340/1676, Loss: 1.0379, Time: 2.00s\n",
      "Epoch: 12, Batch: 350/1676, Loss: 1.3537, Time: 1.99s\n",
      "Epoch: 12, Batch: 360/1676, Loss: 0.5756, Time: 1.99s\n",
      "Epoch: 12, Batch: 370/1676, Loss: 0.3896, Time: 1.99s\n",
      "Epoch: 12, Batch: 380/1676, Loss: 0.6986, Time: 1.99s\n",
      "Epoch: 12, Batch: 390/1676, Loss: 0.7443, Time: 2.00s\n",
      "Epoch: 12, Batch: 400/1676, Loss: 0.5827, Time: 1.99s\n",
      "Epoch: 12, Batch: 410/1676, Loss: 1.3102, Time: 2.01s\n",
      "Epoch: 12, Batch: 420/1676, Loss: 0.5865, Time: 1.97s\n",
      "Epoch: 12, Batch: 430/1676, Loss: 0.6972, Time: 1.97s\n",
      "Epoch: 12, Batch: 440/1676, Loss: 0.5639, Time: 1.97s\n",
      "Epoch: 12, Batch: 450/1676, Loss: 0.3678, Time: 1.97s\n",
      "Epoch: 12, Batch: 460/1676, Loss: 0.5988, Time: 1.97s\n",
      "Epoch: 12, Batch: 470/1676, Loss: 1.2898, Time: 1.97s\n",
      "Epoch: 12, Batch: 480/1676, Loss: 0.9911, Time: 1.97s\n",
      "Epoch: 12, Batch: 490/1676, Loss: 0.8686, Time: 1.97s\n",
      "Epoch: 12, Batch: 500/1676, Loss: 0.3421, Time: 1.97s\n",
      "Epoch: 12, Batch: 510/1676, Loss: 0.7054, Time: 1.97s\n",
      "Epoch: 12, Batch: 520/1676, Loss: 0.8118, Time: 1.97s\n",
      "Epoch: 12, Batch: 530/1676, Loss: 1.0797, Time: 1.97s\n",
      "Epoch: 12, Batch: 540/1676, Loss: 0.6276, Time: 1.97s\n",
      "Epoch: 12, Batch: 550/1676, Loss: 1.0500, Time: 1.97s\n",
      "Epoch: 12, Batch: 560/1676, Loss: 0.5717, Time: 1.97s\n",
      "Epoch: 12, Batch: 570/1676, Loss: 0.9401, Time: 1.96s\n",
      "Epoch: 12, Batch: 580/1676, Loss: 0.6877, Time: 1.97s\n",
      "Epoch: 12, Batch: 590/1676, Loss: 0.4737, Time: 1.97s\n",
      "Epoch: 12, Batch: 600/1676, Loss: 0.4762, Time: 1.97s\n",
      "Epoch: 12, Batch: 610/1676, Loss: 0.6121, Time: 1.97s\n",
      "Epoch: 12, Batch: 620/1676, Loss: 0.8461, Time: 1.97s\n",
      "Epoch: 12, Batch: 630/1676, Loss: 0.5248, Time: 1.97s\n",
      "Epoch: 12, Batch: 640/1676, Loss: 0.8941, Time: 1.97s\n",
      "Epoch: 12, Batch: 650/1676, Loss: 1.0417, Time: 1.97s\n",
      "Epoch: 12, Batch: 660/1676, Loss: 0.6816, Time: 1.98s\n",
      "Epoch: 12, Batch: 670/1676, Loss: 0.6372, Time: 1.97s\n",
      "Epoch: 12, Batch: 680/1676, Loss: 0.3868, Time: 1.97s\n",
      "Epoch: 12, Batch: 690/1676, Loss: 0.6181, Time: 1.97s\n",
      "Epoch: 12, Batch: 700/1676, Loss: 0.6171, Time: 1.98s\n",
      "Epoch: 12, Batch: 710/1676, Loss: 1.1903, Time: 1.97s\n",
      "Epoch: 12, Batch: 720/1676, Loss: 0.3335, Time: 1.97s\n",
      "Epoch: 12, Batch: 730/1676, Loss: 0.6562, Time: 1.98s\n",
      "Epoch: 12, Batch: 740/1676, Loss: 0.4741, Time: 1.97s\n",
      "Epoch: 12, Batch: 750/1676, Loss: 0.5713, Time: 1.97s\n",
      "Epoch: 12, Batch: 760/1676, Loss: 0.6073, Time: 1.98s\n",
      "Epoch: 12, Batch: 770/1676, Loss: 0.7458, Time: 1.98s\n",
      "Epoch: 12, Batch: 780/1676, Loss: 1.0702, Time: 1.97s\n",
      "Epoch: 12, Batch: 790/1676, Loss: 0.7968, Time: 1.97s\n",
      "Epoch: 12, Batch: 800/1676, Loss: 0.8385, Time: 1.97s\n",
      "Epoch: 12, Batch: 810/1676, Loss: 0.8866, Time: 1.98s\n",
      "Epoch: 12, Batch: 820/1676, Loss: 0.9820, Time: 1.98s\n",
      "Epoch: 12, Batch: 830/1676, Loss: 0.9296, Time: 1.97s\n",
      "Epoch: 12, Batch: 840/1676, Loss: 0.9073, Time: 1.97s\n",
      "Epoch: 12, Batch: 850/1676, Loss: 1.0139, Time: 1.97s\n",
      "Epoch: 12, Batch: 860/1676, Loss: 0.9463, Time: 1.97s\n",
      "Epoch: 12, Batch: 870/1676, Loss: 0.6506, Time: 1.97s\n",
      "Epoch: 12, Batch: 880/1676, Loss: 0.5387, Time: 1.97s\n",
      "Epoch: 12, Batch: 890/1676, Loss: 0.8461, Time: 1.98s\n",
      "Epoch: 12, Batch: 900/1676, Loss: 0.4708, Time: 1.98s\n",
      "Epoch: 12, Batch: 910/1676, Loss: 0.6295, Time: 1.97s\n",
      "Epoch: 12, Batch: 920/1676, Loss: 0.6772, Time: 1.98s\n",
      "Epoch: 12, Batch: 930/1676, Loss: 0.7695, Time: 1.98s\n",
      "Epoch: 12, Batch: 940/1676, Loss: 0.3144, Time: 1.98s\n",
      "Epoch: 12, Batch: 950/1676, Loss: 0.6254, Time: 1.98s\n",
      "Epoch: 12, Batch: 960/1676, Loss: 0.9749, Time: 1.97s\n",
      "Epoch: 12, Batch: 970/1676, Loss: 0.7731, Time: 1.97s\n",
      "Epoch: 12, Batch: 980/1676, Loss: 0.9564, Time: 1.97s\n",
      "Epoch: 12, Batch: 990/1676, Loss: 0.5518, Time: 1.97s\n",
      "Epoch: 12, Batch: 1000/1676, Loss: 0.3682, Time: 1.98s\n",
      "Epoch: 12, Batch: 1010/1676, Loss: 0.5923, Time: 1.97s\n",
      "Epoch: 12, Batch: 1020/1676, Loss: 0.3534, Time: 1.97s\n",
      "Epoch: 12, Batch: 1030/1676, Loss: 0.9592, Time: 1.98s\n",
      "Epoch: 12, Batch: 1040/1676, Loss: 0.8150, Time: 1.97s\n",
      "Epoch: 12, Batch: 1050/1676, Loss: 1.2945, Time: 1.97s\n",
      "Epoch: 12, Batch: 1060/1676, Loss: 0.7495, Time: 1.97s\n",
      "Epoch: 12, Batch: 1070/1676, Loss: 0.6321, Time: 1.98s\n",
      "Epoch: 12, Batch: 1080/1676, Loss: 1.3756, Time: 1.98s\n",
      "Epoch: 12, Batch: 1090/1676, Loss: 0.3265, Time: 1.97s\n",
      "Epoch: 12, Batch: 1100/1676, Loss: 0.5601, Time: 1.98s\n",
      "Epoch: 12, Batch: 1110/1676, Loss: 0.9888, Time: 1.97s\n",
      "Epoch: 12, Batch: 1120/1676, Loss: 0.8927, Time: 1.97s\n",
      "Epoch: 12, Batch: 1130/1676, Loss: 0.3048, Time: 1.97s\n",
      "Epoch: 12, Batch: 1140/1676, Loss: 1.0024, Time: 1.98s\n",
      "Epoch: 12, Batch: 1150/1676, Loss: 0.4393, Time: 1.97s\n",
      "Epoch: 12, Batch: 1160/1676, Loss: 0.3804, Time: 1.97s\n",
      "Epoch: 12, Batch: 1170/1676, Loss: 0.3256, Time: 1.97s\n",
      "Epoch: 12, Batch: 1180/1676, Loss: 0.5331, Time: 1.97s\n",
      "Epoch: 12, Batch: 1190/1676, Loss: 0.5462, Time: 1.98s\n",
      "Epoch: 12, Batch: 1200/1676, Loss: 0.3644, Time: 1.98s\n",
      "Epoch: 12, Batch: 1210/1676, Loss: 0.7482, Time: 1.97s\n",
      "Epoch: 12, Batch: 1220/1676, Loss: 0.9720, Time: 1.97s\n",
      "Epoch: 12, Batch: 1230/1676, Loss: 0.7903, Time: 1.98s\n",
      "Epoch: 12, Batch: 1240/1676, Loss: 1.7875, Time: 1.97s\n",
      "Epoch: 12, Batch: 1250/1676, Loss: 0.9235, Time: 1.97s\n",
      "Epoch: 12, Batch: 1260/1676, Loss: 1.0916, Time: 1.97s\n",
      "Epoch: 12, Batch: 1270/1676, Loss: 0.3803, Time: 1.98s\n",
      "Epoch: 12, Batch: 1280/1676, Loss: 0.5344, Time: 1.98s\n",
      "Epoch: 12, Batch: 1290/1676, Loss: 0.5039, Time: 1.97s\n",
      "Epoch: 12, Batch: 1300/1676, Loss: 1.0779, Time: 1.97s\n",
      "Epoch: 12, Batch: 1310/1676, Loss: 0.6150, Time: 1.97s\n",
      "Epoch: 12, Batch: 1320/1676, Loss: 0.5169, Time: 1.97s\n",
      "Epoch: 12, Batch: 1330/1676, Loss: 0.6281, Time: 1.97s\n",
      "Epoch: 12, Batch: 1340/1676, Loss: 0.5701, Time: 1.97s\n",
      "Epoch: 12, Batch: 1350/1676, Loss: 0.5101, Time: 1.97s\n",
      "Epoch: 12, Batch: 1360/1676, Loss: 1.2316, Time: 1.98s\n",
      "Epoch: 12, Batch: 1370/1676, Loss: 0.6776, Time: 1.97s\n",
      "Epoch: 12, Batch: 1380/1676, Loss: 0.5206, Time: 1.97s\n",
      "Epoch: 12, Batch: 1390/1676, Loss: 0.2956, Time: 1.97s\n",
      "Epoch: 12, Batch: 1400/1676, Loss: 0.5247, Time: 1.98s\n",
      "Epoch: 12, Batch: 1410/1676, Loss: 0.6610, Time: 1.98s\n",
      "Epoch: 12, Batch: 1420/1676, Loss: 0.4983, Time: 1.98s\n",
      "Epoch: 12, Batch: 1430/1676, Loss: 0.6719, Time: 1.97s\n",
      "Epoch: 12, Batch: 1440/1676, Loss: 0.7648, Time: 1.97s\n",
      "Epoch: 12, Batch: 1450/1676, Loss: 1.1983, Time: 1.98s\n",
      "Epoch: 12, Batch: 1460/1676, Loss: 1.3480, Time: 1.97s\n",
      "Epoch: 12, Batch: 1470/1676, Loss: 1.0027, Time: 1.98s\n",
      "Epoch: 12, Batch: 1480/1676, Loss: 0.7890, Time: 1.98s\n",
      "Epoch: 12, Batch: 1490/1676, Loss: 0.7092, Time: 1.98s\n",
      "Epoch: 12, Batch: 1500/1676, Loss: 0.8440, Time: 1.97s\n",
      "Epoch: 12, Batch: 1510/1676, Loss: 0.3475, Time: 1.97s\n",
      "Epoch: 12, Batch: 1520/1676, Loss: 0.9337, Time: 1.97s\n",
      "Epoch: 12, Batch: 1530/1676, Loss: 0.2777, Time: 1.98s\n",
      "Epoch: 12, Batch: 1540/1676, Loss: 0.8588, Time: 1.97s\n",
      "Epoch: 12, Batch: 1550/1676, Loss: 0.7324, Time: 1.98s\n",
      "Epoch: 12, Batch: 1560/1676, Loss: 1.2602, Time: 1.97s\n",
      "Epoch: 12, Batch: 1570/1676, Loss: 0.5175, Time: 1.97s\n",
      "Epoch: 12, Batch: 1580/1676, Loss: 0.3690, Time: 1.98s\n",
      "Epoch: 12, Batch: 1590/1676, Loss: 0.5325, Time: 1.98s\n",
      "Epoch: 12, Batch: 1600/1676, Loss: 0.7875, Time: 1.98s\n",
      "Epoch: 12, Batch: 1610/1676, Loss: 0.7195, Time: 1.98s\n",
      "Epoch: 12, Batch: 1620/1676, Loss: 0.4526, Time: 1.98s\n",
      "Epoch: 12, Batch: 1630/1676, Loss: 0.9025, Time: 1.97s\n",
      "Epoch: 12, Batch: 1640/1676, Loss: 0.3682, Time: 1.98s\n",
      "Epoch: 12, Batch: 1650/1676, Loss: 0.4035, Time: 1.98s\n",
      "Epoch: 12, Batch: 1660/1676, Loss: 0.8854, Time: 1.97s\n",
      "Epoch: 12, Batch: 1670/1676, Loss: 0.6407, Time: 1.98s\n",
      "Epoch 13/50: Train Loss: 0.7251, Val Loss: 0.8826, Val IoU: 0.4569, Val Dice: 0.4853\n",
      "Epoch: 13, Batch: 0/1676, Loss: 0.3306, Time: 36.15s\n",
      "Epoch: 13, Batch: 10/1676, Loss: 0.8560, Time: 1.98s\n",
      "Epoch: 13, Batch: 20/1676, Loss: 1.1371, Time: 1.93s\n",
      "Epoch: 13, Batch: 30/1676, Loss: 0.8776, Time: 1.94s\n",
      "Epoch: 13, Batch: 40/1676, Loss: 0.5653, Time: 1.94s\n",
      "Epoch: 13, Batch: 50/1676, Loss: 0.5578, Time: 1.94s\n",
      "Epoch: 13, Batch: 60/1676, Loss: 0.5184, Time: 1.94s\n",
      "Epoch: 13, Batch: 70/1676, Loss: 0.4178, Time: 1.94s\n",
      "Epoch: 13, Batch: 80/1676, Loss: 0.6667, Time: 1.94s\n",
      "Epoch: 13, Batch: 90/1676, Loss: 0.3790, Time: 1.94s\n",
      "Epoch: 13, Batch: 100/1676, Loss: 0.5352, Time: 1.95s\n",
      "Epoch: 13, Batch: 110/1676, Loss: 0.6224, Time: 1.95s\n",
      "Epoch: 13, Batch: 120/1676, Loss: 0.4166, Time: 1.95s\n",
      "Epoch: 13, Batch: 130/1676, Loss: 0.7823, Time: 1.95s\n",
      "Epoch: 13, Batch: 140/1676, Loss: 0.2802, Time: 1.94s\n",
      "Epoch: 13, Batch: 150/1676, Loss: 0.4115, Time: 1.95s\n",
      "Epoch: 13, Batch: 160/1676, Loss: 0.4006, Time: 1.95s\n",
      "Epoch: 13, Batch: 170/1676, Loss: 0.4642, Time: 1.95s\n",
      "Epoch: 13, Batch: 180/1676, Loss: 1.0009, Time: 1.96s\n",
      "Epoch: 13, Batch: 190/1676, Loss: 1.6067, Time: 1.95s\n",
      "Epoch: 13, Batch: 200/1676, Loss: 1.1625, Time: 1.96s\n",
      "Epoch: 13, Batch: 210/1676, Loss: 0.5425, Time: 1.95s\n",
      "Epoch: 13, Batch: 220/1676, Loss: 0.8332, Time: 1.96s\n",
      "Epoch: 13, Batch: 230/1676, Loss: 1.2449, Time: 1.95s\n",
      "Epoch: 13, Batch: 240/1676, Loss: 0.5074, Time: 1.96s\n",
      "Epoch: 13, Batch: 250/1676, Loss: 0.9488, Time: 1.96s\n",
      "Epoch: 13, Batch: 260/1676, Loss: 0.7660, Time: 1.96s\n",
      "Epoch: 13, Batch: 270/1676, Loss: 1.1055, Time: 1.96s\n",
      "Epoch: 13, Batch: 280/1676, Loss: 0.4050, Time: 1.96s\n",
      "Epoch: 13, Batch: 290/1676, Loss: 0.3487, Time: 1.96s\n",
      "Epoch: 13, Batch: 300/1676, Loss: 0.8650, Time: 1.96s\n",
      "Epoch: 13, Batch: 310/1676, Loss: 1.5742, Time: 1.96s\n",
      "Epoch: 13, Batch: 320/1676, Loss: 0.4720, Time: 1.96s\n",
      "Epoch: 13, Batch: 330/1676, Loss: 0.9223, Time: 1.96s\n",
      "Epoch: 13, Batch: 340/1676, Loss: 0.5377, Time: 1.96s\n",
      "Epoch: 13, Batch: 350/1676, Loss: 0.3726, Time: 1.97s\n",
      "Epoch: 13, Batch: 360/1676, Loss: 0.5184, Time: 1.96s\n",
      "Epoch: 13, Batch: 370/1676, Loss: 1.3950, Time: 1.97s\n",
      "Epoch: 13, Batch: 380/1676, Loss: 0.5728, Time: 1.96s\n",
      "Epoch: 13, Batch: 390/1676, Loss: 0.7416, Time: 1.97s\n",
      "Epoch: 13, Batch: 400/1676, Loss: 0.8865, Time: 1.97s\n",
      "Epoch: 13, Batch: 410/1676, Loss: 0.3373, Time: 1.96s\n",
      "Epoch: 13, Batch: 420/1676, Loss: 1.3745, Time: 1.96s\n",
      "Epoch: 13, Batch: 430/1676, Loss: 0.8966, Time: 1.97s\n",
      "Epoch: 13, Batch: 440/1676, Loss: 0.4025, Time: 1.97s\n",
      "Epoch: 13, Batch: 450/1676, Loss: 0.8400, Time: 1.97s\n",
      "Epoch: 13, Batch: 460/1676, Loss: 1.1976, Time: 1.96s\n",
      "Epoch: 13, Batch: 470/1676, Loss: 0.9167, Time: 1.97s\n",
      "Epoch: 13, Batch: 480/1676, Loss: 0.8295, Time: 1.97s\n",
      "Epoch: 13, Batch: 490/1676, Loss: 0.9724, Time: 1.96s\n",
      "Epoch: 13, Batch: 500/1676, Loss: 0.5526, Time: 1.97s\n",
      "Epoch: 13, Batch: 510/1676, Loss: 0.5134, Time: 1.97s\n",
      "Epoch: 13, Batch: 520/1676, Loss: 0.5064, Time: 1.97s\n",
      "Epoch: 13, Batch: 530/1676, Loss: 0.7078, Time: 1.97s\n",
      "Epoch: 13, Batch: 540/1676, Loss: 0.7659, Time: 1.96s\n",
      "Epoch: 13, Batch: 550/1676, Loss: 0.6845, Time: 1.97s\n",
      "Epoch: 13, Batch: 560/1676, Loss: 0.9703, Time: 1.97s\n",
      "Epoch: 13, Batch: 570/1676, Loss: 1.0279, Time: 1.97s\n",
      "Epoch: 13, Batch: 580/1676, Loss: 0.3314, Time: 1.97s\n",
      "Epoch: 13, Batch: 590/1676, Loss: 0.6593, Time: 1.97s\n",
      "Epoch: 13, Batch: 600/1676, Loss: 0.8520, Time: 1.97s\n",
      "Epoch: 13, Batch: 610/1676, Loss: 0.3885, Time: 1.97s\n",
      "Epoch: 13, Batch: 620/1676, Loss: 0.7181, Time: 1.97s\n",
      "Epoch: 13, Batch: 630/1676, Loss: 0.3478, Time: 1.97s\n",
      "Epoch: 13, Batch: 640/1676, Loss: 0.7741, Time: 1.98s\n",
      "Epoch: 13, Batch: 650/1676, Loss: 0.8077, Time: 1.97s\n",
      "Epoch: 13, Batch: 660/1676, Loss: 1.0974, Time: 1.97s\n",
      "Epoch: 13, Batch: 670/1676, Loss: 0.4254, Time: 1.97s\n",
      "Epoch: 13, Batch: 680/1676, Loss: 0.5619, Time: 1.98s\n",
      "Epoch: 13, Batch: 690/1676, Loss: 0.4497, Time: 1.97s\n",
      "Epoch: 13, Batch: 700/1676, Loss: 0.6768, Time: 1.97s\n",
      "Epoch: 13, Batch: 710/1676, Loss: 0.4111, Time: 1.97s\n",
      "Epoch: 13, Batch: 720/1676, Loss: 1.1042, Time: 1.97s\n",
      "Epoch: 13, Batch: 730/1676, Loss: 1.3437, Time: 1.97s\n",
      "Epoch: 13, Batch: 740/1676, Loss: 1.1886, Time: 1.97s\n",
      "Epoch: 13, Batch: 750/1676, Loss: 0.8171, Time: 1.97s\n",
      "Epoch: 13, Batch: 760/1676, Loss: 0.3600, Time: 1.98s\n",
      "Epoch: 13, Batch: 770/1676, Loss: 0.4513, Time: 1.97s\n",
      "Epoch: 13, Batch: 780/1676, Loss: 0.2791, Time: 1.97s\n",
      "Epoch: 13, Batch: 790/1676, Loss: 0.5444, Time: 1.97s\n",
      "Epoch: 13, Batch: 800/1676, Loss: 1.3317, Time: 1.98s\n",
      "Epoch: 13, Batch: 810/1676, Loss: 0.7126, Time: 1.97s\n",
      "Epoch: 13, Batch: 820/1676, Loss: 0.4148, Time: 1.97s\n",
      "Epoch: 13, Batch: 830/1676, Loss: 0.8491, Time: 1.97s\n",
      "Epoch: 13, Batch: 840/1676, Loss: 0.2722, Time: 1.97s\n",
      "Epoch: 13, Batch: 850/1676, Loss: 0.6877, Time: 1.97s\n",
      "Epoch: 13, Batch: 860/1676, Loss: 0.6052, Time: 1.97s\n",
      "Epoch: 13, Batch: 870/1676, Loss: 0.7788, Time: 1.98s\n",
      "Epoch: 13, Batch: 880/1676, Loss: 0.8053, Time: 1.97s\n",
      "Epoch: 13, Batch: 890/1676, Loss: 0.8863, Time: 1.98s\n",
      "Epoch: 13, Batch: 900/1676, Loss: 0.4450, Time: 1.97s\n",
      "Epoch: 13, Batch: 910/1676, Loss: 0.6479, Time: 1.97s\n",
      "Epoch: 13, Batch: 920/1676, Loss: 0.7663, Time: 1.98s\n",
      "Epoch: 13, Batch: 930/1676, Loss: 0.2714, Time: 1.97s\n",
      "Epoch: 13, Batch: 940/1676, Loss: 0.6039, Time: 1.98s\n",
      "Epoch: 13, Batch: 950/1676, Loss: 0.4737, Time: 1.97s\n",
      "Epoch: 13, Batch: 960/1676, Loss: 0.5981, Time: 1.97s\n",
      "Epoch: 13, Batch: 970/1676, Loss: 0.7056, Time: 1.98s\n",
      "Epoch: 13, Batch: 980/1676, Loss: 0.8876, Time: 1.97s\n",
      "Epoch: 13, Batch: 990/1676, Loss: 1.0705, Time: 1.97s\n",
      "Epoch: 13, Batch: 1000/1676, Loss: 1.0459, Time: 1.98s\n",
      "Epoch: 13, Batch: 1010/1676, Loss: 0.6754, Time: 1.97s\n",
      "Epoch: 13, Batch: 1020/1676, Loss: 0.2936, Time: 1.97s\n",
      "Epoch: 13, Batch: 1030/1676, Loss: 0.4640, Time: 1.98s\n",
      "Epoch: 13, Batch: 1040/1676, Loss: 0.7140, Time: 1.97s\n",
      "Epoch: 13, Batch: 1050/1676, Loss: 0.7235, Time: 1.97s\n",
      "Epoch: 13, Batch: 1060/1676, Loss: 0.8806, Time: 1.98s\n",
      "Epoch: 13, Batch: 1070/1676, Loss: 0.6194, Time: 1.97s\n",
      "Epoch: 13, Batch: 1080/1676, Loss: 0.8115, Time: 1.98s\n",
      "Epoch: 13, Batch: 1090/1676, Loss: 0.6172, Time: 1.97s\n",
      "Epoch: 13, Batch: 1100/1676, Loss: 0.7092, Time: 1.97s\n",
      "Epoch: 13, Batch: 1110/1676, Loss: 0.8134, Time: 1.98s\n",
      "Epoch: 13, Batch: 1120/1676, Loss: 0.4709, Time: 1.98s\n",
      "Epoch: 13, Batch: 1130/1676, Loss: 0.9567, Time: 1.97s\n",
      "Epoch: 13, Batch: 1140/1676, Loss: 0.5489, Time: 1.97s\n",
      "Epoch: 13, Batch: 1150/1676, Loss: 0.7573, Time: 1.97s\n",
      "Epoch: 13, Batch: 1160/1676, Loss: 0.8718, Time: 1.97s\n",
      "Epoch: 13, Batch: 1170/1676, Loss: 0.7869, Time: 1.97s\n",
      "Epoch: 13, Batch: 1180/1676, Loss: 1.1154, Time: 1.98s\n",
      "Epoch: 13, Batch: 1190/1676, Loss: 0.9911, Time: 1.98s\n",
      "Epoch: 13, Batch: 1200/1676, Loss: 0.7063, Time: 1.98s\n",
      "Epoch: 13, Batch: 1210/1676, Loss: 0.6759, Time: 1.97s\n",
      "Epoch: 13, Batch: 1220/1676, Loss: 1.0235, Time: 1.98s\n",
      "Epoch: 13, Batch: 1230/1676, Loss: 1.2864, Time: 1.98s\n",
      "Epoch: 13, Batch: 1240/1676, Loss: 0.7756, Time: 1.98s\n",
      "Epoch: 13, Batch: 1250/1676, Loss: 0.8008, Time: 1.97s\n",
      "Epoch: 13, Batch: 1260/1676, Loss: 0.4481, Time: 1.98s\n",
      "Epoch: 13, Batch: 1270/1676, Loss: 1.1167, Time: 1.98s\n",
      "Epoch: 13, Batch: 1280/1676, Loss: 1.1708, Time: 1.97s\n",
      "Epoch: 13, Batch: 1290/1676, Loss: 0.9985, Time: 1.97s\n",
      "Epoch: 13, Batch: 1300/1676, Loss: 0.8370, Time: 1.97s\n",
      "Epoch: 13, Batch: 1310/1676, Loss: 0.4103, Time: 1.97s\n",
      "Epoch: 13, Batch: 1320/1676, Loss: 0.6423, Time: 1.97s\n",
      "Epoch: 13, Batch: 1330/1676, Loss: 0.4235, Time: 1.97s\n",
      "Epoch: 13, Batch: 1340/1676, Loss: 0.5241, Time: 1.97s\n",
      "Epoch: 13, Batch: 1350/1676, Loss: 0.8483, Time: 1.97s\n",
      "Epoch: 13, Batch: 1360/1676, Loss: 0.8075, Time: 1.98s\n",
      "Epoch: 13, Batch: 1370/1676, Loss: 0.5813, Time: 1.97s\n",
      "Epoch: 13, Batch: 1380/1676, Loss: 0.5922, Time: 1.97s\n",
      "Epoch: 13, Batch: 1390/1676, Loss: 1.0736, Time: 1.97s\n",
      "Epoch: 13, Batch: 1400/1676, Loss: 0.9647, Time: 1.97s\n",
      "Epoch: 13, Batch: 1410/1676, Loss: 0.8854, Time: 1.97s\n",
      "Epoch: 13, Batch: 1420/1676, Loss: 1.0565, Time: 1.97s\n",
      "Epoch: 13, Batch: 1430/1676, Loss: 1.1056, Time: 1.97s\n",
      "Epoch: 13, Batch: 1440/1676, Loss: 0.3381, Time: 1.97s\n",
      "Epoch: 13, Batch: 1450/1676, Loss: 1.0363, Time: 1.97s\n",
      "Epoch: 13, Batch: 1460/1676, Loss: 1.3845, Time: 1.97s\n",
      "Epoch: 13, Batch: 1470/1676, Loss: 0.9239, Time: 1.98s\n",
      "Epoch: 13, Batch: 1480/1676, Loss: 0.6203, Time: 1.98s\n",
      "Epoch: 13, Batch: 1490/1676, Loss: 0.9477, Time: 1.97s\n",
      "Epoch: 13, Batch: 1500/1676, Loss: 0.8769, Time: 1.98s\n",
      "Epoch: 13, Batch: 1510/1676, Loss: 0.7903, Time: 1.97s\n",
      "Epoch: 13, Batch: 1520/1676, Loss: 0.7180, Time: 1.98s\n",
      "Epoch: 13, Batch: 1530/1676, Loss: 1.0102, Time: 1.97s\n",
      "Epoch: 13, Batch: 1540/1676, Loss: 0.9509, Time: 1.97s\n",
      "Epoch: 13, Batch: 1550/1676, Loss: 0.3819, Time: 1.98s\n",
      "Epoch: 13, Batch: 1560/1676, Loss: 0.5877, Time: 1.97s\n",
      "Epoch: 13, Batch: 1570/1676, Loss: 0.8889, Time: 1.97s\n",
      "Epoch: 13, Batch: 1580/1676, Loss: 1.0929, Time: 1.97s\n",
      "Epoch: 13, Batch: 1590/1676, Loss: 1.2141, Time: 1.97s\n",
      "Epoch: 13, Batch: 1600/1676, Loss: 1.0512, Time: 1.97s\n",
      "Epoch: 13, Batch: 1610/1676, Loss: 0.6121, Time: 1.98s\n",
      "Epoch: 13, Batch: 1620/1676, Loss: 0.9613, Time: 1.97s\n",
      "Epoch: 13, Batch: 1630/1676, Loss: 0.5576, Time: 1.97s\n",
      "Epoch: 13, Batch: 1640/1676, Loss: 0.3389, Time: 1.98s\n",
      "Epoch: 13, Batch: 1650/1676, Loss: 0.2481, Time: 1.97s\n",
      "Epoch: 13, Batch: 1660/1676, Loss: 0.6126, Time: 1.97s\n",
      "Epoch: 13, Batch: 1670/1676, Loss: 1.0885, Time: 1.98s\n",
      "Epoch 14/50: Train Loss: 0.7238, Val Loss: 0.7747, Val IoU: 0.5289, Val Dice: 0.5518\n",
      "Epoch: 14, Batch: 0/1676, Loss: 0.6572, Time: 35.92s\n",
      "Epoch: 14, Batch: 10/1676, Loss: 1.2612, Time: 1.98s\n",
      "Epoch: 14, Batch: 20/1676, Loss: 0.3959, Time: 1.93s\n",
      "Epoch: 14, Batch: 30/1676, Loss: 0.7171, Time: 1.93s\n",
      "Epoch: 14, Batch: 40/1676, Loss: 0.8173, Time: 1.93s\n",
      "Epoch: 14, Batch: 50/1676, Loss: 0.4793, Time: 1.95s\n",
      "Epoch: 14, Batch: 60/1676, Loss: 0.5401, Time: 1.93s\n",
      "Epoch: 14, Batch: 70/1676, Loss: 0.6154, Time: 1.94s\n",
      "Epoch: 14, Batch: 80/1676, Loss: 0.9579, Time: 1.93s\n",
      "Epoch: 14, Batch: 90/1676, Loss: 1.0139, Time: 1.95s\n",
      "Epoch: 14, Batch: 100/1676, Loss: 0.5753, Time: 1.94s\n",
      "Epoch: 14, Batch: 110/1676, Loss: 0.9120, Time: 1.95s\n",
      "Epoch: 14, Batch: 120/1676, Loss: 1.1944, Time: 1.94s\n",
      "Epoch: 14, Batch: 130/1676, Loss: 0.4294, Time: 1.94s\n",
      "Epoch: 14, Batch: 140/1676, Loss: 1.1139, Time: 1.95s\n",
      "Epoch: 14, Batch: 150/1676, Loss: 0.4354, Time: 1.95s\n",
      "Epoch: 14, Batch: 160/1676, Loss: 1.0079, Time: 1.95s\n",
      "Epoch: 14, Batch: 170/1676, Loss: 0.5583, Time: 1.95s\n",
      "Epoch: 14, Batch: 180/1676, Loss: 0.3428, Time: 1.95s\n",
      "Epoch: 14, Batch: 190/1676, Loss: 0.5460, Time: 1.96s\n",
      "Epoch: 14, Batch: 200/1676, Loss: 0.3412, Time: 1.96s\n",
      "Epoch: 14, Batch: 210/1676, Loss: 0.9723, Time: 1.95s\n",
      "Epoch: 14, Batch: 220/1676, Loss: 1.1266, Time: 1.95s\n",
      "Epoch: 14, Batch: 230/1676, Loss: 0.3716, Time: 1.95s\n",
      "Epoch: 14, Batch: 240/1676, Loss: 0.6001, Time: 1.95s\n",
      "Epoch: 14, Batch: 250/1676, Loss: 0.7602, Time: 1.95s\n",
      "Epoch: 14, Batch: 260/1676, Loss: 0.9083, Time: 1.95s\n",
      "Epoch: 14, Batch: 270/1676, Loss: 1.3739, Time: 1.95s\n",
      "Epoch: 14, Batch: 280/1676, Loss: 0.7580, Time: 1.96s\n",
      "Epoch: 14, Batch: 290/1676, Loss: 0.4919, Time: 1.96s\n",
      "Epoch: 14, Batch: 300/1676, Loss: 0.8984, Time: 1.95s\n",
      "Epoch: 14, Batch: 310/1676, Loss: 0.9162, Time: 1.96s\n",
      "Epoch: 14, Batch: 320/1676, Loss: 0.3419, Time: 1.97s\n",
      "Epoch: 14, Batch: 330/1676, Loss: 0.8085, Time: 1.96s\n",
      "Epoch: 14, Batch: 340/1676, Loss: 0.7870, Time: 1.97s\n",
      "Epoch: 14, Batch: 350/1676, Loss: 0.4028, Time: 1.96s\n",
      "Epoch: 14, Batch: 360/1676, Loss: 0.9883, Time: 1.96s\n",
      "Epoch: 14, Batch: 370/1676, Loss: 0.6174, Time: 1.96s\n",
      "Epoch: 14, Batch: 380/1676, Loss: 0.4283, Time: 1.96s\n",
      "Epoch: 14, Batch: 390/1676, Loss: 0.4637, Time: 1.96s\n",
      "Epoch: 14, Batch: 400/1676, Loss: 0.3250, Time: 1.96s\n",
      "Epoch: 14, Batch: 410/1676, Loss: 0.4767, Time: 1.96s\n",
      "Epoch: 14, Batch: 420/1676, Loss: 0.4406, Time: 1.97s\n",
      "Epoch: 14, Batch: 430/1676, Loss: 0.8132, Time: 1.96s\n",
      "Epoch: 14, Batch: 440/1676, Loss: 0.5211, Time: 1.96s\n",
      "Epoch: 14, Batch: 450/1676, Loss: 0.4255, Time: 1.97s\n",
      "Epoch: 14, Batch: 460/1676, Loss: 0.8134, Time: 1.96s\n",
      "Epoch: 14, Batch: 470/1676, Loss: 0.2223, Time: 1.96s\n",
      "Epoch: 14, Batch: 480/1676, Loss: 0.3838, Time: 1.96s\n",
      "Epoch: 14, Batch: 490/1676, Loss: 0.4691, Time: 1.97s\n",
      "Epoch: 14, Batch: 500/1676, Loss: 0.4886, Time: 1.97s\n",
      "Epoch: 14, Batch: 510/1676, Loss: 0.7829, Time: 1.97s\n",
      "Epoch: 14, Batch: 520/1676, Loss: 0.9319, Time: 1.97s\n",
      "Epoch: 14, Batch: 530/1676, Loss: 0.5455, Time: 1.96s\n",
      "Epoch: 14, Batch: 540/1676, Loss: 0.8655, Time: 1.96s\n",
      "Epoch: 14, Batch: 550/1676, Loss: 0.5318, Time: 1.96s\n",
      "Epoch: 14, Batch: 560/1676, Loss: 0.8971, Time: 1.97s\n",
      "Epoch: 14, Batch: 570/1676, Loss: 0.4249, Time: 1.97s\n",
      "Epoch: 14, Batch: 580/1676, Loss: 0.5847, Time: 1.96s\n",
      "Epoch: 14, Batch: 590/1676, Loss: 0.6255, Time: 1.97s\n",
      "Epoch: 14, Batch: 600/1676, Loss: 0.9689, Time: 1.96s\n",
      "Epoch: 14, Batch: 610/1676, Loss: 1.0987, Time: 1.96s\n",
      "Epoch: 14, Batch: 620/1676, Loss: 0.5793, Time: 1.96s\n",
      "Epoch: 14, Batch: 630/1676, Loss: 0.8715, Time: 1.96s\n",
      "Epoch: 14, Batch: 640/1676, Loss: 0.5452, Time: 1.97s\n",
      "Epoch: 14, Batch: 650/1676, Loss: 0.5063, Time: 1.97s\n",
      "Epoch: 14, Batch: 660/1676, Loss: 0.6715, Time: 1.97s\n",
      "Epoch: 14, Batch: 670/1676, Loss: 0.7217, Time: 1.97s\n",
      "Epoch: 14, Batch: 680/1676, Loss: 0.6927, Time: 1.97s\n",
      "Epoch: 14, Batch: 690/1676, Loss: 1.1429, Time: 1.96s\n",
      "Epoch: 14, Batch: 700/1676, Loss: 0.7748, Time: 1.97s\n",
      "Epoch: 14, Batch: 710/1676, Loss: 0.4360, Time: 1.96s\n",
      "Epoch: 14, Batch: 720/1676, Loss: 0.4326, Time: 1.96s\n",
      "Epoch: 14, Batch: 730/1676, Loss: 0.5940, Time: 1.98s\n",
      "Epoch: 14, Batch: 740/1676, Loss: 0.7908, Time: 1.98s\n",
      "Epoch: 14, Batch: 750/1676, Loss: 1.2361, Time: 1.97s\n",
      "Epoch: 14, Batch: 760/1676, Loss: 0.6202, Time: 1.97s\n",
      "Epoch: 14, Batch: 770/1676, Loss: 0.5269, Time: 1.97s\n",
      "Epoch: 14, Batch: 780/1676, Loss: 0.6122, Time: 1.97s\n",
      "Epoch: 14, Batch: 790/1676, Loss: 0.9626, Time: 1.97s\n",
      "Epoch: 14, Batch: 800/1676, Loss: 0.7015, Time: 1.96s\n",
      "Epoch: 14, Batch: 810/1676, Loss: 0.9274, Time: 1.97s\n",
      "Epoch: 14, Batch: 820/1676, Loss: 0.6885, Time: 1.97s\n",
      "Epoch: 14, Batch: 830/1676, Loss: 0.5269, Time: 1.96s\n",
      "Epoch: 14, Batch: 840/1676, Loss: 0.4763, Time: 1.97s\n",
      "Epoch: 14, Batch: 850/1676, Loss: 0.4947, Time: 1.97s\n",
      "Epoch: 14, Batch: 860/1676, Loss: 0.4642, Time: 1.97s\n",
      "Epoch: 14, Batch: 870/1676, Loss: 0.6374, Time: 1.96s\n",
      "Epoch: 14, Batch: 880/1676, Loss: 0.7727, Time: 1.97s\n",
      "Epoch: 14, Batch: 890/1676, Loss: 0.9156, Time: 1.97s\n",
      "Epoch: 14, Batch: 900/1676, Loss: 0.8755, Time: 1.98s\n",
      "Epoch: 14, Batch: 910/1676, Loss: 0.5339, Time: 1.97s\n",
      "Epoch: 14, Batch: 920/1676, Loss: 0.3264, Time: 1.97s\n",
      "Epoch: 14, Batch: 930/1676, Loss: 0.5476, Time: 1.97s\n",
      "Epoch: 14, Batch: 940/1676, Loss: 0.6383, Time: 1.97s\n",
      "Epoch: 14, Batch: 950/1676, Loss: 0.7590, Time: 1.97s\n",
      "Epoch: 14, Batch: 960/1676, Loss: 0.2490, Time: 1.97s\n",
      "Epoch: 14, Batch: 970/1676, Loss: 0.9517, Time: 1.97s\n",
      "Epoch: 14, Batch: 980/1676, Loss: 0.2771, Time: 1.98s\n",
      "Epoch: 14, Batch: 990/1676, Loss: 0.7763, Time: 1.96s\n",
      "Epoch: 14, Batch: 1000/1676, Loss: 0.4729, Time: 1.97s\n",
      "Epoch: 14, Batch: 1010/1676, Loss: 0.4700, Time: 1.98s\n",
      "Epoch: 14, Batch: 1020/1676, Loss: 0.5138, Time: 1.97s\n",
      "Epoch: 14, Batch: 1030/1676, Loss: 0.2922, Time: 1.97s\n",
      "Epoch: 14, Batch: 1040/1676, Loss: 0.8153, Time: 1.97s\n",
      "Epoch: 14, Batch: 1050/1676, Loss: 0.6356, Time: 1.97s\n",
      "Epoch: 14, Batch: 1060/1676, Loss: 0.3452, Time: 1.98s\n",
      "Epoch: 14, Batch: 1070/1676, Loss: 0.8147, Time: 1.97s\n",
      "Epoch: 14, Batch: 1080/1676, Loss: 0.5675, Time: 1.97s\n",
      "Epoch: 14, Batch: 1090/1676, Loss: 1.0373, Time: 1.98s\n",
      "Epoch: 14, Batch: 1100/1676, Loss: 1.0273, Time: 1.98s\n",
      "Epoch: 14, Batch: 1110/1676, Loss: 0.7565, Time: 1.97s\n",
      "Epoch: 14, Batch: 1120/1676, Loss: 0.8487, Time: 1.97s\n",
      "Epoch: 14, Batch: 1130/1676, Loss: 0.4813, Time: 1.97s\n",
      "Epoch: 14, Batch: 1140/1676, Loss: 0.3630, Time: 1.97s\n",
      "Epoch: 14, Batch: 1150/1676, Loss: 1.0471, Time: 1.97s\n",
      "Epoch: 14, Batch: 1160/1676, Loss: 0.3505, Time: 1.97s\n",
      "Epoch: 14, Batch: 1170/1676, Loss: 0.7766, Time: 1.97s\n",
      "Epoch: 14, Batch: 1180/1676, Loss: 0.6665, Time: 1.97s\n",
      "Epoch: 14, Batch: 1190/1676, Loss: 0.3746, Time: 1.97s\n",
      "Epoch: 14, Batch: 1200/1676, Loss: 1.2475, Time: 1.97s\n",
      "Epoch: 14, Batch: 1210/1676, Loss: 1.3085, Time: 1.97s\n",
      "Epoch: 14, Batch: 1220/1676, Loss: 0.4028, Time: 1.97s\n",
      "Epoch: 14, Batch: 1230/1676, Loss: 1.0652, Time: 1.97s\n",
      "Epoch: 14, Batch: 1240/1676, Loss: 0.6739, Time: 1.97s\n",
      "Epoch: 14, Batch: 1250/1676, Loss: 0.5879, Time: 1.97s\n",
      "Epoch: 14, Batch: 1260/1676, Loss: 1.0837, Time: 1.97s\n",
      "Epoch: 14, Batch: 1270/1676, Loss: 0.4059, Time: 1.97s\n",
      "Epoch: 14, Batch: 1280/1676, Loss: 0.9423, Time: 1.97s\n",
      "Epoch: 14, Batch: 1290/1676, Loss: 0.7084, Time: 1.97s\n",
      "Epoch: 14, Batch: 1300/1676, Loss: 0.3316, Time: 1.97s\n",
      "Epoch: 14, Batch: 1310/1676, Loss: 0.8007, Time: 1.98s\n",
      "Epoch: 14, Batch: 1320/1676, Loss: 0.3230, Time: 1.96s\n",
      "Epoch: 14, Batch: 1330/1676, Loss: 0.4595, Time: 1.97s\n",
      "Epoch: 14, Batch: 1340/1676, Loss: 1.4492, Time: 1.97s\n",
      "Epoch: 14, Batch: 1350/1676, Loss: 1.2192, Time: 1.97s\n",
      "Epoch: 14, Batch: 1360/1676, Loss: 0.6119, Time: 1.97s\n",
      "Epoch: 14, Batch: 1370/1676, Loss: 0.8544, Time: 1.98s\n",
      "Epoch: 14, Batch: 1380/1676, Loss: 0.5223, Time: 1.97s\n",
      "Epoch: 14, Batch: 1390/1676, Loss: 0.9734, Time: 1.97s\n",
      "Epoch: 14, Batch: 1400/1676, Loss: 0.9832, Time: 1.98s\n",
      "Epoch: 14, Batch: 1410/1676, Loss: 0.6558, Time: 1.97s\n",
      "Epoch: 14, Batch: 1420/1676, Loss: 0.4820, Time: 1.98s\n",
      "Epoch: 14, Batch: 1430/1676, Loss: 0.6407, Time: 1.97s\n",
      "Epoch: 14, Batch: 1440/1676, Loss: 0.6900, Time: 1.97s\n",
      "Epoch: 14, Batch: 1450/1676, Loss: 0.7771, Time: 1.97s\n",
      "Epoch: 14, Batch: 1460/1676, Loss: 0.6430, Time: 1.97s\n",
      "Epoch: 14, Batch: 1470/1676, Loss: 0.3408, Time: 1.98s\n",
      "Epoch: 14, Batch: 1480/1676, Loss: 0.7966, Time: 1.97s\n",
      "Epoch: 14, Batch: 1490/1676, Loss: 1.0955, Time: 1.97s\n",
      "Epoch: 14, Batch: 1500/1676, Loss: 0.7465, Time: 1.97s\n",
      "Epoch: 14, Batch: 1510/1676, Loss: 0.3088, Time: 1.97s\n",
      "Epoch: 14, Batch: 1520/1676, Loss: 1.0081, Time: 1.97s\n",
      "Epoch: 14, Batch: 1530/1676, Loss: 0.4794, Time: 1.97s\n",
      "Epoch: 14, Batch: 1540/1676, Loss: 0.4589, Time: 1.97s\n",
      "Epoch: 14, Batch: 1550/1676, Loss: 0.5072, Time: 1.97s\n",
      "Epoch: 14, Batch: 1560/1676, Loss: 0.6290, Time: 1.97s\n",
      "Epoch: 14, Batch: 1570/1676, Loss: 1.2238, Time: 1.97s\n",
      "Epoch: 14, Batch: 1580/1676, Loss: 0.4858, Time: 1.98s\n",
      "Epoch: 14, Batch: 1590/1676, Loss: 1.1479, Time: 1.97s\n",
      "Epoch: 14, Batch: 1600/1676, Loss: 0.8943, Time: 1.97s\n",
      "Epoch: 14, Batch: 1610/1676, Loss: 0.8002, Time: 1.97s\n",
      "Epoch: 14, Batch: 1620/1676, Loss: 0.3699, Time: 1.98s\n",
      "Epoch: 14, Batch: 1630/1676, Loss: 0.5744, Time: 1.98s\n",
      "Epoch: 14, Batch: 1640/1676, Loss: 0.9552, Time: 1.97s\n",
      "Epoch: 14, Batch: 1650/1676, Loss: 1.1082, Time: 1.97s\n",
      "Epoch: 14, Batch: 1660/1676, Loss: 1.0216, Time: 1.97s\n",
      "Epoch: 14, Batch: 1670/1676, Loss: 0.5506, Time: 1.97s\n",
      "Epoch 15/50: Train Loss: 0.7140, Val Loss: 0.7126, Val IoU: 0.5617, Val Dice: 0.5813\n",
      "Saving best model with IoU: 0.5617\n",
      "Epoch: 15, Batch: 0/1676, Loss: 0.5417, Time: 35.85s\n",
      "Epoch: 15, Batch: 10/1676, Loss: 1.1088, Time: 1.99s\n",
      "Epoch: 15, Batch: 20/1676, Loss: 0.5716, Time: 1.93s\n",
      "Epoch: 15, Batch: 30/1676, Loss: 0.7022, Time: 1.94s\n",
      "Epoch: 15, Batch: 40/1676, Loss: 0.8129, Time: 1.94s\n",
      "Epoch: 15, Batch: 50/1676, Loss: 0.7067, Time: 1.94s\n",
      "Epoch: 15, Batch: 60/1676, Loss: 0.5644, Time: 1.93s\n",
      "Epoch: 15, Batch: 70/1676, Loss: 1.2143, Time: 1.94s\n",
      "Epoch: 15, Batch: 80/1676, Loss: 0.8404, Time: 1.94s\n",
      "Epoch: 15, Batch: 90/1676, Loss: 0.6900, Time: 1.94s\n",
      "Epoch: 15, Batch: 100/1676, Loss: 0.7283, Time: 1.94s\n",
      "Epoch: 15, Batch: 110/1676, Loss: 0.6176, Time: 1.94s\n",
      "Epoch: 15, Batch: 120/1676, Loss: 0.2501, Time: 1.94s\n",
      "Epoch: 15, Batch: 130/1676, Loss: 0.9181, Time: 1.94s\n",
      "Epoch: 15, Batch: 140/1676, Loss: 1.1344, Time: 1.94s\n",
      "Epoch: 15, Batch: 150/1676, Loss: 0.3119, Time: 1.94s\n",
      "Epoch: 15, Batch: 160/1676, Loss: 0.6625, Time: 1.94s\n",
      "Epoch: 15, Batch: 170/1676, Loss: 0.4575, Time: 1.95s\n",
      "Epoch: 15, Batch: 180/1676, Loss: 0.6545, Time: 1.94s\n",
      "Epoch: 15, Batch: 190/1676, Loss: 0.5742, Time: 1.95s\n",
      "Epoch: 15, Batch: 200/1676, Loss: 0.6705, Time: 1.94s\n",
      "Epoch: 15, Batch: 210/1676, Loss: 0.8614, Time: 1.95s\n",
      "Epoch: 15, Batch: 220/1676, Loss: 0.8891, Time: 1.95s\n",
      "Epoch: 15, Batch: 230/1676, Loss: 0.3815, Time: 1.95s\n",
      "Epoch: 15, Batch: 240/1676, Loss: 0.8804, Time: 1.95s\n",
      "Epoch: 15, Batch: 250/1676, Loss: 0.7409, Time: 1.96s\n",
      "Epoch: 15, Batch: 260/1676, Loss: 0.8896, Time: 1.95s\n",
      "Epoch: 15, Batch: 270/1676, Loss: 0.9891, Time: 1.96s\n",
      "Epoch: 15, Batch: 280/1676, Loss: 0.5931, Time: 1.96s\n",
      "Epoch: 15, Batch: 290/1676, Loss: 0.8021, Time: 1.95s\n",
      "Epoch: 15, Batch: 300/1676, Loss: 0.7837, Time: 1.96s\n",
      "Epoch: 15, Batch: 310/1676, Loss: 0.9716, Time: 1.96s\n",
      "Epoch: 15, Batch: 320/1676, Loss: 0.8289, Time: 1.95s\n",
      "Epoch: 15, Batch: 330/1676, Loss: 0.7252, Time: 1.96s\n",
      "Epoch: 15, Batch: 340/1676, Loss: 0.7167, Time: 1.97s\n",
      "Epoch: 15, Batch: 350/1676, Loss: 0.4449, Time: 1.95s\n",
      "Epoch: 15, Batch: 360/1676, Loss: 0.7300, Time: 1.96s\n",
      "Epoch: 15, Batch: 370/1676, Loss: 0.4898, Time: 1.96s\n",
      "Epoch: 15, Batch: 380/1676, Loss: 1.1790, Time: 1.96s\n",
      "Epoch: 15, Batch: 390/1676, Loss: 0.3624, Time: 1.97s\n",
      "Epoch: 15, Batch: 400/1676, Loss: 0.4958, Time: 1.96s\n",
      "Epoch: 15, Batch: 410/1676, Loss: 0.7279, Time: 1.96s\n",
      "Epoch: 15, Batch: 420/1676, Loss: 0.4230, Time: 1.96s\n",
      "Epoch: 15, Batch: 430/1676, Loss: 0.7087, Time: 1.96s\n",
      "Epoch: 15, Batch: 440/1676, Loss: 0.3730, Time: 1.96s\n",
      "Epoch: 15, Batch: 450/1676, Loss: 0.7139, Time: 1.96s\n",
      "Epoch: 15, Batch: 460/1676, Loss: 0.5883, Time: 1.96s\n",
      "Epoch: 15, Batch: 470/1676, Loss: 0.5904, Time: 1.96s\n",
      "Epoch: 15, Batch: 480/1676, Loss: 0.5094, Time: 1.96s\n",
      "Epoch: 15, Batch: 490/1676, Loss: 0.6496, Time: 1.97s\n",
      "Epoch: 15, Batch: 500/1676, Loss: 1.0593, Time: 1.96s\n",
      "Epoch: 15, Batch: 510/1676, Loss: 0.7117, Time: 1.97s\n",
      "Epoch: 15, Batch: 520/1676, Loss: 1.3649, Time: 1.96s\n",
      "Epoch: 15, Batch: 530/1676, Loss: 0.5653, Time: 1.96s\n",
      "Epoch: 15, Batch: 540/1676, Loss: 0.4039, Time: 1.96s\n",
      "Epoch: 15, Batch: 550/1676, Loss: 0.6470, Time: 1.96s\n",
      "Epoch: 15, Batch: 560/1676, Loss: 0.4934, Time: 1.96s\n",
      "Epoch: 15, Batch: 570/1676, Loss: 0.4590, Time: 1.96s\n",
      "Epoch: 15, Batch: 580/1676, Loss: 0.9734, Time: 1.96s\n",
      "Epoch: 15, Batch: 590/1676, Loss: 0.6456, Time: 1.97s\n",
      "Epoch: 15, Batch: 600/1676, Loss: 0.4442, Time: 1.96s\n",
      "Epoch: 15, Batch: 610/1676, Loss: 0.5544, Time: 1.96s\n",
      "Epoch: 15, Batch: 620/1676, Loss: 0.6231, Time: 1.96s\n",
      "Epoch: 15, Batch: 630/1676, Loss: 0.7167, Time: 1.96s\n",
      "Epoch: 15, Batch: 640/1676, Loss: 0.2213, Time: 1.97s\n",
      "Epoch: 15, Batch: 650/1676, Loss: 0.6981, Time: 1.96s\n",
      "Epoch: 15, Batch: 660/1676, Loss: 0.3417, Time: 1.97s\n",
      "Epoch: 15, Batch: 670/1676, Loss: 1.1042, Time: 1.97s\n",
      "Epoch: 15, Batch: 680/1676, Loss: 0.6801, Time: 1.97s\n",
      "Epoch: 15, Batch: 690/1676, Loss: 0.6779, Time: 1.96s\n",
      "Epoch: 15, Batch: 700/1676, Loss: 0.8021, Time: 1.96s\n",
      "Epoch: 15, Batch: 710/1676, Loss: 0.7572, Time: 1.97s\n",
      "Epoch: 15, Batch: 720/1676, Loss: 1.2896, Time: 1.96s\n",
      "Epoch: 15, Batch: 730/1676, Loss: 0.5166, Time: 1.97s\n",
      "Epoch: 15, Batch: 740/1676, Loss: 0.7025, Time: 1.97s\n",
      "Epoch: 15, Batch: 750/1676, Loss: 1.2239, Time: 1.97s\n",
      "Epoch: 15, Batch: 760/1676, Loss: 0.3382, Time: 1.97s\n",
      "Epoch: 15, Batch: 770/1676, Loss: 1.2523, Time: 1.97s\n",
      "Epoch: 15, Batch: 780/1676, Loss: 0.9532, Time: 1.97s\n",
      "Epoch: 15, Batch: 790/1676, Loss: 0.9719, Time: 1.96s\n",
      "Epoch: 15, Batch: 800/1676, Loss: 0.7889, Time: 1.97s\n",
      "Epoch: 15, Batch: 810/1676, Loss: 0.9042, Time: 1.97s\n",
      "Epoch: 15, Batch: 820/1676, Loss: 0.5024, Time: 1.97s\n",
      "Epoch: 15, Batch: 830/1676, Loss: 0.7579, Time: 1.97s\n",
      "Epoch: 15, Batch: 840/1676, Loss: 0.6672, Time: 1.96s\n",
      "Epoch: 15, Batch: 850/1676, Loss: 0.6441, Time: 1.97s\n",
      "Epoch: 15, Batch: 860/1676, Loss: 0.4766, Time: 1.97s\n",
      "Epoch: 15, Batch: 870/1676, Loss: 0.5369, Time: 1.97s\n",
      "Epoch: 15, Batch: 880/1676, Loss: 0.6222, Time: 1.97s\n",
      "Epoch: 15, Batch: 890/1676, Loss: 1.1146, Time: 1.97s\n",
      "Epoch: 15, Batch: 900/1676, Loss: 0.3385, Time: 1.97s\n",
      "Epoch: 15, Batch: 910/1676, Loss: 0.7906, Time: 1.96s\n",
      "Epoch: 15, Batch: 920/1676, Loss: 0.5308, Time: 1.97s\n",
      "Epoch: 15, Batch: 930/1676, Loss: 1.1709, Time: 1.97s\n",
      "Epoch: 15, Batch: 940/1676, Loss: 0.9379, Time: 1.97s\n",
      "Epoch: 15, Batch: 950/1676, Loss: 1.1901, Time: 1.98s\n",
      "Epoch: 15, Batch: 960/1676, Loss: 0.9404, Time: 1.96s\n",
      "Epoch: 15, Batch: 970/1676, Loss: 1.0848, Time: 1.96s\n",
      "Epoch: 15, Batch: 980/1676, Loss: 0.5162, Time: 1.98s\n",
      "Epoch: 15, Batch: 990/1676, Loss: 0.4212, Time: 1.96s\n",
      "Epoch: 15, Batch: 1000/1676, Loss: 0.3772, Time: 1.97s\n",
      "Epoch: 15, Batch: 1010/1676, Loss: 0.9216, Time: 1.97s\n",
      "Epoch: 15, Batch: 1020/1676, Loss: 0.6620, Time: 1.97s\n",
      "Epoch: 15, Batch: 1030/1676, Loss: 0.6850, Time: 1.97s\n",
      "Epoch: 15, Batch: 1040/1676, Loss: 0.8532, Time: 1.97s\n",
      "Epoch: 15, Batch: 1050/1676, Loss: 1.0033, Time: 1.98s\n",
      "Epoch: 15, Batch: 1060/1676, Loss: 0.3867, Time: 1.97s\n",
      "Epoch: 15, Batch: 1070/1676, Loss: 0.6193, Time: 1.97s\n",
      "Epoch: 15, Batch: 1080/1676, Loss: 0.8025, Time: 1.97s\n",
      "Epoch: 15, Batch: 1090/1676, Loss: 0.3744, Time: 1.97s\n",
      "Epoch: 15, Batch: 1100/1676, Loss: 1.2722, Time: 1.97s\n",
      "Epoch: 15, Batch: 1110/1676, Loss: 0.7453, Time: 1.97s\n",
      "Epoch: 15, Batch: 1120/1676, Loss: 1.1861, Time: 1.97s\n",
      "Epoch: 15, Batch: 1130/1676, Loss: 0.5711, Time: 1.97s\n",
      "Epoch: 15, Batch: 1140/1676, Loss: 1.0404, Time: 1.96s\n",
      "Epoch: 15, Batch: 1150/1676, Loss: 0.4034, Time: 1.98s\n",
      "Epoch: 15, Batch: 1160/1676, Loss: 1.3253, Time: 1.97s\n",
      "Epoch: 15, Batch: 1170/1676, Loss: 0.4452, Time: 1.98s\n",
      "Epoch: 15, Batch: 1180/1676, Loss: 0.6339, Time: 1.97s\n",
      "Epoch: 15, Batch: 1190/1676, Loss: 0.6960, Time: 1.97s\n",
      "Epoch: 15, Batch: 1200/1676, Loss: 0.8351, Time: 1.97s\n",
      "Epoch: 15, Batch: 1210/1676, Loss: 0.6149, Time: 1.98s\n",
      "Epoch: 15, Batch: 1220/1676, Loss: 0.7930, Time: 1.97s\n",
      "Epoch: 15, Batch: 1230/1676, Loss: 1.3279, Time: 1.97s\n",
      "Epoch: 15, Batch: 1240/1676, Loss: 0.3160, Time: 1.97s\n",
      "Epoch: 15, Batch: 1250/1676, Loss: 0.7645, Time: 1.96s\n",
      "Epoch: 15, Batch: 1260/1676, Loss: 0.4673, Time: 1.97s\n",
      "Epoch: 15, Batch: 1270/1676, Loss: 0.5342, Time: 1.98s\n",
      "Epoch: 15, Batch: 1280/1676, Loss: 0.4331, Time: 1.97s\n",
      "Epoch: 15, Batch: 1290/1676, Loss: 0.6065, Time: 1.97s\n",
      "Epoch: 15, Batch: 1300/1676, Loss: 0.5822, Time: 1.96s\n",
      "Epoch: 15, Batch: 1310/1676, Loss: 0.5032, Time: 1.97s\n",
      "Epoch: 15, Batch: 1320/1676, Loss: 0.8156, Time: 1.98s\n",
      "Epoch: 15, Batch: 1330/1676, Loss: 0.7326, Time: 1.97s\n",
      "Epoch: 15, Batch: 1340/1676, Loss: 0.4119, Time: 1.97s\n",
      "Epoch: 15, Batch: 1350/1676, Loss: 0.4935, Time: 1.97s\n",
      "Epoch: 15, Batch: 1360/1676, Loss: 0.4208, Time: 1.98s\n",
      "Epoch: 15, Batch: 1370/1676, Loss: 0.4839, Time: 1.97s\n",
      "Epoch: 15, Batch: 1380/1676, Loss: 0.5249, Time: 1.97s\n",
      "Epoch: 15, Batch: 1390/1676, Loss: 0.8739, Time: 1.97s\n",
      "Epoch: 15, Batch: 1400/1676, Loss: 0.3581, Time: 1.97s\n",
      "Epoch: 15, Batch: 1410/1676, Loss: 0.6911, Time: 1.97s\n",
      "Epoch: 15, Batch: 1420/1676, Loss: 1.3234, Time: 1.98s\n",
      "Epoch: 15, Batch: 1430/1676, Loss: 1.0398, Time: 1.97s\n",
      "Epoch: 15, Batch: 1440/1676, Loss: 0.3474, Time: 1.98s\n",
      "Epoch: 15, Batch: 1450/1676, Loss: 0.7332, Time: 1.98s\n",
      "Epoch: 15, Batch: 1460/1676, Loss: 0.5187, Time: 1.97s\n",
      "Epoch: 15, Batch: 1470/1676, Loss: 0.8560, Time: 1.97s\n",
      "Epoch: 15, Batch: 1480/1676, Loss: 0.7811, Time: 1.97s\n",
      "Epoch: 15, Batch: 1490/1676, Loss: 0.6781, Time: 1.97s\n",
      "Epoch: 15, Batch: 1500/1676, Loss: 0.3454, Time: 1.97s\n",
      "Epoch: 15, Batch: 1510/1676, Loss: 0.4144, Time: 1.97s\n",
      "Epoch: 15, Batch: 1520/1676, Loss: 1.7618, Time: 1.97s\n",
      "Epoch: 15, Batch: 1530/1676, Loss: 0.6375, Time: 1.97s\n",
      "Epoch: 15, Batch: 1540/1676, Loss: 1.2634, Time: 1.97s\n",
      "Epoch: 15, Batch: 1550/1676, Loss: 1.0125, Time: 1.97s\n",
      "Epoch: 15, Batch: 1560/1676, Loss: 0.5497, Time: 1.97s\n",
      "Epoch: 15, Batch: 1570/1676, Loss: 0.7886, Time: 1.97s\n",
      "Epoch: 15, Batch: 1580/1676, Loss: 0.6534, Time: 1.97s\n",
      "Epoch: 15, Batch: 1590/1676, Loss: 0.7962, Time: 1.97s\n",
      "Epoch: 15, Batch: 1600/1676, Loss: 0.6596, Time: 1.97s\n",
      "Epoch: 15, Batch: 1610/1676, Loss: 0.5907, Time: 1.97s\n",
      "Epoch: 15, Batch: 1620/1676, Loss: 0.4378, Time: 1.97s\n",
      "Epoch: 15, Batch: 1630/1676, Loss: 0.2781, Time: 1.97s\n",
      "Epoch: 15, Batch: 1640/1676, Loss: 0.6534, Time: 1.97s\n",
      "Epoch: 15, Batch: 1650/1676, Loss: 1.1778, Time: 1.98s\n",
      "Epoch: 15, Batch: 1660/1676, Loss: 0.8368, Time: 1.97s\n",
      "Epoch: 15, Batch: 1670/1676, Loss: 0.7144, Time: 1.97s\n",
      "Epoch 16/50: Train Loss: 0.7095, Val Loss: 0.7131, Val IoU: 0.5620, Val Dice: 0.5814\n",
      "Saving best model with IoU: 0.5620\n",
      "Epoch: 16, Batch: 0/1676, Loss: 1.2786, Time: 36.19s\n",
      "Epoch: 16, Batch: 10/1676, Loss: 1.5560, Time: 1.98s\n",
      "Epoch: 16, Batch: 20/1676, Loss: 0.3046, Time: 1.93s\n",
      "Epoch: 16, Batch: 30/1676, Loss: 0.6133, Time: 1.93s\n",
      "Epoch: 16, Batch: 40/1676, Loss: 0.4038, Time: 1.93s\n",
      "Epoch: 16, Batch: 50/1676, Loss: 1.1908, Time: 1.94s\n",
      "Epoch: 16, Batch: 60/1676, Loss: 0.5951, Time: 1.94s\n",
      "Epoch: 16, Batch: 70/1676, Loss: 0.2817, Time: 1.94s\n",
      "Epoch: 16, Batch: 80/1676, Loss: 0.5532, Time: 1.94s\n",
      "Epoch: 16, Batch: 90/1676, Loss: 1.0337, Time: 1.94s\n",
      "Epoch: 16, Batch: 100/1676, Loss: 0.8214, Time: 1.94s\n",
      "Epoch: 16, Batch: 110/1676, Loss: 0.5680, Time: 1.94s\n",
      "Epoch: 16, Batch: 120/1676, Loss: 0.3497, Time: 1.94s\n",
      "Epoch: 16, Batch: 130/1676, Loss: 0.9062, Time: 1.95s\n",
      "Epoch: 16, Batch: 140/1676, Loss: 0.4319, Time: 1.94s\n",
      "Epoch: 16, Batch: 150/1676, Loss: 0.8414, Time: 1.94s\n",
      "Epoch: 16, Batch: 160/1676, Loss: 1.1635, Time: 1.95s\n",
      "Epoch: 16, Batch: 170/1676, Loss: 0.2596, Time: 1.95s\n",
      "Epoch: 16, Batch: 180/1676, Loss: 0.4203, Time: 1.95s\n",
      "Epoch: 16, Batch: 190/1676, Loss: 0.4703, Time: 1.95s\n",
      "Epoch: 16, Batch: 200/1676, Loss: 0.6844, Time: 1.95s\n",
      "Epoch: 16, Batch: 210/1676, Loss: 0.7544, Time: 1.95s\n",
      "Epoch: 16, Batch: 220/1676, Loss: 1.1625, Time: 1.95s\n",
      "Epoch: 16, Batch: 230/1676, Loss: 0.6297, Time: 1.95s\n",
      "Epoch: 16, Batch: 240/1676, Loss: 0.5454, Time: 1.99s\n",
      "Epoch: 16, Batch: 250/1676, Loss: 0.9821, Time: 2.00s\n",
      "Epoch: 16, Batch: 260/1676, Loss: 0.3846, Time: 1.99s\n",
      "Epoch: 16, Batch: 270/1676, Loss: 0.9202, Time: 2.00s\n",
      "Epoch: 16, Batch: 280/1676, Loss: 0.6209, Time: 1.98s\n",
      "Epoch: 16, Batch: 290/1676, Loss: 1.2763, Time: 1.99s\n",
      "Epoch: 16, Batch: 300/1676, Loss: 0.4905, Time: 2.00s\n",
      "Epoch: 16, Batch: 310/1676, Loss: 0.6482, Time: 1.99s\n",
      "Epoch: 16, Batch: 320/1676, Loss: 1.6555, Time: 1.98s\n",
      "Epoch: 16, Batch: 330/1676, Loss: 0.5849, Time: 1.97s\n",
      "Epoch: 16, Batch: 340/1676, Loss: 0.7702, Time: 1.99s\n",
      "Epoch: 16, Batch: 350/1676, Loss: 0.4633, Time: 1.98s\n",
      "Epoch: 16, Batch: 360/1676, Loss: 1.7765, Time: 1.99s\n",
      "Epoch: 16, Batch: 370/1676, Loss: 0.3385, Time: 1.99s\n",
      "Epoch: 16, Batch: 380/1676, Loss: 0.4844, Time: 1.98s\n",
      "Epoch: 16, Batch: 390/1676, Loss: 0.5714, Time: 1.99s\n",
      "Epoch: 16, Batch: 400/1676, Loss: 1.3152, Time: 1.99s\n",
      "Epoch: 16, Batch: 410/1676, Loss: 1.0615, Time: 1.99s\n",
      "Epoch: 16, Batch: 420/1676, Loss: 0.9627, Time: 1.99s\n",
      "Epoch: 16, Batch: 430/1676, Loss: 0.7107, Time: 1.99s\n",
      "Epoch: 16, Batch: 440/1676, Loss: 0.6453, Time: 1.98s\n",
      "Epoch: 16, Batch: 450/1676, Loss: 0.7040, Time: 1.99s\n",
      "Epoch: 16, Batch: 460/1676, Loss: 0.5690, Time: 1.99s\n",
      "Epoch: 16, Batch: 470/1676, Loss: 0.7366, Time: 2.00s\n",
      "Epoch: 16, Batch: 480/1676, Loss: 0.5581, Time: 1.99s\n",
      "Epoch: 16, Batch: 490/1676, Loss: 0.3424, Time: 1.99s\n",
      "Epoch: 16, Batch: 500/1676, Loss: 0.6519, Time: 2.00s\n",
      "Epoch: 16, Batch: 510/1676, Loss: 0.4914, Time: 1.99s\n",
      "Epoch: 16, Batch: 520/1676, Loss: 0.8835, Time: 2.00s\n",
      "Epoch: 16, Batch: 530/1676, Loss: 0.7495, Time: 1.99s\n",
      "Epoch: 16, Batch: 540/1676, Loss: 0.6685, Time: 1.99s\n",
      "Epoch: 16, Batch: 550/1676, Loss: 0.9578, Time: 2.00s\n",
      "Epoch: 16, Batch: 560/1676, Loss: 0.8361, Time: 1.99s\n",
      "Epoch: 16, Batch: 570/1676, Loss: 1.4817, Time: 1.99s\n",
      "Epoch: 16, Batch: 580/1676, Loss: 0.4369, Time: 1.99s\n",
      "Epoch: 16, Batch: 590/1676, Loss: 0.3465, Time: 2.00s\n",
      "Epoch: 16, Batch: 600/1676, Loss: 0.6260, Time: 2.00s\n",
      "Epoch: 16, Batch: 610/1676, Loss: 0.8383, Time: 1.99s\n",
      "Epoch: 16, Batch: 620/1676, Loss: 0.6311, Time: 1.99s\n",
      "Epoch: 16, Batch: 630/1676, Loss: 0.7055, Time: 2.00s\n",
      "Epoch: 16, Batch: 640/1676, Loss: 0.9004, Time: 1.99s\n",
      "Epoch: 16, Batch: 650/1676, Loss: 0.4750, Time: 1.99s\n",
      "Epoch: 16, Batch: 660/1676, Loss: 0.2122, Time: 2.01s\n",
      "Epoch: 16, Batch: 670/1676, Loss: 0.4560, Time: 1.99s\n",
      "Epoch: 16, Batch: 680/1676, Loss: 0.4792, Time: 1.99s\n",
      "Epoch: 16, Batch: 690/1676, Loss: 0.6593, Time: 1.99s\n",
      "Epoch: 16, Batch: 700/1676, Loss: 0.4385, Time: 2.00s\n",
      "Epoch: 16, Batch: 710/1676, Loss: 0.8096, Time: 1.99s\n",
      "Epoch: 16, Batch: 720/1676, Loss: 0.6852, Time: 1.99s\n",
      "Epoch: 16, Batch: 730/1676, Loss: 0.4085, Time: 2.00s\n",
      "Epoch: 16, Batch: 740/1676, Loss: 0.4728, Time: 2.00s\n",
      "Epoch: 16, Batch: 750/1676, Loss: 0.9209, Time: 2.00s\n",
      "Epoch: 16, Batch: 760/1676, Loss: 0.3634, Time: 2.00s\n",
      "Epoch: 16, Batch: 770/1676, Loss: 0.9555, Time: 2.00s\n",
      "Epoch: 16, Batch: 780/1676, Loss: 1.2094, Time: 2.00s\n",
      "Epoch: 16, Batch: 790/1676, Loss: 0.3019, Time: 2.00s\n",
      "Epoch: 16, Batch: 800/1676, Loss: 0.7788, Time: 2.00s\n",
      "Epoch: 16, Batch: 810/1676, Loss: 0.5391, Time: 2.00s\n",
      "Epoch: 16, Batch: 820/1676, Loss: 0.5777, Time: 2.00s\n",
      "Epoch: 16, Batch: 830/1676, Loss: 1.0053, Time: 1.99s\n",
      "Epoch: 16, Batch: 840/1676, Loss: 0.4109, Time: 2.01s\n",
      "Epoch: 16, Batch: 850/1676, Loss: 0.4037, Time: 1.99s\n",
      "Epoch: 16, Batch: 860/1676, Loss: 1.1605, Time: 1.99s\n",
      "Epoch: 16, Batch: 870/1676, Loss: 0.6575, Time: 2.01s\n",
      "Epoch: 16, Batch: 880/1676, Loss: 0.7068, Time: 1.99s\n",
      "Epoch: 16, Batch: 890/1676, Loss: 0.6663, Time: 2.00s\n",
      "Epoch: 16, Batch: 900/1676, Loss: 0.8364, Time: 2.01s\n",
      "Epoch: 16, Batch: 910/1676, Loss: 0.5349, Time: 1.99s\n",
      "Epoch: 16, Batch: 920/1676, Loss: 1.7932, Time: 2.01s\n",
      "Epoch: 16, Batch: 930/1676, Loss: 0.6373, Time: 2.01s\n",
      "Epoch: 16, Batch: 940/1676, Loss: 0.8609, Time: 2.01s\n",
      "Epoch: 16, Batch: 950/1676, Loss: 0.7510, Time: 2.01s\n",
      "Epoch: 16, Batch: 960/1676, Loss: 0.6744, Time: 2.00s\n",
      "Epoch: 16, Batch: 970/1676, Loss: 0.3343, Time: 2.00s\n",
      "Epoch: 16, Batch: 980/1676, Loss: 0.5541, Time: 2.01s\n",
      "Epoch: 16, Batch: 990/1676, Loss: 0.6044, Time: 1.99s\n",
      "Epoch: 16, Batch: 1000/1676, Loss: 0.9465, Time: 2.00s\n",
      "Epoch: 16, Batch: 1010/1676, Loss: 0.4442, Time: 2.00s\n",
      "Epoch: 16, Batch: 1020/1676, Loss: 0.5332, Time: 1.99s\n",
      "Epoch: 16, Batch: 1030/1676, Loss: 0.4959, Time: 2.00s\n",
      "Epoch: 16, Batch: 1040/1676, Loss: 0.4707, Time: 2.01s\n",
      "Epoch: 16, Batch: 1050/1676, Loss: 1.0718, Time: 2.00s\n",
      "Epoch: 16, Batch: 1060/1676, Loss: 0.5667, Time: 2.01s\n",
      "Epoch: 16, Batch: 1070/1676, Loss: 1.2718, Time: 2.01s\n",
      "Epoch: 16, Batch: 1080/1676, Loss: 0.6708, Time: 2.00s\n",
      "Epoch: 16, Batch: 1090/1676, Loss: 0.5120, Time: 2.00s\n",
      "Epoch: 16, Batch: 1100/1676, Loss: 0.5822, Time: 2.00s\n",
      "Epoch: 16, Batch: 1110/1676, Loss: 0.4632, Time: 2.00s\n",
      "Epoch: 16, Batch: 1120/1676, Loss: 0.9363, Time: 2.00s\n",
      "Epoch: 16, Batch: 1130/1676, Loss: 0.6145, Time: 2.01s\n",
      "Epoch: 16, Batch: 1140/1676, Loss: 0.4720, Time: 2.00s\n",
      "Epoch: 16, Batch: 1150/1676, Loss: 0.9118, Time: 2.01s\n",
      "Epoch: 16, Batch: 1160/1676, Loss: 1.0488, Time: 2.00s\n",
      "Epoch: 16, Batch: 1170/1676, Loss: 0.3927, Time: 2.00s\n",
      "Epoch: 16, Batch: 1180/1676, Loss: 0.3539, Time: 2.01s\n",
      "Epoch: 16, Batch: 1190/1676, Loss: 0.5278, Time: 1.99s\n",
      "Epoch: 16, Batch: 1200/1676, Loss: 0.2635, Time: 2.01s\n",
      "Epoch: 16, Batch: 1210/1676, Loss: 0.7578, Time: 1.99s\n",
      "Epoch: 16, Batch: 1220/1676, Loss: 0.9012, Time: 2.01s\n",
      "Epoch: 16, Batch: 1230/1676, Loss: 1.4770, Time: 2.00s\n",
      "Epoch: 16, Batch: 1240/1676, Loss: 0.5204, Time: 2.00s\n",
      "Epoch: 16, Batch: 1250/1676, Loss: 0.9002, Time: 2.01s\n",
      "Epoch: 16, Batch: 1260/1676, Loss: 0.7580, Time: 2.00s\n",
      "Epoch: 16, Batch: 1270/1676, Loss: 0.6466, Time: 2.00s\n",
      "Epoch: 16, Batch: 1280/1676, Loss: 0.5220, Time: 2.00s\n",
      "Epoch: 16, Batch: 1290/1676, Loss: 1.3691, Time: 1.99s\n",
      "Epoch: 16, Batch: 1300/1676, Loss: 0.3443, Time: 2.00s\n",
      "Epoch: 16, Batch: 1310/1676, Loss: 0.5687, Time: 2.00s\n",
      "Epoch: 16, Batch: 1320/1676, Loss: 0.9777, Time: 2.00s\n",
      "Epoch: 16, Batch: 1330/1676, Loss: 0.7687, Time: 2.00s\n",
      "Epoch: 16, Batch: 1340/1676, Loss: 0.3078, Time: 2.01s\n",
      "Epoch: 16, Batch: 1350/1676, Loss: 0.7558, Time: 2.00s\n",
      "Epoch: 16, Batch: 1360/1676, Loss: 0.6607, Time: 2.00s\n",
      "Epoch: 16, Batch: 1370/1676, Loss: 0.5107, Time: 2.00s\n",
      "Epoch: 16, Batch: 1380/1676, Loss: 0.6166, Time: 2.01s\n",
      "Epoch: 16, Batch: 1390/1676, Loss: 0.8136, Time: 2.00s\n",
      "Epoch: 16, Batch: 1400/1676, Loss: 0.9757, Time: 2.00s\n",
      "Epoch: 16, Batch: 1410/1676, Loss: 0.7495, Time: 2.01s\n",
      "Epoch: 16, Batch: 1420/1676, Loss: 0.6722, Time: 2.01s\n",
      "Epoch: 16, Batch: 1430/1676, Loss: 1.3578, Time: 2.00s\n",
      "Epoch: 16, Batch: 1440/1676, Loss: 0.5863, Time: 2.00s\n",
      "Epoch: 16, Batch: 1450/1676, Loss: 0.8589, Time: 2.00s\n",
      "Epoch: 16, Batch: 1460/1676, Loss: 0.3167, Time: 2.01s\n",
      "Epoch: 16, Batch: 1470/1676, Loss: 0.8828, Time: 2.00s\n",
      "Epoch: 16, Batch: 1480/1676, Loss: 0.8661, Time: 2.00s\n",
      "Epoch: 16, Batch: 1490/1676, Loss: 0.8534, Time: 2.00s\n",
      "Epoch: 16, Batch: 1500/1676, Loss: 0.6053, Time: 2.01s\n",
      "Epoch: 16, Batch: 1510/1676, Loss: 0.4689, Time: 2.01s\n",
      "Epoch: 16, Batch: 1520/1676, Loss: 0.5852, Time: 2.00s\n",
      "Epoch: 16, Batch: 1530/1676, Loss: 0.6805, Time: 2.01s\n",
      "Epoch: 16, Batch: 1540/1676, Loss: 0.5748, Time: 2.00s\n",
      "Epoch: 16, Batch: 1550/1676, Loss: 0.7026, Time: 2.00s\n",
      "Epoch: 16, Batch: 1560/1676, Loss: 1.0780, Time: 2.00s\n",
      "Epoch: 16, Batch: 1570/1676, Loss: 0.6650, Time: 2.01s\n",
      "Epoch: 16, Batch: 1580/1676, Loss: 1.1038, Time: 2.01s\n",
      "Epoch: 16, Batch: 1590/1676, Loss: 0.5042, Time: 2.01s\n",
      "Epoch: 16, Batch: 1600/1676, Loss: 0.6175, Time: 2.01s\n",
      "Epoch: 16, Batch: 1610/1676, Loss: 0.2749, Time: 2.01s\n",
      "Epoch: 16, Batch: 1620/1676, Loss: 1.0845, Time: 2.01s\n",
      "Epoch: 16, Batch: 1630/1676, Loss: 0.4098, Time: 2.00s\n",
      "Epoch: 16, Batch: 1640/1676, Loss: 0.3452, Time: 2.00s\n",
      "Epoch: 16, Batch: 1650/1676, Loss: 0.6196, Time: 2.00s\n",
      "Epoch: 16, Batch: 1660/1676, Loss: 0.4442, Time: 2.00s\n",
      "Epoch: 16, Batch: 1670/1676, Loss: 0.3483, Time: 2.01s\n",
      "Epoch 17/50: Train Loss: 0.7073, Val Loss: 0.7053, Val IoU: 0.5610, Val Dice: 0.5806\n",
      "Epoch: 17, Batch: 0/1676, Loss: 0.4584, Time: 64.37s\n",
      "Epoch: 17, Batch: 10/1676, Loss: 0.9533, Time: 2.00s\n",
      "Epoch: 17, Batch: 20/1676, Loss: 0.4595, Time: 1.95s\n",
      "Epoch: 17, Batch: 30/1676, Loss: 0.8306, Time: 1.94s\n",
      "Epoch: 17, Batch: 40/1676, Loss: 0.2577, Time: 1.96s\n",
      "Epoch: 17, Batch: 50/1676, Loss: 0.9382, Time: 1.96s\n",
      "Epoch: 17, Batch: 60/1676, Loss: 0.6208, Time: 1.95s\n",
      "Epoch: 17, Batch: 70/1676, Loss: 1.0572, Time: 1.96s\n",
      "Epoch: 17, Batch: 80/1676, Loss: 0.1743, Time: 1.96s\n",
      "Epoch: 17, Batch: 90/1676, Loss: 0.8182, Time: 1.97s\n",
      "Epoch: 17, Batch: 100/1676, Loss: 0.8520, Time: 1.96s\n",
      "Epoch: 17, Batch: 110/1676, Loss: 0.8026, Time: 1.97s\n",
      "Epoch: 17, Batch: 120/1676, Loss: 0.7802, Time: 1.96s\n",
      "Epoch: 17, Batch: 130/1676, Loss: 0.8553, Time: 1.97s\n",
      "Epoch: 17, Batch: 140/1676, Loss: 0.6406, Time: 1.98s\n",
      "Epoch: 17, Batch: 150/1676, Loss: 0.7450, Time: 1.98s\n",
      "Epoch: 17, Batch: 160/1676, Loss: 0.5622, Time: 1.97s\n",
      "Epoch: 17, Batch: 170/1676, Loss: 0.6038, Time: 1.97s\n",
      "Epoch: 17, Batch: 180/1676, Loss: 0.7589, Time: 1.97s\n",
      "Epoch: 17, Batch: 190/1676, Loss: 0.8440, Time: 1.97s\n",
      "Epoch: 17, Batch: 200/1676, Loss: 0.7634, Time: 1.98s\n",
      "Epoch: 17, Batch: 210/1676, Loss: 0.5612, Time: 1.97s\n",
      "Epoch: 17, Batch: 220/1676, Loss: 0.6372, Time: 1.98s\n",
      "Epoch: 17, Batch: 230/1676, Loss: 0.8816, Time: 1.97s\n",
      "Epoch: 17, Batch: 240/1676, Loss: 0.9822, Time: 1.97s\n",
      "Epoch: 17, Batch: 250/1676, Loss: 0.5248, Time: 1.98s\n",
      "Epoch: 17, Batch: 260/1676, Loss: 0.5813, Time: 1.97s\n",
      "Epoch: 17, Batch: 270/1676, Loss: 0.3891, Time: 1.98s\n",
      "Epoch: 17, Batch: 280/1676, Loss: 0.5767, Time: 1.98s\n",
      "Epoch: 17, Batch: 290/1676, Loss: 0.4223, Time: 1.98s\n",
      "Epoch: 17, Batch: 300/1676, Loss: 0.8564, Time: 1.99s\n",
      "Epoch: 17, Batch: 310/1676, Loss: 0.4658, Time: 1.98s\n",
      "Epoch: 17, Batch: 320/1676, Loss: 0.5465, Time: 1.98s\n",
      "Epoch: 17, Batch: 330/1676, Loss: 0.7164, Time: 1.99s\n",
      "Epoch: 17, Batch: 340/1676, Loss: 0.4583, Time: 1.97s\n",
      "Epoch: 17, Batch: 350/1676, Loss: 0.6826, Time: 1.99s\n",
      "Epoch: 17, Batch: 360/1676, Loss: 0.8786, Time: 1.98s\n",
      "Epoch: 17, Batch: 370/1676, Loss: 1.4598, Time: 1.98s\n",
      "Epoch: 17, Batch: 380/1676, Loss: 0.8378, Time: 1.98s\n",
      "Epoch: 17, Batch: 390/1676, Loss: 0.4252, Time: 1.98s\n",
      "Epoch: 17, Batch: 400/1676, Loss: 0.3879, Time: 1.99s\n",
      "Epoch: 17, Batch: 410/1676, Loss: 0.7398, Time: 1.98s\n",
      "Epoch: 17, Batch: 420/1676, Loss: 0.3840, Time: 1.99s\n",
      "Epoch: 17, Batch: 430/1676, Loss: 0.7934, Time: 1.98s\n",
      "Epoch: 17, Batch: 440/1676, Loss: 0.6799, Time: 1.98s\n",
      "Epoch: 17, Batch: 450/1676, Loss: 0.8053, Time: 1.99s\n",
      "Epoch: 17, Batch: 460/1676, Loss: 0.4765, Time: 1.98s\n",
      "Epoch: 17, Batch: 470/1676, Loss: 0.5643, Time: 1.98s\n",
      "Epoch: 17, Batch: 480/1676, Loss: 0.9138, Time: 1.99s\n",
      "Epoch: 17, Batch: 490/1676, Loss: 1.1319, Time: 1.99s\n",
      "Epoch: 17, Batch: 500/1676, Loss: 0.5835, Time: 2.00s\n",
      "Epoch: 17, Batch: 510/1676, Loss: 0.8465, Time: 1.99s\n",
      "Epoch: 17, Batch: 520/1676, Loss: 1.1851, Time: 1.99s\n",
      "Epoch: 17, Batch: 530/1676, Loss: 0.3337, Time: 1.99s\n",
      "Epoch: 17, Batch: 540/1676, Loss: 0.5296, Time: 1.99s\n",
      "Epoch: 17, Batch: 550/1676, Loss: 0.6531, Time: 1.99s\n",
      "Epoch: 17, Batch: 560/1676, Loss: 0.6018, Time: 1.98s\n",
      "Epoch: 17, Batch: 570/1676, Loss: 0.4725, Time: 2.00s\n",
      "Epoch: 17, Batch: 580/1676, Loss: 0.5187, Time: 1.99s\n",
      "Epoch: 17, Batch: 590/1676, Loss: 0.8173, Time: 1.99s\n",
      "Epoch: 17, Batch: 600/1676, Loss: 0.6784, Time: 2.00s\n",
      "Epoch: 17, Batch: 610/1676, Loss: 0.8105, Time: 1.99s\n",
      "Epoch: 17, Batch: 620/1676, Loss: 0.5984, Time: 1.99s\n",
      "Epoch: 17, Batch: 630/1676, Loss: 0.5296, Time: 1.99s\n",
      "Epoch: 17, Batch: 640/1676, Loss: 0.7420, Time: 1.99s\n",
      "Epoch: 17, Batch: 650/1676, Loss: 0.4461, Time: 1.99s\n",
      "Epoch: 17, Batch: 660/1676, Loss: 0.4961, Time: 2.01s\n",
      "Epoch: 17, Batch: 670/1676, Loss: 0.8057, Time: 2.00s\n",
      "Epoch: 17, Batch: 680/1676, Loss: 1.1221, Time: 1.99s\n",
      "Epoch: 17, Batch: 690/1676, Loss: 0.3037, Time: 2.00s\n",
      "Epoch: 17, Batch: 700/1676, Loss: 0.7471, Time: 1.99s\n",
      "Epoch: 17, Batch: 710/1676, Loss: 0.3357, Time: 1.99s\n",
      "Epoch: 17, Batch: 720/1676, Loss: 0.8537, Time: 2.01s\n",
      "Epoch: 17, Batch: 730/1676, Loss: 0.9873, Time: 2.01s\n",
      "Epoch: 17, Batch: 740/1676, Loss: 0.4545, Time: 2.00s\n",
      "Epoch: 17, Batch: 750/1676, Loss: 0.9884, Time: 2.00s\n",
      "Epoch: 17, Batch: 760/1676, Loss: 1.2017, Time: 2.00s\n",
      "Epoch: 17, Batch: 770/1676, Loss: 0.9281, Time: 2.00s\n",
      "Epoch: 17, Batch: 780/1676, Loss: 1.3912, Time: 2.00s\n",
      "Epoch: 17, Batch: 790/1676, Loss: 0.5879, Time: 2.00s\n",
      "Epoch: 17, Batch: 800/1676, Loss: 0.2985, Time: 2.00s\n",
      "Epoch: 17, Batch: 810/1676, Loss: 0.7085, Time: 1.99s\n",
      "Epoch: 17, Batch: 820/1676, Loss: 1.0657, Time: 1.99s\n",
      "Epoch: 17, Batch: 830/1676, Loss: 0.4138, Time: 1.99s\n",
      "Epoch: 17, Batch: 840/1676, Loss: 0.4344, Time: 2.00s\n",
      "Epoch: 17, Batch: 850/1676, Loss: 0.5775, Time: 2.00s\n",
      "Epoch: 17, Batch: 860/1676, Loss: 0.7611, Time: 2.01s\n",
      "Epoch: 17, Batch: 870/1676, Loss: 0.4240, Time: 1.99s\n",
      "Epoch: 17, Batch: 880/1676, Loss: 0.9534, Time: 2.00s\n",
      "Epoch: 17, Batch: 890/1676, Loss: 0.3797, Time: 1.99s\n",
      "Epoch: 17, Batch: 900/1676, Loss: 0.5481, Time: 2.00s\n",
      "Epoch: 17, Batch: 910/1676, Loss: 0.7298, Time: 2.00s\n",
      "Epoch: 17, Batch: 920/1676, Loss: 0.7084, Time: 2.00s\n",
      "Epoch: 17, Batch: 930/1676, Loss: 0.5396, Time: 2.00s\n",
      "Epoch: 17, Batch: 940/1676, Loss: 0.4697, Time: 2.00s\n",
      "Epoch: 17, Batch: 950/1676, Loss: 0.5815, Time: 2.00s\n",
      "Epoch: 17, Batch: 960/1676, Loss: 0.7743, Time: 2.00s\n",
      "Epoch: 17, Batch: 970/1676, Loss: 0.6066, Time: 2.00s\n",
      "Epoch: 17, Batch: 980/1676, Loss: 1.0549, Time: 2.00s\n",
      "Epoch: 17, Batch: 990/1676, Loss: 0.9899, Time: 2.00s\n",
      "Epoch: 17, Batch: 1000/1676, Loss: 0.5416, Time: 2.00s\n",
      "Epoch: 17, Batch: 1010/1676, Loss: 0.4679, Time: 2.00s\n",
      "Epoch: 17, Batch: 1020/1676, Loss: 0.7917, Time: 2.00s\n",
      "Epoch: 17, Batch: 1030/1676, Loss: 0.9481, Time: 2.00s\n",
      "Epoch: 17, Batch: 1040/1676, Loss: 0.3359, Time: 2.00s\n",
      "Epoch: 17, Batch: 1050/1676, Loss: 0.8430, Time: 1.99s\n",
      "Epoch: 17, Batch: 1060/1676, Loss: 1.1512, Time: 2.00s\n",
      "Epoch: 17, Batch: 1070/1676, Loss: 0.8737, Time: 2.01s\n",
      "Epoch: 17, Batch: 1080/1676, Loss: 0.4480, Time: 2.01s\n",
      "Epoch: 17, Batch: 1090/1676, Loss: 0.2980, Time: 2.01s\n",
      "Epoch: 17, Batch: 1100/1676, Loss: 0.6396, Time: 2.00s\n",
      "Epoch: 17, Batch: 1110/1676, Loss: 0.5402, Time: 2.01s\n",
      "Epoch: 17, Batch: 1120/1676, Loss: 0.7741, Time: 2.00s\n",
      "Epoch: 17, Batch: 1130/1676, Loss: 0.5220, Time: 2.00s\n",
      "Epoch: 17, Batch: 1140/1676, Loss: 0.8247, Time: 2.01s\n",
      "Epoch: 17, Batch: 1150/1676, Loss: 1.1050, Time: 2.00s\n",
      "Epoch: 17, Batch: 1160/1676, Loss: 0.9288, Time: 2.00s\n",
      "Epoch: 17, Batch: 1170/1676, Loss: 0.9895, Time: 2.01s\n",
      "Epoch: 17, Batch: 1180/1676, Loss: 0.3566, Time: 2.01s\n",
      "Epoch: 17, Batch: 1190/1676, Loss: 0.7809, Time: 2.00s\n",
      "Epoch: 17, Batch: 1200/1676, Loss: 0.6519, Time: 2.01s\n",
      "Epoch: 17, Batch: 1210/1676, Loss: 0.5193, Time: 2.00s\n",
      "Epoch: 17, Batch: 1220/1676, Loss: 0.8055, Time: 2.01s\n",
      "Epoch: 17, Batch: 1230/1676, Loss: 0.6259, Time: 2.00s\n",
      "Epoch: 17, Batch: 1240/1676, Loss: 0.7590, Time: 2.01s\n",
      "Epoch: 17, Batch: 1250/1676, Loss: 0.6592, Time: 2.01s\n",
      "Epoch: 17, Batch: 1260/1676, Loss: 0.7580, Time: 2.01s\n",
      "Epoch: 17, Batch: 1270/1676, Loss: 0.8357, Time: 2.00s\n",
      "Epoch: 17, Batch: 1280/1676, Loss: 0.6238, Time: 2.00s\n",
      "Epoch: 17, Batch: 1290/1676, Loss: 0.4386, Time: 2.01s\n",
      "Epoch: 17, Batch: 1300/1676, Loss: 0.2295, Time: 2.01s\n",
      "Epoch: 17, Batch: 1310/1676, Loss: 0.9615, Time: 2.00s\n",
      "Epoch: 17, Batch: 1320/1676, Loss: 0.9084, Time: 2.00s\n",
      "Epoch: 17, Batch: 1330/1676, Loss: 0.7637, Time: 2.00s\n",
      "Epoch: 17, Batch: 1340/1676, Loss: 0.5744, Time: 2.01s\n",
      "Epoch: 17, Batch: 1350/1676, Loss: 0.3608, Time: 2.00s\n",
      "Epoch: 17, Batch: 1360/1676, Loss: 0.5266, Time: 2.01s\n",
      "Epoch: 17, Batch: 1370/1676, Loss: 0.8336, Time: 1.99s\n",
      "Epoch: 17, Batch: 1380/1676, Loss: 0.3858, Time: 2.00s\n",
      "Epoch: 17, Batch: 1390/1676, Loss: 0.7398, Time: 1.99s\n",
      "Epoch: 17, Batch: 1400/1676, Loss: 0.5998, Time: 2.01s\n",
      "Epoch: 17, Batch: 1410/1676, Loss: 1.1854, Time: 2.03s\n",
      "Epoch: 17, Batch: 1420/1676, Loss: 0.7945, Time: 2.02s\n",
      "Epoch: 17, Batch: 1430/1676, Loss: 0.5240, Time: 2.01s\n",
      "Epoch: 17, Batch: 1440/1676, Loss: 0.9490, Time: 2.00s\n",
      "Epoch: 17, Batch: 1450/1676, Loss: 0.7764, Time: 2.00s\n",
      "Epoch: 17, Batch: 1460/1676, Loss: 0.3497, Time: 2.00s\n",
      "Epoch: 17, Batch: 1470/1676, Loss: 0.4656, Time: 2.00s\n",
      "Epoch: 17, Batch: 1480/1676, Loss: 0.8390, Time: 2.00s\n",
      "Epoch: 17, Batch: 1490/1676, Loss: 0.4296, Time: 2.00s\n",
      "Epoch: 17, Batch: 1500/1676, Loss: 0.9279, Time: 2.00s\n",
      "Epoch: 17, Batch: 1510/1676, Loss: 0.9798, Time: 2.01s\n",
      "Epoch: 17, Batch: 1520/1676, Loss: 0.7398, Time: 2.00s\n",
      "Epoch: 17, Batch: 1530/1676, Loss: 0.2859, Time: 2.00s\n",
      "Epoch: 17, Batch: 1540/1676, Loss: 0.5547, Time: 2.01s\n",
      "Epoch: 17, Batch: 1550/1676, Loss: 0.6093, Time: 2.01s\n",
      "Epoch: 17, Batch: 1560/1676, Loss: 1.0589, Time: 2.00s\n",
      "Epoch: 17, Batch: 1570/1676, Loss: 0.3884, Time: 1.99s\n",
      "Epoch: 17, Batch: 1580/1676, Loss: 0.6163, Time: 2.01s\n",
      "Epoch: 17, Batch: 1590/1676, Loss: 0.3395, Time: 2.01s\n",
      "Epoch: 17, Batch: 1600/1676, Loss: 0.9741, Time: 2.01s\n",
      "Epoch: 17, Batch: 1610/1676, Loss: 0.6193, Time: 2.00s\n",
      "Epoch: 17, Batch: 1620/1676, Loss: 1.1048, Time: 2.00s\n",
      "Epoch: 17, Batch: 1630/1676, Loss: 0.5397, Time: 2.00s\n",
      "Epoch: 17, Batch: 1640/1676, Loss: 0.3253, Time: 2.01s\n",
      "Epoch: 17, Batch: 1650/1676, Loss: 0.8770, Time: 2.01s\n",
      "Epoch: 17, Batch: 1660/1676, Loss: 0.4335, Time: 2.00s\n",
      "Epoch: 17, Batch: 1670/1676, Loss: 0.5720, Time: 2.00s\n",
      "Epoch 18/50: Train Loss: 0.7066, Val Loss: 0.7252, Val IoU: 0.5447, Val Dice: 0.5663\n",
      "Epoch: 18, Batch: 0/1676, Loss: 1.4978, Time: 35.58s\n",
      "Epoch: 18, Batch: 10/1676, Loss: 0.4792, Time: 2.01s\n",
      "Epoch: 18, Batch: 20/1676, Loss: 0.7663, Time: 1.96s\n",
      "Epoch: 18, Batch: 30/1676, Loss: 0.9351, Time: 1.96s\n",
      "Epoch: 18, Batch: 40/1676, Loss: 0.4536, Time: 1.96s\n",
      "Epoch: 18, Batch: 50/1676, Loss: 0.8516, Time: 1.97s\n",
      "Epoch: 18, Batch: 60/1676, Loss: 0.4937, Time: 1.96s\n",
      "Epoch: 18, Batch: 70/1676, Loss: 0.6209, Time: 1.97s\n",
      "Epoch: 18, Batch: 80/1676, Loss: 0.7335, Time: 1.98s\n",
      "Epoch: 18, Batch: 90/1676, Loss: 0.4518, Time: 1.96s\n",
      "Epoch: 18, Batch: 100/1676, Loss: 0.8220, Time: 1.97s\n",
      "Epoch: 18, Batch: 110/1676, Loss: 0.3571, Time: 1.97s\n",
      "Epoch: 18, Batch: 120/1676, Loss: 0.7182, Time: 1.97s\n",
      "Epoch: 18, Batch: 130/1676, Loss: 0.8517, Time: 1.97s\n",
      "Epoch: 18, Batch: 140/1676, Loss: 0.5573, Time: 1.98s\n",
      "Epoch: 18, Batch: 150/1676, Loss: 1.1511, Time: 1.97s\n",
      "Epoch: 18, Batch: 160/1676, Loss: 1.0189, Time: 1.98s\n",
      "Epoch: 18, Batch: 170/1676, Loss: 0.8274, Time: 1.98s\n",
      "Epoch: 18, Batch: 180/1676, Loss: 0.9168, Time: 1.97s\n",
      "Epoch: 18, Batch: 190/1676, Loss: 0.6452, Time: 1.98s\n",
      "Epoch: 18, Batch: 200/1676, Loss: 0.5951, Time: 1.98s\n",
      "Epoch: 18, Batch: 210/1676, Loss: 1.0503, Time: 1.98s\n",
      "Epoch: 18, Batch: 220/1676, Loss: 1.0108, Time: 1.97s\n",
      "Epoch: 18, Batch: 230/1676, Loss: 0.6970, Time: 1.98s\n",
      "Epoch: 18, Batch: 240/1676, Loss: 0.3799, Time: 1.98s\n",
      "Epoch: 18, Batch: 250/1676, Loss: 0.4363, Time: 1.99s\n",
      "Epoch: 18, Batch: 260/1676, Loss: 0.3844, Time: 1.97s\n",
      "Epoch: 18, Batch: 270/1676, Loss: 0.7612, Time: 1.98s\n",
      "Epoch: 18, Batch: 280/1676, Loss: 1.1602, Time: 1.98s\n",
      "Epoch: 18, Batch: 290/1676, Loss: 0.4234, Time: 1.98s\n",
      "Epoch: 18, Batch: 300/1676, Loss: 0.4622, Time: 1.98s\n",
      "Epoch: 18, Batch: 310/1676, Loss: 0.7562, Time: 1.98s\n",
      "Epoch: 18, Batch: 320/1676, Loss: 0.8935, Time: 1.99s\n",
      "Epoch: 18, Batch: 330/1676, Loss: 1.1526, Time: 1.99s\n",
      "Epoch: 18, Batch: 340/1676, Loss: 0.6004, Time: 1.99s\n",
      "Epoch: 18, Batch: 350/1676, Loss: 0.8121, Time: 1.99s\n",
      "Epoch: 18, Batch: 360/1676, Loss: 0.6406, Time: 1.98s\n",
      "Epoch: 18, Batch: 370/1676, Loss: 1.2642, Time: 1.99s\n",
      "Epoch: 18, Batch: 380/1676, Loss: 0.2479, Time: 1.99s\n",
      "Epoch: 18, Batch: 390/1676, Loss: 1.0284, Time: 1.99s\n",
      "Epoch: 18, Batch: 400/1676, Loss: 0.3381, Time: 1.99s\n",
      "Epoch: 18, Batch: 410/1676, Loss: 0.8625, Time: 1.98s\n",
      "Epoch: 18, Batch: 420/1676, Loss: 0.8463, Time: 1.99s\n",
      "Epoch: 18, Batch: 430/1676, Loss: 0.4996, Time: 1.99s\n",
      "Epoch: 18, Batch: 440/1676, Loss: 0.7128, Time: 2.00s\n",
      "Epoch: 18, Batch: 450/1676, Loss: 0.9777, Time: 1.98s\n",
      "Epoch: 18, Batch: 460/1676, Loss: 0.6865, Time: 1.98s\n",
      "Epoch: 18, Batch: 470/1676, Loss: 0.6601, Time: 2.00s\n",
      "Epoch: 18, Batch: 480/1676, Loss: 0.6676, Time: 2.00s\n",
      "Epoch: 18, Batch: 490/1676, Loss: 0.5193, Time: 1.99s\n",
      "Epoch: 18, Batch: 500/1676, Loss: 0.5562, Time: 1.99s\n",
      "Epoch: 18, Batch: 510/1676, Loss: 0.4465, Time: 1.99s\n",
      "Epoch: 18, Batch: 520/1676, Loss: 1.2672, Time: 2.00s\n",
      "Epoch: 18, Batch: 530/1676, Loss: 0.6755, Time: 2.01s\n",
      "Epoch: 18, Batch: 540/1676, Loss: 0.3537, Time: 2.00s\n",
      "Epoch: 18, Batch: 550/1676, Loss: 0.6331, Time: 1.99s\n",
      "Epoch: 18, Batch: 560/1676, Loss: 0.5576, Time: 1.99s\n",
      "Epoch: 18, Batch: 570/1676, Loss: 0.3576, Time: 1.99s\n",
      "Epoch: 18, Batch: 580/1676, Loss: 0.3849, Time: 1.99s\n",
      "Epoch: 18, Batch: 590/1676, Loss: 0.8654, Time: 1.99s\n",
      "Epoch: 18, Batch: 600/1676, Loss: 0.4276, Time: 2.00s\n",
      "Epoch: 18, Batch: 610/1676, Loss: 0.7242, Time: 1.99s\n",
      "Epoch: 18, Batch: 620/1676, Loss: 0.2888, Time: 1.99s\n",
      "Epoch: 18, Batch: 630/1676, Loss: 1.1212, Time: 1.99s\n",
      "Epoch: 18, Batch: 640/1676, Loss: 0.2689, Time: 1.99s\n",
      "Epoch: 18, Batch: 650/1676, Loss: 0.3920, Time: 1.99s\n",
      "Epoch: 18, Batch: 660/1676, Loss: 0.6872, Time: 1.99s\n",
      "Epoch: 18, Batch: 670/1676, Loss: 0.4633, Time: 2.00s\n",
      "Epoch: 18, Batch: 680/1676, Loss: 0.9382, Time: 1.99s\n",
      "Epoch: 18, Batch: 690/1676, Loss: 0.7527, Time: 1.99s\n",
      "Epoch: 18, Batch: 700/1676, Loss: 0.4271, Time: 2.00s\n",
      "Epoch: 18, Batch: 710/1676, Loss: 0.6546, Time: 2.00s\n",
      "Epoch: 18, Batch: 720/1676, Loss: 1.0787, Time: 1.99s\n",
      "Epoch: 18, Batch: 730/1676, Loss: 1.0215, Time: 1.99s\n",
      "Epoch: 18, Batch: 740/1676, Loss: 0.7373, Time: 2.01s\n",
      "Epoch: 18, Batch: 750/1676, Loss: 0.7056, Time: 2.01s\n",
      "Epoch: 18, Batch: 760/1676, Loss: 0.7132, Time: 2.01s\n",
      "Epoch: 18, Batch: 770/1676, Loss: 0.3771, Time: 1.99s\n",
      "Epoch: 18, Batch: 780/1676, Loss: 0.4051, Time: 1.99s\n",
      "Epoch: 18, Batch: 790/1676, Loss: 0.6748, Time: 2.00s\n",
      "Epoch: 18, Batch: 800/1676, Loss: 0.5706, Time: 2.00s\n",
      "Epoch: 18, Batch: 810/1676, Loss: 0.4326, Time: 1.99s\n",
      "Epoch: 18, Batch: 820/1676, Loss: 0.6096, Time: 2.00s\n",
      "Epoch: 18, Batch: 830/1676, Loss: 0.6114, Time: 2.00s\n",
      "Epoch: 18, Batch: 840/1676, Loss: 0.9137, Time: 2.00s\n",
      "Epoch: 18, Batch: 850/1676, Loss: 0.3744, Time: 2.01s\n",
      "Epoch: 18, Batch: 860/1676, Loss: 0.5665, Time: 1.99s\n",
      "Epoch: 18, Batch: 870/1676, Loss: 0.3752, Time: 2.00s\n",
      "Epoch: 18, Batch: 880/1676, Loss: 0.7489, Time: 2.01s\n",
      "Epoch: 18, Batch: 890/1676, Loss: 0.8603, Time: 2.00s\n",
      "Epoch: 18, Batch: 900/1676, Loss: 0.4644, Time: 2.00s\n",
      "Epoch: 18, Batch: 910/1676, Loss: 0.6615, Time: 1.99s\n",
      "Epoch: 18, Batch: 920/1676, Loss: 0.2649, Time: 2.00s\n",
      "Epoch: 18, Batch: 930/1676, Loss: 0.4437, Time: 2.00s\n",
      "Epoch: 18, Batch: 940/1676, Loss: 0.9146, Time: 2.00s\n",
      "Epoch: 18, Batch: 950/1676, Loss: 0.7486, Time: 2.00s\n",
      "Epoch: 18, Batch: 960/1676, Loss: 0.5351, Time: 2.01s\n",
      "Epoch: 18, Batch: 970/1676, Loss: 0.7108, Time: 2.01s\n",
      "Epoch: 18, Batch: 980/1676, Loss: 1.0033, Time: 2.00s\n",
      "Epoch: 18, Batch: 990/1676, Loss: 0.5726, Time: 2.00s\n",
      "Epoch: 18, Batch: 1000/1676, Loss: 1.1557, Time: 2.01s\n",
      "Epoch: 18, Batch: 1010/1676, Loss: 0.6493, Time: 2.01s\n",
      "Epoch: 18, Batch: 1020/1676, Loss: 0.4352, Time: 2.00s\n",
      "Epoch: 18, Batch: 1030/1676, Loss: 1.0753, Time: 2.00s\n",
      "Epoch: 18, Batch: 1040/1676, Loss: 1.1137, Time: 2.01s\n",
      "Epoch: 18, Batch: 1050/1676, Loss: 0.8356, Time: 2.00s\n",
      "Epoch: 18, Batch: 1060/1676, Loss: 0.3673, Time: 2.00s\n",
      "Epoch: 18, Batch: 1070/1676, Loss: 0.9866, Time: 2.00s\n",
      "Epoch: 18, Batch: 1080/1676, Loss: 0.3915, Time: 1.99s\n",
      "Epoch: 18, Batch: 1090/1676, Loss: 0.6808, Time: 2.00s\n",
      "Epoch: 18, Batch: 1100/1676, Loss: 0.6186, Time: 1.99s\n",
      "Epoch: 18, Batch: 1110/1676, Loss: 1.2150, Time: 2.00s\n",
      "Epoch: 18, Batch: 1120/1676, Loss: 0.6525, Time: 1.99s\n",
      "Epoch: 18, Batch: 1130/1676, Loss: 1.1566, Time: 2.00s\n",
      "Epoch: 18, Batch: 1140/1676, Loss: 0.7286, Time: 2.01s\n",
      "Epoch: 18, Batch: 1150/1676, Loss: 0.8238, Time: 2.00s\n",
      "Epoch: 18, Batch: 1160/1676, Loss: 0.5126, Time: 2.00s\n",
      "Epoch: 18, Batch: 1170/1676, Loss: 0.7906, Time: 2.00s\n",
      "Epoch: 18, Batch: 1180/1676, Loss: 0.5054, Time: 2.00s\n",
      "Epoch: 18, Batch: 1190/1676, Loss: 0.6305, Time: 2.00s\n",
      "Epoch: 18, Batch: 1200/1676, Loss: 0.8503, Time: 1.99s\n",
      "Epoch: 18, Batch: 1210/1676, Loss: 0.6044, Time: 2.01s\n",
      "Epoch: 18, Batch: 1220/1676, Loss: 1.4385, Time: 2.01s\n",
      "Epoch: 18, Batch: 1230/1676, Loss: 0.5288, Time: 2.01s\n",
      "Epoch: 18, Batch: 1240/1676, Loss: 0.5915, Time: 2.00s\n",
      "Epoch: 18, Batch: 1250/1676, Loss: 0.5341, Time: 1.99s\n",
      "Epoch: 18, Batch: 1260/1676, Loss: 0.8227, Time: 1.98s\n",
      "Epoch: 18, Batch: 1270/1676, Loss: 0.3683, Time: 1.97s\n",
      "Epoch: 18, Batch: 1280/1676, Loss: 0.6138, Time: 1.97s\n",
      "Epoch: 18, Batch: 1290/1676, Loss: 0.5204, Time: 1.97s\n",
      "Epoch: 18, Batch: 1300/1676, Loss: 0.8867, Time: 1.98s\n",
      "Epoch: 18, Batch: 1310/1676, Loss: 0.3955, Time: 1.98s\n",
      "Epoch: 18, Batch: 1320/1676, Loss: 1.5626, Time: 1.97s\n",
      "Epoch: 18, Batch: 1330/1676, Loss: 0.7039, Time: 1.97s\n",
      "Epoch: 18, Batch: 1340/1676, Loss: 0.8080, Time: 1.97s\n",
      "Epoch: 18, Batch: 1350/1676, Loss: 0.6253, Time: 1.97s\n",
      "Epoch: 18, Batch: 1360/1676, Loss: 0.3590, Time: 1.98s\n",
      "Epoch: 18, Batch: 1370/1676, Loss: 0.6488, Time: 1.97s\n",
      "Epoch: 18, Batch: 1380/1676, Loss: 0.9258, Time: 1.97s\n",
      "Epoch: 18, Batch: 1390/1676, Loss: 0.4414, Time: 1.97s\n",
      "Epoch: 18, Batch: 1400/1676, Loss: 0.6200, Time: 1.97s\n",
      "Epoch: 18, Batch: 1410/1676, Loss: 0.4976, Time: 1.97s\n",
      "Epoch: 18, Batch: 1420/1676, Loss: 0.7323, Time: 1.97s\n",
      "Epoch: 18, Batch: 1430/1676, Loss: 0.8850, Time: 1.97s\n",
      "Epoch: 18, Batch: 1440/1676, Loss: 0.9940, Time: 1.97s\n",
      "Epoch: 18, Batch: 1450/1676, Loss: 1.4760, Time: 1.97s\n",
      "Epoch: 18, Batch: 1460/1676, Loss: 0.4798, Time: 1.97s\n",
      "Epoch: 18, Batch: 1470/1676, Loss: 1.0862, Time: 1.98s\n",
      "Epoch: 18, Batch: 1480/1676, Loss: 0.8074, Time: 1.97s\n",
      "Epoch: 18, Batch: 1490/1676, Loss: 0.5802, Time: 1.97s\n",
      "Epoch: 18, Batch: 1500/1676, Loss: 0.8016, Time: 1.97s\n",
      "Epoch: 18, Batch: 1510/1676, Loss: 0.6952, Time: 1.98s\n",
      "Epoch: 18, Batch: 1520/1676, Loss: 0.3232, Time: 1.97s\n",
      "Epoch: 18, Batch: 1530/1676, Loss: 0.8780, Time: 1.97s\n",
      "Epoch: 18, Batch: 1540/1676, Loss: 0.5252, Time: 1.97s\n",
      "Epoch: 18, Batch: 1550/1676, Loss: 0.3703, Time: 1.98s\n",
      "Epoch: 18, Batch: 1560/1676, Loss: 1.3006, Time: 1.97s\n",
      "Epoch: 18, Batch: 1570/1676, Loss: 1.0302, Time: 1.97s\n",
      "Epoch: 18, Batch: 1580/1676, Loss: 0.2482, Time: 1.97s\n",
      "Epoch: 18, Batch: 1590/1676, Loss: 0.8834, Time: 1.97s\n",
      "Epoch: 18, Batch: 1600/1676, Loss: 0.9135, Time: 1.97s\n",
      "Epoch: 18, Batch: 1610/1676, Loss: 1.2105, Time: 1.98s\n",
      "Epoch: 18, Batch: 1620/1676, Loss: 1.1644, Time: 1.97s\n",
      "Epoch: 18, Batch: 1630/1676, Loss: 0.8347, Time: 1.98s\n",
      "Epoch: 18, Batch: 1640/1676, Loss: 0.4267, Time: 1.97s\n",
      "Epoch: 18, Batch: 1650/1676, Loss: 0.7108, Time: 1.97s\n",
      "Epoch: 18, Batch: 1660/1676, Loss: 0.4963, Time: 1.97s\n",
      "Epoch: 18, Batch: 1670/1676, Loss: 1.1074, Time: 1.97s\n",
      "Epoch 19/50: Train Loss: 0.7015, Val Loss: 0.7149, Val IoU: 0.5613, Val Dice: 0.5806\n",
      "Epoch: 19, Batch: 0/1676, Loss: 0.3226, Time: 35.79s\n",
      "Epoch: 19, Batch: 10/1676, Loss: 1.0628, Time: 1.98s\n",
      "Epoch: 19, Batch: 20/1676, Loss: 1.2692, Time: 1.93s\n",
      "Epoch: 19, Batch: 30/1676, Loss: 0.9464, Time: 1.94s\n",
      "Epoch: 19, Batch: 40/1676, Loss: 1.2684, Time: 1.93s\n",
      "Epoch: 19, Batch: 50/1676, Loss: 0.5052, Time: 1.94s\n",
      "Epoch: 19, Batch: 60/1676, Loss: 0.9239, Time: 1.94s\n",
      "Epoch: 19, Batch: 70/1676, Loss: 0.9052, Time: 1.94s\n",
      "Epoch: 19, Batch: 80/1676, Loss: 0.6194, Time: 1.94s\n",
      "Epoch: 19, Batch: 90/1676, Loss: 0.5468, Time: 1.94s\n",
      "Epoch: 19, Batch: 100/1676, Loss: 1.0214, Time: 1.94s\n",
      "Epoch: 19, Batch: 110/1676, Loss: 0.2359, Time: 1.94s\n",
      "Epoch: 19, Batch: 120/1676, Loss: 1.1147, Time: 1.95s\n",
      "Epoch: 19, Batch: 130/1676, Loss: 0.6268, Time: 1.95s\n",
      "Epoch: 19, Batch: 140/1676, Loss: 0.8355, Time: 1.94s\n",
      "Epoch: 19, Batch: 150/1676, Loss: 0.4315, Time: 1.95s\n",
      "Epoch: 19, Batch: 160/1676, Loss: 0.7151, Time: 1.94s\n",
      "Epoch: 19, Batch: 170/1676, Loss: 1.1246, Time: 1.95s\n",
      "Epoch: 19, Batch: 180/1676, Loss: 0.6884, Time: 1.95s\n",
      "Epoch: 19, Batch: 190/1676, Loss: 0.3267, Time: 1.95s\n",
      "Epoch: 19, Batch: 200/1676, Loss: 1.0328, Time: 1.95s\n",
      "Epoch: 19, Batch: 210/1676, Loss: 0.4573, Time: 1.95s\n",
      "Epoch: 19, Batch: 220/1676, Loss: 0.5184, Time: 1.95s\n",
      "Epoch: 19, Batch: 230/1676, Loss: 1.0646, Time: 1.95s\n",
      "Epoch: 19, Batch: 240/1676, Loss: 1.1382, Time: 1.95s\n",
      "Epoch: 19, Batch: 250/1676, Loss: 0.6785, Time: 1.96s\n",
      "Epoch: 19, Batch: 260/1676, Loss: 0.3319, Time: 1.96s\n",
      "Epoch: 19, Batch: 270/1676, Loss: 0.3539, Time: 1.95s\n",
      "Epoch: 19, Batch: 280/1676, Loss: 0.3502, Time: 1.95s\n",
      "Epoch: 19, Batch: 290/1676, Loss: 0.9213, Time: 1.95s\n",
      "Epoch: 19, Batch: 300/1676, Loss: 0.5717, Time: 1.96s\n",
      "Epoch: 19, Batch: 310/1676, Loss: 0.5667, Time: 1.96s\n",
      "Epoch: 19, Batch: 320/1676, Loss: 0.7649, Time: 1.96s\n",
      "Epoch: 19, Batch: 330/1676, Loss: 0.8590, Time: 1.96s\n",
      "Epoch: 19, Batch: 340/1676, Loss: 0.8688, Time: 1.96s\n",
      "Epoch: 19, Batch: 350/1676, Loss: 0.2435, Time: 1.95s\n",
      "Epoch: 19, Batch: 360/1676, Loss: 0.4395, Time: 1.95s\n",
      "Epoch: 19, Batch: 370/1676, Loss: 0.4379, Time: 1.96s\n",
      "Epoch: 19, Batch: 380/1676, Loss: 0.5622, Time: 1.96s\n",
      "Epoch: 19, Batch: 390/1676, Loss: 0.8230, Time: 1.97s\n",
      "Epoch: 19, Batch: 400/1676, Loss: 0.5161, Time: 1.97s\n",
      "Epoch: 19, Batch: 410/1676, Loss: 0.8965, Time: 1.96s\n",
      "Epoch: 19, Batch: 420/1676, Loss: 0.5383, Time: 1.96s\n",
      "Epoch: 19, Batch: 430/1676, Loss: 0.2376, Time: 1.96s\n",
      "Epoch: 19, Batch: 440/1676, Loss: 1.2710, Time: 1.96s\n",
      "Epoch: 19, Batch: 450/1676, Loss: 0.3191, Time: 1.97s\n",
      "Epoch: 19, Batch: 460/1676, Loss: 0.4866, Time: 1.96s\n",
      "Epoch: 19, Batch: 470/1676, Loss: 0.9466, Time: 1.96s\n",
      "Epoch: 19, Batch: 480/1676, Loss: 0.6610, Time: 1.96s\n",
      "Epoch: 19, Batch: 490/1676, Loss: 1.0973, Time: 1.96s\n",
      "Epoch: 19, Batch: 500/1676, Loss: 0.6672, Time: 1.97s\n",
      "Epoch: 19, Batch: 510/1676, Loss: 0.7962, Time: 1.96s\n",
      "Epoch: 19, Batch: 520/1676, Loss: 0.4186, Time: 1.96s\n",
      "Epoch: 19, Batch: 530/1676, Loss: 0.8241, Time: 1.96s\n",
      "Epoch: 19, Batch: 540/1676, Loss: 0.4091, Time: 1.97s\n",
      "Epoch: 19, Batch: 550/1676, Loss: 0.4217, Time: 1.97s\n",
      "Epoch: 19, Batch: 560/1676, Loss: 0.4323, Time: 1.97s\n",
      "Epoch: 19, Batch: 570/1676, Loss: 0.7025, Time: 1.97s\n",
      "Epoch: 19, Batch: 580/1676, Loss: 0.5138, Time: 1.97s\n",
      "Epoch: 19, Batch: 590/1676, Loss: 0.7986, Time: 1.97s\n",
      "Epoch: 19, Batch: 600/1676, Loss: 0.9499, Time: 1.97s\n",
      "Epoch: 19, Batch: 610/1676, Loss: 0.5307, Time: 1.97s\n",
      "Epoch: 19, Batch: 620/1676, Loss: 0.5479, Time: 1.97s\n",
      "Epoch: 19, Batch: 630/1676, Loss: 0.5823, Time: 1.97s\n",
      "Epoch: 19, Batch: 640/1676, Loss: 0.5404, Time: 1.97s\n",
      "Epoch: 19, Batch: 650/1676, Loss: 0.9443, Time: 1.97s\n",
      "Epoch: 19, Batch: 660/1676, Loss: 1.0676, Time: 1.96s\n",
      "Epoch: 19, Batch: 670/1676, Loss: 0.8632, Time: 1.97s\n",
      "Epoch: 19, Batch: 680/1676, Loss: 0.8203, Time: 1.96s\n",
      "Epoch: 19, Batch: 690/1676, Loss: 0.9061, Time: 1.97s\n",
      "Epoch: 19, Batch: 700/1676, Loss: 0.8499, Time: 1.97s\n",
      "Epoch: 19, Batch: 710/1676, Loss: 0.3628, Time: 1.97s\n",
      "Epoch: 19, Batch: 720/1676, Loss: 0.7642, Time: 1.97s\n",
      "Epoch: 19, Batch: 730/1676, Loss: 0.6270, Time: 1.97s\n",
      "Epoch: 19, Batch: 740/1676, Loss: 0.7810, Time: 1.97s\n",
      "Epoch: 19, Batch: 750/1676, Loss: 0.2976, Time: 1.97s\n",
      "Epoch: 19, Batch: 760/1676, Loss: 0.6860, Time: 1.97s\n",
      "Epoch: 19, Batch: 770/1676, Loss: 0.8306, Time: 1.98s\n",
      "Epoch: 19, Batch: 780/1676, Loss: 0.4192, Time: 1.97s\n",
      "Epoch: 19, Batch: 790/1676, Loss: 0.6332, Time: 1.97s\n",
      "Epoch: 19, Batch: 800/1676, Loss: 0.8672, Time: 1.97s\n",
      "Epoch: 19, Batch: 810/1676, Loss: 0.6036, Time: 1.97s\n",
      "Epoch: 19, Batch: 820/1676, Loss: 0.4147, Time: 1.97s\n",
      "Epoch: 19, Batch: 830/1676, Loss: 0.4525, Time: 1.97s\n",
      "Epoch: 19, Batch: 840/1676, Loss: 0.5660, Time: 1.97s\n",
      "Epoch: 19, Batch: 850/1676, Loss: 0.6634, Time: 1.97s\n",
      "Epoch: 19, Batch: 860/1676, Loss: 0.9001, Time: 1.97s\n",
      "Epoch: 19, Batch: 870/1676, Loss: 1.0705, Time: 1.97s\n",
      "Epoch: 19, Batch: 880/1676, Loss: 1.0421, Time: 1.97s\n",
      "Epoch: 19, Batch: 890/1676, Loss: 0.4969, Time: 1.97s\n",
      "Epoch: 19, Batch: 900/1676, Loss: 0.6648, Time: 1.97s\n",
      "Epoch: 19, Batch: 910/1676, Loss: 0.4320, Time: 1.97s\n",
      "Epoch: 19, Batch: 920/1676, Loss: 0.7686, Time: 1.97s\n",
      "Epoch: 19, Batch: 930/1676, Loss: 0.4306, Time: 1.98s\n",
      "Epoch: 19, Batch: 940/1676, Loss: 1.1155, Time: 1.97s\n",
      "Epoch: 19, Batch: 950/1676, Loss: 1.1521, Time: 1.97s\n",
      "Epoch: 19, Batch: 960/1676, Loss: 0.8417, Time: 1.98s\n",
      "Epoch: 19, Batch: 970/1676, Loss: 0.7466, Time: 1.98s\n",
      "Epoch: 19, Batch: 980/1676, Loss: 0.3872, Time: 1.97s\n",
      "Epoch: 19, Batch: 990/1676, Loss: 0.4768, Time: 1.97s\n",
      "Epoch: 19, Batch: 1000/1676, Loss: 0.7396, Time: 1.97s\n",
      "Epoch: 19, Batch: 1010/1676, Loss: 0.9421, Time: 1.97s\n",
      "Epoch: 19, Batch: 1020/1676, Loss: 1.1563, Time: 1.97s\n",
      "Epoch: 19, Batch: 1030/1676, Loss: 0.4688, Time: 1.97s\n",
      "Epoch: 19, Batch: 1040/1676, Loss: 0.9976, Time: 1.98s\n",
      "Epoch: 19, Batch: 1050/1676, Loss: 0.7730, Time: 1.97s\n",
      "Epoch: 19, Batch: 1060/1676, Loss: 0.4485, Time: 1.98s\n",
      "Epoch: 19, Batch: 1070/1676, Loss: 0.5646, Time: 1.97s\n",
      "Epoch: 19, Batch: 1080/1676, Loss: 0.8336, Time: 1.97s\n",
      "Epoch: 19, Batch: 1090/1676, Loss: 0.6712, Time: 1.98s\n",
      "Epoch: 19, Batch: 1100/1676, Loss: 0.4327, Time: 1.97s\n",
      "Epoch: 19, Batch: 1110/1676, Loss: 0.5359, Time: 1.97s\n",
      "Epoch: 19, Batch: 1120/1676, Loss: 0.8254, Time: 1.97s\n",
      "Epoch: 19, Batch: 1130/1676, Loss: 0.8851, Time: 1.97s\n",
      "Epoch: 19, Batch: 1140/1676, Loss: 0.2499, Time: 1.97s\n",
      "Epoch: 19, Batch: 1150/1676, Loss: 0.7871, Time: 1.97s\n",
      "Epoch: 19, Batch: 1160/1676, Loss: 0.2483, Time: 1.97s\n",
      "Epoch: 19, Batch: 1170/1676, Loss: 0.3138, Time: 1.97s\n",
      "Epoch: 19, Batch: 1180/1676, Loss: 0.3339, Time: 1.98s\n",
      "Epoch: 19, Batch: 1190/1676, Loss: 0.9692, Time: 1.97s\n",
      "Epoch: 19, Batch: 1200/1676, Loss: 0.7190, Time: 1.97s\n",
      "Epoch: 19, Batch: 1210/1676, Loss: 0.5343, Time: 1.98s\n",
      "Epoch: 19, Batch: 1220/1676, Loss: 0.7755, Time: 1.97s\n",
      "Epoch: 19, Batch: 1230/1676, Loss: 0.8278, Time: 1.97s\n",
      "Epoch: 19, Batch: 1240/1676, Loss: 0.6943, Time: 1.97s\n",
      "Epoch: 19, Batch: 1250/1676, Loss: 0.6016, Time: 1.97s\n",
      "Epoch: 19, Batch: 1260/1676, Loss: 0.2679, Time: 1.97s\n",
      "Epoch: 19, Batch: 1270/1676, Loss: 0.4087, Time: 1.97s\n",
      "Epoch: 19, Batch: 1280/1676, Loss: 0.9784, Time: 1.98s\n",
      "Epoch: 19, Batch: 1290/1676, Loss: 1.0165, Time: 1.97s\n",
      "Epoch: 19, Batch: 1300/1676, Loss: 0.3783, Time: 1.97s\n",
      "Epoch: 19, Batch: 1310/1676, Loss: 1.2940, Time: 1.97s\n",
      "Epoch: 19, Batch: 1320/1676, Loss: 0.7037, Time: 1.97s\n",
      "Epoch: 19, Batch: 1330/1676, Loss: 0.4343, Time: 1.97s\n",
      "Epoch: 19, Batch: 1340/1676, Loss: 0.6915, Time: 1.97s\n",
      "Epoch: 19, Batch: 1350/1676, Loss: 0.3432, Time: 1.98s\n",
      "Epoch: 19, Batch: 1360/1676, Loss: 0.9116, Time: 1.97s\n",
      "Epoch: 19, Batch: 1370/1676, Loss: 0.6301, Time: 1.97s\n",
      "Epoch: 19, Batch: 1380/1676, Loss: 0.7643, Time: 1.97s\n",
      "Epoch: 19, Batch: 1390/1676, Loss: 0.5408, Time: 1.98s\n",
      "Epoch: 19, Batch: 1400/1676, Loss: 0.3485, Time: 1.98s\n",
      "Epoch: 19, Batch: 1410/1676, Loss: 0.9605, Time: 1.97s\n",
      "Epoch: 19, Batch: 1420/1676, Loss: 0.8301, Time: 1.97s\n",
      "Epoch: 19, Batch: 1430/1676, Loss: 0.8522, Time: 1.98s\n",
      "Epoch: 19, Batch: 1440/1676, Loss: 0.6488, Time: 1.97s\n",
      "Epoch: 19, Batch: 1450/1676, Loss: 0.4300, Time: 1.97s\n",
      "Epoch: 19, Batch: 1460/1676, Loss: 0.5968, Time: 1.97s\n",
      "Epoch: 19, Batch: 1470/1676, Loss: 0.6582, Time: 1.97s\n",
      "Epoch: 19, Batch: 1480/1676, Loss: 0.6585, Time: 1.98s\n",
      "Epoch: 19, Batch: 1490/1676, Loss: 0.3267, Time: 1.98s\n",
      "Epoch: 19, Batch: 1500/1676, Loss: 0.8528, Time: 1.98s\n",
      "Epoch: 19, Batch: 1510/1676, Loss: 0.7263, Time: 1.97s\n",
      "Epoch: 19, Batch: 1520/1676, Loss: 0.3079, Time: 1.98s\n",
      "Epoch: 19, Batch: 1530/1676, Loss: 0.7635, Time: 1.98s\n",
      "Epoch: 19, Batch: 1540/1676, Loss: 1.0421, Time: 1.98s\n",
      "Epoch: 19, Batch: 1550/1676, Loss: 0.7434, Time: 1.97s\n",
      "Epoch: 19, Batch: 1560/1676, Loss: 0.3961, Time: 1.97s\n",
      "Epoch: 19, Batch: 1570/1676, Loss: 0.6515, Time: 1.97s\n",
      "Epoch: 19, Batch: 1580/1676, Loss: 1.4771, Time: 1.98s\n",
      "Epoch: 19, Batch: 1590/1676, Loss: 0.5402, Time: 1.97s\n",
      "Epoch: 19, Batch: 1600/1676, Loss: 0.4635, Time: 1.98s\n",
      "Epoch: 19, Batch: 1610/1676, Loss: 0.5597, Time: 1.98s\n",
      "Epoch: 19, Batch: 1620/1676, Loss: 0.5416, Time: 1.97s\n",
      "Epoch: 19, Batch: 1630/1676, Loss: 0.7121, Time: 1.97s\n",
      "Epoch: 19, Batch: 1640/1676, Loss: 0.3246, Time: 1.97s\n",
      "Epoch: 19, Batch: 1650/1676, Loss: 0.3742, Time: 1.97s\n",
      "Epoch: 19, Batch: 1660/1676, Loss: 0.3562, Time: 1.97s\n",
      "Epoch: 19, Batch: 1670/1676, Loss: 0.5724, Time: 1.97s\n",
      "Epoch 20/50: Train Loss: 0.7025, Val Loss: 0.7226, Val IoU: 0.5583, Val Dice: 0.5779\n",
      "Epoch: 20, Batch: 0/1676, Loss: 0.7396, Time: 35.98s\n",
      "Epoch: 20, Batch: 10/1676, Loss: 0.9871, Time: 1.98s\n",
      "Epoch: 20, Batch: 20/1676, Loss: 0.9118, Time: 1.93s\n",
      "Epoch: 20, Batch: 30/1676, Loss: 0.7763, Time: 1.94s\n",
      "Epoch: 20, Batch: 40/1676, Loss: 0.6546, Time: 1.93s\n",
      "Epoch: 20, Batch: 50/1676, Loss: 0.3041, Time: 1.94s\n",
      "Epoch: 20, Batch: 60/1676, Loss: 0.7933, Time: 1.94s\n",
      "Epoch: 20, Batch: 70/1676, Loss: 0.8961, Time: 1.94s\n",
      "Epoch: 20, Batch: 80/1676, Loss: 0.9530, Time: 1.95s\n",
      "Epoch: 20, Batch: 90/1676, Loss: 0.5868, Time: 1.93s\n",
      "Epoch: 20, Batch: 100/1676, Loss: 0.5029, Time: 1.94s\n",
      "Epoch: 20, Batch: 110/1676, Loss: 0.3131, Time: 1.94s\n",
      "Epoch: 20, Batch: 120/1676, Loss: 0.6095, Time: 1.95s\n",
      "Epoch: 20, Batch: 130/1676, Loss: 1.2108, Time: 1.94s\n",
      "Epoch: 20, Batch: 140/1676, Loss: 0.8237, Time: 1.95s\n",
      "Epoch: 20, Batch: 150/1676, Loss: 0.9585, Time: 1.95s\n",
      "Epoch: 20, Batch: 160/1676, Loss: 0.7264, Time: 1.95s\n",
      "Epoch: 20, Batch: 170/1676, Loss: 1.0162, Time: 1.95s\n",
      "Epoch: 20, Batch: 180/1676, Loss: 0.8531, Time: 1.95s\n",
      "Epoch: 20, Batch: 190/1676, Loss: 1.0784, Time: 1.95s\n",
      "Epoch: 20, Batch: 200/1676, Loss: 1.5190, Time: 1.95s\n",
      "Epoch: 20, Batch: 210/1676, Loss: 0.8083, Time: 1.96s\n",
      "Epoch: 20, Batch: 220/1676, Loss: 0.4180, Time: 1.95s\n",
      "Epoch: 20, Batch: 230/1676, Loss: 0.6851, Time: 1.95s\n",
      "Epoch: 20, Batch: 240/1676, Loss: 0.2267, Time: 1.95s\n",
      "Epoch: 20, Batch: 250/1676, Loss: 0.4138, Time: 1.95s\n",
      "Epoch: 20, Batch: 260/1676, Loss: 0.7486, Time: 1.96s\n",
      "Epoch: 20, Batch: 270/1676, Loss: 0.7800, Time: 1.95s\n",
      "Epoch: 20, Batch: 280/1676, Loss: 1.3800, Time: 1.96s\n",
      "Epoch: 20, Batch: 290/1676, Loss: 0.7579, Time: 1.96s\n",
      "Epoch: 20, Batch: 300/1676, Loss: 0.4879, Time: 1.96s\n",
      "Epoch: 20, Batch: 310/1676, Loss: 1.2225, Time: 1.96s\n",
      "Epoch: 20, Batch: 320/1676, Loss: 0.6310, Time: 1.96s\n",
      "Epoch: 20, Batch: 330/1676, Loss: 1.4052, Time: 1.96s\n",
      "Epoch: 20, Batch: 340/1676, Loss: 0.5897, Time: 1.96s\n",
      "Epoch: 20, Batch: 350/1676, Loss: 0.7689, Time: 1.96s\n",
      "Epoch: 20, Batch: 360/1676, Loss: 0.7581, Time: 1.96s\n",
      "Epoch: 20, Batch: 370/1676, Loss: 0.8537, Time: 1.96s\n",
      "Epoch: 20, Batch: 380/1676, Loss: 1.3164, Time: 1.97s\n",
      "Epoch: 20, Batch: 390/1676, Loss: 1.2388, Time: 1.96s\n",
      "Epoch: 20, Batch: 400/1676, Loss: 0.4105, Time: 1.97s\n",
      "Epoch: 20, Batch: 410/1676, Loss: 1.0803, Time: 1.96s\n",
      "Epoch: 20, Batch: 420/1676, Loss: 0.6384, Time: 1.96s\n",
      "Epoch: 20, Batch: 430/1676, Loss: 0.8301, Time: 1.97s\n",
      "Epoch: 20, Batch: 440/1676, Loss: 1.0630, Time: 1.96s\n",
      "Epoch: 20, Batch: 450/1676, Loss: 0.6019, Time: 1.97s\n",
      "Epoch: 20, Batch: 460/1676, Loss: 0.3336, Time: 1.96s\n",
      "Epoch: 20, Batch: 470/1676, Loss: 1.8267, Time: 1.97s\n",
      "Epoch: 20, Batch: 480/1676, Loss: 0.5812, Time: 1.97s\n",
      "Epoch: 20, Batch: 490/1676, Loss: 1.2411, Time: 1.97s\n",
      "Epoch: 20, Batch: 500/1676, Loss: 0.5851, Time: 1.97s\n",
      "Epoch: 20, Batch: 510/1676, Loss: 0.4880, Time: 1.96s\n",
      "Epoch: 20, Batch: 520/1676, Loss: 0.6251, Time: 1.97s\n",
      "Epoch: 20, Batch: 530/1676, Loss: 0.3486, Time: 1.97s\n",
      "Epoch: 20, Batch: 540/1676, Loss: 1.4829, Time: 1.96s\n",
      "Epoch: 20, Batch: 550/1676, Loss: 0.5611, Time: 1.96s\n",
      "Epoch: 20, Batch: 560/1676, Loss: 0.8322, Time: 1.97s\n",
      "Epoch: 20, Batch: 570/1676, Loss: 0.4636, Time: 1.97s\n",
      "Epoch: 20, Batch: 580/1676, Loss: 0.6358, Time: 1.97s\n",
      "Epoch: 20, Batch: 590/1676, Loss: 0.4965, Time: 1.96s\n",
      "Epoch: 20, Batch: 600/1676, Loss: 0.5087, Time: 1.97s\n",
      "Epoch: 20, Batch: 610/1676, Loss: 0.3755, Time: 1.97s\n",
      "Epoch: 20, Batch: 620/1676, Loss: 0.3769, Time: 1.96s\n",
      "Epoch: 20, Batch: 630/1676, Loss: 0.4328, Time: 1.96s\n",
      "Epoch: 20, Batch: 640/1676, Loss: 0.5019, Time: 1.97s\n",
      "Epoch: 20, Batch: 650/1676, Loss: 0.4913, Time: 1.97s\n",
      "Epoch: 20, Batch: 660/1676, Loss: 0.6797, Time: 1.97s\n",
      "Epoch: 20, Batch: 670/1676, Loss: 0.4396, Time: 1.97s\n",
      "Epoch: 20, Batch: 680/1676, Loss: 0.8646, Time: 1.97s\n",
      "Epoch: 20, Batch: 690/1676, Loss: 0.6125, Time: 1.97s\n",
      "Epoch: 20, Batch: 700/1676, Loss: 0.9927, Time: 1.97s\n",
      "Epoch: 20, Batch: 710/1676, Loss: 1.2275, Time: 1.97s\n",
      "Epoch: 20, Batch: 720/1676, Loss: 0.8786, Time: 1.97s\n",
      "Epoch: 20, Batch: 730/1676, Loss: 0.7383, Time: 1.98s\n",
      "Epoch: 20, Batch: 740/1676, Loss: 0.6117, Time: 1.97s\n",
      "Epoch: 20, Batch: 750/1676, Loss: 0.9614, Time: 1.96s\n",
      "Epoch: 20, Batch: 760/1676, Loss: 0.3921, Time: 1.97s\n",
      "Epoch: 20, Batch: 770/1676, Loss: 0.6611, Time: 1.97s\n",
      "Epoch: 20, Batch: 780/1676, Loss: 0.6730, Time: 1.97s\n",
      "Epoch: 20, Batch: 790/1676, Loss: 0.6533, Time: 1.98s\n",
      "Epoch: 20, Batch: 800/1676, Loss: 0.8881, Time: 1.97s\n",
      "Epoch: 20, Batch: 810/1676, Loss: 0.4009, Time: 1.97s\n",
      "Epoch: 20, Batch: 820/1676, Loss: 0.3215, Time: 1.97s\n",
      "Epoch: 20, Batch: 830/1676, Loss: 0.5776, Time: 1.97s\n",
      "Epoch: 20, Batch: 840/1676, Loss: 0.9376, Time: 1.97s\n",
      "Epoch: 20, Batch: 850/1676, Loss: 0.4312, Time: 1.97s\n",
      "Epoch: 20, Batch: 860/1676, Loss: 0.8388, Time: 1.97s\n",
      "Epoch: 20, Batch: 870/1676, Loss: 0.8157, Time: 1.97s\n",
      "Epoch: 20, Batch: 880/1676, Loss: 1.1782, Time: 1.97s\n",
      "Epoch: 20, Batch: 890/1676, Loss: 1.7413, Time: 1.97s\n",
      "Epoch: 20, Batch: 900/1676, Loss: 0.5958, Time: 1.97s\n",
      "Epoch: 20, Batch: 910/1676, Loss: 0.8743, Time: 1.97s\n",
      "Epoch: 20, Batch: 920/1676, Loss: 0.6519, Time: 1.97s\n",
      "Epoch: 20, Batch: 930/1676, Loss: 0.4774, Time: 1.96s\n",
      "Epoch: 20, Batch: 940/1676, Loss: 0.2780, Time: 1.97s\n",
      "Epoch: 20, Batch: 950/1676, Loss: 0.6715, Time: 1.97s\n",
      "Epoch: 20, Batch: 960/1676, Loss: 0.3644, Time: 1.97s\n",
      "Epoch: 20, Batch: 970/1676, Loss: 0.6539, Time: 1.97s\n",
      "Epoch: 20, Batch: 980/1676, Loss: 0.3301, Time: 1.97s\n",
      "Epoch: 20, Batch: 990/1676, Loss: 0.8234, Time: 1.97s\n",
      "Epoch: 20, Batch: 1000/1676, Loss: 0.4340, Time: 1.97s\n",
      "Epoch: 20, Batch: 1010/1676, Loss: 0.8358, Time: 1.97s\n",
      "Epoch: 20, Batch: 1020/1676, Loss: 0.8031, Time: 1.97s\n",
      "Epoch: 20, Batch: 1030/1676, Loss: 0.7082, Time: 1.97s\n",
      "Epoch: 20, Batch: 1040/1676, Loss: 0.5580, Time: 1.98s\n",
      "Epoch: 20, Batch: 1050/1676, Loss: 0.5183, Time: 1.97s\n",
      "Epoch: 20, Batch: 1060/1676, Loss: 0.4532, Time: 1.97s\n",
      "Epoch: 20, Batch: 1070/1676, Loss: 0.9129, Time: 1.97s\n",
      "Epoch: 20, Batch: 1080/1676, Loss: 0.4579, Time: 1.97s\n",
      "Epoch: 20, Batch: 1090/1676, Loss: 0.6175, Time: 1.97s\n",
      "Epoch: 20, Batch: 1100/1676, Loss: 1.0404, Time: 1.97s\n",
      "Epoch: 20, Batch: 1110/1676, Loss: 0.6109, Time: 1.97s\n",
      "Epoch: 20, Batch: 1120/1676, Loss: 0.9008, Time: 1.98s\n",
      "Epoch: 20, Batch: 1130/1676, Loss: 0.6370, Time: 1.97s\n",
      "Epoch: 20, Batch: 1140/1676, Loss: 0.4375, Time: 1.97s\n",
      "Epoch: 20, Batch: 1150/1676, Loss: 0.8311, Time: 1.97s\n",
      "Epoch: 20, Batch: 1160/1676, Loss: 0.8492, Time: 1.97s\n",
      "Epoch: 20, Batch: 1170/1676, Loss: 0.5792, Time: 1.97s\n",
      "Epoch: 20, Batch: 1180/1676, Loss: 0.3857, Time: 1.97s\n",
      "Epoch: 20, Batch: 1190/1676, Loss: 0.9729, Time: 1.98s\n",
      "Epoch: 20, Batch: 1200/1676, Loss: 1.0915, Time: 1.97s\n",
      "Epoch: 20, Batch: 1210/1676, Loss: 0.9211, Time: 1.97s\n",
      "Epoch: 20, Batch: 1220/1676, Loss: 1.6830, Time: 1.97s\n",
      "Epoch: 20, Batch: 1230/1676, Loss: 0.4993, Time: 1.97s\n",
      "Epoch: 20, Batch: 1240/1676, Loss: 0.6648, Time: 1.97s\n",
      "Epoch: 20, Batch: 1250/1676, Loss: 1.1827, Time: 1.97s\n",
      "Epoch: 20, Batch: 1260/1676, Loss: 0.8314, Time: 1.97s\n",
      "Epoch: 20, Batch: 1270/1676, Loss: 0.4223, Time: 1.97s\n",
      "Epoch: 20, Batch: 1280/1676, Loss: 1.3151, Time: 1.98s\n",
      "Epoch: 20, Batch: 1290/1676, Loss: 0.3565, Time: 1.97s\n",
      "Epoch: 20, Batch: 1300/1676, Loss: 0.4844, Time: 1.97s\n",
      "Epoch: 20, Batch: 1310/1676, Loss: 0.6390, Time: 1.98s\n",
      "Epoch: 20, Batch: 1320/1676, Loss: 0.3699, Time: 1.97s\n",
      "Epoch: 20, Batch: 1330/1676, Loss: 1.0959, Time: 1.97s\n",
      "Epoch: 20, Batch: 1340/1676, Loss: 0.3463, Time: 1.97s\n",
      "Epoch: 20, Batch: 1350/1676, Loss: 0.9242, Time: 1.97s\n",
      "Epoch: 20, Batch: 1360/1676, Loss: 1.0576, Time: 1.97s\n",
      "Epoch: 20, Batch: 1370/1676, Loss: 0.4929, Time: 1.98s\n",
      "Epoch: 20, Batch: 1380/1676, Loss: 0.7705, Time: 1.97s\n",
      "Epoch: 20, Batch: 1390/1676, Loss: 0.6441, Time: 1.98s\n",
      "Epoch: 20, Batch: 1400/1676, Loss: 0.8829, Time: 1.97s\n",
      "Epoch: 20, Batch: 1410/1676, Loss: 1.0321, Time: 1.97s\n",
      "Epoch: 20, Batch: 1420/1676, Loss: 0.5675, Time: 1.97s\n",
      "Epoch: 20, Batch: 1430/1676, Loss: 1.1885, Time: 1.97s\n",
      "Epoch: 20, Batch: 1440/1676, Loss: 0.3073, Time: 1.97s\n",
      "Epoch: 20, Batch: 1450/1676, Loss: 0.9433, Time: 1.98s\n",
      "Epoch: 20, Batch: 1460/1676, Loss: 0.7983, Time: 1.98s\n",
      "Epoch: 20, Batch: 1470/1676, Loss: 0.4675, Time: 1.97s\n",
      "Epoch: 20, Batch: 1480/1676, Loss: 0.5290, Time: 1.98s\n",
      "Epoch: 20, Batch: 1490/1676, Loss: 0.5780, Time: 1.98s\n",
      "Epoch: 20, Batch: 1500/1676, Loss: 0.6719, Time: 1.97s\n",
      "Epoch: 20, Batch: 1510/1676, Loss: 0.4143, Time: 1.97s\n",
      "Epoch: 20, Batch: 1520/1676, Loss: 0.4838, Time: 1.98s\n",
      "Epoch: 20, Batch: 1530/1676, Loss: 0.7952, Time: 1.97s\n",
      "Epoch: 20, Batch: 1540/1676, Loss: 0.2650, Time: 1.97s\n",
      "Epoch: 20, Batch: 1550/1676, Loss: 0.7907, Time: 1.97s\n",
      "Epoch: 20, Batch: 1560/1676, Loss: 1.0420, Time: 1.97s\n",
      "Epoch: 20, Batch: 1570/1676, Loss: 0.5014, Time: 1.97s\n",
      "Epoch: 20, Batch: 1580/1676, Loss: 0.8472, Time: 1.97s\n",
      "Epoch: 20, Batch: 1590/1676, Loss: 0.4648, Time: 1.97s\n",
      "Epoch: 20, Batch: 1600/1676, Loss: 0.3803, Time: 1.98s\n",
      "Epoch: 20, Batch: 1610/1676, Loss: 0.5735, Time: 1.97s\n",
      "Epoch: 20, Batch: 1620/1676, Loss: 0.6269, Time: 1.97s\n",
      "Epoch: 20, Batch: 1630/1676, Loss: 0.5369, Time: 1.97s\n",
      "Epoch: 20, Batch: 1640/1676, Loss: 0.4182, Time: 1.97s\n",
      "Epoch: 20, Batch: 1650/1676, Loss: 0.5528, Time: 1.97s\n",
      "Epoch: 20, Batch: 1660/1676, Loss: 0.6031, Time: 1.98s\n",
      "Epoch: 20, Batch: 1670/1676, Loss: 0.3991, Time: 1.97s\n",
      "Epoch 21/50: Train Loss: 0.6995, Val Loss: 0.7152, Val IoU: 0.5608, Val Dice: 0.5800\n",
      "Epoch: 21, Batch: 0/1676, Loss: 0.4426, Time: 35.92s\n",
      "Epoch: 21, Batch: 10/1676, Loss: 0.6147, Time: 1.98s\n",
      "Epoch: 21, Batch: 20/1676, Loss: 0.4891, Time: 1.93s\n",
      "Epoch: 21, Batch: 30/1676, Loss: 0.7487, Time: 1.94s\n",
      "Epoch: 21, Batch: 40/1676, Loss: 0.8614, Time: 1.93s\n",
      "Epoch: 21, Batch: 50/1676, Loss: 0.7705, Time: 1.93s\n",
      "Epoch: 21, Batch: 60/1676, Loss: 0.6447, Time: 1.93s\n",
      "Epoch: 21, Batch: 70/1676, Loss: 0.2902, Time: 1.94s\n",
      "Epoch: 21, Batch: 80/1676, Loss: 0.8429, Time: 1.94s\n",
      "Epoch: 21, Batch: 90/1676, Loss: 0.2992, Time: 1.94s\n",
      "Epoch: 21, Batch: 100/1676, Loss: 0.5972, Time: 1.94s\n",
      "Epoch: 21, Batch: 110/1676, Loss: 0.4983, Time: 1.94s\n",
      "Epoch: 21, Batch: 120/1676, Loss: 0.5244, Time: 1.94s\n",
      "Epoch: 21, Batch: 130/1676, Loss: 0.3762, Time: 1.94s\n",
      "Epoch: 21, Batch: 140/1676, Loss: 0.4111, Time: 1.95s\n",
      "Epoch: 21, Batch: 150/1676, Loss: 0.3012, Time: 1.94s\n",
      "Epoch: 21, Batch: 160/1676, Loss: 0.6344, Time: 1.94s\n",
      "Epoch: 21, Batch: 170/1676, Loss: 0.8087, Time: 1.95s\n",
      "Epoch: 21, Batch: 180/1676, Loss: 0.8597, Time: 1.94s\n",
      "Epoch: 21, Batch: 190/1676, Loss: 0.6023, Time: 1.95s\n",
      "Epoch: 21, Batch: 200/1676, Loss: 1.1542, Time: 1.95s\n",
      "Epoch: 21, Batch: 210/1676, Loss: 1.1229, Time: 1.95s\n",
      "Epoch: 21, Batch: 220/1676, Loss: 0.6152, Time: 1.96s\n",
      "Epoch: 21, Batch: 230/1676, Loss: 1.1404, Time: 1.95s\n",
      "Epoch: 21, Batch: 240/1676, Loss: 0.4138, Time: 1.95s\n",
      "Epoch: 21, Batch: 250/1676, Loss: 0.3625, Time: 1.95s\n",
      "Epoch: 21, Batch: 260/1676, Loss: 0.5947, Time: 1.96s\n",
      "Epoch: 21, Batch: 270/1676, Loss: 0.3757, Time: 1.95s\n",
      "Epoch: 21, Batch: 280/1676, Loss: 0.4406, Time: 1.96s\n",
      "Epoch: 21, Batch: 290/1676, Loss: 0.8399, Time: 1.95s\n",
      "Epoch: 21, Batch: 300/1676, Loss: 0.7718, Time: 1.95s\n",
      "Epoch: 21, Batch: 310/1676, Loss: 0.4081, Time: 1.96s\n",
      "Epoch: 21, Batch: 320/1676, Loss: 0.8603, Time: 1.95s\n",
      "Epoch: 21, Batch: 330/1676, Loss: 0.3606, Time: 1.95s\n",
      "Epoch: 21, Batch: 340/1676, Loss: 0.6068, Time: 1.96s\n",
      "Epoch: 21, Batch: 350/1676, Loss: 0.6465, Time: 1.96s\n",
      "Epoch: 21, Batch: 360/1676, Loss: 0.6831, Time: 1.96s\n",
      "Epoch: 21, Batch: 370/1676, Loss: 0.7052, Time: 1.96s\n",
      "Epoch: 21, Batch: 380/1676, Loss: 0.7774, Time: 1.95s\n",
      "Epoch: 21, Batch: 390/1676, Loss: 0.8696, Time: 1.96s\n",
      "Epoch: 21, Batch: 400/1676, Loss: 0.3842, Time: 1.96s\n",
      "Epoch: 21, Batch: 410/1676, Loss: 0.3799, Time: 1.95s\n",
      "Epoch: 21, Batch: 420/1676, Loss: 1.1164, Time: 1.96s\n",
      "Epoch: 21, Batch: 430/1676, Loss: 0.8662, Time: 1.97s\n",
      "Epoch: 21, Batch: 440/1676, Loss: 1.0996, Time: 1.96s\n",
      "Epoch: 21, Batch: 450/1676, Loss: 0.4499, Time: 1.96s\n",
      "Epoch: 21, Batch: 460/1676, Loss: 0.6473, Time: 1.96s\n",
      "Epoch: 21, Batch: 470/1676, Loss: 0.5768, Time: 1.96s\n",
      "Epoch: 21, Batch: 480/1676, Loss: 0.7585, Time: 1.96s\n",
      "Epoch: 21, Batch: 490/1676, Loss: 0.3614, Time: 1.96s\n",
      "Epoch: 21, Batch: 500/1676, Loss: 0.5023, Time: 1.97s\n",
      "Epoch: 21, Batch: 510/1676, Loss: 0.4224, Time: 1.96s\n",
      "Epoch: 21, Batch: 520/1676, Loss: 0.5721, Time: 1.97s\n",
      "Epoch: 21, Batch: 530/1676, Loss: 0.7071, Time: 1.96s\n",
      "Epoch: 21, Batch: 540/1676, Loss: 0.6958, Time: 1.96s\n",
      "Epoch: 21, Batch: 550/1676, Loss: 0.4244, Time: 1.96s\n",
      "Epoch: 21, Batch: 560/1676, Loss: 0.5798, Time: 1.97s\n",
      "Epoch: 21, Batch: 570/1676, Loss: 0.6661, Time: 1.97s\n",
      "Epoch: 21, Batch: 580/1676, Loss: 0.3729, Time: 1.97s\n",
      "Epoch: 21, Batch: 590/1676, Loss: 0.6359, Time: 1.96s\n",
      "Epoch: 21, Batch: 600/1676, Loss: 0.5073, Time: 1.96s\n",
      "Epoch: 21, Batch: 610/1676, Loss: 1.1172, Time: 1.96s\n",
      "Epoch: 21, Batch: 620/1676, Loss: 1.1504, Time: 1.96s\n",
      "Epoch: 21, Batch: 630/1676, Loss: 0.9934, Time: 1.97s\n",
      "Epoch: 21, Batch: 640/1676, Loss: 0.9171, Time: 1.96s\n",
      "Epoch: 21, Batch: 650/1676, Loss: 0.6306, Time: 1.97s\n",
      "Epoch: 21, Batch: 660/1676, Loss: 0.7083, Time: 1.96s\n",
      "Epoch: 21, Batch: 670/1676, Loss: 0.7060, Time: 1.97s\n",
      "Epoch: 21, Batch: 680/1676, Loss: 0.9336, Time: 1.96s\n",
      "Epoch: 21, Batch: 690/1676, Loss: 0.7289, Time: 1.96s\n",
      "Epoch: 21, Batch: 700/1676, Loss: 0.4182, Time: 1.97s\n",
      "Epoch: 21, Batch: 710/1676, Loss: 0.2928, Time: 1.97s\n",
      "Epoch: 21, Batch: 720/1676, Loss: 0.4395, Time: 1.97s\n",
      "Epoch: 21, Batch: 730/1676, Loss: 0.7130, Time: 1.97s\n",
      "Epoch: 21, Batch: 740/1676, Loss: 0.3482, Time: 1.97s\n",
      "Epoch: 21, Batch: 750/1676, Loss: 0.4373, Time: 1.98s\n",
      "Epoch: 21, Batch: 760/1676, Loss: 0.6500, Time: 1.97s\n",
      "Epoch: 21, Batch: 770/1676, Loss: 0.9869, Time: 1.97s\n",
      "Epoch: 21, Batch: 780/1676, Loss: 0.7458, Time: 1.97s\n",
      "Epoch: 21, Batch: 790/1676, Loss: 0.6396, Time: 1.96s\n",
      "Epoch: 21, Batch: 800/1676, Loss: 0.6702, Time: 1.97s\n",
      "Epoch: 21, Batch: 810/1676, Loss: 0.6551, Time: 1.97s\n",
      "Epoch: 21, Batch: 820/1676, Loss: 0.7458, Time: 1.97s\n",
      "Epoch: 21, Batch: 830/1676, Loss: 1.3202, Time: 1.97s\n",
      "Epoch: 21, Batch: 840/1676, Loss: 1.1219, Time: 1.97s\n",
      "Epoch: 21, Batch: 850/1676, Loss: 0.9117, Time: 1.97s\n",
      "Epoch: 21, Batch: 860/1676, Loss: 0.8995, Time: 1.97s\n",
      "Epoch: 21, Batch: 870/1676, Loss: 0.9894, Time: 1.96s\n",
      "Epoch: 21, Batch: 880/1676, Loss: 0.5229, Time: 1.97s\n",
      "Epoch: 21, Batch: 890/1676, Loss: 0.8742, Time: 1.97s\n",
      "Epoch: 21, Batch: 900/1676, Loss: 0.7717, Time: 1.97s\n",
      "Epoch: 21, Batch: 910/1676, Loss: 0.5675, Time: 1.96s\n",
      "Epoch: 21, Batch: 920/1676, Loss: 1.1094, Time: 1.97s\n",
      "Epoch: 21, Batch: 930/1676, Loss: 0.4401, Time: 1.97s\n",
      "Epoch: 21, Batch: 940/1676, Loss: 0.7161, Time: 1.97s\n",
      "Epoch: 21, Batch: 950/1676, Loss: 0.8683, Time: 1.97s\n",
      "Epoch: 21, Batch: 960/1676, Loss: 0.5106, Time: 1.97s\n",
      "Epoch: 21, Batch: 970/1676, Loss: 0.7615, Time: 1.97s\n",
      "Epoch: 21, Batch: 980/1676, Loss: 0.8074, Time: 1.97s\n",
      "Epoch: 21, Batch: 990/1676, Loss: 1.0444, Time: 1.96s\n",
      "Epoch: 21, Batch: 1000/1676, Loss: 0.6159, Time: 1.97s\n",
      "Epoch: 21, Batch: 1010/1676, Loss: 0.7218, Time: 1.97s\n",
      "Epoch: 21, Batch: 1020/1676, Loss: 0.9977, Time: 1.97s\n",
      "Epoch: 21, Batch: 1030/1676, Loss: 0.4323, Time: 1.97s\n",
      "Epoch: 21, Batch: 1040/1676, Loss: 0.5908, Time: 1.97s\n",
      "Epoch: 21, Batch: 1050/1676, Loss: 1.0279, Time: 1.97s\n",
      "Epoch: 21, Batch: 1060/1676, Loss: 0.8685, Time: 1.97s\n",
      "Epoch: 21, Batch: 1070/1676, Loss: 0.9372, Time: 1.98s\n",
      "Epoch: 21, Batch: 1080/1676, Loss: 1.0374, Time: 1.97s\n",
      "Epoch: 21, Batch: 1090/1676, Loss: 0.7011, Time: 1.97s\n",
      "Epoch: 21, Batch: 1100/1676, Loss: 0.5571, Time: 1.97s\n",
      "Epoch: 21, Batch: 1110/1676, Loss: 0.2462, Time: 1.97s\n",
      "Epoch: 21, Batch: 1120/1676, Loss: 0.7650, Time: 1.97s\n",
      "Epoch: 21, Batch: 1130/1676, Loss: 0.9100, Time: 1.97s\n",
      "Epoch: 21, Batch: 1140/1676, Loss: 0.5088, Time: 1.97s\n",
      "Epoch: 21, Batch: 1150/1676, Loss: 0.9049, Time: 1.97s\n",
      "Epoch: 21, Batch: 1160/1676, Loss: 1.5793, Time: 1.97s\n",
      "Epoch: 21, Batch: 1170/1676, Loss: 0.8497, Time: 1.98s\n",
      "Epoch: 21, Batch: 1180/1676, Loss: 0.9230, Time: 1.97s\n",
      "Epoch: 21, Batch: 1190/1676, Loss: 1.2547, Time: 1.97s\n",
      "Epoch: 21, Batch: 1200/1676, Loss: 0.6779, Time: 1.97s\n",
      "Epoch: 21, Batch: 1210/1676, Loss: 0.3917, Time: 1.98s\n",
      "Epoch: 21, Batch: 1220/1676, Loss: 0.8798, Time: 1.97s\n",
      "Epoch: 21, Batch: 1230/1676, Loss: 0.7742, Time: 1.97s\n",
      "Epoch: 21, Batch: 1240/1676, Loss: 1.0116, Time: 1.97s\n",
      "Epoch: 21, Batch: 1250/1676, Loss: 0.8953, Time: 1.97s\n",
      "Epoch: 21, Batch: 1260/1676, Loss: 1.2599, Time: 1.98s\n",
      "Epoch: 21, Batch: 1270/1676, Loss: 0.2710, Time: 1.97s\n",
      "Epoch: 21, Batch: 1280/1676, Loss: 0.2831, Time: 1.98s\n",
      "Epoch: 21, Batch: 1290/1676, Loss: 0.8530, Time: 1.97s\n",
      "Epoch: 21, Batch: 1300/1676, Loss: 0.5177, Time: 1.97s\n",
      "Epoch: 21, Batch: 1310/1676, Loss: 0.9649, Time: 1.97s\n",
      "Epoch: 21, Batch: 1320/1676, Loss: 0.7465, Time: 1.98s\n",
      "Epoch: 21, Batch: 1330/1676, Loss: 1.2105, Time: 1.97s\n",
      "Epoch: 21, Batch: 1340/1676, Loss: 0.7764, Time: 1.97s\n",
      "Epoch: 21, Batch: 1350/1676, Loss: 0.7186, Time: 1.97s\n",
      "Epoch: 21, Batch: 1360/1676, Loss: 0.4214, Time: 1.97s\n",
      "Epoch: 21, Batch: 1370/1676, Loss: 0.8935, Time: 1.97s\n",
      "Epoch: 21, Batch: 1380/1676, Loss: 0.3262, Time: 1.97s\n",
      "Epoch: 21, Batch: 1390/1676, Loss: 0.3865, Time: 1.97s\n",
      "Epoch: 21, Batch: 1400/1676, Loss: 0.4050, Time: 1.97s\n",
      "Epoch: 21, Batch: 1410/1676, Loss: 1.1599, Time: 1.97s\n",
      "Epoch: 21, Batch: 1420/1676, Loss: 0.4908, Time: 1.97s\n",
      "Epoch: 21, Batch: 1430/1676, Loss: 0.2951, Time: 1.97s\n",
      "Epoch: 21, Batch: 1440/1676, Loss: 0.3772, Time: 1.97s\n",
      "Epoch: 21, Batch: 1450/1676, Loss: 0.7516, Time: 1.97s\n",
      "Epoch: 21, Batch: 1460/1676, Loss: 0.9113, Time: 1.98s\n",
      "Epoch: 21, Batch: 1470/1676, Loss: 0.9463, Time: 1.97s\n",
      "Epoch: 21, Batch: 1480/1676, Loss: 0.3701, Time: 1.98s\n",
      "Epoch: 21, Batch: 1490/1676, Loss: 0.7698, Time: 1.97s\n",
      "Epoch: 21, Batch: 1500/1676, Loss: 0.3663, Time: 1.97s\n",
      "Epoch: 21, Batch: 1510/1676, Loss: 1.1638, Time: 1.97s\n",
      "Epoch: 21, Batch: 1520/1676, Loss: 0.7314, Time: 1.97s\n",
      "Epoch: 21, Batch: 1530/1676, Loss: 0.3613, Time: 1.97s\n",
      "Epoch: 21, Batch: 1540/1676, Loss: 0.7118, Time: 1.98s\n",
      "Epoch: 21, Batch: 1550/1676, Loss: 0.6728, Time: 1.97s\n",
      "Epoch: 21, Batch: 1560/1676, Loss: 0.5974, Time: 1.98s\n",
      "Epoch: 21, Batch: 1570/1676, Loss: 0.7679, Time: 1.98s\n",
      "Epoch: 21, Batch: 1580/1676, Loss: 1.3212, Time: 1.97s\n",
      "Epoch: 21, Batch: 1590/1676, Loss: 0.3406, Time: 1.98s\n",
      "Epoch: 21, Batch: 1600/1676, Loss: 0.2186, Time: 1.97s\n",
      "Epoch: 21, Batch: 1610/1676, Loss: 0.5224, Time: 1.97s\n",
      "Epoch: 21, Batch: 1620/1676, Loss: 0.6341, Time: 1.97s\n",
      "Epoch: 21, Batch: 1630/1676, Loss: 1.0484, Time: 1.98s\n",
      "Epoch: 21, Batch: 1640/1676, Loss: 1.4478, Time: 1.97s\n",
      "Epoch: 21, Batch: 1650/1676, Loss: 0.8160, Time: 1.97s\n",
      "Epoch: 21, Batch: 1660/1676, Loss: 0.7714, Time: 1.98s\n",
      "Epoch: 21, Batch: 1670/1676, Loss: 0.7265, Time: 1.98s\n",
      "Epoch 22/50: Train Loss: 0.6982, Val Loss: 0.7226, Val IoU: 0.5530, Val Dice: 0.5736\n",
      "Epoch: 22, Batch: 0/1676, Loss: 0.9378, Time: 35.80s\n",
      "Epoch: 22, Batch: 10/1676, Loss: 0.4669, Time: 1.98s\n",
      "Epoch: 22, Batch: 20/1676, Loss: 0.5315, Time: 1.93s\n",
      "Epoch: 22, Batch: 30/1676, Loss: 0.5602, Time: 1.93s\n",
      "Epoch: 22, Batch: 40/1676, Loss: 0.8862, Time: 1.93s\n",
      "Epoch: 22, Batch: 50/1676, Loss: 0.8146, Time: 1.94s\n",
      "Epoch: 22, Batch: 60/1676, Loss: 0.7578, Time: 1.94s\n",
      "Epoch: 22, Batch: 70/1676, Loss: 0.4484, Time: 1.94s\n",
      "Epoch: 22, Batch: 80/1676, Loss: 0.5613, Time: 1.94s\n",
      "Epoch: 22, Batch: 90/1676, Loss: 0.5645, Time: 1.94s\n",
      "Epoch: 22, Batch: 100/1676, Loss: 0.3449, Time: 1.94s\n",
      "Epoch: 22, Batch: 110/1676, Loss: 0.3244, Time: 1.94s\n",
      "Epoch: 22, Batch: 120/1676, Loss: 0.7408, Time: 1.94s\n",
      "Epoch: 22, Batch: 130/1676, Loss: 0.6873, Time: 1.94s\n",
      "Epoch: 22, Batch: 140/1676, Loss: 0.6915, Time: 1.94s\n",
      "Epoch: 22, Batch: 150/1676, Loss: 0.5977, Time: 1.95s\n",
      "Epoch: 22, Batch: 160/1676, Loss: 1.0304, Time: 1.95s\n",
      "Epoch: 22, Batch: 170/1676, Loss: 0.6078, Time: 1.95s\n",
      "Epoch: 22, Batch: 180/1676, Loss: 1.0178, Time: 1.95s\n",
      "Epoch: 22, Batch: 190/1676, Loss: 0.5490, Time: 1.95s\n",
      "Epoch: 22, Batch: 200/1676, Loss: 0.8523, Time: 1.96s\n",
      "Epoch: 22, Batch: 210/1676, Loss: 0.7514, Time: 1.94s\n",
      "Epoch: 22, Batch: 220/1676, Loss: 0.5872, Time: 1.95s\n",
      "Epoch: 22, Batch: 230/1676, Loss: 0.3673, Time: 1.95s\n",
      "Epoch: 22, Batch: 240/1676, Loss: 1.0091, Time: 1.95s\n",
      "Epoch: 22, Batch: 250/1676, Loss: 0.4665, Time: 1.95s\n",
      "Epoch: 22, Batch: 260/1676, Loss: 0.4950, Time: 1.96s\n",
      "Epoch: 22, Batch: 270/1676, Loss: 0.8008, Time: 1.96s\n",
      "Epoch: 22, Batch: 280/1676, Loss: 0.2298, Time: 1.95s\n",
      "Epoch: 22, Batch: 290/1676, Loss: 0.2952, Time: 1.96s\n",
      "Epoch: 22, Batch: 300/1676, Loss: 1.7533, Time: 1.95s\n",
      "Epoch: 22, Batch: 310/1676, Loss: 0.9467, Time: 1.96s\n",
      "Epoch: 22, Batch: 320/1676, Loss: 0.4165, Time: 1.96s\n",
      "Epoch: 22, Batch: 330/1676, Loss: 0.5461, Time: 1.96s\n",
      "Epoch: 22, Batch: 340/1676, Loss: 0.5254, Time: 1.96s\n",
      "Epoch: 22, Batch: 350/1676, Loss: 1.1354, Time: 1.96s\n",
      "Epoch: 22, Batch: 360/1676, Loss: 0.6145, Time: 1.96s\n",
      "Epoch: 22, Batch: 370/1676, Loss: 0.5765, Time: 1.96s\n",
      "Epoch: 22, Batch: 380/1676, Loss: 0.6284, Time: 1.97s\n",
      "Epoch: 22, Batch: 390/1676, Loss: 0.7845, Time: 1.96s\n",
      "Epoch: 22, Batch: 400/1676, Loss: 0.4072, Time: 1.96s\n",
      "Epoch: 22, Batch: 410/1676, Loss: 0.6817, Time: 1.96s\n",
      "Epoch: 22, Batch: 420/1676, Loss: 1.2460, Time: 1.97s\n",
      "Epoch: 22, Batch: 430/1676, Loss: 0.3820, Time: 1.96s\n",
      "Epoch: 22, Batch: 440/1676, Loss: 0.2723, Time: 1.96s\n",
      "Epoch: 22, Batch: 450/1676, Loss: 0.3597, Time: 1.97s\n",
      "Epoch: 22, Batch: 460/1676, Loss: 0.5943, Time: 1.96s\n",
      "Epoch: 22, Batch: 470/1676, Loss: 0.9722, Time: 1.97s\n",
      "Epoch: 22, Batch: 480/1676, Loss: 0.3025, Time: 1.97s\n",
      "Epoch: 22, Batch: 490/1676, Loss: 0.3530, Time: 1.97s\n",
      "Epoch: 22, Batch: 500/1676, Loss: 0.5914, Time: 1.97s\n",
      "Epoch: 22, Batch: 510/1676, Loss: 0.6243, Time: 1.96s\n",
      "Epoch: 22, Batch: 520/1676, Loss: 0.2041, Time: 1.96s\n",
      "Epoch: 22, Batch: 530/1676, Loss: 0.4670, Time: 1.97s\n",
      "Epoch: 22, Batch: 540/1676, Loss: 0.8593, Time: 1.96s\n",
      "Epoch: 22, Batch: 550/1676, Loss: 0.6485, Time: 1.97s\n",
      "Epoch: 22, Batch: 560/1676, Loss: 0.3734, Time: 1.97s\n",
      "Epoch: 22, Batch: 570/1676, Loss: 0.5533, Time: 1.96s\n",
      "Epoch: 22, Batch: 580/1676, Loss: 0.9216, Time: 1.97s\n",
      "Epoch: 22, Batch: 590/1676, Loss: 0.7934, Time: 1.96s\n",
      "Epoch: 22, Batch: 600/1676, Loss: 0.4253, Time: 1.97s\n",
      "Epoch: 22, Batch: 610/1676, Loss: 0.4896, Time: 1.97s\n",
      "Epoch: 22, Batch: 620/1676, Loss: 0.5381, Time: 1.97s\n",
      "Epoch: 22, Batch: 630/1676, Loss: 0.8089, Time: 1.97s\n",
      "Epoch: 22, Batch: 640/1676, Loss: 0.5765, Time: 1.97s\n",
      "Epoch: 22, Batch: 650/1676, Loss: 0.3103, Time: 1.97s\n",
      "Epoch: 22, Batch: 660/1676, Loss: 0.6602, Time: 1.97s\n",
      "Epoch: 22, Batch: 670/1676, Loss: 0.6371, Time: 1.97s\n",
      "Epoch: 22, Batch: 680/1676, Loss: 1.1498, Time: 1.97s\n",
      "Epoch: 22, Batch: 690/1676, Loss: 0.6002, Time: 1.97s\n",
      "Epoch: 22, Batch: 700/1676, Loss: 0.8371, Time: 1.97s\n",
      "Epoch: 22, Batch: 710/1676, Loss: 0.4159, Time: 1.97s\n",
      "Epoch: 22, Batch: 720/1676, Loss: 0.5879, Time: 1.97s\n",
      "Epoch: 22, Batch: 730/1676, Loss: 0.3275, Time: 1.96s\n",
      "Epoch: 22, Batch: 740/1676, Loss: 0.2243, Time: 1.97s\n",
      "Epoch: 22, Batch: 750/1676, Loss: 0.6245, Time: 1.98s\n",
      "Epoch: 22, Batch: 760/1676, Loss: 0.3181, Time: 1.97s\n",
      "Epoch: 22, Batch: 770/1676, Loss: 0.3753, Time: 1.97s\n",
      "Epoch: 22, Batch: 780/1676, Loss: 0.8994, Time: 1.97s\n",
      "Epoch: 22, Batch: 790/1676, Loss: 0.7423, Time: 1.97s\n",
      "Epoch: 22, Batch: 800/1676, Loss: 0.3820, Time: 1.97s\n",
      "Epoch: 22, Batch: 810/1676, Loss: 1.1085, Time: 1.97s\n",
      "Epoch: 22, Batch: 820/1676, Loss: 0.9867, Time: 1.97s\n",
      "Epoch: 22, Batch: 830/1676, Loss: 0.5544, Time: 1.98s\n",
      "Epoch: 22, Batch: 840/1676, Loss: 0.8207, Time: 1.97s\n",
      "Epoch: 22, Batch: 850/1676, Loss: 0.8686, Time: 1.97s\n",
      "Epoch: 22, Batch: 860/1676, Loss: 0.6050, Time: 1.97s\n",
      "Epoch: 22, Batch: 870/1676, Loss: 1.1843, Time: 1.97s\n",
      "Epoch: 22, Batch: 880/1676, Loss: 0.7587, Time: 1.97s\n",
      "Epoch: 22, Batch: 890/1676, Loss: 0.5893, Time: 1.97s\n",
      "Epoch: 22, Batch: 900/1676, Loss: 0.5179, Time: 1.97s\n",
      "Epoch: 22, Batch: 910/1676, Loss: 0.4278, Time: 1.98s\n",
      "Epoch: 22, Batch: 920/1676, Loss: 0.5021, Time: 1.97s\n",
      "Epoch: 22, Batch: 930/1676, Loss: 0.3699, Time: 1.96s\n",
      "Epoch: 22, Batch: 940/1676, Loss: 0.5121, Time: 2.01s\n",
      "Epoch: 22, Batch: 950/1676, Loss: 0.6831, Time: 2.01s\n",
      "Epoch: 22, Batch: 960/1676, Loss: 1.0333, Time: 2.01s\n",
      "Epoch: 22, Batch: 970/1676, Loss: 1.0382, Time: 2.01s\n",
      "Epoch: 22, Batch: 980/1676, Loss: 0.5690, Time: 2.00s\n",
      "Epoch: 22, Batch: 990/1676, Loss: 0.8419, Time: 2.01s\n",
      "Epoch: 22, Batch: 1000/1676, Loss: 0.2815, Time: 2.00s\n",
      "Epoch: 22, Batch: 1010/1676, Loss: 0.4214, Time: 2.01s\n",
      "Epoch: 22, Batch: 1020/1676, Loss: 0.9291, Time: 2.00s\n",
      "Epoch: 22, Batch: 1030/1676, Loss: 0.4557, Time: 2.00s\n",
      "Epoch: 22, Batch: 1040/1676, Loss: 0.9071, Time: 2.01s\n",
      "Epoch: 22, Batch: 1050/1676, Loss: 0.8782, Time: 2.00s\n",
      "Epoch: 22, Batch: 1060/1676, Loss: 0.4304, Time: 2.01s\n",
      "Epoch: 22, Batch: 1070/1676, Loss: 0.4090, Time: 1.97s\n",
      "Epoch: 22, Batch: 1080/1676, Loss: 0.6025, Time: 1.97s\n",
      "Epoch: 22, Batch: 1090/1676, Loss: 0.6351, Time: 1.97s\n",
      "Epoch: 22, Batch: 1100/1676, Loss: 0.6664, Time: 1.97s\n",
      "Epoch: 22, Batch: 1110/1676, Loss: 0.6439, Time: 1.97s\n",
      "Epoch: 22, Batch: 1120/1676, Loss: 0.7365, Time: 1.97s\n",
      "Epoch: 22, Batch: 1130/1676, Loss: 0.7314, Time: 1.97s\n",
      "Epoch: 22, Batch: 1140/1676, Loss: 0.4334, Time: 1.97s\n",
      "Epoch: 22, Batch: 1150/1676, Loss: 0.3678, Time: 1.98s\n",
      "Epoch: 22, Batch: 1160/1676, Loss: 1.1253, Time: 1.97s\n",
      "Epoch: 22, Batch: 1170/1676, Loss: 0.7806, Time: 1.97s\n",
      "Epoch: 22, Batch: 1180/1676, Loss: 0.8197, Time: 1.98s\n",
      "Epoch: 22, Batch: 1190/1676, Loss: 0.4990, Time: 1.97s\n",
      "Epoch: 22, Batch: 1200/1676, Loss: 1.2343, Time: 1.98s\n",
      "Epoch: 22, Batch: 1210/1676, Loss: 0.8277, Time: 1.97s\n",
      "Epoch: 22, Batch: 1220/1676, Loss: 0.8155, Time: 1.97s\n",
      "Epoch: 22, Batch: 1230/1676, Loss: 0.6191, Time: 1.97s\n",
      "Epoch: 22, Batch: 1240/1676, Loss: 0.3339, Time: 1.97s\n",
      "Epoch: 22, Batch: 1250/1676, Loss: 1.0993, Time: 1.97s\n",
      "Epoch: 22, Batch: 1260/1676, Loss: 0.7774, Time: 1.97s\n",
      "Epoch: 22, Batch: 1270/1676, Loss: 0.5227, Time: 1.98s\n",
      "Epoch: 22, Batch: 1280/1676, Loss: 0.4061, Time: 1.97s\n",
      "Epoch: 22, Batch: 1290/1676, Loss: 0.7641, Time: 1.97s\n",
      "Epoch: 22, Batch: 1300/1676, Loss: 1.0304, Time: 1.97s\n",
      "Epoch: 22, Batch: 1310/1676, Loss: 0.9973, Time: 1.98s\n",
      "Epoch: 22, Batch: 1320/1676, Loss: 1.0049, Time: 1.98s\n",
      "Epoch: 22, Batch: 1330/1676, Loss: 0.8482, Time: 1.98s\n",
      "Epoch: 22, Batch: 1340/1676, Loss: 1.1774, Time: 1.97s\n",
      "Epoch: 22, Batch: 1350/1676, Loss: 0.5998, Time: 1.97s\n",
      "Epoch: 22, Batch: 1360/1676, Loss: 0.6539, Time: 1.97s\n",
      "Epoch: 22, Batch: 1370/1676, Loss: 0.7504, Time: 1.97s\n",
      "Epoch: 22, Batch: 1380/1676, Loss: 0.7070, Time: 1.97s\n",
      "Epoch: 22, Batch: 1390/1676, Loss: 0.7843, Time: 1.98s\n",
      "Epoch: 22, Batch: 1400/1676, Loss: 0.3922, Time: 1.97s\n",
      "Epoch: 22, Batch: 1410/1676, Loss: 0.8552, Time: 1.97s\n",
      "Epoch: 22, Batch: 1420/1676, Loss: 0.3925, Time: 1.97s\n",
      "Epoch: 22, Batch: 1430/1676, Loss: 1.1818, Time: 1.98s\n",
      "Epoch: 22, Batch: 1440/1676, Loss: 0.8130, Time: 1.98s\n",
      "Epoch: 22, Batch: 1450/1676, Loss: 1.2928, Time: 1.97s\n",
      "Epoch: 22, Batch: 1460/1676, Loss: 1.0267, Time: 1.97s\n",
      "Epoch: 22, Batch: 1470/1676, Loss: 0.3204, Time: 1.98s\n",
      "Epoch: 22, Batch: 1480/1676, Loss: 1.1999, Time: 1.97s\n",
      "Epoch: 22, Batch: 1490/1676, Loss: 0.5051, Time: 1.97s\n",
      "Epoch: 22, Batch: 1500/1676, Loss: 0.5537, Time: 1.97s\n",
      "Epoch: 22, Batch: 1510/1676, Loss: 0.9420, Time: 1.98s\n",
      "Epoch: 22, Batch: 1520/1676, Loss: 0.3763, Time: 1.97s\n",
      "Epoch: 22, Batch: 1530/1676, Loss: 0.3634, Time: 1.98s\n",
      "Epoch: 22, Batch: 1540/1676, Loss: 0.4047, Time: 1.97s\n",
      "Epoch: 22, Batch: 1550/1676, Loss: 0.7432, Time: 1.98s\n",
      "Epoch: 22, Batch: 1560/1676, Loss: 0.6470, Time: 1.97s\n",
      "Epoch: 22, Batch: 1570/1676, Loss: 0.5859, Time: 1.98s\n",
      "Epoch: 22, Batch: 1580/1676, Loss: 1.4682, Time: 1.97s\n",
      "Epoch: 22, Batch: 1590/1676, Loss: 0.5403, Time: 1.98s\n",
      "Epoch: 22, Batch: 1600/1676, Loss: 0.8650, Time: 1.98s\n",
      "Epoch: 22, Batch: 1610/1676, Loss: 0.2538, Time: 1.97s\n",
      "Epoch: 22, Batch: 1620/1676, Loss: 0.6644, Time: 1.97s\n",
      "Epoch: 22, Batch: 1630/1676, Loss: 1.2833, Time: 1.97s\n",
      "Epoch: 22, Batch: 1640/1676, Loss: 0.7466, Time: 1.98s\n",
      "Epoch: 22, Batch: 1650/1676, Loss: 0.3483, Time: 1.97s\n",
      "Epoch: 22, Batch: 1660/1676, Loss: 0.8751, Time: 1.98s\n",
      "Epoch: 22, Batch: 1670/1676, Loss: 1.2601, Time: 1.97s\n",
      "Epoch 23/50: Train Loss: 0.6972, Val Loss: 0.7071, Val IoU: 0.5627, Val Dice: 0.5820\n",
      "Saving best model with IoU: 0.5627\n",
      "Epoch: 23, Batch: 0/1676, Loss: 1.2080, Time: 36.15s\n",
      "Epoch: 23, Batch: 10/1676, Loss: 0.4201, Time: 1.97s\n",
      "Epoch: 23, Batch: 20/1676, Loss: 0.5247, Time: 1.93s\n",
      "Epoch: 23, Batch: 30/1676, Loss: 0.6471, Time: 1.93s\n",
      "Epoch: 23, Batch: 40/1676, Loss: 0.5299, Time: 1.94s\n",
      "Epoch: 23, Batch: 50/1676, Loss: 0.3388, Time: 1.93s\n",
      "Epoch: 23, Batch: 60/1676, Loss: 0.5526, Time: 1.94s\n",
      "Epoch: 23, Batch: 70/1676, Loss: 0.6666, Time: 1.94s\n",
      "Epoch: 23, Batch: 80/1676, Loss: 0.3755, Time: 1.93s\n",
      "Epoch: 23, Batch: 90/1676, Loss: 0.5556, Time: 1.94s\n",
      "Epoch: 23, Batch: 100/1676, Loss: 0.8448, Time: 1.94s\n",
      "Epoch: 23, Batch: 110/1676, Loss: 0.8763, Time: 1.94s\n",
      "Epoch: 23, Batch: 120/1676, Loss: 0.8338, Time: 1.94s\n",
      "Epoch: 23, Batch: 130/1676, Loss: 0.7069, Time: 1.95s\n",
      "Epoch: 23, Batch: 140/1676, Loss: 0.8601, Time: 1.95s\n",
      "Epoch: 23, Batch: 150/1676, Loss: 0.8133, Time: 1.94s\n",
      "Epoch: 23, Batch: 160/1676, Loss: 0.2651, Time: 1.95s\n",
      "Epoch: 23, Batch: 170/1676, Loss: 0.6945, Time: 1.95s\n",
      "Epoch: 23, Batch: 180/1676, Loss: 0.7376, Time: 1.95s\n",
      "Epoch: 23, Batch: 190/1676, Loss: 0.5621, Time: 1.95s\n",
      "Epoch: 23, Batch: 200/1676, Loss: 0.8141, Time: 1.95s\n",
      "Epoch: 23, Batch: 210/1676, Loss: 0.9108, Time: 1.95s\n",
      "Epoch: 23, Batch: 220/1676, Loss: 0.7159, Time: 1.95s\n",
      "Epoch: 23, Batch: 230/1676, Loss: 0.6441, Time: 1.95s\n",
      "Epoch: 23, Batch: 240/1676, Loss: 0.8082, Time: 1.95s\n",
      "Epoch: 23, Batch: 250/1676, Loss: 0.7973, Time: 1.96s\n",
      "Epoch: 23, Batch: 260/1676, Loss: 0.5396, Time: 1.95s\n",
      "Epoch: 23, Batch: 270/1676, Loss: 0.9515, Time: 1.96s\n",
      "Epoch: 23, Batch: 280/1676, Loss: 0.7931, Time: 1.95s\n",
      "Epoch: 23, Batch: 290/1676, Loss: 0.4897, Time: 1.95s\n",
      "Epoch: 23, Batch: 300/1676, Loss: 0.6281, Time: 1.96s\n",
      "Epoch: 23, Batch: 310/1676, Loss: 0.7393, Time: 1.95s\n",
      "Epoch: 23, Batch: 320/1676, Loss: 0.7783, Time: 1.96s\n",
      "Epoch: 23, Batch: 330/1676, Loss: 0.8134, Time: 1.96s\n",
      "Epoch: 23, Batch: 340/1676, Loss: 0.3969, Time: 1.96s\n",
      "Epoch: 23, Batch: 350/1676, Loss: 0.4791, Time: 1.95s\n",
      "Epoch: 23, Batch: 360/1676, Loss: 0.3570, Time: 1.96s\n",
      "Epoch: 23, Batch: 370/1676, Loss: 0.4520, Time: 1.96s\n",
      "Epoch: 23, Batch: 380/1676, Loss: 0.6262, Time: 1.96s\n",
      "Epoch: 23, Batch: 390/1676, Loss: 0.8478, Time: 1.96s\n",
      "Epoch: 23, Batch: 400/1676, Loss: 0.5903, Time: 1.96s\n",
      "Epoch: 23, Batch: 410/1676, Loss: 0.4503, Time: 1.96s\n",
      "Epoch: 23, Batch: 420/1676, Loss: 0.2857, Time: 1.96s\n",
      "Epoch: 23, Batch: 430/1676, Loss: 0.5131, Time: 1.96s\n",
      "Epoch: 23, Batch: 440/1676, Loss: 0.8232, Time: 1.96s\n",
      "Epoch: 23, Batch: 450/1676, Loss: 0.5751, Time: 1.96s\n",
      "Epoch: 23, Batch: 460/1676, Loss: 0.7351, Time: 1.97s\n",
      "Epoch: 23, Batch: 470/1676, Loss: 0.8034, Time: 1.96s\n",
      "Epoch: 23, Batch: 480/1676, Loss: 0.5970, Time: 1.96s\n",
      "Epoch: 23, Batch: 490/1676, Loss: 0.2243, Time: 1.97s\n",
      "Epoch: 23, Batch: 500/1676, Loss: 0.7983, Time: 1.96s\n",
      "Epoch: 23, Batch: 510/1676, Loss: 0.3836, Time: 1.96s\n",
      "Epoch: 23, Batch: 520/1676, Loss: 0.4809, Time: 1.96s\n",
      "Epoch: 23, Batch: 530/1676, Loss: 0.6690, Time: 1.97s\n",
      "Epoch: 23, Batch: 540/1676, Loss: 0.8709, Time: 1.96s\n",
      "Epoch: 23, Batch: 550/1676, Loss: 0.6679, Time: 1.96s\n",
      "Epoch: 23, Batch: 560/1676, Loss: 0.6999, Time: 1.97s\n",
      "Epoch: 23, Batch: 570/1676, Loss: 1.0424, Time: 1.96s\n",
      "Epoch: 23, Batch: 580/1676, Loss: 0.3613, Time: 1.97s\n",
      "Epoch: 23, Batch: 590/1676, Loss: 0.7343, Time: 1.96s\n",
      "Epoch: 23, Batch: 600/1676, Loss: 0.5320, Time: 1.97s\n",
      "Epoch: 23, Batch: 610/1676, Loss: 0.6443, Time: 1.96s\n",
      "Epoch: 23, Batch: 620/1676, Loss: 0.9947, Time: 1.97s\n",
      "Epoch: 23, Batch: 630/1676, Loss: 0.8030, Time: 1.97s\n",
      "Epoch: 23, Batch: 640/1676, Loss: 0.6363, Time: 1.96s\n",
      "Epoch: 23, Batch: 650/1676, Loss: 1.0459, Time: 1.97s\n",
      "Epoch: 23, Batch: 660/1676, Loss: 0.4919, Time: 1.97s\n",
      "Epoch: 23, Batch: 670/1676, Loss: 0.3087, Time: 1.97s\n",
      "Epoch: 23, Batch: 680/1676, Loss: 0.8105, Time: 1.97s\n",
      "Epoch: 23, Batch: 690/1676, Loss: 0.4876, Time: 1.96s\n",
      "Epoch: 23, Batch: 700/1676, Loss: 0.7468, Time: 1.97s\n",
      "Epoch: 23, Batch: 710/1676, Loss: 0.3338, Time: 1.97s\n",
      "Epoch: 23, Batch: 720/1676, Loss: 1.1095, Time: 1.96s\n",
      "Epoch: 23, Batch: 730/1676, Loss: 0.7601, Time: 1.97s\n",
      "Epoch: 23, Batch: 740/1676, Loss: 0.8942, Time: 1.97s\n",
      "Epoch: 23, Batch: 750/1676, Loss: 0.7073, Time: 1.97s\n",
      "Epoch: 23, Batch: 760/1676, Loss: 0.3948, Time: 1.97s\n",
      "Epoch: 23, Batch: 770/1676, Loss: 0.8273, Time: 1.96s\n",
      "Epoch: 23, Batch: 780/1676, Loss: 0.5585, Time: 1.97s\n",
      "Epoch: 23, Batch: 790/1676, Loss: 0.5556, Time: 1.97s\n",
      "Epoch: 23, Batch: 800/1676, Loss: 1.0642, Time: 1.96s\n",
      "Epoch: 23, Batch: 810/1676, Loss: 0.3286, Time: 1.97s\n",
      "Epoch: 23, Batch: 820/1676, Loss: 0.4290, Time: 1.97s\n",
      "Epoch: 23, Batch: 830/1676, Loss: 0.6036, Time: 1.97s\n",
      "Epoch: 23, Batch: 840/1676, Loss: 0.5607, Time: 1.97s\n",
      "Epoch: 23, Batch: 850/1676, Loss: 0.4286, Time: 1.97s\n",
      "Epoch: 23, Batch: 860/1676, Loss: 0.6861, Time: 1.97s\n",
      "Epoch: 23, Batch: 870/1676, Loss: 0.7610, Time: 1.97s\n",
      "Epoch: 23, Batch: 880/1676, Loss: 0.8940, Time: 1.97s\n",
      "Epoch: 23, Batch: 890/1676, Loss: 0.4648, Time: 1.97s\n",
      "Epoch: 23, Batch: 900/1676, Loss: 0.8131, Time: 1.97s\n",
      "Epoch: 23, Batch: 910/1676, Loss: 0.2659, Time: 1.97s\n",
      "Epoch: 23, Batch: 920/1676, Loss: 0.7361, Time: 1.96s\n",
      "Epoch: 23, Batch: 930/1676, Loss: 0.2635, Time: 1.97s\n",
      "Epoch: 23, Batch: 940/1676, Loss: 1.1523, Time: 1.97s\n",
      "Epoch: 23, Batch: 950/1676, Loss: 0.6378, Time: 1.97s\n",
      "Epoch: 23, Batch: 960/1676, Loss: 0.9383, Time: 1.97s\n",
      "Epoch: 23, Batch: 970/1676, Loss: 1.0692, Time: 1.97s\n",
      "Epoch: 23, Batch: 980/1676, Loss: 0.2896, Time: 1.97s\n",
      "Epoch: 23, Batch: 990/1676, Loss: 1.1012, Time: 1.97s\n",
      "Epoch: 23, Batch: 1000/1676, Loss: 0.6780, Time: 1.97s\n",
      "Epoch: 23, Batch: 1010/1676, Loss: 0.5912, Time: 1.97s\n",
      "Epoch: 23, Batch: 1020/1676, Loss: 0.2916, Time: 1.97s\n",
      "Epoch: 23, Batch: 1030/1676, Loss: 0.5058, Time: 1.97s\n",
      "Epoch: 23, Batch: 1040/1676, Loss: 0.2739, Time: 1.98s\n",
      "Epoch: 23, Batch: 1050/1676, Loss: 2.0410, Time: 1.97s\n",
      "Epoch: 23, Batch: 1060/1676, Loss: 0.5504, Time: 1.98s\n",
      "Epoch: 23, Batch: 1070/1676, Loss: 1.2987, Time: 1.97s\n",
      "Epoch: 23, Batch: 1080/1676, Loss: 0.7105, Time: 1.97s\n",
      "Epoch: 23, Batch: 1090/1676, Loss: 0.4539, Time: 1.97s\n",
      "Epoch: 23, Batch: 1100/1676, Loss: 0.5293, Time: 1.97s\n",
      "Epoch: 23, Batch: 1110/1676, Loss: 0.6236, Time: 1.97s\n",
      "Epoch: 23, Batch: 1120/1676, Loss: 0.4839, Time: 1.97s\n",
      "Epoch: 23, Batch: 1130/1676, Loss: 0.5668, Time: 1.97s\n",
      "Epoch: 23, Batch: 1140/1676, Loss: 1.3138, Time: 1.98s\n",
      "Epoch: 23, Batch: 1150/1676, Loss: 0.4929, Time: 1.97s\n",
      "Epoch: 23, Batch: 1160/1676, Loss: 0.9752, Time: 1.97s\n",
      "Epoch: 23, Batch: 1170/1676, Loss: 0.5029, Time: 1.97s\n",
      "Epoch: 23, Batch: 1180/1676, Loss: 0.8537, Time: 1.98s\n",
      "Epoch: 23, Batch: 1190/1676, Loss: 0.3411, Time: 1.97s\n",
      "Epoch: 23, Batch: 1200/1676, Loss: 1.3839, Time: 1.97s\n",
      "Epoch: 23, Batch: 1210/1676, Loss: 0.4314, Time: 1.97s\n",
      "Epoch: 23, Batch: 1220/1676, Loss: 0.6751, Time: 1.97s\n",
      "Epoch: 23, Batch: 1230/1676, Loss: 0.9511, Time: 1.97s\n",
      "Epoch: 23, Batch: 1240/1676, Loss: 0.4271, Time: 1.97s\n",
      "Epoch: 23, Batch: 1250/1676, Loss: 0.6682, Time: 1.97s\n",
      "Epoch: 23, Batch: 1260/1676, Loss: 0.5414, Time: 1.97s\n",
      "Epoch: 23, Batch: 1270/1676, Loss: 0.7663, Time: 1.97s\n",
      "Epoch: 23, Batch: 1280/1676, Loss: 0.6810, Time: 1.97s\n",
      "Epoch: 23, Batch: 1290/1676, Loss: 0.6793, Time: 1.96s\n",
      "Epoch: 23, Batch: 1300/1676, Loss: 0.8729, Time: 1.98s\n",
      "Epoch: 23, Batch: 1310/1676, Loss: 0.8392, Time: 1.97s\n",
      "Epoch: 23, Batch: 1320/1676, Loss: 1.5802, Time: 1.97s\n",
      "Epoch: 23, Batch: 1330/1676, Loss: 0.6890, Time: 1.97s\n",
      "Epoch: 23, Batch: 1340/1676, Loss: 0.8066, Time: 1.98s\n",
      "Epoch: 23, Batch: 1350/1676, Loss: 0.7622, Time: 1.97s\n",
      "Epoch: 23, Batch: 1360/1676, Loss: 0.4397, Time: 1.97s\n",
      "Epoch: 23, Batch: 1370/1676, Loss: 0.8369, Time: 1.97s\n",
      "Epoch: 23, Batch: 1380/1676, Loss: 0.3664, Time: 1.97s\n",
      "Epoch: 23, Batch: 1390/1676, Loss: 0.9295, Time: 1.97s\n",
      "Epoch: 23, Batch: 1400/1676, Loss: 0.4460, Time: 1.97s\n",
      "Epoch: 23, Batch: 1410/1676, Loss: 1.2814, Time: 1.97s\n",
      "Epoch: 23, Batch: 1420/1676, Loss: 0.3235, Time: 1.97s\n",
      "Epoch: 23, Batch: 1430/1676, Loss: 0.6114, Time: 1.98s\n",
      "Epoch: 23, Batch: 1440/1676, Loss: 0.7300, Time: 1.97s\n",
      "Epoch: 23, Batch: 1450/1676, Loss: 0.9777, Time: 1.97s\n",
      "Epoch: 23, Batch: 1460/1676, Loss: 0.6227, Time: 1.98s\n",
      "Epoch: 23, Batch: 1470/1676, Loss: 0.9853, Time: 1.97s\n",
      "Epoch: 23, Batch: 1480/1676, Loss: 0.4713, Time: 1.97s\n",
      "Epoch: 23, Batch: 1490/1676, Loss: 0.3202, Time: 1.97s\n",
      "Epoch: 23, Batch: 1500/1676, Loss: 0.6500, Time: 1.97s\n",
      "Epoch: 23, Batch: 1510/1676, Loss: 0.2723, Time: 1.97s\n",
      "Epoch: 23, Batch: 1520/1676, Loss: 0.2188, Time: 1.97s\n",
      "Epoch: 23, Batch: 1530/1676, Loss: 0.3808, Time: 1.97s\n",
      "Epoch: 23, Batch: 1540/1676, Loss: 0.6049, Time: 1.97s\n",
      "Epoch: 23, Batch: 1550/1676, Loss: 0.4912, Time: 1.97s\n",
      "Epoch: 23, Batch: 1560/1676, Loss: 0.7047, Time: 1.97s\n",
      "Epoch: 23, Batch: 1570/1676, Loss: 0.3869, Time: 1.97s\n",
      "Epoch: 23, Batch: 1580/1676, Loss: 0.8879, Time: 1.97s\n",
      "Epoch: 23, Batch: 1590/1676, Loss: 0.4282, Time: 1.97s\n",
      "Epoch: 23, Batch: 1600/1676, Loss: 0.7654, Time: 1.97s\n",
      "Epoch: 23, Batch: 1610/1676, Loss: 0.8735, Time: 1.97s\n",
      "Epoch: 23, Batch: 1620/1676, Loss: 0.5857, Time: 1.97s\n",
      "Epoch: 23, Batch: 1630/1676, Loss: 0.7473, Time: 1.97s\n",
      "Epoch: 23, Batch: 1640/1676, Loss: 0.6984, Time: 1.97s\n",
      "Epoch: 23, Batch: 1650/1676, Loss: 0.7945, Time: 1.97s\n",
      "Epoch: 23, Batch: 1660/1676, Loss: 0.2474, Time: 1.98s\n",
      "Epoch: 23, Batch: 1670/1676, Loss: 0.5577, Time: 1.98s\n",
      "Epoch 24/50: Train Loss: 0.6886, Val Loss: 0.6971, Val IoU: 0.5603, Val Dice: 0.5802\n",
      "Epoch: 24, Batch: 0/1676, Loss: 0.8709, Time: 35.89s\n",
      "Epoch: 24, Batch: 10/1676, Loss: 0.6184, Time: 1.97s\n",
      "Epoch: 24, Batch: 20/1676, Loss: 0.6192, Time: 1.93s\n",
      "Epoch: 24, Batch: 30/1676, Loss: 0.5383, Time: 1.92s\n",
      "Epoch: 24, Batch: 40/1676, Loss: 0.9326, Time: 1.93s\n",
      "Epoch: 24, Batch: 50/1676, Loss: 0.6826, Time: 1.94s\n",
      "Epoch: 24, Batch: 60/1676, Loss: 0.4537, Time: 1.93s\n",
      "Epoch: 24, Batch: 70/1676, Loss: 0.6076, Time: 1.94s\n",
      "Epoch: 24, Batch: 80/1676, Loss: 0.4742, Time: 1.93s\n",
      "Epoch: 24, Batch: 90/1676, Loss: 0.3906, Time: 1.94s\n",
      "Epoch: 24, Batch: 100/1676, Loss: 0.7769, Time: 1.94s\n",
      "Epoch: 24, Batch: 110/1676, Loss: 0.4695, Time: 1.94s\n",
      "Epoch: 24, Batch: 120/1676, Loss: 0.6054, Time: 1.94s\n",
      "Epoch: 24, Batch: 130/1676, Loss: 0.9572, Time: 1.94s\n",
      "Epoch: 24, Batch: 140/1676, Loss: 1.1140, Time: 1.95s\n",
      "Epoch: 24, Batch: 150/1676, Loss: 0.7976, Time: 1.95s\n",
      "Epoch: 24, Batch: 160/1676, Loss: 0.4968, Time: 1.94s\n",
      "Epoch: 24, Batch: 170/1676, Loss: 0.6242, Time: 1.95s\n",
      "Epoch: 24, Batch: 180/1676, Loss: 0.9282, Time: 1.94s\n",
      "Epoch: 24, Batch: 190/1676, Loss: 0.4401, Time: 1.95s\n",
      "Epoch: 24, Batch: 200/1676, Loss: 0.3584, Time: 1.94s\n",
      "Epoch: 24, Batch: 210/1676, Loss: 0.6276, Time: 1.95s\n",
      "Epoch: 24, Batch: 220/1676, Loss: 0.6286, Time: 1.96s\n",
      "Epoch: 24, Batch: 230/1676, Loss: 1.1245, Time: 1.95s\n",
      "Epoch: 24, Batch: 240/1676, Loss: 0.9561, Time: 1.95s\n",
      "Epoch: 24, Batch: 250/1676, Loss: 0.7581, Time: 1.95s\n",
      "Epoch: 24, Batch: 260/1676, Loss: 0.5095, Time: 1.95s\n",
      "Epoch: 24, Batch: 270/1676, Loss: 0.6399, Time: 1.95s\n",
      "Epoch: 24, Batch: 280/1676, Loss: 0.7249, Time: 1.96s\n",
      "Epoch: 24, Batch: 290/1676, Loss: 0.7137, Time: 1.95s\n",
      "Epoch: 24, Batch: 300/1676, Loss: 0.5513, Time: 1.96s\n",
      "Epoch: 24, Batch: 310/1676, Loss: 0.4625, Time: 1.96s\n",
      "Epoch: 24, Batch: 320/1676, Loss: 0.8548, Time: 1.95s\n",
      "Epoch: 24, Batch: 330/1676, Loss: 0.9126, Time: 1.96s\n",
      "Epoch: 24, Batch: 340/1676, Loss: 0.3527, Time: 1.96s\n",
      "Epoch: 24, Batch: 350/1676, Loss: 0.8045, Time: 1.96s\n",
      "Epoch: 24, Batch: 360/1676, Loss: 0.7650, Time: 1.96s\n",
      "Epoch: 24, Batch: 370/1676, Loss: 1.0112, Time: 1.95s\n",
      "Epoch: 24, Batch: 380/1676, Loss: 1.0586, Time: 1.96s\n",
      "Epoch: 24, Batch: 390/1676, Loss: 0.5091, Time: 1.95s\n",
      "Epoch: 24, Batch: 400/1676, Loss: 0.8239, Time: 1.96s\n",
      "Epoch: 24, Batch: 410/1676, Loss: 0.9886, Time: 1.96s\n",
      "Epoch: 24, Batch: 420/1676, Loss: 0.5177, Time: 1.96s\n",
      "Epoch: 24, Batch: 430/1676, Loss: 0.8781, Time: 1.96s\n",
      "Epoch: 24, Batch: 440/1676, Loss: 0.4546, Time: 1.96s\n",
      "Epoch: 24, Batch: 450/1676, Loss: 1.5308, Time: 1.96s\n",
      "Epoch: 24, Batch: 460/1676, Loss: 0.6392, Time: 1.96s\n",
      "Epoch: 24, Batch: 470/1676, Loss: 0.3510, Time: 1.96s\n",
      "Epoch: 24, Batch: 480/1676, Loss: 0.7614, Time: 1.96s\n",
      "Epoch: 24, Batch: 490/1676, Loss: 0.6760, Time: 1.97s\n",
      "Epoch: 24, Batch: 500/1676, Loss: 0.6118, Time: 1.96s\n",
      "Epoch: 24, Batch: 510/1676, Loss: 1.3118, Time: 1.97s\n",
      "Epoch: 24, Batch: 520/1676, Loss: 0.5117, Time: 1.96s\n",
      "Epoch: 24, Batch: 530/1676, Loss: 0.5605, Time: 1.97s\n",
      "Epoch: 24, Batch: 540/1676, Loss: 0.6683, Time: 1.96s\n",
      "Epoch: 24, Batch: 550/1676, Loss: 0.4357, Time: 1.96s\n",
      "Epoch: 24, Batch: 560/1676, Loss: 0.8449, Time: 1.97s\n",
      "Epoch: 24, Batch: 570/1676, Loss: 0.8296, Time: 1.97s\n",
      "Epoch: 24, Batch: 580/1676, Loss: 0.5258, Time: 1.97s\n",
      "Epoch: 24, Batch: 590/1676, Loss: 0.4979, Time: 1.96s\n",
      "Epoch: 24, Batch: 600/1676, Loss: 0.4419, Time: 1.97s\n",
      "Epoch: 24, Batch: 610/1676, Loss: 0.5884, Time: 1.96s\n",
      "Epoch: 24, Batch: 620/1676, Loss: 0.6046, Time: 1.97s\n",
      "Epoch: 24, Batch: 630/1676, Loss: 0.6356, Time: 1.97s\n",
      "Epoch: 24, Batch: 640/1676, Loss: 0.7952, Time: 1.97s\n",
      "Epoch: 24, Batch: 650/1676, Loss: 0.2678, Time: 1.96s\n",
      "Epoch: 24, Batch: 660/1676, Loss: 1.3860, Time: 1.96s\n",
      "Epoch: 24, Batch: 670/1676, Loss: 0.3627, Time: 1.97s\n",
      "Epoch: 24, Batch: 680/1676, Loss: 0.3899, Time: 1.97s\n",
      "Epoch: 24, Batch: 690/1676, Loss: 0.3596, Time: 1.96s\n",
      "Epoch: 24, Batch: 700/1676, Loss: 1.9309, Time: 1.97s\n",
      "Epoch: 24, Batch: 710/1676, Loss: 0.5091, Time: 1.97s\n",
      "Epoch: 24, Batch: 720/1676, Loss: 0.8095, Time: 1.97s\n",
      "Epoch: 24, Batch: 730/1676, Loss: 0.7126, Time: 1.96s\n",
      "Epoch: 24, Batch: 740/1676, Loss: 0.5428, Time: 1.97s\n",
      "Epoch: 24, Batch: 750/1676, Loss: 0.5607, Time: 1.97s\n",
      "Epoch: 24, Batch: 760/1676, Loss: 0.6603, Time: 1.97s\n",
      "Epoch: 24, Batch: 770/1676, Loss: 0.6544, Time: 1.97s\n",
      "Epoch: 24, Batch: 780/1676, Loss: 0.9909, Time: 1.97s\n",
      "Epoch: 24, Batch: 790/1676, Loss: 0.4473, Time: 1.96s\n",
      "Epoch: 24, Batch: 800/1676, Loss: 0.4716, Time: 1.97s\n",
      "Epoch: 24, Batch: 810/1676, Loss: 0.7501, Time: 1.97s\n",
      "Epoch: 24, Batch: 820/1676, Loss: 0.5373, Time: 1.97s\n",
      "Epoch: 24, Batch: 830/1676, Loss: 0.7977, Time: 1.97s\n",
      "Epoch: 24, Batch: 840/1676, Loss: 0.7843, Time: 1.97s\n",
      "Epoch: 24, Batch: 850/1676, Loss: 1.3277, Time: 1.97s\n",
      "Epoch: 24, Batch: 860/1676, Loss: 0.3189, Time: 1.97s\n",
      "Epoch: 24, Batch: 870/1676, Loss: 0.6373, Time: 1.97s\n",
      "Epoch: 24, Batch: 880/1676, Loss: 1.2649, Time: 1.96s\n",
      "Epoch: 24, Batch: 890/1676, Loss: 0.6503, Time: 1.97s\n",
      "Epoch: 24, Batch: 900/1676, Loss: 0.7492, Time: 1.97s\n",
      "Epoch: 24, Batch: 910/1676, Loss: 0.4126, Time: 1.96s\n",
      "Epoch: 24, Batch: 920/1676, Loss: 0.6300, Time: 1.97s\n",
      "Epoch: 24, Batch: 930/1676, Loss: 0.5074, Time: 1.98s\n",
      "Epoch: 24, Batch: 940/1676, Loss: 0.6112, Time: 1.97s\n",
      "Epoch: 24, Batch: 950/1676, Loss: 0.6846, Time: 1.97s\n",
      "Epoch: 24, Batch: 960/1676, Loss: 0.7292, Time: 1.97s\n",
      "Epoch: 24, Batch: 970/1676, Loss: 0.2236, Time: 1.97s\n",
      "Epoch: 24, Batch: 980/1676, Loss: 0.5112, Time: 1.97s\n",
      "Epoch: 24, Batch: 990/1676, Loss: 0.5612, Time: 1.96s\n",
      "Epoch: 24, Batch: 1000/1676, Loss: 0.6762, Time: 1.97s\n",
      "Epoch: 24, Batch: 1010/1676, Loss: 0.6510, Time: 1.97s\n",
      "Epoch: 24, Batch: 1020/1676, Loss: 0.6544, Time: 1.97s\n",
      "Epoch: 24, Batch: 1030/1676, Loss: 0.4642, Time: 1.96s\n",
      "Epoch: 24, Batch: 1040/1676, Loss: 0.4482, Time: 1.98s\n",
      "Epoch: 24, Batch: 1050/1676, Loss: 0.2667, Time: 1.97s\n",
      "Epoch: 24, Batch: 1060/1676, Loss: 1.1343, Time: 1.97s\n",
      "Epoch: 24, Batch: 1070/1676, Loss: 0.3332, Time: 1.97s\n",
      "Epoch: 24, Batch: 1080/1676, Loss: 0.6568, Time: 1.97s\n",
      "Epoch: 24, Batch: 1090/1676, Loss: 0.7041, Time: 1.97s\n",
      "Epoch: 24, Batch: 1100/1676, Loss: 0.6661, Time: 1.97s\n",
      "Epoch: 24, Batch: 1110/1676, Loss: 0.9808, Time: 1.97s\n",
      "Epoch: 24, Batch: 1120/1676, Loss: 0.6535, Time: 1.97s\n",
      "Epoch: 24, Batch: 1130/1676, Loss: 0.7138, Time: 1.97s\n",
      "Epoch: 24, Batch: 1140/1676, Loss: 0.4993, Time: 1.97s\n",
      "Epoch: 24, Batch: 1150/1676, Loss: 0.3500, Time: 1.97s\n",
      "Epoch: 24, Batch: 1160/1676, Loss: 0.6034, Time: 1.98s\n",
      "Epoch: 24, Batch: 1170/1676, Loss: 1.5501, Time: 1.97s\n",
      "Epoch: 24, Batch: 1180/1676, Loss: 0.5996, Time: 1.96s\n",
      "Epoch: 24, Batch: 1190/1676, Loss: 0.8860, Time: 1.97s\n",
      "Epoch: 24, Batch: 1200/1676, Loss: 0.4477, Time: 1.97s\n",
      "Epoch: 24, Batch: 1210/1676, Loss: 0.5271, Time: 1.98s\n",
      "Epoch: 24, Batch: 1220/1676, Loss: 0.6653, Time: 1.97s\n",
      "Epoch: 24, Batch: 1230/1676, Loss: 0.6155, Time: 1.96s\n",
      "Epoch: 24, Batch: 1240/1676, Loss: 0.2283, Time: 1.97s\n",
      "Epoch: 24, Batch: 1250/1676, Loss: 0.9817, Time: 1.97s\n",
      "Epoch: 24, Batch: 1260/1676, Loss: 0.9034, Time: 1.97s\n",
      "Epoch: 24, Batch: 1270/1676, Loss: 0.6386, Time: 1.97s\n",
      "Epoch: 24, Batch: 1280/1676, Loss: 0.5621, Time: 1.97s\n",
      "Epoch: 24, Batch: 1290/1676, Loss: 1.0737, Time: 1.97s\n",
      "Epoch: 24, Batch: 1300/1676, Loss: 0.5624, Time: 1.97s\n",
      "Epoch: 24, Batch: 1310/1676, Loss: 0.7535, Time: 1.97s\n",
      "Epoch: 24, Batch: 1320/1676, Loss: 0.3131, Time: 1.98s\n",
      "Epoch: 24, Batch: 1330/1676, Loss: 0.8525, Time: 1.98s\n",
      "Epoch: 24, Batch: 1340/1676, Loss: 0.7229, Time: 1.97s\n",
      "Epoch: 24, Batch: 1350/1676, Loss: 0.3474, Time: 1.98s\n",
      "Epoch: 24, Batch: 1360/1676, Loss: 1.2162, Time: 1.97s\n",
      "Epoch: 24, Batch: 1370/1676, Loss: 0.3612, Time: 1.98s\n",
      "Epoch: 24, Batch: 1380/1676, Loss: 1.0917, Time: 1.97s\n",
      "Epoch: 24, Batch: 1390/1676, Loss: 0.4143, Time: 1.97s\n",
      "Epoch: 24, Batch: 1400/1676, Loss: 0.9028, Time: 1.97s\n",
      "Epoch: 24, Batch: 1410/1676, Loss: 0.5888, Time: 1.97s\n",
      "Epoch: 24, Batch: 1420/1676, Loss: 0.4257, Time: 1.97s\n",
      "Epoch: 24, Batch: 1430/1676, Loss: 0.3464, Time: 1.97s\n",
      "Epoch: 24, Batch: 1440/1676, Loss: 0.5325, Time: 1.98s\n",
      "Epoch: 24, Batch: 1450/1676, Loss: 0.7922, Time: 1.97s\n",
      "Epoch: 24, Batch: 1460/1676, Loss: 1.0809, Time: 1.97s\n",
      "Epoch: 24, Batch: 1470/1676, Loss: 0.3367, Time: 1.96s\n",
      "Epoch: 24, Batch: 1480/1676, Loss: 0.6906, Time: 1.98s\n",
      "Epoch: 24, Batch: 1490/1676, Loss: 0.5939, Time: 1.97s\n",
      "Epoch: 24, Batch: 1500/1676, Loss: 0.5058, Time: 1.97s\n",
      "Epoch: 24, Batch: 1510/1676, Loss: 0.3498, Time: 1.97s\n",
      "Epoch: 24, Batch: 1520/1676, Loss: 0.5354, Time: 1.97s\n",
      "Epoch: 24, Batch: 1530/1676, Loss: 1.0395, Time: 1.97s\n",
      "Epoch: 24, Batch: 1540/1676, Loss: 0.8814, Time: 1.97s\n",
      "Epoch: 24, Batch: 1550/1676, Loss: 1.0563, Time: 1.97s\n",
      "Epoch: 24, Batch: 1560/1676, Loss: 0.7964, Time: 1.97s\n",
      "Epoch: 24, Batch: 1570/1676, Loss: 0.8148, Time: 1.97s\n",
      "Epoch: 24, Batch: 1580/1676, Loss: 0.8072, Time: 1.97s\n",
      "Epoch: 24, Batch: 1590/1676, Loss: 0.7918, Time: 1.96s\n",
      "Epoch: 24, Batch: 1600/1676, Loss: 0.3232, Time: 1.97s\n",
      "Epoch: 24, Batch: 1610/1676, Loss: 0.4007, Time: 1.97s\n",
      "Epoch: 24, Batch: 1620/1676, Loss: 0.6442, Time: 1.97s\n",
      "Epoch: 24, Batch: 1630/1676, Loss: 0.4424, Time: 1.97s\n",
      "Epoch: 24, Batch: 1640/1676, Loss: 0.6327, Time: 1.98s\n",
      "Epoch: 24, Batch: 1650/1676, Loss: 0.6881, Time: 1.97s\n",
      "Epoch: 24, Batch: 1660/1676, Loss: 0.2983, Time: 1.97s\n",
      "Epoch: 24, Batch: 1670/1676, Loss: 0.2325, Time: 1.97s\n",
      "Epoch 25/50: Train Loss: 0.6859, Val Loss: 0.6994, Val IoU: 0.5630, Val Dice: 0.5824\n",
      "Saving best model with IoU: 0.5630\n",
      "Epoch: 25, Batch: 0/1676, Loss: 0.7954, Time: 36.00s\n",
      "Epoch: 25, Batch: 10/1676, Loss: 0.5050, Time: 1.98s\n",
      "Epoch: 25, Batch: 20/1676, Loss: 0.5565, Time: 1.93s\n",
      "Epoch: 25, Batch: 30/1676, Loss: 0.7644, Time: 1.93s\n",
      "Epoch: 25, Batch: 40/1676, Loss: 0.7286, Time: 1.93s\n",
      "Epoch: 25, Batch: 50/1676, Loss: 0.9180, Time: 1.94s\n",
      "Epoch: 25, Batch: 60/1676, Loss: 0.8871, Time: 1.93s\n",
      "Epoch: 25, Batch: 70/1676, Loss: 0.3398, Time: 1.94s\n",
      "Epoch: 25, Batch: 80/1676, Loss: 0.4822, Time: 1.94s\n",
      "Epoch: 25, Batch: 90/1676, Loss: 0.5068, Time: 1.94s\n",
      "Epoch: 25, Batch: 100/1676, Loss: 0.4593, Time: 1.94s\n",
      "Epoch: 25, Batch: 110/1676, Loss: 0.3816, Time: 1.94s\n",
      "Epoch: 25, Batch: 120/1676, Loss: 1.2987, Time: 1.94s\n",
      "Epoch: 25, Batch: 130/1676, Loss: 0.7516, Time: 1.94s\n",
      "Epoch: 25, Batch: 140/1676, Loss: 0.5361, Time: 1.95s\n",
      "Epoch: 25, Batch: 150/1676, Loss: 0.8703, Time: 1.95s\n",
      "Epoch: 25, Batch: 160/1676, Loss: 0.5850, Time: 1.94s\n",
      "Epoch: 25, Batch: 170/1676, Loss: 1.0318, Time: 1.95s\n",
      "Epoch: 25, Batch: 180/1676, Loss: 0.5242, Time: 1.95s\n",
      "Epoch: 25, Batch: 190/1676, Loss: 0.7686, Time: 1.95s\n",
      "Epoch: 25, Batch: 200/1676, Loss: 0.7587, Time: 1.95s\n",
      "Epoch: 25, Batch: 210/1676, Loss: 0.2744, Time: 1.95s\n",
      "Epoch: 25, Batch: 220/1676, Loss: 0.9023, Time: 1.95s\n",
      "Epoch: 25, Batch: 230/1676, Loss: 0.4779, Time: 1.95s\n",
      "Epoch: 25, Batch: 240/1676, Loss: 0.8213, Time: 1.95s\n",
      "Epoch: 25, Batch: 250/1676, Loss: 0.4263, Time: 1.96s\n",
      "Epoch: 25, Batch: 260/1676, Loss: 0.3341, Time: 1.95s\n",
      "Epoch: 25, Batch: 270/1676, Loss: 0.8286, Time: 1.96s\n",
      "Epoch: 25, Batch: 280/1676, Loss: 0.7501, Time: 1.95s\n",
      "Epoch: 25, Batch: 290/1676, Loss: 0.2899, Time: 1.95s\n",
      "Epoch: 25, Batch: 300/1676, Loss: 1.2621, Time: 1.95s\n",
      "Epoch: 25, Batch: 310/1676, Loss: 0.6306, Time: 1.96s\n",
      "Epoch: 25, Batch: 320/1676, Loss: 0.6615, Time: 1.95s\n",
      "Epoch: 25, Batch: 330/1676, Loss: 0.5622, Time: 1.96s\n",
      "Epoch: 25, Batch: 340/1676, Loss: 0.2264, Time: 1.96s\n",
      "Epoch: 25, Batch: 350/1676, Loss: 0.2937, Time: 1.96s\n",
      "Epoch: 25, Batch: 360/1676, Loss: 0.9932, Time: 1.96s\n",
      "Epoch: 25, Batch: 370/1676, Loss: 0.5064, Time: 1.96s\n",
      "Epoch: 25, Batch: 380/1676, Loss: 0.7864, Time: 1.96s\n",
      "Epoch: 25, Batch: 390/1676, Loss: 1.3979, Time: 1.96s\n",
      "Epoch: 25, Batch: 400/1676, Loss: 0.6184, Time: 1.96s\n",
      "Epoch: 25, Batch: 410/1676, Loss: 0.4084, Time: 1.96s\n",
      "Epoch: 25, Batch: 420/1676, Loss: 0.3028, Time: 1.96s\n",
      "Epoch: 25, Batch: 430/1676, Loss: 0.8228, Time: 1.96s\n",
      "Epoch: 25, Batch: 440/1676, Loss: 0.3772, Time: 1.96s\n",
      "Epoch: 25, Batch: 450/1676, Loss: 0.4255, Time: 1.96s\n",
      "Epoch: 25, Batch: 460/1676, Loss: 0.7813, Time: 1.96s\n",
      "Epoch: 25, Batch: 470/1676, Loss: 1.3602, Time: 1.96s\n",
      "Epoch: 25, Batch: 480/1676, Loss: 0.4743, Time: 1.96s\n",
      "Epoch: 25, Batch: 490/1676, Loss: 0.9023, Time: 1.96s\n",
      "Epoch: 25, Batch: 500/1676, Loss: 0.6298, Time: 1.96s\n",
      "Epoch: 25, Batch: 510/1676, Loss: 0.5931, Time: 1.96s\n",
      "Epoch: 25, Batch: 520/1676, Loss: 0.4764, Time: 1.96s\n",
      "Epoch: 25, Batch: 530/1676, Loss: 0.8986, Time: 1.97s\n",
      "Epoch: 25, Batch: 540/1676, Loss: 0.3682, Time: 1.96s\n",
      "Epoch: 25, Batch: 550/1676, Loss: 0.3585, Time: 1.97s\n",
      "Epoch: 25, Batch: 560/1676, Loss: 0.2610, Time: 1.96s\n",
      "Epoch: 25, Batch: 570/1676, Loss: 1.0623, Time: 1.97s\n",
      "Epoch: 25, Batch: 580/1676, Loss: 0.9135, Time: 1.97s\n",
      "Epoch: 25, Batch: 590/1676, Loss: 0.4654, Time: 1.96s\n",
      "Epoch: 25, Batch: 600/1676, Loss: 0.9621, Time: 1.97s\n",
      "Epoch: 25, Batch: 610/1676, Loss: 0.5835, Time: 1.97s\n",
      "Epoch: 25, Batch: 620/1676, Loss: 0.4462, Time: 1.96s\n",
      "Epoch: 25, Batch: 630/1676, Loss: 0.9987, Time: 1.97s\n",
      "Epoch: 25, Batch: 640/1676, Loss: 0.4406, Time: 1.97s\n",
      "Epoch: 25, Batch: 650/1676, Loss: 0.3344, Time: 1.96s\n",
      "Epoch: 25, Batch: 660/1676, Loss: 0.5732, Time: 1.96s\n",
      "Epoch: 25, Batch: 670/1676, Loss: 1.7067, Time: 1.97s\n",
      "Epoch: 25, Batch: 680/1676, Loss: 1.0575, Time: 1.96s\n",
      "Epoch: 25, Batch: 690/1676, Loss: 0.3277, Time: 1.97s\n",
      "Epoch: 25, Batch: 700/1676, Loss: 1.0230, Time: 1.97s\n",
      "Epoch: 25, Batch: 710/1676, Loss: 0.8506, Time: 1.97s\n",
      "Epoch: 25, Batch: 720/1676, Loss: 0.9902, Time: 1.97s\n",
      "Epoch: 25, Batch: 730/1676, Loss: 0.3343, Time: 1.97s\n",
      "Epoch: 25, Batch: 740/1676, Loss: 0.5921, Time: 1.97s\n",
      "Epoch: 25, Batch: 750/1676, Loss: 0.4148, Time: 1.97s\n",
      "Epoch: 25, Batch: 760/1676, Loss: 0.3751, Time: 1.97s\n",
      "Epoch: 25, Batch: 770/1676, Loss: 0.5849, Time: 1.96s\n",
      "Epoch: 25, Batch: 780/1676, Loss: 0.3900, Time: 1.96s\n",
      "Epoch: 25, Batch: 790/1676, Loss: 0.9973, Time: 1.97s\n",
      "Epoch: 25, Batch: 800/1676, Loss: 0.4541, Time: 1.97s\n",
      "Epoch: 25, Batch: 810/1676, Loss: 1.0371, Time: 1.96s\n",
      "Epoch: 25, Batch: 820/1676, Loss: 0.3926, Time: 1.97s\n",
      "Epoch: 25, Batch: 830/1676, Loss: 0.9373, Time: 1.97s\n",
      "Epoch: 25, Batch: 840/1676, Loss: 0.6568, Time: 1.97s\n",
      "Epoch: 25, Batch: 850/1676, Loss: 0.6726, Time: 1.96s\n",
      "Epoch: 25, Batch: 860/1676, Loss: 0.6771, Time: 1.97s\n",
      "Epoch: 25, Batch: 870/1676, Loss: 0.4553, Time: 1.97s\n",
      "Epoch: 25, Batch: 880/1676, Loss: 0.5551, Time: 1.96s\n",
      "Epoch: 25, Batch: 890/1676, Loss: 0.5275, Time: 1.97s\n",
      "Epoch: 25, Batch: 900/1676, Loss: 0.5991, Time: 1.97s\n",
      "Epoch: 25, Batch: 910/1676, Loss: 0.6538, Time: 1.97s\n",
      "Epoch: 25, Batch: 920/1676, Loss: 1.2106, Time: 1.97s\n",
      "Epoch: 25, Batch: 930/1676, Loss: 0.2749, Time: 1.97s\n",
      "Epoch: 25, Batch: 940/1676, Loss: 0.6076, Time: 1.97s\n",
      "Epoch: 25, Batch: 950/1676, Loss: 0.7462, Time: 1.97s\n",
      "Epoch: 25, Batch: 960/1676, Loss: 0.9871, Time: 1.96s\n",
      "Epoch: 25, Batch: 970/1676, Loss: 0.7738, Time: 1.97s\n",
      "Epoch: 25, Batch: 980/1676, Loss: 0.5904, Time: 1.97s\n",
      "Epoch: 25, Batch: 990/1676, Loss: 0.4112, Time: 1.96s\n",
      "Epoch: 25, Batch: 1000/1676, Loss: 0.3688, Time: 1.97s\n",
      "Epoch: 25, Batch: 1010/1676, Loss: 0.4301, Time: 1.97s\n",
      "Epoch: 25, Batch: 1020/1676, Loss: 0.7469, Time: 1.97s\n",
      "Epoch: 25, Batch: 1030/1676, Loss: 0.8738, Time: 1.97s\n",
      "Epoch: 25, Batch: 1040/1676, Loss: 0.7872, Time: 1.96s\n",
      "Epoch: 25, Batch: 1050/1676, Loss: 0.3733, Time: 1.97s\n",
      "Epoch: 25, Batch: 1060/1676, Loss: 0.9346, Time: 1.97s\n",
      "Epoch: 25, Batch: 1070/1676, Loss: 1.1457, Time: 1.97s\n",
      "Epoch: 25, Batch: 1080/1676, Loss: 0.7024, Time: 1.97s\n",
      "Epoch: 25, Batch: 1090/1676, Loss: 0.8509, Time: 1.96s\n",
      "Epoch: 25, Batch: 1100/1676, Loss: 1.2441, Time: 1.97s\n",
      "Epoch: 25, Batch: 1110/1676, Loss: 0.9776, Time: 1.97s\n",
      "Epoch: 25, Batch: 1120/1676, Loss: 0.5709, Time: 1.97s\n",
      "Epoch: 25, Batch: 1130/1676, Loss: 0.6088, Time: 1.97s\n",
      "Epoch: 25, Batch: 1140/1676, Loss: 0.3486, Time: 1.97s\n",
      "Epoch: 25, Batch: 1150/1676, Loss: 0.7584, Time: 1.97s\n",
      "Epoch: 25, Batch: 1160/1676, Loss: 0.5749, Time: 1.98s\n",
      "Epoch: 25, Batch: 1170/1676, Loss: 0.4020, Time: 1.97s\n",
      "Epoch: 25, Batch: 1180/1676, Loss: 1.0297, Time: 1.97s\n",
      "Epoch: 25, Batch: 1190/1676, Loss: 0.6595, Time: 1.96s\n",
      "Epoch: 25, Batch: 1200/1676, Loss: 0.3023, Time: 1.97s\n",
      "Epoch: 25, Batch: 1210/1676, Loss: 0.3124, Time: 1.97s\n",
      "Epoch: 25, Batch: 1220/1676, Loss: 0.6094, Time: 1.96s\n",
      "Epoch: 25, Batch: 1230/1676, Loss: 0.8173, Time: 1.97s\n",
      "Epoch: 25, Batch: 1240/1676, Loss: 0.9908, Time: 1.97s\n",
      "Epoch: 25, Batch: 1250/1676, Loss: 0.5729, Time: 1.97s\n",
      "Epoch: 25, Batch: 1260/1676, Loss: 0.6476, Time: 1.97s\n",
      "Epoch: 25, Batch: 1270/1676, Loss: 0.8500, Time: 1.97s\n",
      "Epoch: 25, Batch: 1280/1676, Loss: 0.3632, Time: 1.97s\n",
      "Epoch: 25, Batch: 1290/1676, Loss: 0.6922, Time: 1.97s\n",
      "Epoch: 25, Batch: 1300/1676, Loss: 0.5309, Time: 1.97s\n",
      "Epoch: 25, Batch: 1310/1676, Loss: 0.8095, Time: 1.97s\n",
      "Epoch: 25, Batch: 1320/1676, Loss: 0.6730, Time: 1.97s\n",
      "Epoch: 25, Batch: 1330/1676, Loss: 0.7074, Time: 1.97s\n",
      "Epoch: 25, Batch: 1340/1676, Loss: 1.2448, Time: 1.97s\n",
      "Epoch: 25, Batch: 1350/1676, Loss: 0.2397, Time: 1.97s\n",
      "Epoch: 25, Batch: 1360/1676, Loss: 0.4540, Time: 1.98s\n",
      "Epoch: 25, Batch: 1370/1676, Loss: 1.2028, Time: 1.98s\n",
      "Epoch: 25, Batch: 1380/1676, Loss: 0.4605, Time: 1.98s\n",
      "Epoch: 25, Batch: 1390/1676, Loss: 1.0234, Time: 2.00s\n",
      "Epoch: 25, Batch: 1400/1676, Loss: 0.4035, Time: 2.00s\n",
      "Epoch: 25, Batch: 1410/1676, Loss: 0.6655, Time: 2.00s\n",
      "Epoch: 25, Batch: 1420/1676, Loss: 0.6289, Time: 2.00s\n",
      "Epoch: 25, Batch: 1430/1676, Loss: 0.5443, Time: 2.00s\n",
      "Epoch: 25, Batch: 1440/1676, Loss: 0.7769, Time: 2.00s\n",
      "Epoch: 25, Batch: 1450/1676, Loss: 0.6746, Time: 2.03s\n",
      "Epoch: 25, Batch: 1460/1676, Loss: 0.4777, Time: 2.00s\n",
      "Epoch: 25, Batch: 1470/1676, Loss: 0.7404, Time: 2.00s\n",
      "Epoch: 25, Batch: 1480/1676, Loss: 1.0569, Time: 2.00s\n",
      "Epoch: 25, Batch: 1490/1676, Loss: 0.6292, Time: 2.00s\n",
      "Epoch: 25, Batch: 1500/1676, Loss: 0.8798, Time: 2.01s\n",
      "Epoch: 25, Batch: 1510/1676, Loss: 0.4879, Time: 2.00s\n",
      "Epoch: 25, Batch: 1520/1676, Loss: 1.0442, Time: 2.01s\n",
      "Epoch: 25, Batch: 1530/1676, Loss: 0.8311, Time: 2.00s\n",
      "Epoch: 25, Batch: 1540/1676, Loss: 0.3757, Time: 2.01s\n",
      "Epoch: 25, Batch: 1550/1676, Loss: 0.6558, Time: 2.01s\n",
      "Epoch: 25, Batch: 1560/1676, Loss: 0.3980, Time: 2.00s\n",
      "Epoch: 25, Batch: 1570/1676, Loss: 0.7719, Time: 2.00s\n",
      "Epoch: 25, Batch: 1580/1676, Loss: 0.8828, Time: 2.01s\n",
      "Epoch: 25, Batch: 1590/1676, Loss: 0.5534, Time: 2.00s\n",
      "Epoch: 25, Batch: 1600/1676, Loss: 0.3712, Time: 2.01s\n",
      "Epoch: 25, Batch: 1610/1676, Loss: 1.0604, Time: 2.00s\n",
      "Epoch: 25, Batch: 1620/1676, Loss: 0.7862, Time: 2.00s\n",
      "Epoch: 25, Batch: 1630/1676, Loss: 0.6176, Time: 2.00s\n",
      "Epoch: 25, Batch: 1640/1676, Loss: 1.0852, Time: 1.99s\n",
      "Epoch: 25, Batch: 1650/1676, Loss: 0.6289, Time: 2.00s\n",
      "Epoch: 25, Batch: 1660/1676, Loss: 0.3944, Time: 2.00s\n",
      "Epoch: 25, Batch: 1670/1676, Loss: 0.7074, Time: 2.00s\n",
      "Epoch 26/50: Train Loss: 0.6823, Val Loss: 0.6964, Val IoU: 0.5623, Val Dice: 0.5821\n",
      "Epoch: 26, Batch: 0/1676, Loss: 1.0883, Time: 35.90s\n",
      "Epoch: 26, Batch: 10/1676, Loss: 0.7762, Time: 1.97s\n",
      "Epoch: 26, Batch: 20/1676, Loss: 0.6157, Time: 1.93s\n",
      "Epoch: 26, Batch: 30/1676, Loss: 0.4201, Time: 1.94s\n",
      "Epoch: 26, Batch: 40/1676, Loss: 0.6398, Time: 1.93s\n",
      "Epoch: 26, Batch: 50/1676, Loss: 0.5180, Time: 1.93s\n",
      "Epoch: 26, Batch: 60/1676, Loss: 0.9132, Time: 1.94s\n",
      "Epoch: 26, Batch: 70/1676, Loss: 1.0073, Time: 1.93s\n",
      "Epoch: 26, Batch: 80/1676, Loss: 0.5642, Time: 1.93s\n",
      "Epoch: 26, Batch: 90/1676, Loss: 0.5991, Time: 1.93s\n",
      "Epoch: 26, Batch: 100/1676, Loss: 0.3760, Time: 1.94s\n",
      "Epoch: 26, Batch: 110/1676, Loss: 0.6101, Time: 1.94s\n",
      "Epoch: 26, Batch: 120/1676, Loss: 0.5133, Time: 1.94s\n",
      "Epoch: 26, Batch: 130/1676, Loss: 0.6877, Time: 1.93s\n",
      "Epoch: 26, Batch: 140/1676, Loss: 0.6431, Time: 1.94s\n",
      "Epoch: 26, Batch: 150/1676, Loss: 0.9637, Time: 1.94s\n",
      "Epoch: 26, Batch: 160/1676, Loss: 0.6831, Time: 1.95s\n",
      "Epoch: 26, Batch: 170/1676, Loss: 0.7799, Time: 1.94s\n",
      "Epoch: 26, Batch: 180/1676, Loss: 0.2813, Time: 1.95s\n",
      "Epoch: 26, Batch: 190/1676, Loss: 0.8342, Time: 1.95s\n",
      "Epoch: 26, Batch: 200/1676, Loss: 0.7191, Time: 1.94s\n",
      "Epoch: 26, Batch: 210/1676, Loss: 0.5833, Time: 1.95s\n",
      "Epoch: 26, Batch: 220/1676, Loss: 0.8360, Time: 1.95s\n",
      "Epoch: 26, Batch: 230/1676, Loss: 0.6757, Time: 1.96s\n",
      "Epoch: 26, Batch: 240/1676, Loss: 0.6626, Time: 1.95s\n",
      "Epoch: 26, Batch: 250/1676, Loss: 0.7629, Time: 1.95s\n",
      "Epoch: 26, Batch: 260/1676, Loss: 0.4982, Time: 1.94s\n",
      "Epoch: 26, Batch: 270/1676, Loss: 0.6638, Time: 1.95s\n",
      "Epoch: 26, Batch: 280/1676, Loss: 0.3284, Time: 1.95s\n",
      "Epoch: 26, Batch: 290/1676, Loss: 0.4877, Time: 1.95s\n",
      "Epoch: 26, Batch: 300/1676, Loss: 0.5846, Time: 1.95s\n",
      "Epoch: 26, Batch: 310/1676, Loss: 0.9173, Time: 1.96s\n",
      "Epoch: 26, Batch: 320/1676, Loss: 0.7328, Time: 1.95s\n",
      "Epoch: 26, Batch: 330/1676, Loss: 0.7029, Time: 1.96s\n",
      "Epoch: 26, Batch: 340/1676, Loss: 0.7179, Time: 1.95s\n",
      "Epoch: 26, Batch: 350/1676, Loss: 0.6010, Time: 1.95s\n",
      "Epoch: 26, Batch: 360/1676, Loss: 0.4050, Time: 1.96s\n",
      "Epoch: 26, Batch: 370/1676, Loss: 0.7487, Time: 1.96s\n",
      "Epoch: 26, Batch: 380/1676, Loss: 0.5321, Time: 1.96s\n",
      "Epoch: 26, Batch: 390/1676, Loss: 0.7644, Time: 1.96s\n",
      "Epoch: 26, Batch: 400/1676, Loss: 0.6846, Time: 1.95s\n",
      "Epoch: 26, Batch: 410/1676, Loss: 0.4856, Time: 1.96s\n",
      "Epoch: 26, Batch: 420/1676, Loss: 0.8686, Time: 1.96s\n",
      "Epoch: 26, Batch: 430/1676, Loss: 0.9251, Time: 1.95s\n",
      "Epoch: 26, Batch: 440/1676, Loss: 0.6476, Time: 1.96s\n",
      "Epoch: 26, Batch: 450/1676, Loss: 0.4915, Time: 1.96s\n",
      "Epoch: 26, Batch: 460/1676, Loss: 0.7521, Time: 1.96s\n",
      "Epoch: 26, Batch: 470/1676, Loss: 0.8371, Time: 1.96s\n",
      "Epoch: 26, Batch: 480/1676, Loss: 0.7689, Time: 1.96s\n",
      "Epoch: 26, Batch: 490/1676, Loss: 0.6094, Time: 1.96s\n",
      "Epoch: 26, Batch: 500/1676, Loss: 1.0696, Time: 1.96s\n",
      "Epoch: 26, Batch: 510/1676, Loss: 0.9807, Time: 1.96s\n",
      "Epoch: 26, Batch: 520/1676, Loss: 0.5599, Time: 1.96s\n",
      "Epoch: 26, Batch: 530/1676, Loss: 0.6380, Time: 1.96s\n",
      "Epoch: 26, Batch: 540/1676, Loss: 0.4467, Time: 1.96s\n",
      "Epoch: 26, Batch: 550/1676, Loss: 0.4665, Time: 1.96s\n",
      "Epoch: 26, Batch: 560/1676, Loss: 0.7341, Time: 1.97s\n",
      "Epoch: 26, Batch: 570/1676, Loss: 0.5176, Time: 1.96s\n",
      "Epoch: 26, Batch: 580/1676, Loss: 0.5010, Time: 1.96s\n",
      "Epoch: 26, Batch: 590/1676, Loss: 0.2933, Time: 1.97s\n",
      "Epoch: 26, Batch: 600/1676, Loss: 0.9540, Time: 1.96s\n",
      "Epoch: 26, Batch: 610/1676, Loss: 0.4114, Time: 1.96s\n",
      "Epoch: 26, Batch: 620/1676, Loss: 0.4796, Time: 1.96s\n",
      "Epoch: 26, Batch: 630/1676, Loss: 0.7057, Time: 1.96s\n",
      "Epoch: 26, Batch: 640/1676, Loss: 0.7951, Time: 1.96s\n",
      "Epoch: 26, Batch: 650/1676, Loss: 0.6512, Time: 1.97s\n",
      "Epoch: 26, Batch: 660/1676, Loss: 1.3579, Time: 1.96s\n",
      "Epoch: 26, Batch: 670/1676, Loss: 1.4295, Time: 1.96s\n",
      "Epoch: 26, Batch: 680/1676, Loss: 0.6965, Time: 1.96s\n",
      "Epoch: 26, Batch: 690/1676, Loss: 1.0181, Time: 1.96s\n",
      "Epoch: 26, Batch: 700/1676, Loss: 0.4188, Time: 1.97s\n",
      "Epoch: 26, Batch: 710/1676, Loss: 0.8508, Time: 1.96s\n",
      "Epoch: 26, Batch: 720/1676, Loss: 0.7389, Time: 1.96s\n",
      "Epoch: 26, Batch: 730/1676, Loss: 0.8732, Time: 1.97s\n",
      "Epoch: 26, Batch: 740/1676, Loss: 0.5166, Time: 1.97s\n",
      "Epoch: 26, Batch: 750/1676, Loss: 0.5016, Time: 1.97s\n",
      "Epoch: 26, Batch: 760/1676, Loss: 0.4963, Time: 1.96s\n",
      "Epoch: 26, Batch: 770/1676, Loss: 0.4043, Time: 1.96s\n",
      "Epoch: 26, Batch: 780/1676, Loss: 0.9696, Time: 1.97s\n",
      "Epoch: 26, Batch: 790/1676, Loss: 0.7104, Time: 1.97s\n",
      "Epoch: 26, Batch: 800/1676, Loss: 0.7770, Time: 1.96s\n",
      "Epoch: 26, Batch: 810/1676, Loss: 0.3318, Time: 1.97s\n",
      "Epoch: 26, Batch: 820/1676, Loss: 0.8180, Time: 1.96s\n",
      "Epoch: 26, Batch: 830/1676, Loss: 0.4971, Time: 1.96s\n",
      "Epoch: 26, Batch: 840/1676, Loss: 0.8990, Time: 1.97s\n",
      "Epoch: 26, Batch: 850/1676, Loss: 0.7342, Time: 1.96s\n",
      "Epoch: 26, Batch: 860/1676, Loss: 0.2983, Time: 1.97s\n",
      "Epoch: 26, Batch: 870/1676, Loss: 0.7869, Time: 1.96s\n",
      "Epoch: 26, Batch: 880/1676, Loss: 0.7460, Time: 1.97s\n",
      "Epoch: 26, Batch: 890/1676, Loss: 0.6047, Time: 1.97s\n",
      "Epoch: 26, Batch: 900/1676, Loss: 1.2420, Time: 1.96s\n",
      "Epoch: 26, Batch: 910/1676, Loss: 0.7366, Time: 1.97s\n",
      "Epoch: 26, Batch: 920/1676, Loss: 0.3208, Time: 1.97s\n",
      "Epoch: 26, Batch: 930/1676, Loss: 1.2057, Time: 1.96s\n",
      "Epoch: 26, Batch: 940/1676, Loss: 0.5832, Time: 1.97s\n",
      "Epoch: 26, Batch: 950/1676, Loss: 0.6676, Time: 1.97s\n",
      "Epoch: 26, Batch: 960/1676, Loss: 0.2996, Time: 1.97s\n",
      "Epoch: 26, Batch: 970/1676, Loss: 0.6338, Time: 1.97s\n",
      "Epoch: 26, Batch: 980/1676, Loss: 0.4585, Time: 1.97s\n",
      "Epoch: 26, Batch: 990/1676, Loss: 1.0281, Time: 1.97s\n",
      "Epoch: 26, Batch: 1000/1676, Loss: 0.4110, Time: 1.97s\n",
      "Epoch: 26, Batch: 1010/1676, Loss: 0.3848, Time: 1.97s\n",
      "Epoch: 26, Batch: 1020/1676, Loss: 0.7907, Time: 1.97s\n",
      "Epoch: 26, Batch: 1030/1676, Loss: 0.4444, Time: 1.97s\n",
      "Epoch: 26, Batch: 1040/1676, Loss: 0.6789, Time: 1.97s\n",
      "Epoch: 26, Batch: 1050/1676, Loss: 0.7297, Time: 1.97s\n",
      "Epoch: 26, Batch: 1060/1676, Loss: 0.7511, Time: 1.97s\n",
      "Epoch: 26, Batch: 1070/1676, Loss: 0.6315, Time: 1.97s\n",
      "Epoch: 26, Batch: 1080/1676, Loss: 0.5193, Time: 1.97s\n",
      "Epoch: 26, Batch: 1090/1676, Loss: 0.5975, Time: 1.96s\n",
      "Epoch: 26, Batch: 1100/1676, Loss: 1.2443, Time: 1.97s\n",
      "Epoch: 26, Batch: 1110/1676, Loss: 1.1688, Time: 1.96s\n",
      "Epoch: 26, Batch: 1120/1676, Loss: 1.2580, Time: 1.96s\n",
      "Epoch: 26, Batch: 1130/1676, Loss: 0.3176, Time: 1.97s\n",
      "Epoch: 26, Batch: 1140/1676, Loss: 0.6003, Time: 1.97s\n",
      "Epoch: 26, Batch: 1150/1676, Loss: 0.7163, Time: 1.97s\n",
      "Epoch: 26, Batch: 1160/1676, Loss: 0.7749, Time: 1.96s\n",
      "Epoch: 26, Batch: 1170/1676, Loss: 0.4359, Time: 1.98s\n",
      "Epoch: 26, Batch: 1180/1676, Loss: 0.9425, Time: 1.97s\n",
      "Epoch: 26, Batch: 1190/1676, Loss: 1.1669, Time: 1.96s\n",
      "Epoch: 26, Batch: 1200/1676, Loss: 0.7420, Time: 1.96s\n",
      "Epoch: 26, Batch: 1210/1676, Loss: 1.1546, Time: 1.96s\n",
      "Epoch: 26, Batch: 1220/1676, Loss: 0.6485, Time: 1.97s\n",
      "Epoch: 26, Batch: 1230/1676, Loss: 0.4975, Time: 1.96s\n",
      "Epoch: 26, Batch: 1240/1676, Loss: 0.6924, Time: 1.97s\n",
      "Epoch: 26, Batch: 1250/1676, Loss: 0.6019, Time: 1.98s\n",
      "Epoch: 26, Batch: 1260/1676, Loss: 1.2940, Time: 1.96s\n",
      "Epoch: 26, Batch: 1270/1676, Loss: 0.7751, Time: 1.97s\n",
      "Epoch: 26, Batch: 1280/1676, Loss: 0.5554, Time: 1.97s\n",
      "Epoch: 26, Batch: 1290/1676, Loss: 0.5712, Time: 1.98s\n",
      "Epoch: 26, Batch: 1300/1676, Loss: 0.5907, Time: 1.98s\n",
      "Epoch: 26, Batch: 1310/1676, Loss: 0.6214, Time: 1.97s\n",
      "Epoch: 26, Batch: 1320/1676, Loss: 0.5624, Time: 1.97s\n",
      "Epoch: 26, Batch: 1330/1676, Loss: 0.8869, Time: 1.97s\n",
      "Epoch: 26, Batch: 1340/1676, Loss: 1.0490, Time: 1.97s\n",
      "Epoch: 26, Batch: 1350/1676, Loss: 0.6258, Time: 1.97s\n",
      "Epoch: 26, Batch: 1360/1676, Loss: 0.5676, Time: 1.97s\n",
      "Epoch: 26, Batch: 1370/1676, Loss: 0.4491, Time: 1.97s\n",
      "Epoch: 26, Batch: 1380/1676, Loss: 0.6323, Time: 1.97s\n",
      "Epoch: 26, Batch: 1390/1676, Loss: 0.5912, Time: 1.97s\n",
      "Epoch: 26, Batch: 1400/1676, Loss: 0.7869, Time: 1.97s\n",
      "Epoch: 26, Batch: 1410/1676, Loss: 0.8955, Time: 1.97s\n",
      "Epoch: 26, Batch: 1420/1676, Loss: 0.5484, Time: 1.97s\n",
      "Epoch: 26, Batch: 1430/1676, Loss: 0.4355, Time: 1.97s\n",
      "Epoch: 26, Batch: 1440/1676, Loss: 0.5129, Time: 1.97s\n",
      "Epoch: 26, Batch: 1450/1676, Loss: 0.4405, Time: 1.97s\n",
      "Epoch: 26, Batch: 1460/1676, Loss: 0.4059, Time: 1.97s\n",
      "Epoch: 26, Batch: 1470/1676, Loss: 1.2641, Time: 1.97s\n",
      "Epoch: 26, Batch: 1480/1676, Loss: 0.3307, Time: 1.97s\n",
      "Epoch: 26, Batch: 1490/1676, Loss: 0.5471, Time: 1.97s\n",
      "Epoch: 26, Batch: 1500/1676, Loss: 0.8930, Time: 1.96s\n",
      "Epoch: 26, Batch: 1510/1676, Loss: 0.3387, Time: 1.96s\n",
      "Epoch: 26, Batch: 1520/1676, Loss: 0.2683, Time: 1.97s\n",
      "Epoch: 26, Batch: 1530/1676, Loss: 1.1373, Time: 1.97s\n",
      "Epoch: 26, Batch: 1540/1676, Loss: 0.2410, Time: 1.97s\n",
      "Epoch: 26, Batch: 1550/1676, Loss: 0.9763, Time: 1.96s\n",
      "Epoch: 26, Batch: 1560/1676, Loss: 0.4320, Time: 1.97s\n",
      "Epoch: 26, Batch: 1570/1676, Loss: 0.5282, Time: 1.97s\n",
      "Epoch: 26, Batch: 1580/1676, Loss: 0.7810, Time: 1.97s\n",
      "Epoch: 26, Batch: 1590/1676, Loss: 1.2373, Time: 1.97s\n",
      "Epoch: 26, Batch: 1600/1676, Loss: 0.7195, Time: 1.97s\n",
      "Epoch: 26, Batch: 1610/1676, Loss: 0.9240, Time: 1.97s\n",
      "Epoch: 26, Batch: 1620/1676, Loss: 1.3130, Time: 1.97s\n",
      "Epoch: 26, Batch: 1630/1676, Loss: 0.6425, Time: 1.97s\n",
      "Epoch: 26, Batch: 1640/1676, Loss: 0.8456, Time: 1.97s\n",
      "Epoch: 26, Batch: 1650/1676, Loss: 0.7951, Time: 1.97s\n",
      "Epoch: 26, Batch: 1660/1676, Loss: 0.7130, Time: 1.96s\n",
      "Epoch: 26, Batch: 1670/1676, Loss: 0.9096, Time: 1.97s\n",
      "Epoch 27/50: Train Loss: 0.6823, Val Loss: 0.7018, Val IoU: 0.5560, Val Dice: 0.5759\n",
      "Epoch: 27, Batch: 0/1676, Loss: 0.3602, Time: 35.65s\n",
      "Epoch: 27, Batch: 10/1676, Loss: 0.7804, Time: 1.98s\n",
      "Epoch: 27, Batch: 20/1676, Loss: 1.3081, Time: 1.92s\n",
      "Epoch: 27, Batch: 30/1676, Loss: 0.3891, Time: 1.93s\n",
      "Epoch: 27, Batch: 40/1676, Loss: 0.4837, Time: 1.93s\n",
      "Epoch: 27, Batch: 50/1676, Loss: 0.3104, Time: 1.94s\n",
      "Epoch: 27, Batch: 60/1676, Loss: 0.6671, Time: 1.93s\n",
      "Epoch: 27, Batch: 70/1676, Loss: 0.7586, Time: 1.94s\n",
      "Epoch: 27, Batch: 80/1676, Loss: 0.5495, Time: 1.94s\n",
      "Epoch: 27, Batch: 90/1676, Loss: 1.3335, Time: 1.94s\n",
      "Epoch: 27, Batch: 100/1676, Loss: 0.5632, Time: 1.94s\n",
      "Epoch: 27, Batch: 110/1676, Loss: 0.2720, Time: 1.94s\n",
      "Epoch: 27, Batch: 120/1676, Loss: 1.1018, Time: 1.94s\n",
      "Epoch: 27, Batch: 130/1676, Loss: 0.6054, Time: 1.94s\n",
      "Epoch: 27, Batch: 140/1676, Loss: 0.9865, Time: 1.94s\n",
      "Epoch: 27, Batch: 150/1676, Loss: 0.5375, Time: 1.94s\n",
      "Epoch: 27, Batch: 160/1676, Loss: 0.4367, Time: 1.94s\n",
      "Epoch: 27, Batch: 170/1676, Loss: 0.4452, Time: 1.95s\n",
      "Epoch: 27, Batch: 180/1676, Loss: 0.4901, Time: 1.95s\n",
      "Epoch: 27, Batch: 190/1676, Loss: 0.7564, Time: 1.95s\n",
      "Epoch: 27, Batch: 200/1676, Loss: 0.7989, Time: 1.95s\n",
      "Epoch: 27, Batch: 210/1676, Loss: 0.7418, Time: 1.95s\n",
      "Epoch: 27, Batch: 220/1676, Loss: 1.1497, Time: 1.94s\n",
      "Epoch: 27, Batch: 230/1676, Loss: 0.6904, Time: 1.95s\n",
      "Epoch: 27, Batch: 240/1676, Loss: 0.7415, Time: 1.95s\n",
      "Epoch: 27, Batch: 250/1676, Loss: 0.7890, Time: 1.95s\n",
      "Epoch: 27, Batch: 260/1676, Loss: 0.3283, Time: 1.95s\n",
      "Epoch: 27, Batch: 270/1676, Loss: 0.7804, Time: 1.95s\n",
      "Epoch: 27, Batch: 280/1676, Loss: 0.5988, Time: 1.95s\n",
      "Epoch: 27, Batch: 290/1676, Loss: 0.5661, Time: 1.95s\n",
      "Epoch: 27, Batch: 300/1676, Loss: 0.5178, Time: 1.95s\n",
      "Epoch: 27, Batch: 310/1676, Loss: 0.4734, Time: 1.95s\n",
      "Epoch: 27, Batch: 320/1676, Loss: 0.4306, Time: 1.95s\n",
      "Epoch: 27, Batch: 330/1676, Loss: 0.2725, Time: 1.95s\n",
      "Epoch: 27, Batch: 340/1676, Loss: 0.4805, Time: 1.95s\n",
      "Epoch: 27, Batch: 350/1676, Loss: 0.6330, Time: 1.95s\n",
      "Epoch: 27, Batch: 360/1676, Loss: 0.6580, Time: 1.96s\n",
      "Epoch: 27, Batch: 370/1676, Loss: 0.7511, Time: 1.95s\n",
      "Epoch: 27, Batch: 380/1676, Loss: 0.9931, Time: 1.97s\n",
      "Epoch: 27, Batch: 390/1676, Loss: 0.6925, Time: 1.96s\n",
      "Epoch: 27, Batch: 400/1676, Loss: 0.4019, Time: 1.96s\n",
      "Epoch: 27, Batch: 410/1676, Loss: 0.5131, Time: 1.96s\n",
      "Epoch: 27, Batch: 420/1676, Loss: 0.7414, Time: 1.95s\n",
      "Epoch: 27, Batch: 430/1676, Loss: 0.6592, Time: 1.95s\n",
      "Epoch: 27, Batch: 440/1676, Loss: 0.8541, Time: 1.96s\n",
      "Epoch: 27, Batch: 450/1676, Loss: 0.5760, Time: 1.96s\n",
      "Epoch: 27, Batch: 460/1676, Loss: 0.3123, Time: 1.96s\n",
      "Epoch: 27, Batch: 470/1676, Loss: 0.6241, Time: 1.96s\n",
      "Epoch: 27, Batch: 480/1676, Loss: 0.6518, Time: 1.96s\n",
      "Epoch: 27, Batch: 490/1676, Loss: 0.8074, Time: 1.96s\n",
      "Epoch: 27, Batch: 500/1676, Loss: 0.7957, Time: 1.96s\n",
      "Epoch: 27, Batch: 510/1676, Loss: 0.6736, Time: 1.96s\n",
      "Epoch: 27, Batch: 520/1676, Loss: 0.4210, Time: 1.96s\n",
      "Epoch: 27, Batch: 530/1676, Loss: 0.8583, Time: 1.96s\n",
      "Epoch: 27, Batch: 540/1676, Loss: 0.8407, Time: 1.96s\n",
      "Epoch: 27, Batch: 550/1676, Loss: 0.5733, Time: 1.97s\n",
      "Epoch: 27, Batch: 560/1676, Loss: 1.2219, Time: 1.96s\n",
      "Epoch: 27, Batch: 570/1676, Loss: 1.1130, Time: 1.96s\n",
      "Epoch: 27, Batch: 580/1676, Loss: 0.8428, Time: 1.96s\n",
      "Epoch: 27, Batch: 590/1676, Loss: 1.1376, Time: 1.96s\n",
      "Epoch: 27, Batch: 600/1676, Loss: 0.6519, Time: 1.98s\n",
      "Epoch: 27, Batch: 610/1676, Loss: 1.1653, Time: 2.00s\n",
      "Epoch: 27, Batch: 620/1676, Loss: 0.9844, Time: 2.00s\n",
      "Epoch: 27, Batch: 630/1676, Loss: 1.0234, Time: 2.00s\n",
      "Epoch: 27, Batch: 640/1676, Loss: 1.2555, Time: 2.00s\n",
      "Epoch: 27, Batch: 650/1676, Loss: 0.7553, Time: 2.01s\n",
      "Epoch: 27, Batch: 660/1676, Loss: 1.1279, Time: 2.00s\n",
      "Epoch: 27, Batch: 670/1676, Loss: 0.4123, Time: 1.99s\n",
      "Epoch: 27, Batch: 680/1676, Loss: 0.3958, Time: 1.99s\n",
      "Epoch: 27, Batch: 690/1676, Loss: 0.6286, Time: 2.00s\n",
      "Epoch: 27, Batch: 700/1676, Loss: 0.7561, Time: 1.99s\n",
      "Epoch: 27, Batch: 710/1676, Loss: 0.5681, Time: 2.00s\n",
      "Epoch: 27, Batch: 720/1676, Loss: 0.4272, Time: 2.00s\n",
      "Epoch: 27, Batch: 730/1676, Loss: 0.8975, Time: 1.97s\n",
      "Epoch: 27, Batch: 740/1676, Loss: 0.9236, Time: 1.97s\n",
      "Epoch: 27, Batch: 750/1676, Loss: 0.7226, Time: 1.96s\n",
      "Epoch: 27, Batch: 760/1676, Loss: 0.3487, Time: 1.97s\n",
      "Epoch: 27, Batch: 770/1676, Loss: 0.5525, Time: 1.96s\n",
      "Epoch: 27, Batch: 780/1676, Loss: 0.3902, Time: 1.97s\n",
      "Epoch: 27, Batch: 790/1676, Loss: 0.8123, Time: 1.96s\n",
      "Epoch: 27, Batch: 800/1676, Loss: 0.6081, Time: 1.97s\n",
      "Epoch: 27, Batch: 810/1676, Loss: 0.8385, Time: 1.97s\n",
      "Epoch: 27, Batch: 820/1676, Loss: 0.7604, Time: 1.96s\n",
      "Epoch: 27, Batch: 830/1676, Loss: 1.2957, Time: 1.97s\n",
      "Epoch: 27, Batch: 840/1676, Loss: 0.4477, Time: 1.97s\n",
      "Epoch: 27, Batch: 850/1676, Loss: 0.2795, Time: 1.97s\n",
      "Epoch: 27, Batch: 860/1676, Loss: 1.0868, Time: 1.97s\n",
      "Epoch: 27, Batch: 870/1676, Loss: 0.7902, Time: 1.97s\n",
      "Epoch: 27, Batch: 880/1676, Loss: 1.9238, Time: 1.97s\n",
      "Epoch: 27, Batch: 890/1676, Loss: 1.2220, Time: 1.96s\n",
      "Epoch: 27, Batch: 900/1676, Loss: 0.6278, Time: 1.97s\n",
      "Epoch: 27, Batch: 910/1676, Loss: 0.9960, Time: 1.97s\n",
      "Epoch: 27, Batch: 920/1676, Loss: 0.3026, Time: 1.97s\n",
      "Epoch: 27, Batch: 930/1676, Loss: 0.4224, Time: 1.97s\n",
      "Epoch: 27, Batch: 940/1676, Loss: 1.0199, Time: 1.98s\n",
      "Epoch: 27, Batch: 950/1676, Loss: 0.7459, Time: 1.97s\n",
      "Epoch: 27, Batch: 960/1676, Loss: 0.3685, Time: 1.97s\n",
      "Epoch: 27, Batch: 970/1676, Loss: 0.4890, Time: 1.96s\n",
      "Epoch: 27, Batch: 980/1676, Loss: 0.6761, Time: 1.97s\n",
      "Epoch: 27, Batch: 990/1676, Loss: 0.3601, Time: 1.97s\n",
      "Epoch: 27, Batch: 1000/1676, Loss: 0.9827, Time: 1.97s\n",
      "Epoch: 27, Batch: 1010/1676, Loss: 0.6341, Time: 1.96s\n",
      "Epoch: 27, Batch: 1020/1676, Loss: 0.8798, Time: 1.98s\n",
      "Epoch: 27, Batch: 1030/1676, Loss: 1.1063, Time: 1.97s\n",
      "Epoch: 27, Batch: 1040/1676, Loss: 1.1789, Time: 1.97s\n",
      "Epoch: 27, Batch: 1050/1676, Loss: 1.2526, Time: 1.97s\n",
      "Epoch: 27, Batch: 1060/1676, Loss: 0.9933, Time: 1.97s\n",
      "Epoch: 27, Batch: 1070/1676, Loss: 0.3603, Time: 1.97s\n",
      "Epoch: 27, Batch: 1080/1676, Loss: 0.8773, Time: 1.96s\n",
      "Epoch: 27, Batch: 1090/1676, Loss: 0.7417, Time: 1.97s\n",
      "Epoch: 27, Batch: 1100/1676, Loss: 0.6088, Time: 1.97s\n",
      "Epoch: 27, Batch: 1110/1676, Loss: 0.9718, Time: 1.97s\n",
      "Epoch: 27, Batch: 1120/1676, Loss: 0.6885, Time: 1.97s\n",
      "Epoch: 27, Batch: 1130/1676, Loss: 0.9661, Time: 1.97s\n",
      "Epoch: 27, Batch: 1140/1676, Loss: 0.4300, Time: 1.98s\n",
      "Epoch: 27, Batch: 1150/1676, Loss: 0.8770, Time: 1.96s\n",
      "Epoch: 27, Batch: 1160/1676, Loss: 0.8798, Time: 1.97s\n",
      "Epoch: 27, Batch: 1170/1676, Loss: 0.2899, Time: 1.97s\n",
      "Epoch: 27, Batch: 1180/1676, Loss: 0.6347, Time: 1.98s\n",
      "Epoch: 27, Batch: 1190/1676, Loss: 0.2726, Time: 1.97s\n",
      "Epoch: 27, Batch: 1200/1676, Loss: 0.7807, Time: 1.97s\n",
      "Epoch: 27, Batch: 1210/1676, Loss: 1.0234, Time: 1.97s\n",
      "Epoch: 27, Batch: 1220/1676, Loss: 0.6006, Time: 1.97s\n",
      "Epoch: 27, Batch: 1230/1676, Loss: 0.5290, Time: 1.98s\n",
      "Epoch: 27, Batch: 1240/1676, Loss: 0.5905, Time: 1.97s\n",
      "Epoch: 27, Batch: 1250/1676, Loss: 0.3781, Time: 1.98s\n",
      "Epoch: 27, Batch: 1260/1676, Loss: 0.6213, Time: 1.97s\n",
      "Epoch: 27, Batch: 1270/1676, Loss: 1.1889, Time: 1.97s\n",
      "Epoch: 27, Batch: 1280/1676, Loss: 0.3294, Time: 1.96s\n",
      "Epoch: 27, Batch: 1290/1676, Loss: 0.6427, Time: 1.97s\n",
      "Epoch: 27, Batch: 1300/1676, Loss: 0.9450, Time: 1.98s\n",
      "Epoch: 27, Batch: 1310/1676, Loss: 0.6702, Time: 1.97s\n",
      "Epoch: 27, Batch: 1320/1676, Loss: 0.5882, Time: 1.97s\n",
      "Epoch: 27, Batch: 1330/1676, Loss: 0.8064, Time: 1.97s\n",
      "Epoch: 27, Batch: 1340/1676, Loss: 0.6795, Time: 1.97s\n",
      "Epoch: 27, Batch: 1350/1676, Loss: 0.8646, Time: 1.97s\n",
      "Epoch: 27, Batch: 1360/1676, Loss: 0.4546, Time: 1.97s\n",
      "Epoch: 27, Batch: 1370/1676, Loss: 0.6032, Time: 1.97s\n",
      "Epoch: 27, Batch: 1380/1676, Loss: 0.4708, Time: 1.97s\n",
      "Epoch: 27, Batch: 1390/1676, Loss: 0.3343, Time: 1.97s\n",
      "Epoch: 27, Batch: 1400/1676, Loss: 0.8923, Time: 1.97s\n",
      "Epoch: 27, Batch: 1410/1676, Loss: 0.8556, Time: 1.97s\n",
      "Epoch: 27, Batch: 1420/1676, Loss: 0.2600, Time: 1.97s\n",
      "Epoch: 27, Batch: 1430/1676, Loss: 0.6003, Time: 1.97s\n",
      "Epoch: 27, Batch: 1440/1676, Loss: 0.8479, Time: 1.98s\n",
      "Epoch: 27, Batch: 1450/1676, Loss: 0.4037, Time: 1.96s\n",
      "Epoch: 27, Batch: 1460/1676, Loss: 0.8159, Time: 1.98s\n",
      "Epoch: 27, Batch: 1470/1676, Loss: 0.6728, Time: 1.97s\n",
      "Epoch: 27, Batch: 1480/1676, Loss: 0.4554, Time: 1.97s\n",
      "Epoch: 27, Batch: 1490/1676, Loss: 0.8871, Time: 1.97s\n",
      "Epoch: 27, Batch: 1500/1676, Loss: 0.4515, Time: 1.98s\n",
      "Epoch: 27, Batch: 1510/1676, Loss: 0.4932, Time: 1.97s\n",
      "Epoch: 27, Batch: 1520/1676, Loss: 0.5194, Time: 1.97s\n",
      "Epoch: 27, Batch: 1530/1676, Loss: 0.7999, Time: 1.98s\n",
      "Epoch: 27, Batch: 1540/1676, Loss: 0.7119, Time: 1.97s\n",
      "Epoch: 27, Batch: 1550/1676, Loss: 0.4216, Time: 1.97s\n",
      "Epoch: 27, Batch: 1560/1676, Loss: 0.6345, Time: 1.96s\n",
      "Epoch: 27, Batch: 1570/1676, Loss: 0.9655, Time: 1.97s\n",
      "Epoch: 27, Batch: 1580/1676, Loss: 0.9298, Time: 1.97s\n",
      "Epoch: 27, Batch: 1590/1676, Loss: 0.6040, Time: 1.97s\n",
      "Epoch: 27, Batch: 1600/1676, Loss: 0.9192, Time: 1.97s\n",
      "Epoch: 27, Batch: 1610/1676, Loss: 0.6148, Time: 1.98s\n",
      "Epoch: 27, Batch: 1620/1676, Loss: 1.1008, Time: 1.98s\n",
      "Epoch: 27, Batch: 1630/1676, Loss: 0.8768, Time: 1.97s\n",
      "Epoch: 27, Batch: 1640/1676, Loss: 0.5024, Time: 1.97s\n",
      "Epoch: 27, Batch: 1650/1676, Loss: 0.5289, Time: 1.97s\n",
      "Epoch: 27, Batch: 1660/1676, Loss: 0.2853, Time: 1.98s\n",
      "Epoch: 27, Batch: 1670/1676, Loss: 0.7770, Time: 1.97s\n",
      "Epoch 28/50: Train Loss: 0.6819, Val Loss: 0.7097, Val IoU: 0.5627, Val Dice: 0.5823\n",
      "Epoch: 28, Batch: 0/1676, Loss: 0.6193, Time: 35.11s\n",
      "Epoch: 28, Batch: 10/1676, Loss: 0.9136, Time: 1.97s\n",
      "Epoch: 28, Batch: 20/1676, Loss: 0.3767, Time: 1.94s\n",
      "Epoch: 28, Batch: 30/1676, Loss: 0.6033, Time: 1.96s\n",
      "Epoch: 28, Batch: 40/1676, Loss: 0.7606, Time: 1.96s\n",
      "Epoch: 28, Batch: 50/1676, Loss: 0.4152, Time: 1.97s\n",
      "Epoch: 28, Batch: 60/1676, Loss: 0.5254, Time: 1.97s\n",
      "Epoch: 28, Batch: 70/1676, Loss: 0.4332, Time: 1.97s\n",
      "Epoch: 28, Batch: 80/1676, Loss: 0.6915, Time: 1.97s\n",
      "Epoch: 28, Batch: 90/1676, Loss: 0.9360, Time: 1.97s\n",
      "Epoch: 28, Batch: 100/1676, Loss: 0.3534, Time: 1.97s\n",
      "Epoch: 28, Batch: 110/1676, Loss: 0.4920, Time: 1.97s\n",
      "Epoch: 28, Batch: 120/1676, Loss: 0.6402, Time: 1.98s\n",
      "Epoch: 28, Batch: 130/1676, Loss: 0.2225, Time: 1.96s\n",
      "Epoch: 28, Batch: 140/1676, Loss: 0.2553, Time: 1.98s\n",
      "Epoch: 28, Batch: 150/1676, Loss: 0.7371, Time: 1.98s\n",
      "Epoch: 28, Batch: 160/1676, Loss: 0.7894, Time: 1.97s\n",
      "Epoch: 28, Batch: 170/1676, Loss: 0.6132, Time: 1.97s\n",
      "Epoch: 28, Batch: 180/1676, Loss: 0.6270, Time: 1.98s\n",
      "Epoch: 28, Batch: 190/1676, Loss: 0.6845, Time: 1.98s\n",
      "Epoch: 28, Batch: 200/1676, Loss: 0.6681, Time: 1.97s\n",
      "Epoch: 28, Batch: 210/1676, Loss: 1.2108, Time: 1.97s\n",
      "Epoch: 28, Batch: 220/1676, Loss: 0.7338, Time: 1.97s\n",
      "Epoch: 28, Batch: 230/1676, Loss: 0.9773, Time: 1.98s\n",
      "Epoch: 28, Batch: 240/1676, Loss: 1.6385, Time: 1.98s\n",
      "Epoch: 28, Batch: 250/1676, Loss: 0.4771, Time: 1.98s\n",
      "Epoch: 28, Batch: 260/1676, Loss: 0.4285, Time: 1.98s\n",
      "Epoch: 28, Batch: 270/1676, Loss: 0.8692, Time: 1.98s\n",
      "Epoch: 28, Batch: 280/1676, Loss: 0.8990, Time: 1.98s\n",
      "Epoch: 28, Batch: 290/1676, Loss: 0.7680, Time: 1.99s\n",
      "Epoch: 28, Batch: 300/1676, Loss: 0.9485, Time: 1.99s\n",
      "Epoch: 28, Batch: 310/1676, Loss: 0.7755, Time: 1.99s\n",
      "Epoch: 28, Batch: 320/1676, Loss: 0.5574, Time: 1.99s\n",
      "Epoch: 28, Batch: 330/1676, Loss: 0.5907, Time: 1.98s\n",
      "Epoch: 28, Batch: 340/1676, Loss: 0.5174, Time: 1.98s\n",
      "Epoch: 28, Batch: 350/1676, Loss: 1.4035, Time: 1.99s\n",
      "Epoch: 28, Batch: 360/1676, Loss: 0.9062, Time: 1.99s\n",
      "Epoch: 28, Batch: 370/1676, Loss: 0.9997, Time: 2.00s\n",
      "Epoch: 28, Batch: 380/1676, Loss: 0.7640, Time: 2.00s\n",
      "Epoch: 28, Batch: 390/1676, Loss: 0.4291, Time: 2.00s\n",
      "Epoch: 28, Batch: 400/1676, Loss: 0.7951, Time: 2.02s\n",
      "Epoch: 28, Batch: 410/1676, Loss: 0.3224, Time: 2.01s\n",
      "Epoch: 28, Batch: 420/1676, Loss: 0.2994, Time: 2.00s\n",
      "Epoch: 28, Batch: 430/1676, Loss: 1.4144, Time: 1.97s\n",
      "Epoch: 28, Batch: 440/1676, Loss: 1.6999, Time: 1.97s\n",
      "Epoch: 28, Batch: 450/1676, Loss: 0.2643, Time: 1.96s\n",
      "Epoch: 28, Batch: 460/1676, Loss: 0.4979, Time: 1.97s\n",
      "Epoch: 28, Batch: 470/1676, Loss: 1.2493, Time: 1.95s\n",
      "Epoch: 28, Batch: 480/1676, Loss: 1.4960, Time: 1.96s\n",
      "Epoch: 28, Batch: 490/1676, Loss: 0.5016, Time: 1.96s\n",
      "Epoch: 28, Batch: 500/1676, Loss: 0.7418, Time: 2.00s\n",
      "Epoch: 28, Batch: 510/1676, Loss: 0.7366, Time: 1.97s\n",
      "Epoch: 28, Batch: 520/1676, Loss: 1.3971, Time: 1.97s\n",
      "Epoch: 28, Batch: 530/1676, Loss: 0.9842, Time: 1.98s\n",
      "Epoch: 28, Batch: 540/1676, Loss: 1.2633, Time: 1.96s\n",
      "Epoch: 28, Batch: 550/1676, Loss: 0.4058, Time: 1.96s\n",
      "Epoch: 28, Batch: 560/1676, Loss: 0.9574, Time: 1.97s\n",
      "Epoch: 28, Batch: 570/1676, Loss: 0.4700, Time: 1.97s\n",
      "Epoch: 28, Batch: 580/1676, Loss: 0.5284, Time: 1.97s\n",
      "Epoch: 28, Batch: 590/1676, Loss: 0.3118, Time: 1.96s\n",
      "Epoch: 28, Batch: 600/1676, Loss: 0.6095, Time: 1.98s\n",
      "Epoch: 28, Batch: 610/1676, Loss: 0.6738, Time: 1.98s\n",
      "Epoch: 28, Batch: 620/1676, Loss: 0.5839, Time: 2.00s\n",
      "Epoch: 28, Batch: 630/1676, Loss: 0.9848, Time: 2.01s\n",
      "Epoch: 28, Batch: 640/1676, Loss: 0.9800, Time: 2.02s\n",
      "Epoch: 28, Batch: 650/1676, Loss: 0.8810, Time: 1.97s\n",
      "Epoch: 28, Batch: 660/1676, Loss: 0.7980, Time: 1.96s\n",
      "Epoch: 28, Batch: 670/1676, Loss: 0.5501, Time: 1.99s\n",
      "Epoch: 28, Batch: 680/1676, Loss: 0.3487, Time: 2.09s\n",
      "Epoch: 28, Batch: 690/1676, Loss: 1.4826, Time: 2.01s\n",
      "Epoch: 28, Batch: 700/1676, Loss: 1.0638, Time: 2.01s\n",
      "Epoch: 28, Batch: 710/1676, Loss: 0.9138, Time: 1.96s\n",
      "Epoch: 28, Batch: 720/1676, Loss: 0.5251, Time: 2.00s\n",
      "Epoch: 28, Batch: 730/1676, Loss: 0.3285, Time: 2.06s\n",
      "Epoch: 28, Batch: 740/1676, Loss: 0.6065, Time: 2.07s\n",
      "Epoch: 28, Batch: 750/1676, Loss: 0.5599, Time: 1.97s\n",
      "Epoch: 28, Batch: 760/1676, Loss: 1.1221, Time: 2.02s\n",
      "Epoch: 28, Batch: 770/1676, Loss: 0.6018, Time: 1.98s\n",
      "Epoch: 28, Batch: 780/1676, Loss: 0.7569, Time: 1.98s\n",
      "Epoch: 28, Batch: 790/1676, Loss: 0.5533, Time: 1.97s\n",
      "Epoch: 28, Batch: 800/1676, Loss: 0.7784, Time: 1.98s\n",
      "Epoch: 28, Batch: 810/1676, Loss: 0.5337, Time: 1.97s\n",
      "Epoch: 28, Batch: 820/1676, Loss: 1.3102, Time: 1.96s\n",
      "Epoch: 28, Batch: 830/1676, Loss: 0.5178, Time: 1.96s\n",
      "Epoch: 28, Batch: 840/1676, Loss: 0.5276, Time: 1.97s\n",
      "Epoch: 28, Batch: 850/1676, Loss: 0.3008, Time: 1.97s\n",
      "Epoch: 28, Batch: 860/1676, Loss: 0.8212, Time: 1.96s\n",
      "Epoch: 28, Batch: 870/1676, Loss: 0.8197, Time: 1.97s\n",
      "Epoch: 28, Batch: 880/1676, Loss: 0.7728, Time: 1.97s\n",
      "Epoch: 28, Batch: 890/1676, Loss: 0.7273, Time: 1.96s\n",
      "Epoch: 28, Batch: 900/1676, Loss: 0.5796, Time: 1.97s\n",
      "Epoch: 28, Batch: 910/1676, Loss: 0.4565, Time: 1.96s\n",
      "Epoch: 28, Batch: 920/1676, Loss: 0.8872, Time: 1.97s\n",
      "Epoch: 28, Batch: 930/1676, Loss: 0.7738, Time: 1.96s\n",
      "Epoch: 28, Batch: 940/1676, Loss: 0.4527, Time: 1.97s\n",
      "Epoch: 28, Batch: 950/1676, Loss: 0.6607, Time: 1.97s\n",
      "Epoch: 28, Batch: 960/1676, Loss: 0.6180, Time: 1.96s\n",
      "Epoch: 28, Batch: 970/1676, Loss: 0.9747, Time: 1.97s\n",
      "Epoch: 28, Batch: 980/1676, Loss: 0.9431, Time: 1.97s\n",
      "Epoch: 28, Batch: 990/1676, Loss: 1.1044, Time: 1.96s\n",
      "Epoch: 28, Batch: 1000/1676, Loss: 1.1958, Time: 1.97s\n",
      "Epoch: 28, Batch: 1010/1676, Loss: 0.5424, Time: 1.97s\n",
      "Epoch: 28, Batch: 1020/1676, Loss: 0.8338, Time: 1.97s\n",
      "Epoch: 28, Batch: 1030/1676, Loss: 0.8073, Time: 1.97s\n",
      "Epoch: 28, Batch: 1040/1676, Loss: 0.3190, Time: 1.97s\n",
      "Epoch: 28, Batch: 1050/1676, Loss: 0.2985, Time: 1.97s\n",
      "Epoch: 28, Batch: 1060/1676, Loss: 0.7626, Time: 1.97s\n",
      "Epoch: 28, Batch: 1070/1676, Loss: 0.3981, Time: 1.97s\n",
      "Epoch: 28, Batch: 1080/1676, Loss: 0.8504, Time: 1.97s\n",
      "Epoch: 28, Batch: 1090/1676, Loss: 0.5057, Time: 1.97s\n",
      "Epoch: 28, Batch: 1100/1676, Loss: 0.6856, Time: 1.97s\n",
      "Epoch: 28, Batch: 1110/1676, Loss: 0.5681, Time: 1.97s\n",
      "Epoch: 28, Batch: 1120/1676, Loss: 0.8950, Time: 1.96s\n",
      "Epoch: 28, Batch: 1130/1676, Loss: 0.7801, Time: 1.97s\n",
      "Epoch: 28, Batch: 1140/1676, Loss: 0.5606, Time: 1.97s\n",
      "Epoch: 28, Batch: 1150/1676, Loss: 0.7808, Time: 1.97s\n",
      "Epoch: 28, Batch: 1160/1676, Loss: 0.3796, Time: 1.97s\n",
      "Epoch: 28, Batch: 1170/1676, Loss: 0.4854, Time: 1.97s\n",
      "Epoch: 28, Batch: 1180/1676, Loss: 0.2796, Time: 1.96s\n",
      "Epoch: 28, Batch: 1190/1676, Loss: 0.5294, Time: 1.97s\n",
      "Epoch: 28, Batch: 1200/1676, Loss: 0.4242, Time: 1.97s\n",
      "Epoch: 28, Batch: 1210/1676, Loss: 0.6412, Time: 1.97s\n",
      "Epoch: 28, Batch: 1220/1676, Loss: 0.5898, Time: 1.97s\n",
      "Epoch: 28, Batch: 1230/1676, Loss: 0.5574, Time: 1.97s\n",
      "Epoch: 28, Batch: 1240/1676, Loss: 1.0748, Time: 1.97s\n",
      "Epoch: 28, Batch: 1250/1676, Loss: 0.6688, Time: 1.97s\n",
      "Epoch: 28, Batch: 1260/1676, Loss: 0.6499, Time: 1.97s\n",
      "Epoch: 28, Batch: 1270/1676, Loss: 0.8000, Time: 1.97s\n",
      "Epoch: 28, Batch: 1280/1676, Loss: 0.7599, Time: 1.97s\n",
      "Epoch: 28, Batch: 1290/1676, Loss: 0.7504, Time: 1.97s\n",
      "Epoch: 28, Batch: 1300/1676, Loss: 0.3049, Time: 1.97s\n",
      "Epoch: 28, Batch: 1310/1676, Loss: 1.0411, Time: 1.97s\n",
      "Epoch: 28, Batch: 1320/1676, Loss: 1.2461, Time: 1.98s\n",
      "Epoch: 28, Batch: 1330/1676, Loss: 0.4327, Time: 1.97s\n",
      "Epoch: 28, Batch: 1340/1676, Loss: 0.9842, Time: 1.97s\n",
      "Epoch: 28, Batch: 1350/1676, Loss: 0.4178, Time: 1.96s\n",
      "Epoch: 28, Batch: 1360/1676, Loss: 0.3616, Time: 1.97s\n",
      "Epoch: 28, Batch: 1370/1676, Loss: 0.6381, Time: 1.97s\n",
      "Epoch: 28, Batch: 1380/1676, Loss: 0.4426, Time: 1.97s\n",
      "Epoch: 28, Batch: 1390/1676, Loss: 0.8935, Time: 1.97s\n",
      "Epoch: 28, Batch: 1400/1676, Loss: 0.6545, Time: 1.97s\n",
      "Epoch: 28, Batch: 1410/1676, Loss: 0.6753, Time: 1.97s\n",
      "Epoch: 28, Batch: 1420/1676, Loss: 0.3117, Time: 1.97s\n",
      "Epoch: 28, Batch: 1430/1676, Loss: 0.3840, Time: 1.97s\n",
      "Epoch: 28, Batch: 1440/1676, Loss: 0.5205, Time: 1.96s\n",
      "Epoch: 28, Batch: 1450/1676, Loss: 0.9282, Time: 1.96s\n",
      "Epoch: 28, Batch: 1460/1676, Loss: 0.7807, Time: 1.98s\n",
      "Epoch: 28, Batch: 1470/1676, Loss: 0.4731, Time: 1.96s\n",
      "Epoch: 28, Batch: 1480/1676, Loss: 0.6120, Time: 1.97s\n",
      "Epoch: 28, Batch: 1490/1676, Loss: 0.7625, Time: 1.97s\n",
      "Epoch: 28, Batch: 1500/1676, Loss: 0.7713, Time: 1.98s\n",
      "Epoch: 28, Batch: 1510/1676, Loss: 0.7807, Time: 1.98s\n",
      "Epoch: 28, Batch: 1520/1676, Loss: 0.5965, Time: 1.96s\n",
      "Epoch: 28, Batch: 1530/1676, Loss: 0.2928, Time: 1.97s\n",
      "Epoch: 28, Batch: 1540/1676, Loss: 0.6681, Time: 1.97s\n",
      "Epoch: 28, Batch: 1550/1676, Loss: 0.7093, Time: 1.98s\n",
      "Epoch: 28, Batch: 1560/1676, Loss: 0.3879, Time: 1.97s\n",
      "Epoch: 28, Batch: 1570/1676, Loss: 0.4368, Time: 1.97s\n",
      "Epoch: 28, Batch: 1580/1676, Loss: 0.4627, Time: 1.98s\n",
      "Epoch: 28, Batch: 1590/1676, Loss: 0.4806, Time: 1.97s\n",
      "Epoch: 28, Batch: 1600/1676, Loss: 0.6791, Time: 1.98s\n",
      "Epoch: 28, Batch: 1610/1676, Loss: 0.6918, Time: 1.97s\n",
      "Epoch: 28, Batch: 1620/1676, Loss: 1.0291, Time: 1.97s\n",
      "Epoch: 28, Batch: 1630/1676, Loss: 0.5689, Time: 1.97s\n",
      "Epoch: 28, Batch: 1640/1676, Loss: 0.3718, Time: 1.98s\n",
      "Epoch: 28, Batch: 1650/1676, Loss: 1.0216, Time: 1.97s\n",
      "Epoch: 28, Batch: 1660/1676, Loss: 0.8808, Time: 1.97s\n",
      "Epoch: 28, Batch: 1670/1676, Loss: 0.5474, Time: 1.98s\n",
      "Epoch 29/50: Train Loss: 0.6792, Val Loss: 0.6935, Val IoU: 0.5608, Val Dice: 0.5803\n",
      "Epoch: 29, Batch: 0/1676, Loss: 0.7961, Time: 35.89s\n",
      "Epoch: 29, Batch: 10/1676, Loss: 0.5905, Time: 1.98s\n",
      "Epoch: 29, Batch: 20/1676, Loss: 0.5622, Time: 1.93s\n",
      "Epoch: 29, Batch: 30/1676, Loss: 0.3865, Time: 1.94s\n",
      "Epoch: 29, Batch: 40/1676, Loss: 0.5043, Time: 1.93s\n",
      "Epoch: 29, Batch: 50/1676, Loss: 0.9471, Time: 1.94s\n",
      "Epoch: 29, Batch: 60/1676, Loss: 0.5752, Time: 1.93s\n",
      "Epoch: 29, Batch: 70/1676, Loss: 1.0976, Time: 1.93s\n",
      "Epoch: 29, Batch: 80/1676, Loss: 0.4996, Time: 1.93s\n",
      "Epoch: 29, Batch: 90/1676, Loss: 0.7911, Time: 1.94s\n",
      "Epoch: 29, Batch: 100/1676, Loss: 0.8019, Time: 1.94s\n",
      "Epoch: 29, Batch: 110/1676, Loss: 0.7579, Time: 1.94s\n",
      "Epoch: 29, Batch: 120/1676, Loss: 1.1944, Time: 1.94s\n",
      "Epoch: 29, Batch: 130/1676, Loss: 0.6626, Time: 1.94s\n",
      "Epoch: 29, Batch: 140/1676, Loss: 0.4478, Time: 1.94s\n",
      "Epoch: 29, Batch: 150/1676, Loss: 0.5056, Time: 1.94s\n",
      "Epoch: 29, Batch: 160/1676, Loss: 0.4206, Time: 1.94s\n",
      "Epoch: 29, Batch: 170/1676, Loss: 0.5313, Time: 1.95s\n",
      "Epoch: 29, Batch: 180/1676, Loss: 0.5021, Time: 1.94s\n",
      "Epoch: 29, Batch: 190/1676, Loss: 0.5170, Time: 1.95s\n",
      "Epoch: 29, Batch: 200/1676, Loss: 0.5242, Time: 1.95s\n",
      "Epoch: 29, Batch: 210/1676, Loss: 0.3767, Time: 1.95s\n",
      "Epoch: 29, Batch: 220/1676, Loss: 0.4408, Time: 1.95s\n",
      "Epoch: 29, Batch: 230/1676, Loss: 1.0735, Time: 1.95s\n",
      "Epoch: 29, Batch: 240/1676, Loss: 0.9376, Time: 1.95s\n",
      "Epoch: 29, Batch: 250/1676, Loss: 0.6194, Time: 1.95s\n",
      "Epoch: 29, Batch: 260/1676, Loss: 0.6848, Time: 1.95s\n",
      "Epoch: 29, Batch: 270/1676, Loss: 0.9535, Time: 1.96s\n",
      "Epoch: 29, Batch: 280/1676, Loss: 0.8916, Time: 1.95s\n",
      "Epoch: 29, Batch: 290/1676, Loss: 0.4589, Time: 1.95s\n",
      "Epoch: 29, Batch: 300/1676, Loss: 0.6958, Time: 1.96s\n",
      "Epoch: 29, Batch: 310/1676, Loss: 0.4380, Time: 1.95s\n",
      "Epoch: 29, Batch: 320/1676, Loss: 0.8459, Time: 1.96s\n",
      "Epoch: 29, Batch: 330/1676, Loss: 0.4241, Time: 1.96s\n",
      "Epoch: 29, Batch: 340/1676, Loss: 0.7461, Time: 1.95s\n",
      "Epoch: 29, Batch: 350/1676, Loss: 0.9276, Time: 1.96s\n",
      "Epoch: 29, Batch: 360/1676, Loss: 0.3226, Time: 1.97s\n",
      "Epoch: 29, Batch: 370/1676, Loss: 0.4722, Time: 1.96s\n",
      "Epoch: 29, Batch: 380/1676, Loss: 1.0240, Time: 1.96s\n",
      "Epoch: 29, Batch: 390/1676, Loss: 0.6032, Time: 1.96s\n",
      "Epoch: 29, Batch: 400/1676, Loss: 0.3272, Time: 1.96s\n",
      "Epoch: 29, Batch: 410/1676, Loss: 0.3675, Time: 1.96s\n",
      "Epoch: 29, Batch: 420/1676, Loss: 0.7258, Time: 1.96s\n",
      "Epoch: 29, Batch: 430/1676, Loss: 0.6737, Time: 1.96s\n",
      "Epoch: 29, Batch: 440/1676, Loss: 1.0882, Time: 1.96s\n",
      "Epoch: 29, Batch: 450/1676, Loss: 0.9168, Time: 1.96s\n",
      "Epoch: 29, Batch: 460/1676, Loss: 0.8104, Time: 1.97s\n",
      "Epoch: 29, Batch: 470/1676, Loss: 0.5933, Time: 1.96s\n",
      "Epoch: 29, Batch: 480/1676, Loss: 0.8420, Time: 1.96s\n",
      "Epoch: 29, Batch: 490/1676, Loss: 0.4215, Time: 1.96s\n",
      "Epoch: 29, Batch: 500/1676, Loss: 0.3366, Time: 1.96s\n",
      "Epoch: 29, Batch: 510/1676, Loss: 0.8152, Time: 1.96s\n",
      "Epoch: 29, Batch: 520/1676, Loss: 0.7330, Time: 1.97s\n",
      "Epoch: 29, Batch: 530/1676, Loss: 0.6605, Time: 1.96s\n",
      "Epoch: 29, Batch: 540/1676, Loss: 0.5670, Time: 1.96s\n",
      "Epoch: 29, Batch: 550/1676, Loss: 0.9596, Time: 1.97s\n",
      "Epoch: 29, Batch: 560/1676, Loss: 0.4936, Time: 1.97s\n",
      "Epoch: 29, Batch: 570/1676, Loss: 1.1675, Time: 1.96s\n",
      "Epoch: 29, Batch: 580/1676, Loss: 0.6406, Time: 1.97s\n",
      "Epoch: 29, Batch: 590/1676, Loss: 1.1344, Time: 1.96s\n",
      "Epoch: 29, Batch: 600/1676, Loss: 0.8339, Time: 1.96s\n",
      "Epoch: 29, Batch: 610/1676, Loss: 0.9350, Time: 1.96s\n",
      "Epoch: 29, Batch: 620/1676, Loss: 0.5119, Time: 1.97s\n",
      "Epoch: 29, Batch: 630/1676, Loss: 0.8642, Time: 1.96s\n",
      "Epoch: 29, Batch: 640/1676, Loss: 1.0267, Time: 1.96s\n",
      "Epoch: 29, Batch: 650/1676, Loss: 0.2998, Time: 1.97s\n",
      "Epoch: 29, Batch: 660/1676, Loss: 0.5045, Time: 1.97s\n",
      "Epoch: 29, Batch: 670/1676, Loss: 1.0045, Time: 1.97s\n",
      "Epoch: 29, Batch: 680/1676, Loss: 0.3744, Time: 1.96s\n",
      "Epoch: 29, Batch: 690/1676, Loss: 0.2574, Time: 1.96s\n",
      "Epoch: 29, Batch: 700/1676, Loss: 0.7587, Time: 1.96s\n",
      "Epoch: 29, Batch: 710/1676, Loss: 0.3324, Time: 1.97s\n",
      "Epoch: 29, Batch: 720/1676, Loss: 0.7797, Time: 1.97s\n",
      "Epoch: 29, Batch: 730/1676, Loss: 0.9436, Time: 1.97s\n",
      "Epoch: 29, Batch: 740/1676, Loss: 0.7082, Time: 1.96s\n",
      "Epoch: 29, Batch: 750/1676, Loss: 0.4357, Time: 1.96s\n",
      "Epoch: 29, Batch: 760/1676, Loss: 0.5199, Time: 1.97s\n",
      "Epoch: 29, Batch: 770/1676, Loss: 0.6563, Time: 1.97s\n",
      "Epoch: 29, Batch: 780/1676, Loss: 0.9820, Time: 1.97s\n",
      "Epoch: 29, Batch: 790/1676, Loss: 0.8584, Time: 1.97s\n",
      "Epoch: 29, Batch: 800/1676, Loss: 0.5508, Time: 1.97s\n",
      "Epoch: 29, Batch: 810/1676, Loss: 1.1262, Time: 1.97s\n",
      "Epoch: 29, Batch: 820/1676, Loss: 0.3054, Time: 1.97s\n",
      "Epoch: 29, Batch: 830/1676, Loss: 0.8173, Time: 1.96s\n",
      "Epoch: 29, Batch: 840/1676, Loss: 0.8282, Time: 1.97s\n",
      "Epoch: 29, Batch: 850/1676, Loss: 0.6963, Time: 1.97s\n",
      "Epoch: 29, Batch: 860/1676, Loss: 0.8231, Time: 1.96s\n",
      "Epoch: 29, Batch: 870/1676, Loss: 0.3882, Time: 1.97s\n",
      "Epoch: 29, Batch: 880/1676, Loss: 0.8903, Time: 1.97s\n",
      "Epoch: 29, Batch: 890/1676, Loss: 0.3397, Time: 1.97s\n",
      "Epoch: 29, Batch: 900/1676, Loss: 0.9171, Time: 1.97s\n",
      "Epoch: 29, Batch: 910/1676, Loss: 0.3252, Time: 1.97s\n",
      "Epoch: 29, Batch: 920/1676, Loss: 0.7878, Time: 1.97s\n",
      "Epoch: 29, Batch: 930/1676, Loss: 0.3751, Time: 1.97s\n",
      "Epoch: 29, Batch: 940/1676, Loss: 0.9638, Time: 1.97s\n",
      "Epoch: 29, Batch: 950/1676, Loss: 0.8441, Time: 1.97s\n",
      "Epoch: 29, Batch: 960/1676, Loss: 1.0085, Time: 1.97s\n",
      "Epoch: 29, Batch: 970/1676, Loss: 0.4233, Time: 1.97s\n",
      "Epoch: 29, Batch: 980/1676, Loss: 1.1182, Time: 1.97s\n",
      "Epoch: 29, Batch: 990/1676, Loss: 0.4502, Time: 1.97s\n",
      "Epoch: 29, Batch: 1000/1676, Loss: 0.2320, Time: 1.97s\n",
      "Epoch: 29, Batch: 1010/1676, Loss: 0.3930, Time: 1.96s\n",
      "Epoch: 29, Batch: 1020/1676, Loss: 1.4055, Time: 1.97s\n",
      "Epoch: 29, Batch: 1030/1676, Loss: 0.6909, Time: 1.97s\n",
      "Epoch: 29, Batch: 1040/1676, Loss: 0.2823, Time: 1.96s\n",
      "Epoch: 29, Batch: 1050/1676, Loss: 0.6461, Time: 1.97s\n",
      "Epoch: 29, Batch: 1060/1676, Loss: 1.2909, Time: 1.97s\n",
      "Epoch: 29, Batch: 1070/1676, Loss: 1.0016, Time: 1.97s\n",
      "Epoch: 29, Batch: 1080/1676, Loss: 0.4383, Time: 1.97s\n",
      "Epoch: 29, Batch: 1090/1676, Loss: 0.9300, Time: 1.97s\n",
      "Epoch: 29, Batch: 1100/1676, Loss: 0.8869, Time: 1.97s\n",
      "Epoch: 29, Batch: 1110/1676, Loss: 0.6192, Time: 1.97s\n",
      "Epoch: 29, Batch: 1120/1676, Loss: 1.2919, Time: 1.97s\n",
      "Epoch: 29, Batch: 1130/1676, Loss: 0.9588, Time: 1.97s\n",
      "Epoch: 29, Batch: 1140/1676, Loss: 0.6603, Time: 1.97s\n",
      "Epoch: 29, Batch: 1150/1676, Loss: 0.3571, Time: 1.97s\n",
      "Epoch: 29, Batch: 1160/1676, Loss: 0.3220, Time: 1.97s\n",
      "Epoch: 29, Batch: 1170/1676, Loss: 0.7682, Time: 1.97s\n",
      "Epoch: 29, Batch: 1180/1676, Loss: 0.6080, Time: 1.97s\n",
      "Epoch: 29, Batch: 1190/1676, Loss: 0.9985, Time: 1.97s\n",
      "Epoch: 29, Batch: 1200/1676, Loss: 1.0824, Time: 1.97s\n",
      "Epoch: 29, Batch: 1210/1676, Loss: 0.7339, Time: 1.97s\n",
      "Epoch: 29, Batch: 1220/1676, Loss: 0.7202, Time: 1.97s\n",
      "Epoch: 29, Batch: 1230/1676, Loss: 0.4356, Time: 1.97s\n",
      "Epoch: 29, Batch: 1240/1676, Loss: 0.8535, Time: 1.97s\n",
      "Epoch: 29, Batch: 1250/1676, Loss: 0.8246, Time: 1.97s\n",
      "Epoch: 29, Batch: 1260/1676, Loss: 0.6312, Time: 1.97s\n",
      "Epoch: 29, Batch: 1270/1676, Loss: 1.2198, Time: 1.97s\n",
      "Epoch: 29, Batch: 1280/1676, Loss: 0.6254, Time: 1.97s\n",
      "Epoch: 29, Batch: 1290/1676, Loss: 1.4332, Time: 1.97s\n",
      "Epoch: 29, Batch: 1300/1676, Loss: 0.8029, Time: 1.97s\n",
      "Epoch: 29, Batch: 1310/1676, Loss: 0.3041, Time: 1.97s\n",
      "Epoch: 29, Batch: 1320/1676, Loss: 0.4655, Time: 1.97s\n",
      "Epoch: 29, Batch: 1330/1676, Loss: 0.7000, Time: 1.97s\n",
      "Epoch: 29, Batch: 1340/1676, Loss: 0.5469, Time: 1.97s\n",
      "Epoch: 29, Batch: 1350/1676, Loss: 0.4189, Time: 1.97s\n",
      "Epoch: 29, Batch: 1360/1676, Loss: 0.7734, Time: 1.97s\n",
      "Epoch: 29, Batch: 1370/1676, Loss: 1.0022, Time: 1.97s\n",
      "Epoch: 29, Batch: 1380/1676, Loss: 0.6121, Time: 1.97s\n",
      "Epoch: 29, Batch: 1390/1676, Loss: 0.7025, Time: 1.97s\n",
      "Epoch: 29, Batch: 1400/1676, Loss: 0.9332, Time: 1.97s\n",
      "Epoch: 29, Batch: 1410/1676, Loss: 1.0017, Time: 1.97s\n",
      "Epoch: 29, Batch: 1420/1676, Loss: 0.5555, Time: 1.98s\n",
      "Epoch: 29, Batch: 1430/1676, Loss: 0.8213, Time: 1.97s\n",
      "Epoch: 29, Batch: 1440/1676, Loss: 0.4927, Time: 1.97s\n",
      "Epoch: 29, Batch: 1450/1676, Loss: 0.3579, Time: 1.98s\n",
      "Epoch: 29, Batch: 1460/1676, Loss: 0.4306, Time: 1.97s\n",
      "Epoch: 29, Batch: 1470/1676, Loss: 0.4555, Time: 1.97s\n",
      "Epoch: 29, Batch: 1480/1676, Loss: 0.6479, Time: 1.97s\n",
      "Epoch: 29, Batch: 1490/1676, Loss: 0.6721, Time: 1.98s\n",
      "Epoch: 29, Batch: 1500/1676, Loss: 0.6877, Time: 1.98s\n",
      "Epoch: 29, Batch: 1510/1676, Loss: 0.3644, Time: 2.00s\n",
      "Epoch: 29, Batch: 1520/1676, Loss: 0.7381, Time: 2.00s\n",
      "Epoch: 29, Batch: 1530/1676, Loss: 0.6293, Time: 2.01s\n",
      "Epoch: 29, Batch: 1540/1676, Loss: 0.9408, Time: 2.01s\n",
      "Epoch: 29, Batch: 1550/1676, Loss: 0.9580, Time: 2.01s\n",
      "Epoch: 29, Batch: 1560/1676, Loss: 0.3543, Time: 2.00s\n",
      "Epoch: 29, Batch: 1570/1676, Loss: 0.4082, Time: 2.00s\n",
      "Epoch: 29, Batch: 1580/1676, Loss: 0.5257, Time: 2.01s\n",
      "Epoch: 29, Batch: 1590/1676, Loss: 1.0009, Time: 2.01s\n",
      "Epoch: 29, Batch: 1600/1676, Loss: 0.4705, Time: 2.01s\n",
      "Epoch: 29, Batch: 1610/1676, Loss: 0.6540, Time: 2.01s\n",
      "Epoch: 29, Batch: 1620/1676, Loss: 0.3492, Time: 2.01s\n",
      "Epoch: 29, Batch: 1630/1676, Loss: 1.0996, Time: 2.01s\n",
      "Epoch: 29, Batch: 1640/1676, Loss: 1.0521, Time: 2.01s\n",
      "Epoch: 29, Batch: 1650/1676, Loss: 0.7000, Time: 1.97s\n",
      "Epoch: 29, Batch: 1660/1676, Loss: 0.5269, Time: 1.96s\n",
      "Epoch: 29, Batch: 1670/1676, Loss: 0.6203, Time: 1.96s\n",
      "Epoch 30/50: Train Loss: 0.6780, Val Loss: 0.7026, Val IoU: 0.5575, Val Dice: 0.5779\n",
      "Epoch: 30, Batch: 0/1676, Loss: 0.4403, Time: 35.58s\n",
      "Epoch: 30, Batch: 10/1676, Loss: 1.0652, Time: 1.97s\n",
      "Epoch: 30, Batch: 20/1676, Loss: 0.4486, Time: 1.92s\n",
      "Epoch: 30, Batch: 30/1676, Loss: 1.4406, Time: 1.92s\n",
      "Epoch: 30, Batch: 40/1676, Loss: 0.4168, Time: 1.93s\n",
      "Epoch: 30, Batch: 50/1676, Loss: 0.8210, Time: 1.92s\n",
      "Epoch: 30, Batch: 60/1676, Loss: 0.8073, Time: 1.93s\n",
      "Epoch: 30, Batch: 70/1676, Loss: 0.3993, Time: 1.93s\n",
      "Epoch: 30, Batch: 80/1676, Loss: 0.6498, Time: 1.93s\n",
      "Epoch: 30, Batch: 90/1676, Loss: 0.8600, Time: 1.91s\n",
      "Epoch: 30, Batch: 100/1676, Loss: 0.3337, Time: 1.95s\n",
      "Epoch: 30, Batch: 110/1676, Loss: 0.3074, Time: 1.93s\n",
      "Epoch: 30, Batch: 120/1676, Loss: 1.1685, Time: 1.93s\n",
      "Epoch: 30, Batch: 130/1676, Loss: 0.5206, Time: 1.94s\n",
      "Epoch: 30, Batch: 140/1676, Loss: 0.6109, Time: 1.93s\n",
      "Epoch: 30, Batch: 150/1676, Loss: 0.9253, Time: 1.94s\n",
      "Epoch: 30, Batch: 160/1676, Loss: 0.2846, Time: 1.94s\n",
      "Epoch: 30, Batch: 170/1676, Loss: 0.6980, Time: 1.94s\n",
      "Epoch: 30, Batch: 180/1676, Loss: 0.8022, Time: 1.93s\n",
      "Epoch: 30, Batch: 190/1676, Loss: 0.5283, Time: 1.94s\n",
      "Epoch: 30, Batch: 200/1676, Loss: 0.4178, Time: 1.94s\n",
      "Epoch: 30, Batch: 210/1676, Loss: 0.4866, Time: 1.94s\n",
      "Epoch: 30, Batch: 220/1676, Loss: 0.5383, Time: 1.94s\n",
      "Epoch: 30, Batch: 230/1676, Loss: 0.9023, Time: 1.93s\n",
      "Epoch: 30, Batch: 240/1676, Loss: 0.7611, Time: 1.94s\n",
      "Epoch: 30, Batch: 250/1676, Loss: 0.7895, Time: 1.94s\n",
      "Epoch: 30, Batch: 260/1676, Loss: 0.5313, Time: 1.93s\n",
      "Epoch: 30, Batch: 270/1676, Loss: 0.7242, Time: 1.95s\n",
      "Epoch: 30, Batch: 280/1676, Loss: 0.8671, Time: 1.95s\n",
      "Epoch: 30, Batch: 290/1676, Loss: 0.5579, Time: 1.95s\n",
      "Epoch: 30, Batch: 300/1676, Loss: 0.7992, Time: 1.94s\n",
      "Epoch: 30, Batch: 310/1676, Loss: 0.7017, Time: 1.95s\n",
      "Epoch: 30, Batch: 320/1676, Loss: 0.3387, Time: 1.94s\n",
      "Epoch: 30, Batch: 330/1676, Loss: 0.2221, Time: 1.96s\n",
      "Epoch: 30, Batch: 340/1676, Loss: 0.4674, Time: 1.95s\n",
      "Epoch: 30, Batch: 350/1676, Loss: 0.6181, Time: 1.95s\n",
      "Epoch: 30, Batch: 360/1676, Loss: 0.9034, Time: 1.95s\n",
      "Epoch: 30, Batch: 370/1676, Loss: 0.7251, Time: 1.95s\n",
      "Epoch: 30, Batch: 380/1676, Loss: 0.4564, Time: 1.95s\n",
      "Epoch: 30, Batch: 390/1676, Loss: 0.3914, Time: 1.96s\n",
      "Epoch: 30, Batch: 400/1676, Loss: 0.7885, Time: 1.95s\n",
      "Epoch: 30, Batch: 410/1676, Loss: 0.6002, Time: 1.95s\n",
      "Epoch: 30, Batch: 420/1676, Loss: 0.4793, Time: 1.95s\n",
      "Epoch: 30, Batch: 430/1676, Loss: 0.7329, Time: 1.95s\n",
      "Epoch: 30, Batch: 440/1676, Loss: 0.5648, Time: 1.95s\n",
      "Epoch: 30, Batch: 450/1676, Loss: 0.4743, Time: 1.96s\n",
      "Epoch: 30, Batch: 460/1676, Loss: 0.7395, Time: 1.95s\n",
      "Epoch: 30, Batch: 470/1676, Loss: 1.2539, Time: 1.96s\n",
      "Epoch: 30, Batch: 480/1676, Loss: 0.7613, Time: 1.95s\n",
      "Epoch: 30, Batch: 490/1676, Loss: 0.8183, Time: 1.95s\n",
      "Epoch: 30, Batch: 500/1676, Loss: 0.3878, Time: 1.97s\n",
      "Epoch: 30, Batch: 510/1676, Loss: 0.2784, Time: 1.95s\n",
      "Epoch: 30, Batch: 520/1676, Loss: 0.5047, Time: 1.96s\n",
      "Epoch: 30, Batch: 530/1676, Loss: 0.6588, Time: 1.95s\n",
      "Epoch: 30, Batch: 540/1676, Loss: 0.4240, Time: 1.96s\n",
      "Epoch: 30, Batch: 550/1676, Loss: 0.8951, Time: 1.95s\n",
      "Epoch: 30, Batch: 560/1676, Loss: 0.6938, Time: 1.96s\n",
      "Epoch: 30, Batch: 570/1676, Loss: 0.9022, Time: 1.95s\n",
      "Epoch: 30, Batch: 580/1676, Loss: 1.1370, Time: 1.95s\n",
      "Epoch: 30, Batch: 590/1676, Loss: 0.4913, Time: 1.96s\n",
      "Epoch: 30, Batch: 600/1676, Loss: 0.7263, Time: 1.96s\n",
      "Epoch: 30, Batch: 610/1676, Loss: 0.3369, Time: 1.96s\n",
      "Epoch: 30, Batch: 620/1676, Loss: 0.8113, Time: 1.96s\n",
      "Epoch: 30, Batch: 630/1676, Loss: 0.5848, Time: 1.95s\n",
      "Epoch: 30, Batch: 640/1676, Loss: 0.4564, Time: 1.95s\n",
      "Epoch: 30, Batch: 650/1676, Loss: 0.3724, Time: 1.96s\n",
      "Epoch: 30, Batch: 660/1676, Loss: 0.5456, Time: 1.95s\n",
      "Epoch: 30, Batch: 670/1676, Loss: 1.0483, Time: 1.95s\n",
      "Epoch: 30, Batch: 680/1676, Loss: 0.7175, Time: 1.95s\n",
      "Epoch: 30, Batch: 690/1676, Loss: 0.4882, Time: 1.96s\n",
      "Epoch: 30, Batch: 700/1676, Loss: 0.9312, Time: 1.95s\n",
      "Epoch: 30, Batch: 710/1676, Loss: 0.6119, Time: 1.97s\n",
      "Epoch: 30, Batch: 720/1676, Loss: 0.7119, Time: 1.95s\n",
      "Epoch: 30, Batch: 730/1676, Loss: 0.2106, Time: 1.96s\n",
      "Epoch: 30, Batch: 740/1676, Loss: 0.7542, Time: 1.96s\n",
      "Epoch: 30, Batch: 750/1676, Loss: 0.2516, Time: 1.96s\n",
      "Epoch: 30, Batch: 760/1676, Loss: 0.6431, Time: 1.96s\n",
      "Epoch: 30, Batch: 770/1676, Loss: 1.0162, Time: 1.95s\n",
      "Epoch: 30, Batch: 780/1676, Loss: 1.0900, Time: 1.96s\n",
      "Epoch: 30, Batch: 790/1676, Loss: 0.8724, Time: 1.96s\n",
      "Epoch: 30, Batch: 800/1676, Loss: 0.5988, Time: 1.96s\n",
      "Epoch: 30, Batch: 810/1676, Loss: 0.7260, Time: 1.96s\n",
      "Epoch: 30, Batch: 820/1676, Loss: 0.6436, Time: 1.96s\n",
      "Epoch: 30, Batch: 830/1676, Loss: 0.7602, Time: 1.96s\n",
      "Epoch: 30, Batch: 840/1676, Loss: 0.4240, Time: 1.96s\n",
      "Epoch: 30, Batch: 850/1676, Loss: 0.5913, Time: 1.96s\n",
      "Epoch: 30, Batch: 860/1676, Loss: 0.7298, Time: 1.97s\n",
      "Epoch: 30, Batch: 870/1676, Loss: 0.5998, Time: 1.95s\n",
      "Epoch: 30, Batch: 880/1676, Loss: 0.3916, Time: 1.96s\n",
      "Epoch: 30, Batch: 890/1676, Loss: 1.0217, Time: 1.96s\n",
      "Epoch: 30, Batch: 900/1676, Loss: 0.4813, Time: 1.95s\n",
      "Epoch: 30, Batch: 910/1676, Loss: 0.5411, Time: 1.96s\n",
      "Epoch: 30, Batch: 920/1676, Loss: 0.4356, Time: 1.96s\n",
      "Epoch: 30, Batch: 930/1676, Loss: 0.5262, Time: 1.96s\n",
      "Epoch: 30, Batch: 940/1676, Loss: 0.7602, Time: 1.96s\n",
      "Epoch: 30, Batch: 950/1676, Loss: 0.6668, Time: 1.96s\n",
      "Epoch: 30, Batch: 960/1676, Loss: 0.4572, Time: 1.96s\n",
      "Epoch: 30, Batch: 970/1676, Loss: 1.2384, Time: 1.96s\n",
      "Epoch: 30, Batch: 980/1676, Loss: 0.6809, Time: 1.96s\n",
      "Epoch: 30, Batch: 990/1676, Loss: 1.0049, Time: 1.95s\n",
      "Epoch: 30, Batch: 1000/1676, Loss: 1.0206, Time: 1.97s\n",
      "Epoch: 30, Batch: 1010/1676, Loss: 0.7964, Time: 1.96s\n",
      "Epoch: 30, Batch: 1020/1676, Loss: 0.7920, Time: 1.96s\n",
      "Epoch: 30, Batch: 1030/1676, Loss: 1.2397, Time: 1.96s\n",
      "Epoch: 30, Batch: 1040/1676, Loss: 0.5215, Time: 1.97s\n",
      "Epoch: 30, Batch: 1050/1676, Loss: 0.3474, Time: 1.97s\n",
      "Epoch: 30, Batch: 1060/1676, Loss: 0.5850, Time: 1.97s\n",
      "Epoch: 30, Batch: 1070/1676, Loss: 0.6223, Time: 1.96s\n",
      "Epoch: 30, Batch: 1080/1676, Loss: 0.4848, Time: 1.97s\n",
      "Epoch: 30, Batch: 1090/1676, Loss: 0.6415, Time: 1.95s\n",
      "Epoch: 30, Batch: 1100/1676, Loss: 0.6277, Time: 1.96s\n",
      "Epoch: 30, Batch: 1110/1676, Loss: 0.9016, Time: 1.97s\n",
      "Epoch: 30, Batch: 1120/1676, Loss: 1.0862, Time: 1.95s\n",
      "Epoch: 30, Batch: 1130/1676, Loss: 0.3909, Time: 1.96s\n",
      "Epoch: 30, Batch: 1140/1676, Loss: 0.6274, Time: 1.96s\n",
      "Epoch: 30, Batch: 1150/1676, Loss: 0.8915, Time: 1.96s\n",
      "Epoch: 30, Batch: 1160/1676, Loss: 0.6903, Time: 1.96s\n",
      "Epoch: 30, Batch: 1170/1676, Loss: 0.5521, Time: 1.95s\n",
      "Epoch: 30, Batch: 1180/1676, Loss: 1.3554, Time: 1.97s\n",
      "Epoch: 30, Batch: 1190/1676, Loss: 0.4208, Time: 1.95s\n",
      "Epoch: 30, Batch: 1200/1676, Loss: 0.2746, Time: 1.96s\n",
      "Epoch: 30, Batch: 1210/1676, Loss: 0.3859, Time: 1.97s\n",
      "Epoch: 30, Batch: 1220/1676, Loss: 0.9201, Time: 1.96s\n",
      "Epoch: 30, Batch: 1230/1676, Loss: 0.4978, Time: 1.97s\n",
      "Epoch: 30, Batch: 1240/1676, Loss: 0.4075, Time: 1.97s\n",
      "Epoch: 30, Batch: 1250/1676, Loss: 0.5847, Time: 1.99s\n",
      "Epoch: 30, Batch: 1260/1676, Loss: 0.3559, Time: 2.01s\n",
      "Epoch: 30, Batch: 1270/1676, Loss: 0.5218, Time: 2.01s\n",
      "Epoch: 30, Batch: 1280/1676, Loss: 0.4079, Time: 2.00s\n",
      "Epoch: 30, Batch: 1290/1676, Loss: 1.0508, Time: 2.00s\n",
      "Epoch: 30, Batch: 1300/1676, Loss: 0.3454, Time: 2.01s\n",
      "Epoch: 30, Batch: 1310/1676, Loss: 0.2890, Time: 2.01s\n",
      "Epoch: 30, Batch: 1320/1676, Loss: 0.5426, Time: 2.01s\n",
      "Epoch: 30, Batch: 1330/1676, Loss: 0.5116, Time: 2.00s\n",
      "Epoch: 30, Batch: 1340/1676, Loss: 1.4241, Time: 2.00s\n",
      "Epoch: 30, Batch: 1350/1676, Loss: 1.7783, Time: 1.99s\n",
      "Epoch: 30, Batch: 1360/1676, Loss: 0.4210, Time: 2.01s\n",
      "Epoch: 30, Batch: 1370/1676, Loss: 0.3308, Time: 1.99s\n",
      "Epoch: 30, Batch: 1380/1676, Loss: 0.2522, Time: 2.00s\n",
      "Epoch: 30, Batch: 1390/1676, Loss: 0.6834, Time: 1.98s\n",
      "Epoch: 30, Batch: 1400/1676, Loss: 0.4576, Time: 2.00s\n",
      "Epoch: 30, Batch: 1410/1676, Loss: 0.7840, Time: 1.98s\n",
      "Epoch: 30, Batch: 1420/1676, Loss: 0.6929, Time: 2.00s\n",
      "Epoch: 30, Batch: 1430/1676, Loss: 1.3121, Time: 2.00s\n",
      "Epoch: 30, Batch: 1440/1676, Loss: 0.8903, Time: 1.99s\n",
      "Epoch: 30, Batch: 1450/1676, Loss: 0.6285, Time: 2.00s\n",
      "Epoch: 30, Batch: 1460/1676, Loss: 1.0182, Time: 1.99s\n",
      "Epoch: 30, Batch: 1470/1676, Loss: 0.5338, Time: 2.01s\n",
      "Epoch: 30, Batch: 1480/1676, Loss: 0.3991, Time: 1.99s\n",
      "Epoch: 30, Batch: 1490/1676, Loss: 0.9385, Time: 2.02s\n",
      "Epoch: 30, Batch: 1500/1676, Loss: 0.7740, Time: 2.00s\n",
      "Epoch: 30, Batch: 1510/1676, Loss: 0.6405, Time: 2.01s\n",
      "Epoch: 30, Batch: 1520/1676, Loss: 0.7545, Time: 2.00s\n",
      "Epoch: 30, Batch: 1530/1676, Loss: 0.4719, Time: 2.00s\n",
      "Epoch: 30, Batch: 1540/1676, Loss: 0.8303, Time: 1.99s\n",
      "Epoch: 30, Batch: 1550/1676, Loss: 0.5553, Time: 1.99s\n",
      "Epoch: 30, Batch: 1560/1676, Loss: 0.7401, Time: 1.99s\n",
      "Epoch: 30, Batch: 1570/1676, Loss: 0.7156, Time: 2.00s\n",
      "Epoch: 30, Batch: 1580/1676, Loss: 0.6352, Time: 1.99s\n",
      "Epoch: 30, Batch: 1590/1676, Loss: 0.2185, Time: 2.00s\n",
      "Epoch: 30, Batch: 1600/1676, Loss: 0.3550, Time: 1.99s\n",
      "Epoch: 30, Batch: 1610/1676, Loss: 0.6785, Time: 1.99s\n",
      "Epoch: 30, Batch: 1620/1676, Loss: 1.0338, Time: 1.99s\n",
      "Epoch: 30, Batch: 1630/1676, Loss: 0.8465, Time: 2.01s\n",
      "Epoch: 30, Batch: 1640/1676, Loss: 0.3945, Time: 2.00s\n",
      "Epoch: 30, Batch: 1650/1676, Loss: 0.3404, Time: 2.00s\n",
      "Epoch: 30, Batch: 1660/1676, Loss: 0.7301, Time: 2.00s\n",
      "Epoch: 30, Batch: 1670/1676, Loss: 0.4385, Time: 2.00s\n",
      "Epoch 31/50: Train Loss: 0.6765, Val Loss: 0.6918, Val IoU: 0.5630, Val Dice: 0.5827\n",
      "Epoch: 31, Batch: 0/1676, Loss: 0.4172, Time: 35.80s\n",
      "Epoch: 31, Batch: 10/1676, Loss: 0.2922, Time: 1.97s\n",
      "Epoch: 31, Batch: 20/1676, Loss: 0.8049, Time: 1.93s\n",
      "Epoch: 31, Batch: 30/1676, Loss: 0.6862, Time: 1.94s\n",
      "Epoch: 31, Batch: 40/1676, Loss: 0.3710, Time: 1.93s\n",
      "Epoch: 31, Batch: 50/1676, Loss: 0.7042, Time: 1.94s\n",
      "Epoch: 31, Batch: 60/1676, Loss: 0.5614, Time: 1.93s\n",
      "Epoch: 31, Batch: 70/1676, Loss: 0.6288, Time: 1.94s\n",
      "Epoch: 31, Batch: 80/1676, Loss: 0.8102, Time: 1.93s\n",
      "Epoch: 31, Batch: 90/1676, Loss: 0.4140, Time: 1.94s\n",
      "Epoch: 31, Batch: 100/1676, Loss: 0.4354, Time: 1.94s\n",
      "Epoch: 31, Batch: 110/1676, Loss: 0.2715, Time: 1.94s\n",
      "Epoch: 31, Batch: 120/1676, Loss: 0.4401, Time: 1.94s\n",
      "Epoch: 31, Batch: 130/1676, Loss: 0.8706, Time: 1.94s\n",
      "Epoch: 31, Batch: 140/1676, Loss: 0.8676, Time: 1.94s\n",
      "Epoch: 31, Batch: 150/1676, Loss: 0.5108, Time: 1.94s\n",
      "Epoch: 31, Batch: 160/1676, Loss: 0.5189, Time: 1.95s\n",
      "Epoch: 31, Batch: 170/1676, Loss: 0.4337, Time: 1.95s\n",
      "Epoch: 31, Batch: 180/1676, Loss: 0.8914, Time: 1.94s\n",
      "Epoch: 31, Batch: 190/1676, Loss: 0.3615, Time: 1.94s\n",
      "Epoch: 31, Batch: 200/1676, Loss: 0.6827, Time: 1.95s\n",
      "Epoch: 31, Batch: 210/1676, Loss: 0.6722, Time: 1.95s\n",
      "Epoch: 31, Batch: 220/1676, Loss: 0.8561, Time: 1.95s\n",
      "Epoch: 31, Batch: 230/1676, Loss: 1.1756, Time: 1.95s\n",
      "Epoch: 31, Batch: 240/1676, Loss: 1.2092, Time: 1.95s\n",
      "Epoch: 31, Batch: 250/1676, Loss: 0.4922, Time: 1.95s\n",
      "Epoch: 31, Batch: 260/1676, Loss: 0.5659, Time: 1.95s\n",
      "Epoch: 31, Batch: 270/1676, Loss: 0.9028, Time: 1.95s\n",
      "Epoch: 31, Batch: 280/1676, Loss: 0.4147, Time: 1.95s\n",
      "Epoch: 31, Batch: 290/1676, Loss: 1.1557, Time: 1.95s\n",
      "Epoch: 31, Batch: 300/1676, Loss: 1.0132, Time: 1.96s\n",
      "Epoch: 31, Batch: 310/1676, Loss: 0.8761, Time: 1.95s\n",
      "Epoch: 31, Batch: 320/1676, Loss: 1.0415, Time: 1.96s\n",
      "Epoch: 31, Batch: 330/1676, Loss: 1.0526, Time: 1.95s\n",
      "Epoch: 31, Batch: 340/1676, Loss: 0.8293, Time: 1.96s\n",
      "Epoch: 31, Batch: 350/1676, Loss: 0.5586, Time: 1.95s\n",
      "Epoch: 31, Batch: 360/1676, Loss: 1.5401, Time: 1.96s\n",
      "Epoch: 31, Batch: 370/1676, Loss: 1.0138, Time: 1.96s\n",
      "Epoch: 31, Batch: 380/1676, Loss: 0.9272, Time: 1.96s\n",
      "Epoch: 31, Batch: 390/1676, Loss: 0.7889, Time: 1.96s\n",
      "Epoch: 31, Batch: 400/1676, Loss: 0.4391, Time: 1.95s\n",
      "Epoch: 31, Batch: 410/1676, Loss: 0.5306, Time: 1.96s\n",
      "Epoch: 31, Batch: 420/1676, Loss: 0.5317, Time: 1.96s\n",
      "Epoch: 31, Batch: 430/1676, Loss: 0.6756, Time: 1.96s\n",
      "Epoch: 31, Batch: 440/1676, Loss: 1.1138, Time: 1.96s\n",
      "Epoch: 31, Batch: 450/1676, Loss: 1.7533, Time: 1.96s\n",
      "Epoch: 31, Batch: 460/1676, Loss: 0.4954, Time: 1.96s\n",
      "Epoch: 31, Batch: 470/1676, Loss: 0.3460, Time: 1.96s\n",
      "Epoch: 31, Batch: 480/1676, Loss: 1.0644, Time: 1.96s\n",
      "Epoch: 31, Batch: 490/1676, Loss: 0.2811, Time: 1.95s\n",
      "Epoch: 31, Batch: 500/1676, Loss: 0.4227, Time: 1.96s\n",
      "Epoch: 31, Batch: 510/1676, Loss: 0.3303, Time: 1.96s\n",
      "Epoch: 31, Batch: 520/1676, Loss: 0.6002, Time: 1.97s\n",
      "Epoch: 31, Batch: 530/1676, Loss: 0.3676, Time: 1.96s\n",
      "Epoch: 31, Batch: 540/1676, Loss: 0.4741, Time: 1.97s\n",
      "Epoch: 31, Batch: 550/1676, Loss: 0.6302, Time: 1.97s\n",
      "Epoch: 31, Batch: 560/1676, Loss: 0.3848, Time: 1.96s\n",
      "Epoch: 31, Batch: 570/1676, Loss: 0.6704, Time: 1.96s\n",
      "Epoch: 31, Batch: 580/1676, Loss: 0.7351, Time: 1.96s\n",
      "Epoch: 31, Batch: 590/1676, Loss: 0.5291, Time: 1.96s\n",
      "Epoch: 31, Batch: 600/1676, Loss: 0.3055, Time: 1.96s\n",
      "Epoch: 31, Batch: 610/1676, Loss: 0.4375, Time: 1.97s\n",
      "Epoch: 31, Batch: 620/1676, Loss: 0.2648, Time: 1.96s\n",
      "Epoch: 31, Batch: 630/1676, Loss: 0.5250, Time: 1.96s\n",
      "Epoch: 31, Batch: 640/1676, Loss: 0.6550, Time: 1.97s\n",
      "Epoch: 31, Batch: 650/1676, Loss: 0.4423, Time: 1.96s\n",
      "Epoch: 31, Batch: 660/1676, Loss: 0.8322, Time: 1.96s\n",
      "Epoch: 31, Batch: 670/1676, Loss: 0.4526, Time: 1.96s\n",
      "Epoch: 31, Batch: 680/1676, Loss: 0.6056, Time: 1.98s\n",
      "Epoch: 31, Batch: 690/1676, Loss: 1.1860, Time: 1.96s\n",
      "Epoch: 31, Batch: 700/1676, Loss: 0.4559, Time: 1.97s\n",
      "Epoch: 31, Batch: 710/1676, Loss: 0.6645, Time: 1.96s\n",
      "Epoch: 31, Batch: 720/1676, Loss: 0.9090, Time: 1.97s\n",
      "Epoch: 31, Batch: 730/1676, Loss: 0.8221, Time: 1.96s\n",
      "Epoch: 31, Batch: 740/1676, Loss: 1.1462, Time: 1.97s\n",
      "Epoch: 31, Batch: 750/1676, Loss: 0.5498, Time: 1.96s\n",
      "Epoch: 31, Batch: 760/1676, Loss: 0.4729, Time: 1.96s\n",
      "Epoch: 31, Batch: 770/1676, Loss: 1.3770, Time: 1.96s\n",
      "Epoch: 31, Batch: 780/1676, Loss: 0.9220, Time: 1.97s\n",
      "Epoch: 31, Batch: 790/1676, Loss: 1.2871, Time: 1.97s\n",
      "Epoch: 31, Batch: 800/1676, Loss: 1.3380, Time: 1.96s\n",
      "Epoch: 31, Batch: 810/1676, Loss: 0.4095, Time: 1.96s\n",
      "Epoch: 31, Batch: 820/1676, Loss: 0.8320, Time: 1.97s\n",
      "Epoch: 31, Batch: 830/1676, Loss: 0.2992, Time: 1.96s\n",
      "Epoch: 31, Batch: 840/1676, Loss: 0.3642, Time: 1.96s\n",
      "Epoch: 31, Batch: 850/1676, Loss: 0.4871, Time: 1.97s\n",
      "Epoch: 31, Batch: 860/1676, Loss: 0.5666, Time: 1.96s\n",
      "Epoch: 31, Batch: 870/1676, Loss: 0.5570, Time: 1.96s\n",
      "Epoch: 31, Batch: 880/1676, Loss: 1.2037, Time: 1.97s\n",
      "Epoch: 31, Batch: 890/1676, Loss: 0.5360, Time: 1.97s\n",
      "Epoch: 31, Batch: 900/1676, Loss: 1.0791, Time: 1.96s\n",
      "Epoch: 31, Batch: 910/1676, Loss: 0.8954, Time: 1.97s\n",
      "Epoch: 31, Batch: 920/1676, Loss: 0.2973, Time: 1.97s\n",
      "Epoch: 31, Batch: 930/1676, Loss: 0.5844, Time: 1.97s\n",
      "Epoch: 31, Batch: 940/1676, Loss: 0.6895, Time: 1.96s\n",
      "Epoch: 31, Batch: 950/1676, Loss: 0.3737, Time: 1.97s\n",
      "Epoch: 31, Batch: 960/1676, Loss: 0.9579, Time: 1.97s\n",
      "Epoch: 31, Batch: 970/1676, Loss: 0.6237, Time: 1.96s\n",
      "Epoch: 31, Batch: 980/1676, Loss: 0.6700, Time: 1.97s\n",
      "Epoch: 31, Batch: 990/1676, Loss: 0.7580, Time: 1.97s\n",
      "Epoch: 31, Batch: 1000/1676, Loss: 0.3919, Time: 1.97s\n",
      "Epoch: 31, Batch: 1010/1676, Loss: 0.5729, Time: 1.97s\n",
      "Epoch: 31, Batch: 1020/1676, Loss: 0.4556, Time: 1.96s\n",
      "Epoch: 31, Batch: 1030/1676, Loss: 0.8092, Time: 1.96s\n",
      "Epoch: 31, Batch: 1040/1676, Loss: 0.8604, Time: 1.97s\n",
      "Epoch: 31, Batch: 1050/1676, Loss: 0.6876, Time: 1.96s\n",
      "Epoch: 31, Batch: 1060/1676, Loss: 0.3616, Time: 1.96s\n",
      "Epoch: 31, Batch: 1070/1676, Loss: 1.0333, Time: 1.97s\n",
      "Epoch: 31, Batch: 1080/1676, Loss: 0.7938, Time: 1.96s\n",
      "Epoch: 31, Batch: 1090/1676, Loss: 1.0421, Time: 1.97s\n",
      "Epoch: 31, Batch: 1100/1676, Loss: 0.3364, Time: 1.97s\n",
      "Epoch: 31, Batch: 1110/1676, Loss: 0.4337, Time: 1.97s\n",
      "Epoch: 31, Batch: 1120/1676, Loss: 0.6750, Time: 1.97s\n",
      "Epoch: 31, Batch: 1130/1676, Loss: 1.1094, Time: 1.97s\n",
      "Epoch: 31, Batch: 1140/1676, Loss: 0.7290, Time: 1.96s\n",
      "Epoch: 31, Batch: 1150/1676, Loss: 0.4797, Time: 1.97s\n",
      "Epoch: 31, Batch: 1160/1676, Loss: 0.5600, Time: 1.97s\n",
      "Epoch: 31, Batch: 1170/1676, Loss: 0.5477, Time: 1.97s\n",
      "Epoch: 31, Batch: 1180/1676, Loss: 0.4155, Time: 1.97s\n",
      "Epoch: 31, Batch: 1190/1676, Loss: 0.4392, Time: 1.97s\n",
      "Epoch: 31, Batch: 1200/1676, Loss: 0.4017, Time: 1.97s\n",
      "Epoch: 31, Batch: 1210/1676, Loss: 0.3655, Time: 1.97s\n",
      "Epoch: 31, Batch: 1220/1676, Loss: 0.2804, Time: 1.97s\n",
      "Epoch: 31, Batch: 1230/1676, Loss: 0.6202, Time: 1.97s\n",
      "Epoch: 31, Batch: 1240/1676, Loss: 0.8255, Time: 1.96s\n",
      "Epoch: 31, Batch: 1250/1676, Loss: 0.8281, Time: 1.97s\n",
      "Epoch: 31, Batch: 1260/1676, Loss: 0.6770, Time: 1.97s\n",
      "Epoch: 31, Batch: 1270/1676, Loss: 0.4173, Time: 1.97s\n",
      "Epoch: 31, Batch: 1280/1676, Loss: 0.6145, Time: 1.97s\n",
      "Epoch: 31, Batch: 1290/1676, Loss: 1.0923, Time: 1.97s\n",
      "Epoch: 31, Batch: 1300/1676, Loss: 0.3339, Time: 1.97s\n",
      "Epoch: 31, Batch: 1310/1676, Loss: 0.3990, Time: 1.97s\n",
      "Epoch: 31, Batch: 1320/1676, Loss: 0.6823, Time: 1.97s\n",
      "Epoch: 31, Batch: 1330/1676, Loss: 0.4294, Time: 1.97s\n",
      "Epoch: 31, Batch: 1340/1676, Loss: 0.5764, Time: 1.97s\n",
      "Epoch: 31, Batch: 1350/1676, Loss: 0.7615, Time: 1.96s\n",
      "Epoch: 31, Batch: 1360/1676, Loss: 0.8919, Time: 1.96s\n",
      "Epoch: 31, Batch: 1370/1676, Loss: 0.6888, Time: 1.97s\n",
      "Epoch: 31, Batch: 1380/1676, Loss: 0.4504, Time: 1.97s\n",
      "Epoch: 31, Batch: 1390/1676, Loss: 1.0213, Time: 1.97s\n",
      "Epoch: 31, Batch: 1400/1676, Loss: 1.2189, Time: 1.97s\n",
      "Epoch: 31, Batch: 1410/1676, Loss: 0.3220, Time: 1.98s\n",
      "Epoch: 31, Batch: 1420/1676, Loss: 0.7229, Time: 1.97s\n",
      "Epoch: 31, Batch: 1430/1676, Loss: 0.6224, Time: 1.97s\n",
      "Epoch: 31, Batch: 1440/1676, Loss: 0.7231, Time: 1.97s\n",
      "Epoch: 31, Batch: 1450/1676, Loss: 0.3718, Time: 1.97s\n",
      "Epoch: 31, Batch: 1460/1676, Loss: 0.9289, Time: 1.97s\n",
      "Epoch: 31, Batch: 1470/1676, Loss: 0.9690, Time: 1.97s\n",
      "Epoch: 31, Batch: 1480/1676, Loss: 0.8019, Time: 1.97s\n",
      "Epoch: 31, Batch: 1490/1676, Loss: 0.4043, Time: 1.97s\n",
      "Epoch: 31, Batch: 1500/1676, Loss: 0.7262, Time: 2.02s\n",
      "Epoch: 31, Batch: 1510/1676, Loss: 0.6699, Time: 2.00s\n",
      "Epoch: 31, Batch: 1520/1676, Loss: 0.6107, Time: 2.02s\n",
      "Epoch: 31, Batch: 1530/1676, Loss: 0.9162, Time: 2.00s\n",
      "Epoch: 31, Batch: 1540/1676, Loss: 0.5795, Time: 2.00s\n",
      "Epoch: 31, Batch: 1550/1676, Loss: 0.6369, Time: 2.01s\n",
      "Epoch: 31, Batch: 1560/1676, Loss: 0.9075, Time: 2.01s\n",
      "Epoch: 31, Batch: 1570/1676, Loss: 0.7375, Time: 2.01s\n",
      "Epoch: 31, Batch: 1580/1676, Loss: 0.3393, Time: 2.01s\n",
      "Epoch: 31, Batch: 1590/1676, Loss: 0.6765, Time: 2.00s\n",
      "Epoch: 31, Batch: 1600/1676, Loss: 0.6041, Time: 2.00s\n",
      "Epoch: 31, Batch: 1610/1676, Loss: 0.8303, Time: 2.01s\n",
      "Epoch: 31, Batch: 1620/1676, Loss: 0.9399, Time: 2.01s\n",
      "Epoch: 31, Batch: 1630/1676, Loss: 0.8502, Time: 2.01s\n",
      "Epoch: 31, Batch: 1640/1676, Loss: 1.0240, Time: 2.00s\n",
      "Epoch: 31, Batch: 1650/1676, Loss: 0.4669, Time: 2.00s\n",
      "Epoch: 31, Batch: 1660/1676, Loss: 0.8125, Time: 2.00s\n",
      "Epoch: 31, Batch: 1670/1676, Loss: 0.6233, Time: 2.00s\n",
      "Epoch 32/50: Train Loss: 0.6767, Val Loss: 0.7013, Val IoU: 0.5619, Val Dice: 0.5812\n",
      "Epoch: 32, Batch: 0/1676, Loss: 0.5979, Time: 35.53s\n",
      "Epoch: 32, Batch: 10/1676, Loss: 0.6836, Time: 2.01s\n",
      "Epoch: 32, Batch: 20/1676, Loss: 0.4146, Time: 1.96s\n",
      "Epoch: 32, Batch: 30/1676, Loss: 0.8893, Time: 1.95s\n",
      "Epoch: 32, Batch: 40/1676, Loss: 0.4471, Time: 1.96s\n",
      "Epoch: 32, Batch: 50/1676, Loss: 0.8212, Time: 1.96s\n",
      "Epoch: 32, Batch: 60/1676, Loss: 0.7407, Time: 1.96s\n",
      "Epoch: 32, Batch: 70/1676, Loss: 0.6517, Time: 1.96s\n",
      "Epoch: 32, Batch: 80/1676, Loss: 1.0300, Time: 1.97s\n",
      "Epoch: 32, Batch: 90/1676, Loss: 0.7488, Time: 1.96s\n",
      "Epoch: 32, Batch: 100/1676, Loss: 1.3158, Time: 1.97s\n",
      "Epoch: 32, Batch: 110/1676, Loss: 0.5919, Time: 1.97s\n",
      "Epoch: 32, Batch: 120/1676, Loss: 0.5556, Time: 1.96s\n",
      "Epoch: 32, Batch: 130/1676, Loss: 0.3863, Time: 1.97s\n",
      "Epoch: 32, Batch: 140/1676, Loss: 0.4546, Time: 1.96s\n",
      "Epoch: 32, Batch: 150/1676, Loss: 0.4663, Time: 1.97s\n",
      "Epoch: 32, Batch: 160/1676, Loss: 0.6620, Time: 1.97s\n",
      "Epoch: 32, Batch: 170/1676, Loss: 0.7861, Time: 1.97s\n",
      "Epoch: 32, Batch: 180/1676, Loss: 0.6180, Time: 1.99s\n",
      "Epoch: 32, Batch: 190/1676, Loss: 0.4182, Time: 1.98s\n",
      "Epoch: 32, Batch: 200/1676, Loss: 1.7207, Time: 1.98s\n",
      "Epoch: 32, Batch: 210/1676, Loss: 0.6335, Time: 1.97s\n",
      "Epoch: 32, Batch: 220/1676, Loss: 0.6598, Time: 1.98s\n",
      "Epoch: 32, Batch: 230/1676, Loss: 0.6387, Time: 1.99s\n",
      "Epoch: 32, Batch: 240/1676, Loss: 0.7658, Time: 1.99s\n",
      "Epoch: 32, Batch: 250/1676, Loss: 0.4728, Time: 1.98s\n",
      "Epoch: 32, Batch: 260/1676, Loss: 0.9193, Time: 1.97s\n",
      "Epoch: 32, Batch: 270/1676, Loss: 0.7317, Time: 1.98s\n",
      "Epoch: 32, Batch: 280/1676, Loss: 0.8651, Time: 1.99s\n",
      "Epoch: 32, Batch: 290/1676, Loss: 0.9290, Time: 1.97s\n",
      "Epoch: 32, Batch: 300/1676, Loss: 0.8880, Time: 2.00s\n",
      "Epoch: 32, Batch: 310/1676, Loss: 0.4466, Time: 1.98s\n",
      "Epoch: 32, Batch: 320/1676, Loss: 0.3147, Time: 1.98s\n",
      "Epoch: 32, Batch: 330/1676, Loss: 0.3826, Time: 1.97s\n",
      "Epoch: 32, Batch: 340/1676, Loss: 0.4139, Time: 1.98s\n",
      "Epoch: 32, Batch: 350/1676, Loss: 1.1419, Time: 1.98s\n",
      "Epoch: 32, Batch: 360/1676, Loss: 0.7523, Time: 1.99s\n",
      "Epoch: 32, Batch: 370/1676, Loss: 0.3718, Time: 1.97s\n",
      "Epoch: 32, Batch: 380/1676, Loss: 1.0239, Time: 1.99s\n",
      "Epoch: 32, Batch: 390/1676, Loss: 0.7469, Time: 1.99s\n",
      "Epoch: 32, Batch: 400/1676, Loss: 0.3365, Time: 1.99s\n",
      "Epoch: 32, Batch: 410/1676, Loss: 0.8501, Time: 1.99s\n",
      "Epoch: 32, Batch: 420/1676, Loss: 0.8678, Time: 1.97s\n",
      "Epoch: 32, Batch: 430/1676, Loss: 0.7251, Time: 1.99s\n",
      "Epoch: 32, Batch: 440/1676, Loss: 1.2463, Time: 1.99s\n",
      "Epoch: 32, Batch: 450/1676, Loss: 0.9275, Time: 1.98s\n",
      "Epoch: 32, Batch: 460/1676, Loss: 0.4490, Time: 1.99s\n",
      "Epoch: 32, Batch: 470/1676, Loss: 0.5620, Time: 2.00s\n",
      "Epoch: 32, Batch: 480/1676, Loss: 0.6240, Time: 1.97s\n",
      "Epoch: 32, Batch: 490/1676, Loss: 0.7902, Time: 1.97s\n",
      "Epoch: 32, Batch: 500/1676, Loss: 0.6098, Time: 2.00s\n",
      "Epoch: 32, Batch: 510/1676, Loss: 0.7823, Time: 1.99s\n",
      "Epoch: 32, Batch: 520/1676, Loss: 0.3759, Time: 1.98s\n",
      "Epoch: 32, Batch: 530/1676, Loss: 0.3360, Time: 2.02s\n"
     ]
    }
   ],
   "source": [
    "# Train U-Net model\n",
    "geoai.train_segmentation_model(\n",
    "    images_dir=f\"{out_folder}/images\",\n",
    "    labels_dir=f\"{out_folder}/labels\",\n",
    "    output_dir=f\"{out_folder}/unet_models\",\n",
    "    architecture=\"unet\",\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    num_channels=4,\n",
    "    num_classes=13,\n",
    "    batch_size=8,\n",
    "    num_epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    val_split=0.2,\n",
    "    verbose=True,\n",
    "    checkpoint_path=f\"{out_folder}/unet_models/checkpoint.pth\",\n",
    "    resume_training=True,\n",
    "    plot_curves=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "masks_path = \"naip_test_semantic_prediction.tif\"\n",
    "model_path = f\"{out_folder}/unet_models/best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run semantic segmentation inference\n",
    "geoai.semantic_segmentation(\n",
    "    input_path=test_raster_path,\n",
    "    output_path=masks_path,\n",
    "    model_path=model_path,\n",
    "    architecture=\"unet\",\n",
    "    encoder_name=\"resnet34\",\n",
    "    num_channels=4,\n",
    "    num_classes=13,\n",
    "    window_size=512,\n",
    "    overlap=256,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36029dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masks_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m geoai.write_colormap(\u001b[43mmasks_path\u001b[49m, train_landcover_path, output=masks_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'masks_path' is not defined"
     ]
    }
   ],
   "source": [
    "geoai.write_colormap(masks_path, train_landcover_path, output=masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f97930",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.view_raster(masks_path, basemap=test_raster_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
