def train_segmentation_model(
    images_dir,
    labels_dir,
    output_dir,
    architecture="unet",
    encoder_name="resnet34",
    encoder_weights="imagenet",
    num_channels=3,
    num_classes=2,
    batch_size=8,
    num_epochs=50,
    learning_rate=0.001,
    weight_decay=1e-4,
    seed=42,
    val_split=0.2,
    print_freq=10,
    verbose=True,
    save_best_only=True,
    plot_curves=False,
    **kwargs,
):
    import datetime
    import os
    import torch
    import numpy as np
    import random
    import matplotlib.pyplot as plt
    from torch.utils.data import DataLoader
    from sklearn.model_selection import train_test_split

    if not SMP_AVAILABLE:
        raise ImportError("segmentation-models-pytorch is not installed. "
                          "Please install it with: pip install segmentation-models-pytorch")

    # Set random seeds for reproducibility
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    # Create output directory
    os.makedirs(output_dir, exist_ok=True)

    # Get device
    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    print(f"Using device: {device}")

    # Get image and label files
    image_files = sorted([
        os.path.join(images_dir, f) for f in os.listdir(images_dir) if f.endswith(".tif")
    ])
    label_files = sorted([
        os.path.join(labels_dir, f) for f in os.listdir(labels_dir) if f.endswith(".tif")
    ])

    print(f"Found {len(image_files)} image files and {len(label_files)} label files")

    if len(image_files) != len(label_files):
        print("Warning: Number of image and label files don't match!")
        basenames = [os.path.basename(f) for f in image_files]
        label_files = [
            os.path.join(labels_dir, os.path.basename(f)) for f in image_files
            if os.path.exists(os.path.join(labels_dir, os.path.basename(f)))
        ]
        image_files = [
            f for f, b in zip(image_files, basenames)
            if os.path.exists(os.path.join(labels_dir, b))
        ]
        print(f"Using {len(image_files)} matching files")

    if len(image_files) == 0:
        raise FileNotFoundError("No matching image and label files found")

    # Split into train and validation sets
    train_imgs, val_imgs, train_labels, val_labels = train_test_split(
        image_files, label_files, test_size=val_split, random_state=seed
    )

    print(f"Training on {len(train_imgs)} images, validating on {len(val_imgs)} images")

    # Datasets and loaders
    train_dataset = SemanticSegmentationDataset(
        train_imgs, train_labels, transforms=get_semantic_transform(train=True), num_channels=num_channels
    )
    val_dataset = SemanticSegmentationDataset(
        val_imgs, val_labels, transforms=get_semantic_transform(train=False), num_channels=num_channels
    )

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)

    # Model setup
    model = get_smp_model(
        architecture=architecture,
        encoder_name=encoder_name,
        encoder_weights=encoder_weights,
        in_channels=num_channels,
        classes=num_classes,
        activation=None,
        **kwargs,
    )
    model.to(device)

    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode="min", factor=0.5, patience=5)

    # Tracking variables
    best_iou = 0
    train_losses = []
    val_losses = []
    val_ious = []
    val_dices = []
    start_epoch = 0

    # Resume from checkpoint if available
    checkpoint_path = os.path.join(output_dir, "last_checkpoint.pth")
    if os.path.exists(checkpoint_path):
        print("Resuming training from checkpoint...")
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint["model_state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        lr_scheduler.load_state_dict(checkpoint["scheduler_state_dict"])
        best_iou = checkpoint.get("best_iou", 0)
        start_epoch = checkpoint.get("epoch", 0) + 1
        train_losses = checkpoint.get("train_losses", [])
        val_losses = checkpoint.get("val_losses", [])
        val_ious = checkpoint.get("val_ious", [])
        val_dices = checkpoint.get("val_dices", [])
        print(f"Resumed from epoch {start_epoch}, best IoU: {best_iou:.4f}")

    print(f"Starting training with {architecture} + {encoder_name}")
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")

    for epoch in range(start_epoch, num_epochs):
        train_loss = train_semantic_one_epoch(
            model, optimizer, train_loader, device, epoch, criterion, print_freq, verbose
        )
        train_losses.append(train_loss)

        eval_metrics = evaluate_semantic(
            model, val_loader, device, criterion, num_classes=num_classes
        )
        val_losses.append(eval_metrics["loss"])
        val_ious.append(eval_metrics["IoU"])
        val_dices.append(eval_metrics["Dice"])

        lr_scheduler.step(eval_metrics["loss"])

        print(
            f"Epoch {epoch+1}/{num_epochs}: "
            f"Train Loss: {train_loss:.4f}, "
            f"Val Loss: {eval_metrics['loss']:.4f}, "
            f"Val IoU: {eval_metrics['IoU']:.4f}, "
            f"Val Dice: {eval_metrics['Dice']:.4f}"
        )

        # Save best model
        if eval_metrics["IoU"] > best_iou:
            best_iou = eval_metrics["IoU"]
            print(f"Saving best model with IoU: {best_iou:.4f}")
            torch.save(model.state_dict(), os.path.join(output_dir, "best_model.pth"))

        # Save full checkpoint every 10 epochs or last
        if not save_best_only and ((epoch + 1) % 10 == 0 or epoch == num_epochs - 1):
            torch.save(
                {
                    "epoch": epoch,
                    "model_state_dict": model.state_dict(),
                    "optimizer_state_dict": optimizer.state_dict(),
                    "scheduler_state_dict": lr_scheduler.state_dict(),
                    "best_iou": best_iou,
                    "architecture": architecture,
                    "encoder_name": encoder_name,
                    "num_channels": num_channels,
                    "num_classes": num_classes,
                },
                os.path.join(output_dir, f"checkpoint_epoch_{epoch+1}.pth"),
            )

        # Save last checkpoint
        torch.save(
            {
                "epoch": epoch,
                "model_state_dict": model.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
                "scheduler_state_dict": lr_scheduler.state_dict(),
                "best_iou": best_iou,
                "train_losses": train_losses,
                "val_losses": val_losses,
                "val_ious": val_ious,
                "val_dices": val_dices,
            },
            checkpoint_path,
        )

    # Final save
    torch.save(model.state_dict(), os.path.join(output_dir, "final_model.pth"))

    # Remove resume checkpoint
    if os.path.exists(checkpoint_path):
        os.remove(checkpoint_path)

    # Save training history
    history = {
        "train_losses": train_losses,
        "val_losses": val_losses,
        "val_ious": val_ious,
        "val_dices": val_dices,
    }
    torch.save(history, os.path.join(output_dir, "training_history.pth"))

    with open(os.path.join(output_dir, "training_summary.txt"), "w") as f:
        f.write(f"Training completed on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Architecture: {architecture}\n")
        f.write(f"Encoder: {encoder_name}\n")
        f.write(f"Total epochs: {num_epochs}\n")
        f.write(f"Best validation IoU: {best_iou:.4f}\n")
        f.write(f"Final validation IoU: {val_ious[-1]:.4f}\n")
        f.write(f"Final validation Dice: {val_dices[-1]:.4f}\n")
        f.write(f"Final validation loss: {val_losses[-1]:.4f}\n")

    print(f"Training complete! Best IoU: {best_iou:.4f}")
    print(f"Models saved to {output_dir}")

    # Plot training curves
    if plot_curves:
        try:
            plt.figure(figsize=(15, 5))
            plt.subplot(1, 3, 1)
            plt.plot(train_losses, label="Train Loss")
            plt.plot(val_losses, label="Val Loss")
            plt.title("Loss")
            plt.xlabel("Epoch")
            plt.ylabel("Loss")
            plt.legend()
            plt.grid(True)

            plt.subplot(1, 3, 2)
            plt.plot(val_ious, label="Val IoU")
            plt.title("IoU Score")
            plt.xlabel("Epoch")
            plt.ylabel("IoU")
            plt.legend()
            plt.grid(True)

            plt.subplot(1, 3, 3)
            plt.plot(val_dices, label="Val Dice")
            plt.title("Dice Score")
            plt.xlabel("Epoch")
            plt.ylabel("Dice")
            plt.legend()
            plt.grid(True)

            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, "training_curves.png"), dpi=150, bbox_inches="tight")
            print(f"Training curves saved to {os.path.join(output_dir, 'training_curves.png')}")
            plt.close()
        except Exception as e:
            print(f"Could not save training curves: {e}")
